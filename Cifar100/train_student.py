{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar_kd.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "H04cv_LK833s"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lrezqi/ICKD-DCKD/blob/main/Cifar100/train_student.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piAVeOax6ph6"
      },
      "source": [
        "# Distilling knowledge in models pretrained on CIFAR-10/100 datasets, using ***torchdistill***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqZF7kY-6zDh"
      },
      "source": [
        "## 1. Make sure you have access to GPU/TPU\n",
        "Google Colab: *Runtime* -> *Change runtime type* -> *Hardware accelarator*: \"GPU\" or \"TPU\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Is GPU available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI4Yc9bz_dp7",
        "outputId": "545032bc-fd66-4ecb-d910-ceeef12593f5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Is GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.config.list_physical_devices('GPU'):\n",
        "    with tf.device('/GPU:0'):\n",
        "        # Run a simple operation on the GPU\n",
        "        a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
        "        b = tf.constant([[5.0, 6.0], [7.0, 8.0]])\n",
        "        c = tf.matmul(a, b)\n",
        "        print(\"GPU operation result:\", c)\n",
        "else:\n",
        "    print(\"No GPU available for TensorFlow.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsEkfLRAAdo9",
        "outputId": "ba1349aa-756f-4787-b24d-3ff631cab4ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU operation result: tf.Tensor(\n",
            "[[19. 22.]\n",
            " [43. 50.]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy7V9yQH6o3J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96dcd4b7-7ff9-438e-e84f-314e5e572170"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 19 18:16:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   46C    P0             28W /   72W |     203MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/lrezqi/ICKD-DCKD.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8U76W0rikw7",
        "outputId": "fc422efc-0309-486c-c099-79ce6a1232db"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'ICKD-DCKD' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard_logger"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-MIN0KoMJF2",
        "outputId": "4efa2260-ce13-4bdc-8808-2a5bf0231824"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboard_logger\n",
            "  Downloading tensorboard_logger-0.1.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (1.15.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (11.2.1)\n",
            "Downloading tensorboard_logger-0.1.0-py2.py3-none-any.whl (17 kB)\n",
            "Installing collected packages: tensorboard_logger\n",
            "Successfully installed tensorboard_logger-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pudb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcpUHRZSMC4p",
        "outputId": "1a6c2093-8152-4426-d947-cb377c51e219"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pudb\n",
            "  Downloading pudb-2025.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting jedi<1,>=0.18 (from pudb)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pudb) (24.2)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from pudb) (2.19.1)\n",
            "Collecting urwid-readline (from pudb)\n",
            "  Downloading urwid_readline-0.15.1.tar.gz (9.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urwid (from pudb)\n",
            "  Downloading urwid-3.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi<1,>=0.18->pudb) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from urwid->pudb) (0.2.13)\n",
            "Downloading pudb-2025.1-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urwid-3.0.2-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.0/296.0 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: urwid-readline\n",
            "  Building wheel for urwid-readline (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for urwid-readline: filename=urwid_readline-0.15.1-py3-none-any.whl size=9326 sha256=2c82d367523c7cdcb90ffe213de1c308bab3ce9e8cb4ed696946b69119bfb427\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/a1/b6/f1e168ef992a1302e1bfab45f07ddd0e9f6039f69c107089d4\n",
            "Successfully built urwid-readline\n",
            "Installing collected packages: urwid, jedi, urwid-readline, pudb\n",
            "Successfully installed jedi-0.19.2 pudb-2025.1 urwid-3.0.2 urwid-readline-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/ICKD-DCKD/Cifar100/helper/util.py'\n",
        "\n",
        "# Lire le contenu\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Remplacer la ligne fautive\n",
        "with open(file_path, 'w') as f:\n",
        "    for line in lines:\n",
        "        if 'view(-1)' in line:\n",
        "            f.write(line.replace('view(-1)', 'reshape(-1)'))\n",
        "        else:\n",
        "            f.write(line)\n",
        "\n",
        "print(\"✅ Remplacement de .view(-1) par .reshape(-1) effectué.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqF79zI_lpFc",
        "outputId": "67c32181-ffd2-4821-888f-d2369610ff2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Remplacement de .view(-1) par .reshape(-1) effectué.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fileinput\n",
        "\n",
        "BASE = \"/content/ICKD/ICKD-DCKD/Cifar100\"\n",
        "\n",
        "# 1) util.py : view → reshape\n",
        "util = f\"{BASE}/helper/util.py\"\n",
        "for line in fileinput.input(util, inplace=True):\n",
        "    print(line.replace(\".view(-1)\", \".reshape(-1)\"), end=\"\")\n",
        "\n",
        "# 2) train_student.py : ajouter --model_t dans argparse\n",
        "ts = f\"{BASE}/train_student.py\"\n",
        "inserted = False\n",
        "new = []\n",
        "with open(ts) as f:\n",
        "    for line in f:\n",
        "        new.append(line)\n",
        "        if not inserted and \"parser.add_argument('--model_s'\" in line:\n",
        "            new.append(\"    parser.add_argument('--model_t', type=str, required=True, help='teacher model')\\n\")\n",
        "            inserted = True\n",
        "with open(ts, \"w\") as f:\n",
        "    f.writelines(new)\n",
        "\n",
        "# 3) train_student.py : forcer model_t et corriger get_teacher_name\n",
        "patched = []\n",
        "with open(ts) as f:\n",
        "    for line in f:\n",
        "        if \"opt.model_t = get_teacher_name(opt.path_t)\" in line:\n",
        "            patched.append(\"# \" + line)\n",
        "            patched.append(\"    opt.model_t = 'resnet32x4'\\n\")\n",
        "        else:\n",
        "            patched.append(line)\n",
        "with open(ts, \"w\") as f:\n",
        "    f.writelines(patched)\n",
        "\n",
        "print(\"✅ Tous les patchs appliqués.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "oWrdNvIvldgR",
        "outputId": "1e739137-83a6-48d4-b9a7-46f9c6793b55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/ICKD/ICKD-DCKD/Cifar100/helper/util.py' -> '/content/ICKD/ICKD-DCKD/Cifar100/helper/util.py.bak'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-412489188.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1) util.py : view → reshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mutil\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{BASE}/helper/util.py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileinput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".view(-1)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".reshape(-1)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/fileinput.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filelineno\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/fileinput.py\u001b[0m in \u001b[0;36m_readline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                 \u001b[0;31m# The next few lines may raise OSError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backupfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m                 self._file = open(self._backupfilename, self._mode,\n\u001b[1;32m    339\u001b[0m                                   encoding=encoding, errors=self._errors)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ICKD/ICKD-DCKD/Cifar100/helper/util.py' -> '/content/ICKD/ICKD-DCKD/Cifar100/helper/util.py.bak'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Revenir à la racine du projet\n",
        "%cd /content/torchdistill\n",
        "\n",
        "# Installer en mode editable\n",
        "!pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWSUvE9UQK5m",
        "outputId": "69a1c091-fe58-4f9d-cac2-539c7f94fc35"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/torchdistill'\n",
            "/content\n",
            "Obtaining file:///content\n",
            "\u001b[31mERROR: file:///content does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ICKD/ICKD-DCKD/Cifar100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHiGtMFwNK92",
        "outputId": "0aae0d57-a4a2-4e73-c38a-d971fd145d60"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/ICKD/ICKD-DCKD/Cifar100': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd ICKD-DCKD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycPUsndwR8Sy",
        "outputId": "580d0788-5bb4-449f-8266-2a406760935d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --model_t resnet32x4 \\\n",
        "  --path_t \"/content/ICKD-DCKD/save/teacher_resnet32x4_cifar100_240epochs.pth\" \\\n",
        "  --distill dckd \\\n",
        "  --trial run1 \\\n",
        "  --batch_size 64 \\\n",
        "  --learning_rate 0.05 \\\n",
        "  --epochs 5 \\\n",
        "  --kd_T 4 \\\n",
        "  --gamma 1 \\\n",
        "  --alpha 0.5 \\\n",
        "  --beta 0.5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-TDvHP7bRXv",
        "outputId": "15b0e9dd-bf70-460c-dd7b-867acc504dc9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-19 18:17:18.384880: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750357038.405893    4101 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750357038.412309    4101 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "100% 169M/169M [00:03<00:00, 42.8MB/s]\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 416, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 204, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 162, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'teacher'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --model_t resnet32x4 \\\n",
        "  --path_t \"/content/ICKD-DCKD/save/teacher_resnet32x4_cifar100_240epochs.pth\" \\\n",
        "  --distill dckd \\\n",
        "  --trial run1 \\\n",
        "  --batch_size 64 \\\n",
        "  --learning_rate 0.05 \\\n",
        "  --epochs 5 \\\n",
        "  --kd_T 4 \\\n",
        "  --gamma 1 \\\n",
        "  --alpha 0.5 \\\n",
        "  --beta 0.5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-7m221YbZ_D",
        "outputId": "ff3e6195-7d9b-48d8-b1e7-4a03152e4d16"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-19 18:22:40.637835: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750357360.658649    5466 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750357360.665047    5466 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 416, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 204, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 162, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'teacher'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérifier que la ligne est bien commentée\n",
        "with open('/content/ICKD-DCKD/Cifar100/train_student.py', 'r') as f:\n",
        "    for i, line in enumerate(f.readlines()):\n",
        "        if 'opt.model_t = get_teacher_name' in line:\n",
        "            print(f\"Ligne {i+1} : {line.strip()}\")\n"
      ],
      "metadata": {
        "id": "bAA7X-WReaXR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --model_t resnet32x4 \\\n",
        "  --path_t \"/content/ICKD-DCKD/save/teacher_resnet32x4_cifar100_240epochs.pth\" \\\n",
        "  --distill dckd \\\n",
        "  --trial run1 \\\n",
        "  --batch_size 64 \\\n",
        "  --learning_rate 0.05 \\\n",
        "  --epochs 5 \\\n",
        "  --kd_T 4 \\\n",
        "  --gamma 1 \\\n",
        "  --alpha 0.5 \\\n",
        "  --beta 0.5\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRqOaQk3e340",
        "outputId": "1d2ac64d-9b2a-4626-fd73-26362195d3e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-19 18:37:44.185112: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750358264.206258    9178 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750358264.212633    9178 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 416, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 204, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 162, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'teacher'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/ICKD-DCKD/Cifar100/train_student.sh', 'w') as f:\n",
        "    f.write(\"\"\"#! /bin/bash\n",
        "\n",
        "python train_student.py \\\\\n",
        "    --path_t ./save/teacher_resnet32x4_best.pth \\\\\n",
        "    --distill dckd \\\\\n",
        "    --model_s resnet8x4 \\\\\n",
        "    --model_t resnet32x4 \\\\\n",
        "    -a 0.5 -b 0.5 --trial 1\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "kcvUdy_pmcYq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37QRmNT_nA1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Corriger automatiquement train_student.py\n",
        "file_path = '/content/ICKD-DCKD/Cifar100/train_student.py'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    for line in lines:\n",
        "        if 'opt.model_t = get_teacher_name' in line:\n",
        "            f.write(f\"# {line}\")  # commenter la ligne\n",
        "        else:\n",
        "            f.write(line)\n",
        "\n",
        "print(\"✅ Ligne opt.model_t = get_teacher_name(...) commentée.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu9f_EUCng6H",
        "outputId": "1159998f-ee6d-40a9-bcc9-d914ee2f61e0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Ligne opt.model_t = get_teacher_name(...) commentée.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exécution depuis le bon répertoire\n",
        "%cd /content/ICKD-DCKD/Cifar100\n",
        "\n",
        "# Lancer l'entraînement avec DCKD\n",
        "!python train_student.py \\\n",
        "    --path_t ./save/teacher_resnet32x4_best.pth \\\n",
        "    --distill dckd \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --model_t resnet32x4 \\\n",
        "    -a 0.5 -b 0.5 --trial 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqxdousQnveL",
        "outputId": "cdef4596-29d4-4baa-c58c-638812c39dc8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100\n",
            "2025-06-19 19:16:30.265115: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750360590.286454   18800 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750360590.293021   18800 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 416, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 204, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 162, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'teacher'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/ICKD-DCKD -type f -name \"*.pth\"\n"
      ],
      "metadata": {
        "id": "EgYr0aBmo2L6"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_path = '/content/ICKD-DCKD/Cifar100/train_student.sh'\n",
        "\n",
        "with open(script_path, 'w') as f:\n",
        "    f.write(\"\"\"#!/bin/bash\n",
        "cd /content/ICKD-DCKD/Cifar100\n",
        "\n",
        "python train_student.py \\\\\n",
        "    --path_t ./save/teacher_resnet32x4_best.pth \\\\\n",
        "    --distill dckd \\\\\n",
        "    --model_s resnet8x4 \\\\\n",
        "    --model_t resnet32x4 \\\\\n",
        "    -a 0.5 -b 0.5 --trial 1\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "Cee9iawwnAjb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd /content/ICKD-DCKD/Cifar100\n",
        "\n",
        "python train_student.py \\\n",
        "    --path_t ./save/teacher_resnet32x4_best.pth \\\n",
        "    --distill dckd \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --model_t resnet32x4 \\\n",
        "    -a 0.5 -b 0.5 --trial 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "wBtEoSbpl6ed",
        "outputId": "022c007b-c110-4f26-82cc-70d8d8968b2f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> loading teacher model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-19 19:12:18.221724: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750360338.242698   17724 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750360338.249099   17724 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\r  0%|          | 0.00/169M [00:00<?, ?B/s]\r  0%|          | 65.5k/169M [00:00<05:14, 537kB/s]\r  0%|          | 229k/169M [00:00<02:46, 1.01MB/s]\r  1%|          | 918k/169M [00:00<00:53, 3.12MB/s]\r  2%|▏         | 3.64M/169M [00:00<00:15, 10.7MB/s]\r  6%|▌         | 9.57M/169M [00:00<00:06, 24.0MB/s]\r  9%|▉         | 16.0M/169M [00:00<00:04, 32.8MB/s]\r 13%|█▎        | 22.3M/169M [00:00<00:03, 38.2MB/s]\r 17%|█▋        | 28.7M/169M [00:01<00:03, 41.7MB/s]\r 21%|██        | 35.1M/169M [00:01<00:03, 44.0MB/s]\r 25%|██▍       | 41.5M/169M [00:01<00:02, 45.6MB/s]\r 28%|██▊       | 47.9M/169M [00:01<00:02, 46.7MB/s]\r 32%|███▏      | 54.3M/169M [00:01<00:02, 47.8MB/s]\r 36%|███▌      | 60.6M/169M [00:01<00:02, 49.1MB/s]\r 39%|███▉      | 66.3M/169M [00:01<00:02, 51.1MB/s]\r 42%|████▏     | 71.4M/169M [00:01<00:01, 48.9MB/s]\r 45%|████▌     | 76.8M/169M [00:01<00:01, 49.3MB/s]\r 49%|████▊     | 82.0M/169M [00:02<00:01, 50.1MB/s]\r 52%|█████▏    | 87.1M/169M [00:02<00:01, 47.9MB/s]\r 55%|█████▍    | 92.8M/169M [00:02<00:01, 49.9MB/s]\r 58%|█████▊    | 97.8M/169M [00:02<00:01, 49.7MB/s]\r 61%|██████    | 103M/169M [00:02<00:01, 47.6MB/s] \r 64%|██████▍   | 109M/169M [00:02<00:01, 47.4MB/s]\r 68%|██████▊   | 115M/169M [00:02<00:01, 49.6MB/s]\r 71%|███████   | 120M/169M [00:02<00:00, 50.5MB/s]\r 74%|███████▍  | 125M/169M [00:02<00:00, 48.4MB/s]\r 78%|███████▊  | 131M/169M [00:03<00:00, 49.3MB/s]\r 81%|████████  | 136M/169M [00:03<00:00, 50.1MB/s]\r 84%|████████▎ | 141M/169M [00:03<00:00, 48.0MB/s]\r 87%|████████▋ | 147M/169M [00:03<00:00, 49.9MB/s]\r 90%|█████████ | 152M/169M [00:03<00:00, 50.0MB/s]\r 93%|█████████▎| 157M/169M [00:03<00:00, 47.5MB/s]\r 97%|█████████▋| 163M/169M [00:03<00:00, 50.6MB/s]\r100%|█████████▉| 168M/169M [00:03<00:00, 50.0MB/s]\r100%|██████████| 169M/169M [00:03<00:00, 44.1MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 416, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 204, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 162, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'teacher'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'cd /content/ICKD-DCKD/Cifar100\\n\\npython train_student.py \\\\\\n    --path_t ./save/teacher_resnet32x4_best.pth \\\\\\n    --distill dckd \\\\\\n    --model_s resnet8x4 \\\\\\n    --model_t resnet32x4 \\\\\\n    -a 0.5 -b 0.5 --trial 1\\n\\n'' returned non-zero exit status 1.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-24-405780435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cd /content/ICKD-DCKD/Cifar100\\n\\npython train_student.py \\\\\\n    --path_t ./save/teacher_resnet32x4_best.pth \\\\\\n    --distill dckd \\\\\\n    --model_s resnet8x4 \\\\\\n    --model_t resnet32x4 \\\\\\n    -a 0.5 -b 0.5 --trial 1\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'cd /content/ICKD-DCKD/Cifar100\\n\\npython train_student.py \\\\\\n    --path_t ./save/teacher_resnet32x4_best.pth \\\\\\n    --distill dckd \\\\\\n    --model_s resnet8x4 \\\\\\n    --model_t resnet32x4 \\\\\\n    -a 0.5 -b 0.5 --trial 1\\n\\n'' returned non-zero exit status 1."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep \"model_t\" /content/ICKD-DCKD/Cifar100/train_student.py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36-0UZ2efDxt",
        "outputId": "d2a42f87-a4ef-48d6-ec11-2029805d3e96"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    parser.add_argument('--model_t', type=str, required=True, help='teacher model')\n",
            "    opt.model_t = 'resnet32x4'\n",
            "    opt.model_name = 'S:{}_T:{}_{}_{}_r:{}_a:{}_b:{}_{}'.format(opt.model_s, opt.model_t, opt.dataset, opt.distill,\n",
            "    model_t = get_teacher_name(model_path)\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "    model_t.eval()\n",
            "    feat_t, _ = model_t(data, is_feat=True)\n",
            "        opt.guide_layers = np.arange(14,16) #LAYER[opt.model_t] \n",
            "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
            "        init(model_s, model_t, init_trainable_list, criterion_init, train_loader, logger, opt)\n",
            "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
            "    module_list.append(model_t)\n",
            "    teacher_acc, _, _ = validate(val_loader, model_t, criterion_cls, opt)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!grep \"opt.model_t =\" /content/ICKD-DCKD/Cifar100/train_student.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Eca_VRghq2Y",
        "outputId": "1c2f76f9-bf5f-4bdc-8938-7b2792af22d4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    opt.model_t = 'resnet32x4'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/ICKD-DCKD/Cifar100/train_student.py'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    for line in lines:\n",
        "        if 'opt.model_t = get_teacher_name' in line:\n",
        "            f.write('# ' + line)  # commenter la ligne\n",
        "        else:\n",
        "            f.write(line)\n",
        "\n",
        "print(\"✅ Ligne opt.model_t = get_teacher_name(...) commentée.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMRAX1-8bTE1",
        "outputId": "437d0b19-0c48-4d25-96cb-891c882acb3b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Ligne opt.model_t = get_teacher_name(...) commentée.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/ICKD-DCKD -type f -name \"*.pth\"\n"
      ],
      "metadata": {
        "id": "FJMyOET-t4_F"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD-DCKD/Cifar100/train_teacher.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFairpo0Dxxw",
        "outputId": "f91a96d4-51b0-438e-b1fa-879720dc5c86"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-19 19:43:27.704305: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750362207.724842   25456 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750362207.731113   25456 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "==> training...\n",
            "Epoch: [1][0/782]\tTime 2.295 (2.295)\tData 0.176 (0.176)\tLoss 5.6652 (5.6652)\tAcc@1 4.688 (4.688)\tAcc@5 7.812 (7.812)\n",
            "Epoch: [1][100/782]\tTime 0.055 (0.073)\tData 0.001 (0.003)\tLoss 4.5321 (4.7661)\tAcc@1 1.562 (1.408)\tAcc@5 4.688 (7.024)\n",
            "Epoch: [1][200/782]\tTime 0.049 (0.062)\tData 0.001 (0.002)\tLoss 4.5206 (4.6300)\tAcc@1 3.125 (1.850)\tAcc@5 9.375 (8.318)\n",
            "Epoch: [1][300/782]\tTime 0.048 (0.058)\tData 0.001 (0.002)\tLoss 4.4594 (4.5677)\tAcc@1 0.000 (1.947)\tAcc@5 3.125 (9.224)\n",
            "Epoch: [1][400/782]\tTime 0.049 (0.056)\tData 0.001 (0.002)\tLoss 4.2770 (4.5252)\tAcc@1 4.688 (2.151)\tAcc@5 18.750 (9.885)\n",
            "Epoch: [1][500/782]\tTime 0.049 (0.055)\tData 0.001 (0.002)\tLoss 4.1607 (4.4832)\tAcc@1 1.562 (2.445)\tAcc@5 17.188 (10.909)\n",
            "Epoch: [1][600/782]\tTime 0.049 (0.054)\tData 0.001 (0.002)\tLoss 4.5076 (4.4423)\tAcc@1 3.125 (2.644)\tAcc@5 6.250 (11.985)\n",
            "Epoch: [1][700/782]\tTime 0.054 (0.054)\tData 0.001 (0.002)\tLoss 4.1119 (4.4007)\tAcc@1 4.688 (3.045)\tAcc@5 17.188 (13.135)\n",
            " * Acc@1 3.294 Acc@5 13.958\n",
            "epoch 1, total time 42.21\n",
            "makedirs /mnt_venus/luis.ll/venus/vis/channel/\n",
            "Test: [0/313]\tTime 0.159 (0.159)\tLoss 3.8396 (3.8396)\tAcc@1 9.375 (9.375)\tAcc@5 31.250 (31.250)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 4.0160 (4.0526)\tAcc@1 6.250 (6.281)\tAcc@5 21.875 (23.886)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 3.9874 (4.0530)\tAcc@1 3.125 (6.297)\tAcc@5 18.750 (23.803)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 4.2513 (4.0686)\tAcc@1 9.375 (6.053)\tAcc@5 21.875 (23.578)\n",
            " * Acc@1 6.090 Acc@5 23.770\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [2][0/782]\tTime 0.281 (0.281)\tData 0.201 (0.201)\tLoss 4.0278 (4.0278)\tAcc@1 3.125 (3.125)\tAcc@5 20.312 (20.312)\n",
            "Epoch: [2][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 3.9554 (4.0609)\tAcc@1 9.375 (6.204)\tAcc@5 29.688 (22.618)\n",
            "Epoch: [2][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 4.1143 (4.0414)\tAcc@1 9.375 (6.592)\tAcc@5 23.438 (23.733)\n",
            "Epoch: [2][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 3.8979 (4.0095)\tAcc@1 12.500 (7.070)\tAcc@5 26.562 (24.751)\n",
            "Epoch: [2][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 3.7843 (3.9730)\tAcc@1 10.938 (7.345)\tAcc@5 37.500 (26.044)\n",
            "Epoch: [2][500/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 3.8113 (3.9391)\tAcc@1 10.938 (7.844)\tAcc@5 31.250 (27.246)\n",
            "Epoch: [2][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 3.7063 (3.9047)\tAcc@1 12.500 (8.405)\tAcc@5 32.812 (28.429)\n",
            "Epoch: [2][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 3.6228 (3.8763)\tAcc@1 10.938 (8.833)\tAcc@5 34.375 (29.311)\n",
            " * Acc@1 9.278 Acc@5 30.040\n",
            "epoch 2, total time 39.91\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 3.5224 (3.5224)\tAcc@1 21.875 (21.875)\tAcc@5 50.000 (50.000)\n",
            "Test: [100/313]\tTime 0.024 (0.022)\tLoss 3.6912 (3.6785)\tAcc@1 3.125 (12.840)\tAcc@5 31.250 (37.902)\n",
            "Test: [200/313]\tTime 0.024 (0.021)\tLoss 3.3062 (3.6717)\tAcc@1 12.500 (12.951)\tAcc@5 40.625 (36.940)\n",
            "Test: [300/313]\tTime 0.024 (0.021)\tLoss 4.0587 (3.6739)\tAcc@1 12.500 (13.092)\tAcc@5 34.375 (36.597)\n",
            " * Acc@1 13.090 Acc@5 36.550\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [3][0/782]\tTime 0.277 (0.277)\tData 0.186 (0.186)\tLoss 3.6180 (3.6180)\tAcc@1 14.062 (14.062)\tAcc@5 37.500 (37.500)\n",
            "Epoch: [3][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 3.8160 (3.6414)\tAcc@1 12.500 (13.026)\tAcc@5 25.000 (37.283)\n",
            "Epoch: [3][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 3.4804 (3.6000)\tAcc@1 20.312 (13.720)\tAcc@5 43.750 (38.588)\n",
            "Epoch: [3][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 3.8621 (3.5685)\tAcc@1 12.500 (14.062)\tAcc@5 37.500 (39.550)\n",
            "Epoch: [3][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 3.6198 (3.5481)\tAcc@1 10.938 (14.600)\tAcc@5 37.500 (40.138)\n",
            "Epoch: [3][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 3.3783 (3.5272)\tAcc@1 18.750 (14.998)\tAcc@5 45.312 (40.722)\n",
            "Epoch: [3][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 3.4792 (3.5059)\tAcc@1 12.500 (15.279)\tAcc@5 45.312 (41.283)\n",
            "Epoch: [3][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 3.1794 (3.4822)\tAcc@1 29.688 (15.707)\tAcc@5 53.125 (41.974)\n",
            " * Acc@1 16.098 Acc@5 42.462\n",
            "epoch 3, total time 39.76\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 3.5119 (3.5119)\tAcc@1 28.125 (28.125)\tAcc@5 50.000 (50.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 3.2483 (3.1872)\tAcc@1 25.000 (21.101)\tAcc@5 53.125 (50.650)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 3.0134 (3.1894)\tAcc@1 25.000 (20.833)\tAcc@5 59.375 (50.264)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 3.4749 (3.2014)\tAcc@1 3.125 (20.546)\tAcc@5 34.375 (50.363)\n",
            " * Acc@1 20.600 Acc@5 50.330\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [4][0/782]\tTime 0.270 (0.270)\tData 0.185 (0.185)\tLoss 3.1495 (3.1495)\tAcc@1 17.188 (17.188)\tAcc@5 48.438 (48.438)\n",
            "Epoch: [4][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 3.0067 (3.2160)\tAcc@1 20.312 (19.817)\tAcc@5 50.000 (49.319)\n",
            "Epoch: [4][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 3.1725 (3.2040)\tAcc@1 14.062 (20.382)\tAcc@5 54.688 (49.829)\n",
            "Epoch: [4][300/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 3.2856 (3.1804)\tAcc@1 21.875 (20.847)\tAcc@5 50.000 (50.415)\n",
            "Epoch: [4][400/782]\tTime 0.055 (0.051)\tData 0.001 (0.002)\tLoss 3.1541 (3.1603)\tAcc@1 21.875 (21.396)\tAcc@5 54.688 (51.107)\n",
            "Epoch: [4][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.9113 (3.1365)\tAcc@1 20.312 (21.903)\tAcc@5 56.250 (51.693)\n",
            "Epoch: [4][600/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 3.2666 (3.1181)\tAcc@1 32.812 (22.281)\tAcc@5 46.875 (52.088)\n",
            "Epoch: [4][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 2.9966 (3.0933)\tAcc@1 17.188 (22.722)\tAcc@5 59.375 (52.808)\n",
            " * Acc@1 23.116 Acc@5 53.254\n",
            "epoch 4, total time 39.68\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 2.7859 (2.7859)\tAcc@1 34.375 (34.375)\tAcc@5 59.375 (59.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.8905 (2.8826)\tAcc@1 21.875 (27.135)\tAcc@5 59.375 (59.035)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 2.5270 (2.8868)\tAcc@1 37.500 (27.192)\tAcc@5 75.000 (58.473)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 3.3823 (2.9018)\tAcc@1 12.500 (27.025)\tAcc@5 46.875 (58.295)\n",
            " * Acc@1 26.960 Acc@5 58.250\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [5][0/782]\tTime 0.267 (0.267)\tData 0.183 (0.183)\tLoss 2.9430 (2.9430)\tAcc@1 26.562 (26.562)\tAcc@5 56.250 (56.250)\n",
            "Epoch: [5][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 2.3558 (2.8282)\tAcc@1 42.188 (28.202)\tAcc@5 68.750 (59.251)\n",
            "Epoch: [5][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 2.8408 (2.8346)\tAcc@1 28.125 (27.713)\tAcc@5 59.375 (59.344)\n",
            "Epoch: [5][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.3578 (2.8094)\tAcc@1 34.375 (28.130)\tAcc@5 71.875 (60.102)\n",
            "Epoch: [5][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.5170 (2.7978)\tAcc@1 37.500 (28.480)\tAcc@5 64.062 (60.396)\n",
            "Epoch: [5][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 2.8074 (2.7944)\tAcc@1 21.875 (28.502)\tAcc@5 64.062 (60.463)\n",
            "Epoch: [5][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 3.0066 (2.7758)\tAcc@1 20.312 (28.804)\tAcc@5 57.812 (60.844)\n",
            "Epoch: [5][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.9212 (2.7615)\tAcc@1 25.000 (29.037)\tAcc@5 50.000 (61.232)\n",
            " * Acc@1 29.244 Acc@5 61.430\n",
            "epoch 5, total time 39.66\n",
            "Test: [0/313]\tTime 0.132 (0.132)\tLoss 2.6363 (2.6363)\tAcc@1 31.250 (31.250)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 3.0358 (2.6384)\tAcc@1 21.875 (31.807)\tAcc@5 50.000 (64.418)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 2.2293 (2.6248)\tAcc@1 46.875 (32.074)\tAcc@5 71.875 (64.272)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.9650 (2.6373)\tAcc@1 21.875 (31.696)\tAcc@5 56.250 (64.099)\n",
            " * Acc@1 31.790 Acc@5 64.220\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [6][0/782]\tTime 0.278 (0.278)\tData 0.197 (0.197)\tLoss 2.5703 (2.5703)\tAcc@1 39.062 (39.062)\tAcc@5 67.188 (67.188)\n",
            "Epoch: [6][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 2.8672 (2.5904)\tAcc@1 21.875 (32.550)\tAcc@5 53.125 (64.960)\n",
            "Epoch: [6][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 2.6218 (2.5488)\tAcc@1 29.688 (33.738)\tAcc@5 67.188 (65.804)\n",
            "Epoch: [6][300/782]\tTime 0.053 (0.052)\tData 0.002 (0.002)\tLoss 2.6655 (2.5441)\tAcc@1 20.312 (33.576)\tAcc@5 70.312 (66.097)\n",
            "Epoch: [6][400/782]\tTime 0.048 (0.052)\tData 0.001 (0.002)\tLoss 2.1377 (2.5404)\tAcc@1 40.625 (33.806)\tAcc@5 71.875 (66.093)\n",
            "Epoch: [6][500/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 2.1191 (2.5311)\tAcc@1 40.625 (33.935)\tAcc@5 78.125 (66.576)\n",
            "Epoch: [6][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 2.3942 (2.5208)\tAcc@1 37.500 (34.201)\tAcc@5 71.875 (66.821)\n",
            "Epoch: [6][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 2.4393 (2.5099)\tAcc@1 34.375 (34.413)\tAcc@5 68.750 (67.105)\n",
            " * Acc@1 34.568 Acc@5 67.320\n",
            "epoch 6, total time 40.13\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 2.2180 (2.2180)\tAcc@1 50.000 (50.000)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.019 (0.019)\tLoss 2.4872 (2.5921)\tAcc@1 31.250 (32.735)\tAcc@5 71.875 (66.275)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 2.0118 (2.5658)\tAcc@1 50.000 (33.209)\tAcc@5 81.250 (66.947)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 3.2499 (2.5838)\tAcc@1 12.500 (33.223)\tAcc@5 50.000 (66.269)\n",
            " * Acc@1 33.250 Acc@5 66.210\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [7][0/782]\tTime 0.279 (0.279)\tData 0.185 (0.185)\tLoss 2.6560 (2.6560)\tAcc@1 31.250 (31.250)\tAcc@5 64.062 (64.062)\n",
            "Epoch: [7][100/782]\tTime 0.049 (0.052)\tData 0.001 (0.003)\tLoss 2.1571 (2.3805)\tAcc@1 45.312 (37.036)\tAcc@5 79.688 (69.895)\n",
            "Epoch: [7][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 2.1301 (2.3675)\tAcc@1 48.438 (37.477)\tAcc@5 75.000 (70.227)\n",
            "Epoch: [7][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 2.4245 (2.3609)\tAcc@1 34.375 (37.791)\tAcc@5 67.188 (70.370)\n",
            "Epoch: [7][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 2.4266 (2.3532)\tAcc@1 37.500 (37.695)\tAcc@5 68.750 (70.523)\n",
            "Epoch: [7][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 2.2478 (2.3430)\tAcc@1 40.625 (37.980)\tAcc@5 71.875 (70.727)\n",
            "Epoch: [7][600/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 2.2143 (2.3389)\tAcc@1 42.188 (38.116)\tAcc@5 73.438 (70.721)\n",
            "Epoch: [7][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.4438 (2.3319)\tAcc@1 32.812 (38.193)\tAcc@5 75.000 (70.879)\n",
            " * Acc@1 38.328 Acc@5 71.058\n",
            "epoch 7, total time 39.79\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.5341 (2.5341)\tAcc@1 43.750 (43.750)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.5298 (2.3180)\tAcc@1 37.500 (38.057)\tAcc@5 65.625 (72.401)\n",
            "Test: [200/313]\tTime 0.019 (0.019)\tLoss 1.5464 (2.3101)\tAcc@1 53.125 (39.101)\tAcc@5 87.500 (72.341)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 2.4812 (2.3231)\tAcc@1 31.250 (38.902)\tAcc@5 78.125 (71.968)\n",
            " * Acc@1 38.850 Acc@5 72.010\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [8][0/782]\tTime 0.278 (0.278)\tData 0.199 (0.199)\tLoss 1.8197 (1.8197)\tAcc@1 51.562 (51.562)\tAcc@5 78.125 (78.125)\n",
            "Epoch: [8][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 2.0109 (2.1891)\tAcc@1 56.250 (41.012)\tAcc@5 76.562 (74.165)\n",
            "Epoch: [8][200/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.1853 (2.2005)\tAcc@1 32.812 (40.532)\tAcc@5 73.438 (73.958)\n",
            "Epoch: [8][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.3216 (2.1980)\tAcc@1 37.500 (40.474)\tAcc@5 71.875 (74.024)\n",
            "Epoch: [8][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.0042 (2.1988)\tAcc@1 48.438 (40.555)\tAcc@5 75.000 (73.932)\n",
            "Epoch: [8][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 2.2212 (2.1889)\tAcc@1 40.625 (40.899)\tAcc@5 73.438 (74.096)\n",
            "Epoch: [8][600/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 2.3197 (2.1845)\tAcc@1 39.062 (41.142)\tAcc@5 71.875 (74.194)\n",
            "Epoch: [8][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 2.0504 (2.1767)\tAcc@1 46.875 (41.343)\tAcc@5 76.562 (74.432)\n",
            " * Acc@1 41.578 Acc@5 74.566\n",
            "epoch 8, total time 39.65\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 3.2358 (3.2358)\tAcc@1 43.750 (43.750)\tAcc@5 59.375 (59.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 2.6876 (2.8456)\tAcc@1 40.625 (31.436)\tAcc@5 71.875 (64.047)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 2.2445 (2.9058)\tAcc@1 28.125 (30.908)\tAcc@5 75.000 (63.355)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.9635 (2.9056)\tAcc@1 25.000 (30.939)\tAcc@5 65.625 (62.988)\n",
            " * Acc@1 30.980 Acc@5 63.030\n",
            "==> training...\n",
            "Epoch: [9][0/782]\tTime 0.276 (0.276)\tData 0.194 (0.194)\tLoss 2.0640 (2.0640)\tAcc@1 40.625 (40.625)\tAcc@5 79.688 (79.688)\n",
            "Epoch: [9][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 2.0233 (2.0608)\tAcc@1 45.312 (43.564)\tAcc@5 73.438 (76.547)\n",
            "Epoch: [9][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 2.0239 (2.0628)\tAcc@1 45.312 (43.766)\tAcc@5 76.562 (76.679)\n",
            "Epoch: [9][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.1500 (2.0499)\tAcc@1 50.000 (44.300)\tAcc@5 78.125 (76.765)\n",
            "Epoch: [9][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 2.5428 (2.0528)\tAcc@1 34.375 (44.323)\tAcc@5 65.625 (76.664)\n",
            "Epoch: [9][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.2323 (2.0529)\tAcc@1 32.812 (44.212)\tAcc@5 76.562 (76.765)\n",
            "Epoch: [9][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.8165 (2.0533)\tAcc@1 51.562 (44.179)\tAcc@5 84.375 (76.713)\n",
            "Epoch: [9][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.0579 (2.0510)\tAcc@1 48.438 (44.240)\tAcc@5 76.562 (76.739)\n",
            " * Acc@1 44.402 Acc@5 76.872\n",
            "epoch 9, total time 39.49\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 2.8028 (2.8028)\tAcc@1 46.875 (46.875)\tAcc@5 62.500 (62.500)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.6474 (2.4157)\tAcc@1 34.375 (39.356)\tAcc@5 71.875 (71.720)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 2.0443 (2.4211)\tAcc@1 34.375 (39.303)\tAcc@5 68.750 (71.269)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.1803 (2.4200)\tAcc@1 37.500 (39.566)\tAcc@5 75.000 (71.387)\n",
            " * Acc@1 39.370 Acc@5 71.360\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [10][0/782]\tTime 0.287 (0.287)\tData 0.197 (0.197)\tLoss 2.2087 (2.2087)\tAcc@1 45.312 (45.312)\tAcc@5 76.562 (76.562)\n",
            "Epoch: [10][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.8330 (2.0034)\tAcc@1 51.562 (45.142)\tAcc@5 76.562 (77.692)\n",
            "Epoch: [10][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.7500 (1.9692)\tAcc@1 48.438 (46.222)\tAcc@5 89.062 (78.008)\n",
            "Epoch: [10][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.9783 (1.9835)\tAcc@1 50.000 (45.707)\tAcc@5 73.438 (77.788)\n",
            "Epoch: [10][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 2.2489 (1.9705)\tAcc@1 46.875 (45.971)\tAcc@5 75.000 (78.102)\n",
            "Epoch: [10][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 2.0687 (1.9727)\tAcc@1 43.750 (46.014)\tAcc@5 79.688 (78.203)\n",
            "Epoch: [10][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.0326 (1.9654)\tAcc@1 39.062 (46.092)\tAcc@5 79.688 (78.333)\n",
            "Epoch: [10][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.8014 (1.9583)\tAcc@1 48.438 (46.414)\tAcc@5 76.562 (78.493)\n",
            " * Acc@1 46.384 Acc@5 78.480\n",
            "epoch 10, total time 40.04\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.8940 (1.8940)\tAcc@1 56.250 (56.250)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 2.2556 (2.1027)\tAcc@1 34.375 (43.843)\tAcc@5 78.125 (76.578)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.7540 (2.0984)\tAcc@1 40.625 (43.299)\tAcc@5 84.375 (75.824)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.6720 (2.1163)\tAcc@1 34.375 (43.002)\tAcc@5 71.875 (75.384)\n",
            " * Acc@1 43.140 Acc@5 75.420\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [11][0/782]\tTime 0.292 (0.292)\tData 0.200 (0.200)\tLoss 1.6933 (1.6933)\tAcc@1 51.562 (51.562)\tAcc@5 81.250 (81.250)\n",
            "Epoch: [11][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 1.7611 (1.8679)\tAcc@1 48.438 (48.592)\tAcc@5 87.500 (80.213)\n",
            "Epoch: [11][200/782]\tTime 0.068 (0.053)\tData 0.001 (0.002)\tLoss 2.1250 (1.8706)\tAcc@1 45.312 (48.539)\tAcc@5 75.000 (80.185)\n",
            "Epoch: [11][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 2.0418 (1.8708)\tAcc@1 43.750 (48.339)\tAcc@5 73.438 (80.009)\n",
            "Epoch: [11][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.7871 (1.8788)\tAcc@1 45.312 (48.309)\tAcc@5 76.562 (79.828)\n",
            "Epoch: [11][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.9333 (1.8767)\tAcc@1 54.688 (48.456)\tAcc@5 79.688 (79.850)\n",
            "Epoch: [11][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.7904 (1.8843)\tAcc@1 51.562 (48.198)\tAcc@5 81.250 (79.810)\n",
            "Epoch: [11][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 2.0036 (1.8811)\tAcc@1 50.000 (48.273)\tAcc@5 78.125 (79.846)\n",
            " * Acc@1 48.292 Acc@5 79.828\n",
            "epoch 11, total time 39.99\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.0175 (2.0175)\tAcc@1 50.000 (50.000)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.8433 (2.0591)\tAcc@1 37.500 (44.400)\tAcc@5 87.500 (76.392)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.9313 (2.0789)\tAcc@1 37.500 (44.279)\tAcc@5 84.375 (75.731)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.2450 (2.0912)\tAcc@1 37.500 (44.487)\tAcc@5 75.000 (75.571)\n",
            " * Acc@1 44.530 Acc@5 75.580\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [12][0/782]\tTime 0.281 (0.281)\tData 0.187 (0.187)\tLoss 1.9350 (1.9350)\tAcc@1 45.312 (45.312)\tAcc@5 78.125 (78.125)\n",
            "Epoch: [12][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.9361 (1.8135)\tAcc@1 48.438 (49.551)\tAcc@5 81.250 (80.709)\n",
            "Epoch: [12][200/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.9582 (1.8280)\tAcc@1 50.000 (49.300)\tAcc@5 76.562 (80.955)\n",
            "Epoch: [12][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.9693 (1.8246)\tAcc@1 45.312 (49.372)\tAcc@5 84.375 (81.006)\n",
            "Epoch: [12][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.9155 (1.8278)\tAcc@1 43.750 (49.260)\tAcc@5 79.688 (80.997)\n",
            "Epoch: [12][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.8815 (1.8194)\tAcc@1 51.562 (49.492)\tAcc@5 82.812 (81.306)\n",
            "Epoch: [12][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7264 (1.8264)\tAcc@1 48.438 (49.342)\tAcc@5 73.438 (81.123)\n",
            "Epoch: [12][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.8478 (1.8307)\tAcc@1 54.688 (49.358)\tAcc@5 79.688 (80.994)\n",
            " * Acc@1 49.344 Acc@5 80.902\n",
            "epoch 12, total time 39.59\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 2.1320 (2.1320)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.2939 (1.9631)\tAcc@1 43.750 (47.803)\tAcc@5 65.625 (78.342)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.5932 (1.9790)\tAcc@1 53.125 (46.859)\tAcc@5 84.375 (77.907)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.0209 (1.9816)\tAcc@1 40.625 (46.885)\tAcc@5 71.875 (77.886)\n",
            " * Acc@1 46.890 Acc@5 77.900\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [13][0/782]\tTime 0.265 (0.265)\tData 0.184 (0.184)\tLoss 1.9168 (1.9168)\tAcc@1 45.312 (45.312)\tAcc@5 81.250 (81.250)\n",
            "Epoch: [13][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.8179 (1.7020)\tAcc@1 46.875 (52.413)\tAcc@5 82.812 (82.983)\n",
            "Epoch: [13][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 2.0028 (1.7431)\tAcc@1 54.688 (51.734)\tAcc@5 81.250 (82.478)\n",
            "Epoch: [13][300/782]\tTime 0.048 (0.052)\tData 0.001 (0.002)\tLoss 1.7373 (1.7598)\tAcc@1 51.562 (51.319)\tAcc@5 84.375 (82.288)\n",
            "Epoch: [13][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.8643 (1.7643)\tAcc@1 57.812 (51.060)\tAcc@5 81.250 (82.244)\n",
            "Epoch: [13][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.9088 (1.7684)\tAcc@1 53.125 (50.967)\tAcc@5 78.125 (82.123)\n",
            "Epoch: [13][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7620 (1.7778)\tAcc@1 51.562 (50.811)\tAcc@5 81.250 (81.929)\n",
            "Epoch: [13][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6761 (1.7757)\tAcc@1 64.062 (50.898)\tAcc@5 84.375 (81.845)\n",
            " * Acc@1 50.778 Acc@5 81.824\n",
            "epoch 13, total time 39.58\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.9785 (1.9785)\tAcc@1 53.125 (53.125)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.6961 (1.9726)\tAcc@1 53.125 (47.463)\tAcc@5 87.500 (77.785)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.1388 (1.9564)\tAcc@1 65.625 (47.559)\tAcc@5 90.625 (78.032)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.2229 (1.9717)\tAcc@1 34.375 (47.114)\tAcc@5 78.125 (77.689)\n",
            " * Acc@1 47.180 Acc@5 77.560\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [14][0/782]\tTime 0.286 (0.286)\tData 0.191 (0.191)\tLoss 1.8603 (1.8603)\tAcc@1 46.875 (46.875)\tAcc@5 82.812 (82.812)\n",
            "Epoch: [14][100/782]\tTime 0.051 (0.052)\tData 0.001 (0.003)\tLoss 1.7190 (1.7248)\tAcc@1 57.812 (52.290)\tAcc@5 82.812 (82.550)\n",
            "Epoch: [14][200/782]\tTime 0.062 (0.051)\tData 0.001 (0.002)\tLoss 1.5189 (1.7069)\tAcc@1 57.812 (52.317)\tAcc@5 85.938 (83.007)\n",
            "Epoch: [14][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7036 (1.7271)\tAcc@1 54.688 (51.812)\tAcc@5 89.062 (82.750)\n",
            "Epoch: [14][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 2.0593 (1.7323)\tAcc@1 40.625 (51.605)\tAcc@5 79.688 (82.727)\n",
            "Epoch: [14][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6174 (1.7297)\tAcc@1 57.812 (51.712)\tAcc@5 81.250 (82.756)\n",
            "Epoch: [14][600/782]\tTime 0.049 (0.050)\tData 0.001 (0.002)\tLoss 1.8577 (1.7275)\tAcc@1 46.875 (51.820)\tAcc@5 82.812 (82.805)\n",
            "Epoch: [14][700/782]\tTime 0.049 (0.050)\tData 0.001 (0.002)\tLoss 1.4967 (1.7312)\tAcc@1 60.938 (51.674)\tAcc@5 87.500 (82.777)\n",
            " * Acc@1 51.718 Acc@5 82.760\n",
            "epoch 14, total time 39.44\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 2.7731 (2.7731)\tAcc@1 46.875 (46.875)\tAcc@5 65.625 (65.625)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.2343 (2.4164)\tAcc@1 50.000 (41.368)\tAcc@5 78.125 (71.380)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 2.0057 (2.4178)\tAcc@1 43.750 (41.029)\tAcc@5 78.125 (71.657)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.7938 (2.4288)\tAcc@1 34.375 (40.843)\tAcc@5 65.625 (71.491)\n",
            " * Acc@1 40.880 Acc@5 71.540\n",
            "==> training...\n",
            "Epoch: [15][0/782]\tTime 0.279 (0.279)\tData 0.197 (0.197)\tLoss 1.7683 (1.7683)\tAcc@1 43.750 (43.750)\tAcc@5 81.250 (81.250)\n",
            "Epoch: [15][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.8118 (1.7148)\tAcc@1 50.000 (52.614)\tAcc@5 76.562 (82.658)\n",
            "Epoch: [15][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4660 (1.6848)\tAcc@1 54.688 (52.876)\tAcc@5 85.938 (83.209)\n",
            "Epoch: [15][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5604 (1.6956)\tAcc@1 54.688 (52.409)\tAcc@5 84.375 (83.093)\n",
            "Epoch: [15][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5946 (1.6972)\tAcc@1 51.562 (52.400)\tAcc@5 90.625 (83.113)\n",
            "Epoch: [15][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6951 (1.7010)\tAcc@1 51.562 (52.458)\tAcc@5 81.250 (83.056)\n",
            "Epoch: [15][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7318 (1.7013)\tAcc@1 56.250 (52.407)\tAcc@5 75.000 (83.062)\n",
            "Epoch: [15][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.6905 (1.7026)\tAcc@1 56.250 (52.459)\tAcc@5 82.812 (83.009)\n",
            " * Acc@1 52.530 Acc@5 83.058\n",
            "epoch 15, total time 39.73\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.8690 (1.8690)\tAcc@1 50.000 (50.000)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.9654 (1.9386)\tAcc@1 40.625 (48.824)\tAcc@5 78.125 (80.043)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.6362 (1.9178)\tAcc@1 59.375 (48.989)\tAcc@5 84.375 (80.115)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 2.2260 (1.9272)\tAcc@1 31.250 (49.201)\tAcc@5 84.375 (79.931)\n",
            " * Acc@1 49.180 Acc@5 79.870\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [16][0/782]\tTime 0.687 (0.687)\tData 0.210 (0.210)\tLoss 1.3687 (1.3687)\tAcc@1 65.625 (65.625)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [16][100/782]\tTime 0.055 (0.060)\tData 0.001 (0.005)\tLoss 1.7443 (1.6247)\tAcc@1 57.812 (54.486)\tAcc@5 76.562 (84.808)\n",
            "Epoch: [16][200/782]\tTime 0.057 (0.055)\tData 0.002 (0.003)\tLoss 2.0855 (1.6713)\tAcc@1 40.625 (53.459)\tAcc@5 73.438 (83.784)\n",
            "Epoch: [16][300/782]\tTime 0.048 (0.054)\tData 0.001 (0.002)\tLoss 1.4577 (1.6742)\tAcc@1 60.938 (53.322)\tAcc@5 84.375 (83.742)\n",
            "Epoch: [16][400/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.3709 (1.6701)\tAcc@1 64.062 (53.281)\tAcc@5 85.938 (83.818)\n",
            "Epoch: [16][500/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.7386 (1.6663)\tAcc@1 50.000 (53.509)\tAcc@5 84.375 (83.832)\n",
            "Epoch: [16][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.5717 (1.6687)\tAcc@1 53.125 (53.421)\tAcc@5 89.062 (83.787)\n",
            "Epoch: [16][700/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.4950 (1.6697)\tAcc@1 53.125 (53.428)\tAcc@5 84.375 (83.738)\n",
            " * Acc@1 53.246 Acc@5 83.638\n",
            "epoch 16, total time 40.57\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.7997 (1.7997)\tAcc@1 53.125 (53.125)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.0749 (2.0136)\tAcc@1 50.000 (46.535)\tAcc@5 81.250 (76.887)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.6173 (1.9996)\tAcc@1 53.125 (46.642)\tAcc@5 87.500 (77.410)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.5059 (2.0270)\tAcc@1 43.750 (45.889)\tAcc@5 75.000 (76.858)\n",
            " * Acc@1 45.960 Acc@5 76.820\n",
            "==> training...\n",
            "Epoch: [17][0/782]\tTime 0.268 (0.268)\tData 0.180 (0.180)\tLoss 1.5273 (1.5273)\tAcc@1 51.562 (51.562)\tAcc@5 82.812 (82.812)\n",
            "Epoch: [17][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.5208 (1.6161)\tAcc@1 54.688 (54.734)\tAcc@5 89.062 (85.257)\n",
            "Epoch: [17][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.6418 (1.6229)\tAcc@1 53.125 (54.524)\tAcc@5 82.812 (84.857)\n",
            "Epoch: [17][300/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.5215 (1.6268)\tAcc@1 53.125 (54.402)\tAcc@5 84.375 (84.640)\n",
            "Epoch: [17][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.8308 (1.6291)\tAcc@1 40.625 (54.310)\tAcc@5 85.938 (84.562)\n",
            "Epoch: [17][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.7290 (1.6290)\tAcc@1 53.125 (54.307)\tAcc@5 87.500 (84.503)\n",
            "Epoch: [17][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.9221 (1.6318)\tAcc@1 45.312 (54.178)\tAcc@5 76.562 (84.453)\n",
            "Epoch: [17][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.8353 (1.6397)\tAcc@1 48.438 (54.139)\tAcc@5 85.938 (84.317)\n",
            " * Acc@1 53.984 Acc@5 84.234\n",
            "epoch 17, total time 40.33\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 2.2100 (2.2100)\tAcc@1 50.000 (50.000)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.9311 (1.9314)\tAcc@1 50.000 (48.948)\tAcc@5 87.500 (79.981)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.2961 (1.9114)\tAcc@1 46.875 (49.067)\tAcc@5 90.625 (79.882)\n",
            "Test: [300/313]\tTime 0.017 (0.017)\tLoss 2.3160 (1.9255)\tAcc@1 40.625 (49.315)\tAcc@5 75.000 (79.402)\n",
            " * Acc@1 49.420 Acc@5 79.430\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [18][0/782]\tTime 0.283 (0.283)\tData 0.201 (0.201)\tLoss 1.3750 (1.3750)\tAcc@1 57.812 (57.812)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [18][100/782]\tTime 0.051 (0.055)\tData 0.001 (0.003)\tLoss 1.3851 (1.5717)\tAcc@1 60.938 (55.446)\tAcc@5 87.500 (85.845)\n",
            "Epoch: [18][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.6832 (1.6039)\tAcc@1 56.250 (55.162)\tAcc@5 81.250 (84.787)\n",
            "Epoch: [18][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4333 (1.5915)\tAcc@1 59.375 (55.264)\tAcc@5 89.062 (84.925)\n",
            "Epoch: [18][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4102 (1.5988)\tAcc@1 64.062 (55.256)\tAcc@5 87.500 (84.765)\n",
            "Epoch: [18][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.6306 (1.6131)\tAcc@1 53.125 (54.794)\tAcc@5 87.500 (84.484)\n",
            "Epoch: [18][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.7679 (1.6189)\tAcc@1 48.438 (54.677)\tAcc@5 89.062 (84.391)\n",
            "Epoch: [18][700/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.5873 (1.6212)\tAcc@1 53.125 (54.458)\tAcc@5 85.938 (84.428)\n",
            " * Acc@1 54.322 Acc@5 84.300\n",
            "epoch 18, total time 40.21\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.7404 (1.7404)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.026 (0.019)\tLoss 2.2334 (1.9302)\tAcc@1 28.125 (47.618)\tAcc@5 81.250 (79.022)\n",
            "Test: [200/313]\tTime 0.025 (0.019)\tLoss 1.2430 (1.9233)\tAcc@1 59.375 (47.606)\tAcc@5 90.625 (78.980)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.6242 (1.9223)\tAcc@1 31.250 (47.685)\tAcc@5 71.875 (78.883)\n",
            " * Acc@1 47.930 Acc@5 78.860\n",
            "==> training...\n",
            "Epoch: [19][0/782]\tTime 0.266 (0.266)\tData 0.180 (0.180)\tLoss 1.5794 (1.5794)\tAcc@1 59.375 (59.375)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [19][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.4455 (1.5746)\tAcc@1 57.812 (55.043)\tAcc@5 87.500 (84.978)\n",
            "Epoch: [19][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2437 (1.5644)\tAcc@1 57.812 (55.333)\tAcc@5 95.312 (85.331)\n",
            "Epoch: [19][300/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.8070 (1.5747)\tAcc@1 50.000 (55.134)\tAcc@5 79.688 (85.154)\n",
            "Epoch: [19][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3338 (1.5831)\tAcc@1 54.688 (55.077)\tAcc@5 92.188 (85.014)\n",
            "Epoch: [19][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.8261 (1.5856)\tAcc@1 50.000 (55.174)\tAcc@5 84.375 (85.002)\n",
            "Epoch: [19][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.7392 (1.5911)\tAcc@1 51.562 (55.096)\tAcc@5 85.938 (84.978)\n",
            "Epoch: [19][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4424 (1.5982)\tAcc@1 59.375 (54.982)\tAcc@5 90.625 (84.839)\n",
            " * Acc@1 55.010 Acc@5 84.742\n",
            "epoch 19, total time 39.72\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.8095 (1.8095)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.8508 (1.8491)\tAcc@1 43.750 (50.031)\tAcc@5 78.125 (81.095)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.4674 (1.8572)\tAcc@1 50.000 (50.047)\tAcc@5 84.375 (81.017)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.0018 (1.8636)\tAcc@1 43.750 (49.834)\tAcc@5 78.125 (80.959)\n",
            " * Acc@1 49.870 Acc@5 80.910\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [20][0/782]\tTime 0.283 (0.283)\tData 0.203 (0.203)\tLoss 1.3184 (1.3184)\tAcc@1 60.938 (60.938)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [20][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 1.9558 (1.5259)\tAcc@1 46.875 (56.791)\tAcc@5 76.562 (85.968)\n",
            "Epoch: [20][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5846 (1.5513)\tAcc@1 51.562 (56.126)\tAcc@5 84.375 (85.401)\n",
            "Epoch: [20][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.6629 (1.5618)\tAcc@1 56.250 (55.814)\tAcc@5 85.938 (85.455)\n",
            "Epoch: [20][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4060 (1.5650)\tAcc@1 57.812 (55.938)\tAcc@5 87.500 (85.330)\n",
            "Epoch: [20][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.7452 (1.5765)\tAcc@1 56.250 (55.670)\tAcc@5 90.625 (85.173)\n",
            "Epoch: [20][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3013 (1.5807)\tAcc@1 60.938 (55.423)\tAcc@5 87.500 (85.093)\n",
            "Epoch: [20][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 2.1104 (1.5809)\tAcc@1 40.625 (55.521)\tAcc@5 70.312 (85.064)\n",
            " * Acc@1 55.532 Acc@5 85.092\n",
            "epoch 20, total time 39.91\n",
            "Test: [0/313]\tTime 0.112 (0.112)\tLoss 2.0948 (2.0948)\tAcc@1 46.875 (46.875)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.0333 (2.1035)\tAcc@1 43.750 (45.545)\tAcc@5 75.000 (78.063)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.7549 (2.0617)\tAcc@1 59.375 (46.720)\tAcc@5 81.250 (78.249)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.4397 (2.0727)\tAcc@1 28.125 (46.501)\tAcc@5 71.875 (77.814)\n",
            " * Acc@1 46.580 Acc@5 77.870\n",
            "==> training...\n",
            "Epoch: [21][0/782]\tTime 0.266 (0.266)\tData 0.191 (0.191)\tLoss 1.4368 (1.4368)\tAcc@1 64.062 (64.062)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [21][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 1.6869 (1.4997)\tAcc@1 51.562 (57.209)\tAcc@5 84.375 (86.680)\n",
            "Epoch: [21][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.4377 (1.5624)\tAcc@1 59.375 (55.628)\tAcc@5 85.938 (85.627)\n",
            "Epoch: [21][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.4279 (1.5582)\tAcc@1 51.562 (56.089)\tAcc@5 92.188 (85.636)\n",
            "Epoch: [21][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2992 (1.5578)\tAcc@1 60.938 (56.028)\tAcc@5 95.312 (85.688)\n",
            "Epoch: [21][500/782]\tTime 0.071 (0.051)\tData 0.001 (0.002)\tLoss 1.7032 (1.5675)\tAcc@1 57.812 (55.748)\tAcc@5 79.688 (85.432)\n",
            "Epoch: [21][600/782]\tTime 0.056 (0.051)\tData 0.001 (0.002)\tLoss 1.3592 (1.5681)\tAcc@1 60.938 (55.748)\tAcc@5 89.062 (85.347)\n",
            "Epoch: [21][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.8236 (1.5701)\tAcc@1 56.250 (55.766)\tAcc@5 79.688 (85.307)\n",
            " * Acc@1 55.740 Acc@5 85.246\n",
            "epoch 21, total time 39.96\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.1619 (2.1619)\tAcc@1 53.125 (53.125)\tAcc@5 65.625 (65.625)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 2.7175 (1.8733)\tAcc@1 31.250 (49.350)\tAcc@5 71.875 (80.972)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.1330 (1.8651)\tAcc@1 65.625 (49.378)\tAcc@5 90.625 (80.955)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.7906 (1.8780)\tAcc@1 43.750 (49.398)\tAcc@5 84.375 (80.762)\n",
            " * Acc@1 49.370 Acc@5 80.690\n",
            "==> training...\n",
            "Epoch: [22][0/782]\tTime 0.282 (0.282)\tData 0.192 (0.192)\tLoss 1.7623 (1.7623)\tAcc@1 57.812 (57.812)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [22][100/782]\tTime 0.048 (0.054)\tData 0.001 (0.003)\tLoss 2.1054 (1.5521)\tAcc@1 40.625 (56.637)\tAcc@5 73.438 (85.860)\n",
            "Epoch: [22][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.5373 (1.5311)\tAcc@1 51.562 (56.856)\tAcc@5 85.938 (86.171)\n",
            "Epoch: [22][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.5787 (1.5329)\tAcc@1 57.812 (56.743)\tAcc@5 78.125 (86.109)\n",
            "Epoch: [22][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6461 (1.5426)\tAcc@1 60.938 (56.566)\tAcc@5 79.688 (85.918)\n",
            "Epoch: [22][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5911 (1.5400)\tAcc@1 54.688 (56.621)\tAcc@5 82.812 (85.872)\n",
            "Epoch: [22][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6795 (1.5400)\tAcc@1 53.125 (56.598)\tAcc@5 79.688 (85.828)\n",
            "Epoch: [22][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6164 (1.5480)\tAcc@1 50.000 (56.444)\tAcc@5 82.812 (85.735)\n",
            " * Acc@1 56.466 Acc@5 85.670\n",
            "epoch 22, total time 39.83\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 1.7950 (1.7950)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.024 (0.020)\tLoss 2.1374 (1.7224)\tAcc@1 50.000 (53.342)\tAcc@5 87.500 (82.488)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.3339 (1.7653)\tAcc@1 59.375 (52.348)\tAcc@5 84.375 (81.841)\n",
            "Test: [300/313]\tTime 0.019 (0.019)\tLoss 1.8518 (1.7975)\tAcc@1 53.125 (52.076)\tAcc@5 87.500 (81.613)\n",
            " * Acc@1 52.050 Acc@5 81.520\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [23][0/782]\tTime 0.265 (0.265)\tData 0.194 (0.194)\tLoss 1.5168 (1.5168)\tAcc@1 54.688 (54.688)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [23][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 1.6981 (1.4905)\tAcc@1 59.375 (57.658)\tAcc@5 81.250 (87.113)\n",
            "Epoch: [23][200/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.9638 (1.5260)\tAcc@1 42.188 (56.911)\tAcc@5 75.000 (86.116)\n",
            "Epoch: [23][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2076 (1.5283)\tAcc@1 64.062 (56.831)\tAcc@5 90.625 (85.901)\n",
            "Epoch: [23][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4852 (1.5234)\tAcc@1 50.000 (56.788)\tAcc@5 84.375 (86.027)\n",
            "Epoch: [23][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6015 (1.5274)\tAcc@1 57.812 (56.818)\tAcc@5 85.938 (85.981)\n",
            "Epoch: [23][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4149 (1.5324)\tAcc@1 59.375 (56.757)\tAcc@5 85.938 (85.885)\n",
            "Epoch: [23][700/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.5228 (1.5342)\tAcc@1 57.812 (56.631)\tAcc@5 84.375 (85.831)\n",
            " * Acc@1 56.632 Acc@5 85.828\n",
            "epoch 23, total time 39.85\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 2.7972 (2.7972)\tAcc@1 46.875 (46.875)\tAcc@5 65.625 (65.625)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.1227 (2.2333)\tAcc@1 31.250 (46.411)\tAcc@5 71.875 (77.011)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.7958 (2.2305)\tAcc@1 50.000 (45.927)\tAcc@5 81.250 (76.912)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.8254 (2.2594)\tAcc@1 31.250 (45.754)\tAcc@5 68.750 (76.713)\n",
            " * Acc@1 45.770 Acc@5 76.680\n",
            "==> training...\n",
            "Epoch: [24][0/782]\tTime 0.268 (0.268)\tData 0.189 (0.189)\tLoss 1.5312 (1.5312)\tAcc@1 56.250 (56.250)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [24][100/782]\tTime 0.049 (0.055)\tData 0.001 (0.003)\tLoss 1.3472 (1.5265)\tAcc@1 62.500 (57.039)\tAcc@5 89.062 (85.860)\n",
            "Epoch: [24][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.6747 (1.5244)\tAcc@1 48.438 (56.794)\tAcc@5 85.938 (86.046)\n",
            "Epoch: [24][300/782]\tTime 0.055 (0.052)\tData 0.001 (0.002)\tLoss 1.2774 (1.5262)\tAcc@1 62.500 (56.722)\tAcc@5 93.750 (85.875)\n",
            "Epoch: [24][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.7532 (1.5290)\tAcc@1 46.875 (56.877)\tAcc@5 85.938 (85.828)\n",
            "Epoch: [24][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4743 (1.5169)\tAcc@1 56.250 (57.148)\tAcc@5 89.062 (85.972)\n",
            "Epoch: [24][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4632 (1.5214)\tAcc@1 59.375 (57.178)\tAcc@5 89.062 (85.878)\n",
            "Epoch: [24][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3191 (1.5285)\tAcc@1 65.625 (56.972)\tAcc@5 87.500 (85.864)\n",
            " * Acc@1 56.880 Acc@5 85.862\n",
            "epoch 24, total time 39.85\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.0379 (2.0379)\tAcc@1 56.250 (56.250)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.0295 (1.9235)\tAcc@1 40.625 (50.186)\tAcc@5 78.125 (81.250)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.5611 (1.9265)\tAcc@1 59.375 (49.922)\tAcc@5 84.375 (81.079)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.5417 (1.9480)\tAcc@1 37.500 (49.772)\tAcc@5 78.125 (80.544)\n",
            " * Acc@1 49.740 Acc@5 80.560\n",
            "==> training...\n",
            "Epoch: [25][0/782]\tTime 0.273 (0.273)\tData 0.191 (0.191)\tLoss 1.3882 (1.3882)\tAcc@1 59.375 (59.375)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [25][100/782]\tTime 0.058 (0.054)\tData 0.001 (0.003)\tLoss 1.4593 (1.4788)\tAcc@1 54.688 (58.106)\tAcc@5 85.938 (86.618)\n",
            "Epoch: [25][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2818 (1.4683)\tAcc@1 57.812 (58.147)\tAcc@5 96.875 (86.940)\n",
            "Epoch: [25][300/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 1.1729 (1.4662)\tAcc@1 67.188 (58.025)\tAcc@5 89.062 (86.981)\n",
            "Epoch: [25][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5524 (1.4830)\tAcc@1 54.688 (57.727)\tAcc@5 81.250 (86.600)\n",
            "Epoch: [25][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4670 (1.4929)\tAcc@1 54.688 (57.547)\tAcc@5 90.625 (86.477)\n",
            "Epoch: [25][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6687 (1.5013)\tAcc@1 53.125 (57.285)\tAcc@5 78.125 (86.403)\n",
            "Epoch: [25][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6061 (1.5131)\tAcc@1 48.438 (57.110)\tAcc@5 85.938 (86.245)\n",
            " * Acc@1 57.098 Acc@5 86.198\n",
            "epoch 25, total time 39.79\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.6362 (1.6362)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.7176 (1.8039)\tAcc@1 46.875 (50.990)\tAcc@5 93.750 (81.126)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.2170 (1.8163)\tAcc@1 62.500 (50.513)\tAcc@5 96.875 (81.468)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.5361 (1.8327)\tAcc@1 34.375 (50.623)\tAcc@5 71.875 (80.990)\n",
            " * Acc@1 50.660 Acc@5 80.970\n",
            "==> training...\n",
            "Epoch: [26][0/782]\tTime 0.249 (0.249)\tData 0.178 (0.178)\tLoss 1.6675 (1.6675)\tAcc@1 56.250 (56.250)\tAcc@5 79.688 (79.688)\n",
            "Epoch: [26][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 1.4498 (1.4721)\tAcc@1 60.938 (57.921)\tAcc@5 89.062 (86.989)\n",
            "Epoch: [26][200/782]\tTime 0.056 (0.052)\tData 0.001 (0.002)\tLoss 1.7213 (1.4738)\tAcc@1 48.438 (57.867)\tAcc@5 82.812 (86.692)\n",
            "Epoch: [26][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3328 (1.4742)\tAcc@1 65.625 (58.020)\tAcc@5 87.500 (86.602)\n",
            "Epoch: [26][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4707 (1.4775)\tAcc@1 56.250 (57.789)\tAcc@5 89.062 (86.580)\n",
            "Epoch: [26][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3995 (1.4849)\tAcc@1 59.375 (57.772)\tAcc@5 84.375 (86.511)\n",
            "Epoch: [26][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6760 (1.4913)\tAcc@1 57.812 (57.573)\tAcc@5 84.375 (86.434)\n",
            "Epoch: [26][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4330 (1.4993)\tAcc@1 62.500 (57.456)\tAcc@5 89.062 (86.341)\n",
            " * Acc@1 57.302 Acc@5 86.270\n",
            "epoch 26, total time 40.00\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.6468 (1.6468)\tAcc@1 65.625 (65.625)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.9982 (1.8475)\tAcc@1 43.750 (51.423)\tAcc@5 81.250 (81.621)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.0327 (1.8475)\tAcc@1 62.500 (51.555)\tAcc@5 96.875 (81.623)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.9307 (1.8568)\tAcc@1 46.875 (51.755)\tAcc@5 87.500 (81.728)\n",
            " * Acc@1 51.760 Acc@5 81.720\n",
            "==> training...\n",
            "Epoch: [27][0/782]\tTime 0.267 (0.267)\tData 0.185 (0.185)\tLoss 1.3655 (1.3655)\tAcc@1 56.250 (56.250)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [27][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.8804 (1.4239)\tAcc@1 42.188 (58.957)\tAcc@5 84.375 (87.407)\n",
            "Epoch: [27][200/782]\tTime 0.048 (0.052)\tData 0.001 (0.002)\tLoss 1.2909 (1.4339)\tAcc@1 62.500 (58.784)\tAcc@5 92.188 (87.484)\n",
            "Epoch: [27][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3739 (1.4470)\tAcc@1 54.688 (58.503)\tAcc@5 87.500 (87.251)\n",
            "Epoch: [27][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7723 (1.4648)\tAcc@1 51.562 (58.144)\tAcc@5 78.125 (87.036)\n",
            "Epoch: [27][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6062 (1.4745)\tAcc@1 57.812 (58.037)\tAcc@5 76.562 (86.829)\n",
            "Epoch: [27][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7420 (1.4780)\tAcc@1 43.750 (57.870)\tAcc@5 82.812 (86.788)\n",
            "Epoch: [27][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 1.7283 (1.4847)\tAcc@1 56.250 (57.770)\tAcc@5 84.375 (86.691)\n",
            " * Acc@1 57.682 Acc@5 86.612\n",
            "epoch 27, total time 39.64\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.5431 (1.5431)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.7400 (1.9432)\tAcc@1 50.000 (48.267)\tAcc@5 84.375 (79.239)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.6502 (1.9551)\tAcc@1 50.000 (48.134)\tAcc@5 84.375 (79.213)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.2504 (1.9725)\tAcc@1 40.625 (48.328)\tAcc@5 84.375 (79.018)\n",
            " * Acc@1 48.280 Acc@5 79.020\n",
            "==> training...\n",
            "Epoch: [28][0/782]\tTime 0.272 (0.272)\tData 0.187 (0.187)\tLoss 1.4626 (1.4626)\tAcc@1 60.938 (60.938)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [28][100/782]\tTime 0.049 (0.052)\tData 0.001 (0.003)\tLoss 1.6405 (1.4484)\tAcc@1 56.250 (58.478)\tAcc@5 85.938 (87.283)\n",
            "Epoch: [28][200/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4339 (1.4475)\tAcc@1 57.812 (58.567)\tAcc@5 89.062 (87.376)\n",
            "Epoch: [28][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1297 (1.4420)\tAcc@1 71.875 (58.923)\tAcc@5 90.625 (87.396)\n",
            "Epoch: [28][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7454 (1.4559)\tAcc@1 56.250 (58.646)\tAcc@5 79.688 (87.138)\n",
            "Epoch: [28][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.7024 (1.4636)\tAcc@1 46.875 (58.293)\tAcc@5 82.812 (87.107)\n",
            "Epoch: [28][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6521 (1.4690)\tAcc@1 57.812 (58.228)\tAcc@5 84.375 (86.962)\n",
            "Epoch: [28][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2042 (1.4791)\tAcc@1 65.625 (57.995)\tAcc@5 92.188 (86.729)\n",
            " * Acc@1 57.986 Acc@5 86.722\n",
            "epoch 28, total time 39.89\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.2648 (2.2648)\tAcc@1 53.125 (53.125)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 2.0389 (2.0479)\tAcc@1 40.625 (48.422)\tAcc@5 84.375 (77.908)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 1.6926 (2.0502)\tAcc@1 59.375 (47.699)\tAcc@5 71.875 (77.254)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 2.1683 (2.0588)\tAcc@1 46.875 (47.539)\tAcc@5 84.375 (77.035)\n",
            " * Acc@1 47.580 Acc@5 76.970\n",
            "==> training...\n",
            "Epoch: [29][0/782]\tTime 0.270 (0.270)\tData 0.176 (0.176)\tLoss 1.3276 (1.3276)\tAcc@1 60.938 (60.938)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [29][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.6401 (1.4280)\tAcc@1 51.562 (59.127)\tAcc@5 81.250 (87.624)\n",
            "Epoch: [29][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.6079 (1.4341)\tAcc@1 56.250 (59.196)\tAcc@5 89.062 (87.516)\n",
            "Epoch: [29][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5688 (1.4422)\tAcc@1 57.812 (58.944)\tAcc@5 87.500 (87.355)\n",
            "Epoch: [29][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3363 (1.4506)\tAcc@1 54.688 (58.627)\tAcc@5 93.750 (87.184)\n",
            "Epoch: [29][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4676 (1.4647)\tAcc@1 50.000 (58.249)\tAcc@5 92.188 (86.979)\n",
            "Epoch: [29][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2998 (1.4720)\tAcc@1 62.500 (57.984)\tAcc@5 87.500 (86.876)\n",
            "Epoch: [29][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2294 (1.4779)\tAcc@1 71.875 (57.886)\tAcc@5 92.188 (86.760)\n",
            " * Acc@1 57.726 Acc@5 86.638\n",
            "epoch 29, total time 40.04\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 2.2841 (2.2841)\tAcc@1 56.250 (56.250)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 2.4070 (2.1676)\tAcc@1 46.875 (45.916)\tAcc@5 78.125 (75.650)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.6927 (2.1623)\tAcc@1 43.750 (45.569)\tAcc@5 84.375 (75.622)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.2083 (2.1603)\tAcc@1 40.625 (45.681)\tAcc@5 78.125 (75.758)\n",
            " * Acc@1 45.710 Acc@5 75.670\n",
            "==> training...\n",
            "Epoch: [30][0/782]\tTime 0.261 (0.261)\tData 0.189 (0.189)\tLoss 1.8900 (1.8900)\tAcc@1 45.312 (45.312)\tAcc@5 78.125 (78.125)\n",
            "Epoch: [30][100/782]\tTime 0.051 (0.056)\tData 0.001 (0.003)\tLoss 1.2514 (1.4413)\tAcc@1 65.625 (59.097)\tAcc@5 82.812 (87.237)\n",
            "Epoch: [30][200/782]\tTime 0.050 (0.054)\tData 0.001 (0.002)\tLoss 1.2179 (1.4364)\tAcc@1 64.062 (59.305)\tAcc@5 92.188 (87.407)\n",
            "Epoch: [30][300/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.0112 (1.4371)\tAcc@1 68.750 (59.385)\tAcc@5 92.188 (87.266)\n",
            "Epoch: [30][400/782]\tTime 0.054 (0.053)\tData 0.001 (0.002)\tLoss 1.2463 (1.4445)\tAcc@1 59.375 (59.075)\tAcc@5 85.938 (87.278)\n",
            "Epoch: [30][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3445 (1.4492)\tAcc@1 60.938 (58.948)\tAcc@5 89.062 (87.250)\n",
            "Epoch: [30][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2909 (1.4603)\tAcc@1 68.750 (58.561)\tAcc@5 85.938 (87.146)\n",
            "Epoch: [30][700/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.5331 (1.4649)\tAcc@1 60.938 (58.470)\tAcc@5 84.375 (87.085)\n",
            " * Acc@1 58.390 Acc@5 87.046\n",
            "epoch 30, total time 40.58\n",
            "Test: [0/313]\tTime 0.126 (0.126)\tLoss 2.8611 (2.8611)\tAcc@1 56.250 (56.250)\tAcc@5 65.625 (65.625)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 3.4670 (2.1779)\tAcc@1 25.000 (47.246)\tAcc@5 56.250 (75.928)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.5693 (2.1871)\tAcc@1 59.375 (46.455)\tAcc@5 81.250 (75.871)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.7536 (2.1832)\tAcc@1 37.500 (46.532)\tAcc@5 75.000 (75.924)\n",
            " * Acc@1 46.700 Acc@5 76.050\n",
            "==> training...\n",
            "Epoch: [31][0/782]\tTime 0.268 (0.268)\tData 0.195 (0.195)\tLoss 1.5939 (1.5939)\tAcc@1 54.688 (54.688)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [31][100/782]\tTime 0.051 (0.054)\tData 0.002 (0.003)\tLoss 1.2395 (1.4352)\tAcc@1 68.750 (59.158)\tAcc@5 90.625 (87.314)\n",
            "Epoch: [31][200/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.3683 (1.4145)\tAcc@1 56.250 (59.795)\tAcc@5 89.062 (87.640)\n",
            "Epoch: [31][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3363 (1.4333)\tAcc@1 62.500 (59.302)\tAcc@5 89.062 (87.484)\n",
            "Epoch: [31][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.4948 (1.4455)\tAcc@1 60.938 (59.055)\tAcc@5 85.938 (87.231)\n",
            "Epoch: [31][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3199 (1.4432)\tAcc@1 62.500 (58.976)\tAcc@5 87.500 (87.285)\n",
            "Epoch: [31][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.8069 (1.4566)\tAcc@1 51.562 (58.670)\tAcc@5 87.500 (87.097)\n",
            "Epoch: [31][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5851 (1.4617)\tAcc@1 54.688 (58.555)\tAcc@5 82.812 (87.034)\n",
            " * Acc@1 58.450 Acc@5 86.982\n",
            "epoch 31, total time 39.81\n",
            "Test: [0/313]\tTime 0.130 (0.130)\tLoss 1.8229 (1.8229)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 2.1126 (1.6944)\tAcc@1 37.500 (54.022)\tAcc@5 84.375 (84.220)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.3046 (1.6984)\tAcc@1 59.375 (53.809)\tAcc@5 90.625 (84.173)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0325 (1.7116)\tAcc@1 46.875 (53.551)\tAcc@5 87.500 (83.752)\n",
            " * Acc@1 53.530 Acc@5 83.700\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [32][0/782]\tTime 0.279 (0.279)\tData 0.194 (0.194)\tLoss 1.6383 (1.6383)\tAcc@1 60.938 (60.938)\tAcc@5 79.688 (79.688)\n",
            "Epoch: [32][100/782]\tTime 0.049 (0.052)\tData 0.001 (0.003)\tLoss 1.0252 (1.4046)\tAcc@1 70.312 (60.179)\tAcc@5 96.875 (87.701)\n",
            "Epoch: [32][200/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2154 (1.4126)\tAcc@1 59.375 (59.663)\tAcc@5 90.625 (87.725)\n",
            "Epoch: [32][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.7322 (1.4363)\tAcc@1 54.688 (59.001)\tAcc@5 85.938 (87.360)\n",
            "Epoch: [32][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5218 (1.4444)\tAcc@1 62.500 (59.017)\tAcc@5 85.938 (87.282)\n",
            "Epoch: [32][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5598 (1.4565)\tAcc@1 51.562 (58.645)\tAcc@5 84.375 (87.054)\n",
            "Epoch: [32][600/782]\tTime 0.051 (0.050)\tData 0.001 (0.002)\tLoss 1.3641 (1.4561)\tAcc@1 59.375 (58.660)\tAcc@5 82.812 (87.009)\n",
            "Epoch: [32][700/782]\tTime 0.050 (0.050)\tData 0.001 (0.002)\tLoss 1.9395 (1.4563)\tAcc@1 51.562 (58.602)\tAcc@5 68.750 (86.996)\n",
            " * Acc@1 58.600 Acc@5 86.998\n",
            "epoch 32, total time 39.43\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 2.0726 (2.0726)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.8989 (1.7032)\tAcc@1 40.625 (53.620)\tAcc@5 93.750 (82.457)\n",
            "Test: [200/313]\tTime 0.025 (0.020)\tLoss 1.5183 (1.7249)\tAcc@1 56.250 (53.218)\tAcc@5 84.375 (82.447)\n",
            "Test: [300/313]\tTime 0.018 (0.020)\tLoss 2.3258 (1.7535)\tAcc@1 43.750 (52.668)\tAcc@5 87.500 (81.914)\n",
            " * Acc@1 52.550 Acc@5 81.860\n",
            "==> training...\n",
            "Epoch: [33][0/782]\tTime 0.266 (0.266)\tData 0.191 (0.191)\tLoss 1.2661 (1.2661)\tAcc@1 59.375 (59.375)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [33][100/782]\tTime 0.055 (0.052)\tData 0.001 (0.003)\tLoss 1.3597 (1.4187)\tAcc@1 62.500 (59.236)\tAcc@5 85.938 (87.670)\n",
            "Epoch: [33][200/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3877 (1.4188)\tAcc@1 64.062 (59.414)\tAcc@5 89.062 (87.710)\n",
            "Epoch: [33][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4232 (1.4210)\tAcc@1 62.500 (59.510)\tAcc@5 87.500 (87.567)\n",
            "Epoch: [33][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3878 (1.4440)\tAcc@1 59.375 (58.911)\tAcc@5 84.375 (87.332)\n",
            "Epoch: [33][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.8172 (1.4458)\tAcc@1 46.875 (58.826)\tAcc@5 81.250 (87.297)\n",
            "Epoch: [33][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4215 (1.4491)\tAcc@1 56.250 (58.720)\tAcc@5 89.062 (87.232)\n",
            "Epoch: [33][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6794 (1.4524)\tAcc@1 56.250 (58.775)\tAcc@5 82.812 (87.112)\n",
            " * Acc@1 58.768 Acc@5 87.062\n",
            "epoch 33, total time 39.54\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.1196 (2.1196)\tAcc@1 43.750 (43.750)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.1940 (1.9918)\tAcc@1 40.625 (48.639)\tAcc@5 78.125 (79.301)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.6024 (1.9442)\tAcc@1 53.125 (49.254)\tAcc@5 78.125 (80.177)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.6935 (1.9495)\tAcc@1 37.500 (49.273)\tAcc@5 75.000 (79.890)\n",
            " * Acc@1 49.290 Acc@5 79.970\n",
            "==> training...\n",
            "Epoch: [34][0/782]\tTime 0.279 (0.279)\tData 0.197 (0.197)\tLoss 1.4699 (1.4699)\tAcc@1 57.812 (57.812)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [34][100/782]\tTime 0.051 (0.054)\tData 0.002 (0.003)\tLoss 1.3458 (1.4036)\tAcc@1 54.688 (59.344)\tAcc@5 87.500 (88.289)\n",
            "Epoch: [34][200/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.4744 (1.4252)\tAcc@1 54.688 (58.924)\tAcc@5 85.938 (87.834)\n",
            "Epoch: [34][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3481 (1.4197)\tAcc@1 64.062 (59.173)\tAcc@5 85.938 (87.832)\n",
            "Epoch: [34][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4717 (1.4231)\tAcc@1 60.938 (59.165)\tAcc@5 87.500 (87.726)\n",
            "Epoch: [34][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.5873 (1.4277)\tAcc@1 57.812 (59.125)\tAcc@5 76.562 (87.656)\n",
            "Epoch: [34][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3576 (1.4266)\tAcc@1 62.500 (59.245)\tAcc@5 89.062 (87.666)\n",
            "Epoch: [34][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6554 (1.4349)\tAcc@1 56.250 (59.070)\tAcc@5 81.250 (87.516)\n",
            " * Acc@1 58.924 Acc@5 87.398\n",
            "epoch 34, total time 40.04\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 2.1560 (2.1560)\tAcc@1 46.875 (46.875)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.019 (0.020)\tLoss 2.0480 (1.8789)\tAcc@1 37.500 (50.835)\tAcc@5 84.375 (79.579)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.5790 (1.8716)\tAcc@1 53.125 (50.871)\tAcc@5 84.375 (79.649)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.4202 (1.8759)\tAcc@1 34.375 (50.882)\tAcc@5 81.250 (79.662)\n",
            " * Acc@1 50.980 Acc@5 79.660\n",
            "==> training...\n",
            "Epoch: [35][0/782]\tTime 0.259 (0.259)\tData 0.187 (0.187)\tLoss 1.6706 (1.6706)\tAcc@1 54.688 (54.688)\tAcc@5 82.812 (82.812)\n",
            "Epoch: [35][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.3786 (1.3662)\tAcc@1 64.062 (60.938)\tAcc@5 85.938 (88.459)\n",
            "Epoch: [35][200/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.5907 (1.4027)\tAcc@1 54.688 (59.748)\tAcc@5 87.500 (88.060)\n",
            "Epoch: [35][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4780 (1.4211)\tAcc@1 60.938 (59.370)\tAcc@5 79.688 (87.687)\n",
            "Epoch: [35][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.5096 (1.4224)\tAcc@1 53.125 (59.324)\tAcc@5 82.812 (87.629)\n",
            "Epoch: [35][500/782]\tTime 0.048 (0.052)\tData 0.001 (0.002)\tLoss 1.4714 (1.4205)\tAcc@1 62.500 (59.447)\tAcc@5 85.938 (87.653)\n",
            "Epoch: [35][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4372 (1.4321)\tAcc@1 59.375 (59.185)\tAcc@5 84.375 (87.440)\n",
            "Epoch: [35][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4893 (1.4363)\tAcc@1 54.688 (59.206)\tAcc@5 87.500 (87.402)\n",
            " * Acc@1 59.240 Acc@5 87.478\n",
            "epoch 35, total time 40.07\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.8111 (1.8111)\tAcc@1 65.625 (65.625)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.7080 (1.8910)\tAcc@1 40.625 (50.433)\tAcc@5 90.625 (80.353)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.4337 (1.9367)\tAcc@1 46.875 (49.938)\tAcc@5 93.750 (80.100)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.0732 (1.9534)\tAcc@1 50.000 (49.522)\tAcc@5 78.125 (80.004)\n",
            " * Acc@1 49.540 Acc@5 80.010\n",
            "==> training...\n",
            "Epoch: [36][0/782]\tTime 0.278 (0.278)\tData 0.196 (0.196)\tLoss 1.2570 (1.2570)\tAcc@1 64.062 (64.062)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [36][100/782]\tTime 0.053 (0.053)\tData 0.001 (0.003)\tLoss 1.3605 (1.4197)\tAcc@1 60.938 (59.329)\tAcc@5 90.625 (87.314)\n",
            "Epoch: [36][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3461 (1.3993)\tAcc@1 59.375 (60.137)\tAcc@5 89.062 (87.687)\n",
            "Epoch: [36][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3673 (1.4051)\tAcc@1 62.500 (60.013)\tAcc@5 82.812 (87.775)\n",
            "Epoch: [36][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.1960 (1.4153)\tAcc@1 60.938 (59.811)\tAcc@5 93.750 (87.742)\n",
            "Epoch: [36][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3002 (1.4227)\tAcc@1 62.500 (59.550)\tAcc@5 87.500 (87.609)\n",
            "Epoch: [36][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3145 (1.4251)\tAcc@1 62.500 (59.458)\tAcc@5 87.500 (87.609)\n",
            "Epoch: [36][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7709 (1.4318)\tAcc@1 56.250 (59.375)\tAcc@5 82.812 (87.525)\n",
            " * Acc@1 59.328 Acc@5 87.444\n",
            "epoch 36, total time 39.82\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.5695 (1.5695)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.9932 (1.9291)\tAcc@1 43.750 (51.423)\tAcc@5 78.125 (80.136)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.8176 (1.8848)\tAcc@1 59.375 (51.555)\tAcc@5 78.125 (80.473)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0544 (1.8945)\tAcc@1 43.750 (51.350)\tAcc@5 81.250 (80.378)\n",
            " * Acc@1 51.330 Acc@5 80.380\n",
            "==> training...\n",
            "Epoch: [37][0/782]\tTime 0.267 (0.267)\tData 0.185 (0.185)\tLoss 1.7485 (1.7485)\tAcc@1 43.750 (43.750)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [37][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.6778 (1.3764)\tAcc@1 54.688 (60.334)\tAcc@5 84.375 (88.490)\n",
            "Epoch: [37][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.6372 (1.3824)\tAcc@1 56.250 (60.285)\tAcc@5 79.688 (88.441)\n",
            "Epoch: [37][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5894 (1.3958)\tAcc@1 56.250 (59.956)\tAcc@5 84.375 (88.351)\n",
            "Epoch: [37][400/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.3965 (1.4055)\tAcc@1 59.375 (59.613)\tAcc@5 87.500 (88.116)\n",
            "Epoch: [37][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4314 (1.4254)\tAcc@1 70.312 (59.210)\tAcc@5 84.375 (87.675)\n",
            "Epoch: [37][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.7099 (1.4305)\tAcc@1 48.438 (59.193)\tAcc@5 75.000 (87.588)\n",
            "Epoch: [37][700/782]\tTime 0.060 (0.051)\tData 0.001 (0.002)\tLoss 1.4899 (1.4338)\tAcc@1 57.812 (59.101)\tAcc@5 81.250 (87.489)\n",
            " * Acc@1 58.994 Acc@5 87.386\n",
            "epoch 37, total time 39.93\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.2268 (2.2268)\tAcc@1 56.250 (56.250)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.8242 (1.7529)\tAcc@1 53.125 (53.465)\tAcc@5 81.250 (82.550)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.5313 (1.7811)\tAcc@1 56.250 (52.488)\tAcc@5 81.250 (81.950)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.5148 (1.7784)\tAcc@1 59.375 (52.689)\tAcc@5 87.500 (81.998)\n",
            " * Acc@1 52.730 Acc@5 81.940\n",
            "==> training...\n",
            "Epoch: [38][0/782]\tTime 0.282 (0.282)\tData 0.199 (0.199)\tLoss 1.1566 (1.1566)\tAcc@1 64.062 (64.062)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [38][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.6776 (1.3942)\tAcc@1 54.688 (59.267)\tAcc@5 84.375 (88.304)\n",
            "Epoch: [38][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4458 (1.3865)\tAcc@1 57.812 (59.919)\tAcc@5 85.938 (88.456)\n",
            "Epoch: [38][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5331 (1.3968)\tAcc@1 50.000 (59.951)\tAcc@5 87.500 (88.154)\n",
            "Epoch: [38][400/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.4183 (1.4174)\tAcc@1 57.812 (59.535)\tAcc@5 89.062 (87.757)\n",
            "Epoch: [38][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2077 (1.4070)\tAcc@1 64.062 (59.911)\tAcc@5 89.062 (87.921)\n",
            "Epoch: [38][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5138 (1.4154)\tAcc@1 57.812 (59.783)\tAcc@5 87.500 (87.750)\n",
            "Epoch: [38][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.6120 (1.4206)\tAcc@1 54.688 (59.649)\tAcc@5 85.938 (87.603)\n",
            " * Acc@1 59.610 Acc@5 87.516\n",
            "epoch 38, total time 39.67\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.6261 (1.6261)\tAcc@1 65.625 (65.625)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.1566 (1.7348)\tAcc@1 53.125 (52.661)\tAcc@5 87.500 (82.921)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.6035 (1.7485)\tAcc@1 53.125 (52.534)\tAcc@5 90.625 (83.256)\n",
            "Test: [300/313]\tTime 0.022 (0.018)\tLoss 2.1517 (1.7613)\tAcc@1 53.125 (52.585)\tAcc@5 87.500 (83.088)\n",
            " * Acc@1 52.660 Acc@5 83.100\n",
            "==> training...\n",
            "Epoch: [39][0/782]\tTime 0.278 (0.278)\tData 0.195 (0.195)\tLoss 1.3985 (1.3985)\tAcc@1 59.375 (59.375)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [39][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.2616 (1.4034)\tAcc@1 65.625 (59.653)\tAcc@5 92.188 (88.258)\n",
            "Epoch: [39][200/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.6955 (1.4017)\tAcc@1 59.375 (59.849)\tAcc@5 76.562 (87.896)\n",
            "Epoch: [39][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3734 (1.3984)\tAcc@1 59.375 (59.879)\tAcc@5 89.062 (87.858)\n",
            "Epoch: [39][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1326 (1.4092)\tAcc@1 70.312 (59.656)\tAcc@5 90.625 (87.695)\n",
            "Epoch: [39][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6183 (1.4097)\tAcc@1 56.250 (59.731)\tAcc@5 81.250 (87.746)\n",
            "Epoch: [39][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5958 (1.4216)\tAcc@1 64.062 (59.513)\tAcc@5 89.062 (87.529)\n",
            "Epoch: [39][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6636 (1.4241)\tAcc@1 57.812 (59.428)\tAcc@5 84.375 (87.531)\n",
            " * Acc@1 59.422 Acc@5 87.600\n",
            "epoch 39, total time 39.71\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 2.2596 (2.2596)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.8713 (2.1812)\tAcc@1 53.125 (46.287)\tAcc@5 81.250 (77.104)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.8799 (2.1383)\tAcc@1 53.125 (47.217)\tAcc@5 84.375 (77.612)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.5790 (2.1423)\tAcc@1 34.375 (47.031)\tAcc@5 78.125 (77.357)\n",
            " * Acc@1 47.090 Acc@5 77.350\n",
            "==> training...\n",
            "Epoch: [40][0/782]\tTime 0.293 (0.293)\tData 0.204 (0.204)\tLoss 1.1724 (1.1724)\tAcc@1 65.625 (65.625)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [40][100/782]\tTime 0.049 (0.052)\tData 0.001 (0.003)\tLoss 0.9081 (1.3483)\tAcc@1 73.438 (61.355)\tAcc@5 96.875 (89.001)\n",
            "Epoch: [40][200/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.1524 (1.3617)\tAcc@1 67.188 (61.272)\tAcc@5 92.188 (88.495)\n",
            "Epoch: [40][300/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.5524 (1.3886)\tAcc@1 57.812 (60.673)\tAcc@5 85.938 (88.050)\n",
            "Epoch: [40][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4899 (1.3886)\tAcc@1 60.938 (60.595)\tAcc@5 84.375 (87.979)\n",
            "Epoch: [40][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5393 (1.3950)\tAcc@1 56.250 (60.526)\tAcc@5 87.500 (87.921)\n",
            "Epoch: [40][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.5162 (1.3999)\tAcc@1 53.125 (60.407)\tAcc@5 89.062 (87.848)\n",
            "Epoch: [40][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.0666 (1.4064)\tAcc@1 68.750 (60.211)\tAcc@5 95.312 (87.819)\n",
            " * Acc@1 60.002 Acc@5 87.718\n",
            "epoch 40, total time 39.75\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 1.7729 (1.7729)\tAcc@1 56.250 (56.250)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.7689 (1.6551)\tAcc@1 43.750 (54.641)\tAcc@5 90.625 (83.725)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.4407 (1.6717)\tAcc@1 62.500 (54.120)\tAcc@5 81.250 (83.396)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.1374 (1.6703)\tAcc@1 37.500 (54.174)\tAcc@5 84.375 (83.368)\n",
            " * Acc@1 54.250 Acc@5 83.490\n",
            "saving the best model!\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [41][0/782]\tTime 0.284 (0.284)\tData 0.211 (0.211)\tLoss 1.2685 (1.2685)\tAcc@1 65.625 (65.625)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [41][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.3222 (1.3665)\tAcc@1 65.625 (60.721)\tAcc@5 89.062 (89.124)\n",
            "Epoch: [41][200/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2382 (1.3736)\tAcc@1 68.750 (60.914)\tAcc@5 93.750 (88.596)\n",
            "Epoch: [41][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3912 (1.3902)\tAcc@1 54.688 (60.662)\tAcc@5 92.188 (88.133)\n",
            "Epoch: [41][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5331 (1.3947)\tAcc@1 53.125 (60.489)\tAcc@5 85.938 (88.010)\n",
            "Epoch: [41][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5459 (1.4036)\tAcc@1 56.250 (60.220)\tAcc@5 85.938 (87.799)\n",
            "Epoch: [41][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4966 (1.4085)\tAcc@1 57.812 (60.033)\tAcc@5 84.375 (87.698)\n",
            "Epoch: [41][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2740 (1.4112)\tAcc@1 68.750 (59.955)\tAcc@5 92.188 (87.718)\n",
            " * Acc@1 59.798 Acc@5 87.782\n",
            "epoch 41, total time 39.65\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 1.5686 (1.5686)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.025 (0.021)\tLoss 2.1646 (2.0660)\tAcc@1 40.625 (47.710)\tAcc@5 81.250 (77.599)\n",
            "Test: [200/313]\tTime 0.024 (0.020)\tLoss 2.0298 (2.0809)\tAcc@1 56.250 (47.544)\tAcc@5 78.125 (77.861)\n",
            "Test: [300/313]\tTime 0.024 (0.020)\tLoss 2.6629 (2.0734)\tAcc@1 40.625 (47.643)\tAcc@5 68.750 (78.156)\n",
            " * Acc@1 47.750 Acc@5 78.240\n",
            "==> training...\n",
            "Epoch: [42][0/782]\tTime 0.270 (0.270)\tData 0.192 (0.192)\tLoss 1.3066 (1.3066)\tAcc@1 60.938 (60.938)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [42][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.2365 (1.3513)\tAcc@1 62.500 (61.649)\tAcc@5 90.625 (88.830)\n",
            "Epoch: [42][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2809 (1.3649)\tAcc@1 62.500 (61.039)\tAcc@5 87.500 (88.456)\n",
            "Epoch: [42][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.7455 (1.3814)\tAcc@1 51.562 (60.491)\tAcc@5 87.500 (88.253)\n",
            "Epoch: [42][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2496 (1.3919)\tAcc@1 65.625 (60.185)\tAcc@5 87.500 (88.213)\n",
            "Epoch: [42][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2155 (1.4043)\tAcc@1 65.625 (59.855)\tAcc@5 92.188 (88.064)\n",
            "Epoch: [42][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1451 (1.4058)\tAcc@1 68.750 (59.913)\tAcc@5 93.750 (88.054)\n",
            "Epoch: [42][700/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.5871 (1.4117)\tAcc@1 59.375 (59.830)\tAcc@5 82.812 (87.946)\n",
            " * Acc@1 59.822 Acc@5 87.858\n",
            "epoch 42, total time 40.11\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 2.2132 (2.2132)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 2.3049 (1.9054)\tAcc@1 43.750 (52.351)\tAcc@5 81.250 (80.972)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.2553 (1.9174)\tAcc@1 68.750 (52.068)\tAcc@5 87.500 (80.877)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.6706 (1.9097)\tAcc@1 50.000 (52.056)\tAcc@5 93.750 (81.032)\n",
            " * Acc@1 52.030 Acc@5 81.050\n",
            "==> training...\n",
            "Epoch: [43][0/782]\tTime 0.293 (0.293)\tData 0.200 (0.200)\tLoss 1.4547 (1.4547)\tAcc@1 57.812 (57.812)\tAcc@5 82.812 (82.812)\n",
            "Epoch: [43][100/782]\tTime 0.051 (0.054)\tData 0.002 (0.003)\tLoss 1.1823 (1.3666)\tAcc@1 62.500 (61.015)\tAcc@5 92.188 (88.134)\n",
            "Epoch: [43][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4161 (1.3959)\tAcc@1 53.125 (60.393)\tAcc@5 90.625 (87.780)\n",
            "Epoch: [43][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2432 (1.3940)\tAcc@1 62.500 (60.507)\tAcc@5 89.062 (87.962)\n",
            "Epoch: [43][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6646 (1.3900)\tAcc@1 50.000 (60.571)\tAcc@5 84.375 (88.084)\n",
            "Epoch: [43][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5459 (1.3956)\tAcc@1 54.688 (60.417)\tAcc@5 90.625 (88.068)\n",
            "Epoch: [43][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2502 (1.4000)\tAcc@1 62.500 (60.316)\tAcc@5 90.625 (88.010)\n",
            "Epoch: [43][700/782]\tTime 0.054 (0.051)\tData 0.002 (0.002)\tLoss 1.6897 (1.4043)\tAcc@1 48.438 (60.175)\tAcc@5 82.812 (87.964)\n",
            " * Acc@1 60.080 Acc@5 87.926\n",
            "epoch 43, total time 40.14\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 2.0459 (2.0459)\tAcc@1 46.875 (46.875)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.024 (0.020)\tLoss 2.2237 (1.8629)\tAcc@1 37.500 (49.443)\tAcc@5 78.125 (80.600)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.4980 (1.8588)\tAcc@1 50.000 (49.549)\tAcc@5 87.500 (81.017)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.9820 (1.8734)\tAcc@1 43.750 (49.491)\tAcc@5 81.250 (80.793)\n",
            " * Acc@1 49.530 Acc@5 80.800\n",
            "==> training...\n",
            "Epoch: [44][0/782]\tTime 0.282 (0.282)\tData 0.199 (0.199)\tLoss 1.2813 (1.2813)\tAcc@1 59.375 (59.375)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [44][100/782]\tTime 0.054 (0.054)\tData 0.002 (0.003)\tLoss 1.4496 (1.3337)\tAcc@1 56.250 (62.082)\tAcc@5 87.500 (89.186)\n",
            "Epoch: [44][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2045 (1.3713)\tAcc@1 70.312 (61.303)\tAcc@5 89.062 (88.448)\n",
            "Epoch: [44][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1525 (1.3801)\tAcc@1 65.625 (60.932)\tAcc@5 92.188 (88.434)\n",
            "Epoch: [44][400/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.1662 (1.3851)\tAcc@1 76.562 (60.895)\tAcc@5 93.750 (88.272)\n",
            "Epoch: [44][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.4544 (1.3820)\tAcc@1 57.812 (60.878)\tAcc@5 82.812 (88.370)\n",
            "Epoch: [44][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3331 (1.3925)\tAcc@1 59.375 (60.493)\tAcc@5 93.750 (88.202)\n",
            "Epoch: [44][700/782]\tTime 0.053 (0.052)\tData 0.002 (0.002)\tLoss 1.0831 (1.3943)\tAcc@1 67.188 (60.425)\tAcc@5 92.188 (88.151)\n",
            " * Acc@1 60.290 Acc@5 88.044\n",
            "epoch 44, total time 40.62\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 2.0301 (2.0301)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.9310 (1.8314)\tAcc@1 50.000 (52.135)\tAcc@5 81.250 (80.941)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 1.6593 (1.8236)\tAcc@1 56.250 (52.192)\tAcc@5 84.375 (80.939)\n",
            "Test: [300/313]\tTime 0.018 (0.020)\tLoss 2.0344 (1.8348)\tAcc@1 40.625 (52.315)\tAcc@5 81.250 (80.731)\n",
            " * Acc@1 52.220 Acc@5 80.650\n",
            "==> training...\n",
            "Epoch: [45][0/782]\tTime 0.272 (0.272)\tData 0.186 (0.186)\tLoss 1.1627 (1.1627)\tAcc@1 68.750 (68.750)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [45][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.3866 (1.3179)\tAcc@1 57.812 (62.392)\tAcc@5 90.625 (88.722)\n",
            "Epoch: [45][200/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.0920 (1.3437)\tAcc@1 70.312 (61.419)\tAcc@5 92.188 (88.643)\n",
            "Epoch: [45][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4464 (1.3695)\tAcc@1 65.625 (60.854)\tAcc@5 87.500 (88.434)\n",
            "Epoch: [45][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4938 (1.3796)\tAcc@1 59.375 (60.583)\tAcc@5 82.812 (88.233)\n",
            "Epoch: [45][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.1263 (1.3889)\tAcc@1 71.875 (60.336)\tAcc@5 87.500 (88.089)\n",
            "Epoch: [45][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2280 (1.3909)\tAcc@1 64.062 (60.373)\tAcc@5 89.062 (88.020)\n",
            "Epoch: [45][700/782]\tTime 0.055 (0.051)\tData 0.002 (0.002)\tLoss 1.4248 (1.3949)\tAcc@1 60.938 (60.284)\tAcc@5 89.062 (87.988)\n",
            " * Acc@1 60.128 Acc@5 87.880\n",
            "epoch 45, total time 39.75\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 2.1973 (2.1973)\tAcc@1 46.875 (46.875)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.8300 (1.8497)\tAcc@1 50.000 (50.928)\tAcc@5 93.750 (82.240)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.5497 (1.8571)\tAcc@1 59.375 (50.218)\tAcc@5 87.500 (81.468)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.1451 (1.8754)\tAcc@1 50.000 (50.031)\tAcc@5 84.375 (81.063)\n",
            " * Acc@1 50.090 Acc@5 80.950\n",
            "==> training...\n",
            "Epoch: [46][0/782]\tTime 0.267 (0.267)\tData 0.182 (0.182)\tLoss 0.9757 (0.9757)\tAcc@1 71.875 (71.875)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [46][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 1.8270 (1.3126)\tAcc@1 50.000 (62.577)\tAcc@5 79.688 (89.496)\n",
            "Epoch: [46][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.4534 (1.3463)\tAcc@1 68.750 (61.816)\tAcc@5 84.375 (89.008)\n",
            "Epoch: [46][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1772 (1.3532)\tAcc@1 67.188 (61.560)\tAcc@5 90.625 (88.673)\n",
            "Epoch: [46][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.5625 (1.3682)\tAcc@1 54.688 (61.160)\tAcc@5 85.938 (88.420)\n",
            "Epoch: [46][500/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 1.3086 (1.3832)\tAcc@1 62.500 (60.757)\tAcc@5 87.500 (88.136)\n",
            "Epoch: [46][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4388 (1.3895)\tAcc@1 57.812 (60.532)\tAcc@5 92.188 (87.981)\n",
            "Epoch: [46][700/782]\tTime 0.070 (0.051)\tData 0.002 (0.002)\tLoss 1.0924 (1.3879)\tAcc@1 68.750 (60.452)\tAcc@5 90.625 (87.988)\n",
            " * Acc@1 60.470 Acc@5 87.970\n",
            "epoch 46, total time 40.10\n",
            "Test: [0/313]\tTime 0.126 (0.126)\tLoss 1.9582 (1.9582)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.024 (0.021)\tLoss 1.7173 (1.8055)\tAcc@1 56.250 (53.589)\tAcc@5 87.500 (81.869)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.3419 (1.7958)\tAcc@1 56.250 (52.954)\tAcc@5 90.625 (82.525)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.6625 (1.8126)\tAcc@1 43.750 (52.917)\tAcc@5 93.750 (82.340)\n",
            " * Acc@1 52.950 Acc@5 82.330\n",
            "==> training...\n",
            "Epoch: [47][0/782]\tTime 0.272 (0.272)\tData 0.194 (0.194)\tLoss 1.1937 (1.1937)\tAcc@1 62.500 (62.500)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [47][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.2662 (1.3378)\tAcc@1 70.312 (61.850)\tAcc@5 87.500 (88.923)\n",
            "Epoch: [47][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.9776 (1.3444)\tAcc@1 76.562 (61.614)\tAcc@5 92.188 (88.783)\n",
            "Epoch: [47][300/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.7375 (1.3662)\tAcc@1 53.125 (61.124)\tAcc@5 79.688 (88.466)\n",
            "Epoch: [47][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4405 (1.3755)\tAcc@1 64.062 (61.086)\tAcc@5 89.062 (88.252)\n",
            "Epoch: [47][500/782]\tTime 0.060 (0.051)\tData 0.001 (0.002)\tLoss 1.8475 (1.3816)\tAcc@1 46.875 (60.819)\tAcc@5 81.250 (88.177)\n",
            "Epoch: [47][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4676 (1.3860)\tAcc@1 60.938 (60.659)\tAcc@5 81.250 (88.129)\n",
            "Epoch: [47][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5479 (1.3888)\tAcc@1 57.812 (60.483)\tAcc@5 87.500 (88.095)\n",
            " * Acc@1 60.344 Acc@5 88.018\n",
            "epoch 47, total time 39.72\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.2887 (2.2887)\tAcc@1 56.250 (56.250)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 2.2807 (1.9227)\tAcc@1 31.250 (50.835)\tAcc@5 75.000 (80.817)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.7595 (1.9105)\tAcc@1 46.875 (50.715)\tAcc@5 93.750 (80.613)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.1058 (1.9090)\tAcc@1 50.000 (51.163)\tAcc@5 75.000 (80.731)\n",
            " * Acc@1 51.220 Acc@5 80.780\n",
            "==> training...\n",
            "Epoch: [48][0/782]\tTime 0.280 (0.280)\tData 0.198 (0.198)\tLoss 1.1526 (1.1526)\tAcc@1 65.625 (65.625)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [48][100/782]\tTime 0.052 (0.054)\tData 0.002 (0.003)\tLoss 1.3922 (1.3327)\tAcc@1 60.938 (61.696)\tAcc@5 87.500 (89.124)\n",
            "Epoch: [48][200/782]\tTime 0.067 (0.052)\tData 0.001 (0.002)\tLoss 1.2686 (1.3605)\tAcc@1 59.375 (61.163)\tAcc@5 90.625 (88.619)\n",
            "Epoch: [48][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.9929 (1.3675)\tAcc@1 70.312 (60.953)\tAcc@5 89.062 (88.580)\n",
            "Epoch: [48][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4961 (1.3789)\tAcc@1 56.250 (60.591)\tAcc@5 85.938 (88.330)\n",
            "Epoch: [48][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.6160 (1.3822)\tAcc@1 59.375 (60.582)\tAcc@5 81.250 (88.283)\n",
            "Epoch: [48][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1875 (1.3859)\tAcc@1 62.500 (60.470)\tAcc@5 90.625 (88.244)\n",
            "Epoch: [48][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.3860 (1.3864)\tAcc@1 60.938 (60.492)\tAcc@5 85.938 (88.265)\n",
            " * Acc@1 60.292 Acc@5 88.178\n",
            "epoch 48, total time 39.85\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.8625 (1.8625)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 2.3778 (1.7864)\tAcc@1 34.375 (53.094)\tAcc@5 75.000 (82.333)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.4815 (1.7871)\tAcc@1 53.125 (52.985)\tAcc@5 84.375 (82.540)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0422 (1.7912)\tAcc@1 37.500 (52.741)\tAcc@5 75.000 (82.402)\n",
            " * Acc@1 52.780 Acc@5 82.340\n",
            "==> training...\n",
            "Epoch: [49][0/782]\tTime 0.270 (0.270)\tData 0.195 (0.195)\tLoss 1.3520 (1.3520)\tAcc@1 64.062 (64.062)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [49][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 1.5963 (1.3290)\tAcc@1 56.250 (62.593)\tAcc@5 89.062 (88.614)\n",
            "Epoch: [49][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.4331 (1.3377)\tAcc@1 53.125 (62.026)\tAcc@5 92.188 (88.728)\n",
            "Epoch: [49][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1971 (1.3482)\tAcc@1 67.188 (61.846)\tAcc@5 89.062 (88.678)\n",
            "Epoch: [49][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4824 (1.3677)\tAcc@1 57.812 (61.284)\tAcc@5 87.500 (88.560)\n",
            "Epoch: [49][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.1994 (1.3685)\tAcc@1 71.875 (61.246)\tAcc@5 92.188 (88.573)\n",
            "Epoch: [49][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.5355 (1.3847)\tAcc@1 62.500 (60.870)\tAcc@5 85.938 (88.244)\n",
            "Epoch: [49][700/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.4393 (1.3938)\tAcc@1 54.688 (60.623)\tAcc@5 90.625 (88.120)\n",
            " * Acc@1 60.582 Acc@5 88.054\n",
            "epoch 49, total time 40.20\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.6974 (1.6974)\tAcc@1 56.250 (56.250)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.021)\tLoss 1.8512 (1.9127)\tAcc@1 56.250 (50.650)\tAcc@5 87.500 (81.095)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.8665 (1.9231)\tAcc@1 43.750 (50.420)\tAcc@5 81.250 (80.690)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.4691 (1.9253)\tAcc@1 37.500 (50.322)\tAcc@5 68.750 (80.482)\n",
            " * Acc@1 50.450 Acc@5 80.560\n",
            "==> training...\n",
            "Epoch: [50][0/782]\tTime 0.278 (0.278)\tData 0.196 (0.196)\tLoss 1.3844 (1.3844)\tAcc@1 60.938 (60.938)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [50][100/782]\tTime 0.052 (0.054)\tData 0.001 (0.003)\tLoss 1.3474 (1.3229)\tAcc@1 60.938 (61.912)\tAcc@5 92.188 (88.985)\n",
            "Epoch: [50][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.0766 (1.3298)\tAcc@1 68.750 (61.777)\tAcc@5 92.188 (88.923)\n",
            "Epoch: [50][300/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.3567 (1.3450)\tAcc@1 59.375 (61.363)\tAcc@5 89.062 (88.663)\n",
            "Epoch: [50][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4886 (1.3546)\tAcc@1 60.938 (61.280)\tAcc@5 84.375 (88.544)\n",
            "Epoch: [50][500/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.3588 (1.3684)\tAcc@1 56.250 (60.894)\tAcc@5 93.750 (88.286)\n",
            "Epoch: [50][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2431 (1.3747)\tAcc@1 65.625 (60.818)\tAcc@5 90.625 (88.207)\n",
            "Epoch: [50][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2510 (1.3845)\tAcc@1 64.062 (60.601)\tAcc@5 90.625 (88.084)\n",
            " * Acc@1 60.504 Acc@5 88.090\n",
            "epoch 50, total time 39.70\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.9776 (1.9776)\tAcc@1 53.125 (53.125)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.8346 (1.8975)\tAcc@1 43.750 (51.795)\tAcc@5 84.375 (80.693)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 2.0016 (1.9136)\tAcc@1 46.875 (50.824)\tAcc@5 90.625 (80.955)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.8422 (1.9059)\tAcc@1 50.000 (50.851)\tAcc@5 87.500 (80.990)\n",
            " * Acc@1 50.860 Acc@5 80.970\n",
            "==> training...\n",
            "Epoch: [51][0/782]\tTime 0.291 (0.291)\tData 0.202 (0.202)\tLoss 1.7532 (1.7532)\tAcc@1 51.562 (51.562)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [51][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.2582 (1.3334)\tAcc@1 65.625 (61.665)\tAcc@5 92.188 (88.800)\n",
            "Epoch: [51][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.0836 (1.3484)\tAcc@1 71.875 (61.326)\tAcc@5 90.625 (88.604)\n",
            "Epoch: [51][300/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.2372 (1.3613)\tAcc@1 70.312 (60.792)\tAcc@5 89.062 (88.580)\n",
            "Epoch: [51][400/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 1.5903 (1.3541)\tAcc@1 56.250 (60.980)\tAcc@5 75.000 (88.564)\n",
            "Epoch: [51][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3473 (1.3614)\tAcc@1 57.812 (60.738)\tAcc@5 90.625 (88.535)\n",
            "Epoch: [51][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3463 (1.3678)\tAcc@1 56.250 (60.615)\tAcc@5 90.625 (88.433)\n",
            "Epoch: [51][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3521 (1.3795)\tAcc@1 59.375 (60.416)\tAcc@5 90.625 (88.222)\n",
            " * Acc@1 60.424 Acc@5 88.230\n",
            "epoch 51, total time 39.96\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.6182 (2.6182)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.021)\tLoss 2.2244 (2.1984)\tAcc@1 43.750 (46.535)\tAcc@5 81.250 (79.858)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 2.1747 (2.2354)\tAcc@1 46.875 (46.751)\tAcc@5 81.250 (78.949)\n",
            "Test: [300/313]\tTime 0.019 (0.019)\tLoss 2.8084 (2.2463)\tAcc@1 40.625 (47.062)\tAcc@5 65.625 (79.028)\n",
            " * Acc@1 47.020 Acc@5 79.000\n",
            "==> training...\n",
            "Epoch: [52][0/782]\tTime 0.292 (0.292)\tData 0.203 (0.203)\tLoss 1.3169 (1.3169)\tAcc@1 67.188 (67.188)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [52][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.2945 (1.3421)\tAcc@1 65.625 (61.618)\tAcc@5 90.625 (89.032)\n",
            "Epoch: [52][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3883 (1.3450)\tAcc@1 67.188 (61.730)\tAcc@5 89.062 (88.829)\n",
            "Epoch: [52][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1633 (1.3506)\tAcc@1 64.062 (61.462)\tAcc@5 93.750 (88.735)\n",
            "Epoch: [52][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1320 (1.3558)\tAcc@1 64.062 (61.276)\tAcc@5 93.750 (88.657)\n",
            "Epoch: [52][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4065 (1.3592)\tAcc@1 57.812 (61.265)\tAcc@5 87.500 (88.585)\n",
            "Epoch: [52][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5431 (1.3633)\tAcc@1 57.812 (61.065)\tAcc@5 87.500 (88.558)\n",
            "Epoch: [52][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2554 (1.3727)\tAcc@1 57.812 (60.766)\tAcc@5 93.750 (88.369)\n",
            " * Acc@1 60.786 Acc@5 88.322\n",
            "epoch 52, total time 39.89\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 2.3887 (2.3887)\tAcc@1 53.125 (53.125)\tAcc@5 65.625 (65.625)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.0064 (1.8380)\tAcc@1 50.000 (51.887)\tAcc@5 84.375 (82.550)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.4126 (1.8409)\tAcc@1 71.875 (52.130)\tAcc@5 87.500 (82.229)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.4781 (1.8527)\tAcc@1 53.125 (51.734)\tAcc@5 90.625 (81.956)\n",
            " * Acc@1 51.710 Acc@5 81.960\n",
            "==> training...\n",
            "Epoch: [53][0/782]\tTime 0.273 (0.273)\tData 0.203 (0.203)\tLoss 1.0854 (1.0854)\tAcc@1 67.188 (67.188)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [53][100/782]\tTime 0.057 (0.053)\tData 0.002 (0.003)\tLoss 1.1041 (1.3858)\tAcc@1 64.062 (60.056)\tAcc@5 93.750 (88.923)\n",
            "Epoch: [53][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3456 (1.3683)\tAcc@1 60.938 (60.759)\tAcc@5 84.375 (88.915)\n",
            "Epoch: [53][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3227 (1.3615)\tAcc@1 59.375 (60.844)\tAcc@5 87.500 (88.928)\n",
            "Epoch: [53][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4445 (1.3627)\tAcc@1 57.812 (60.867)\tAcc@5 96.875 (88.840)\n",
            "Epoch: [53][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1972 (1.3674)\tAcc@1 62.500 (60.691)\tAcc@5 87.500 (88.632)\n",
            "Epoch: [53][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2802 (1.3773)\tAcc@1 60.938 (60.506)\tAcc@5 92.188 (88.459)\n",
            "Epoch: [53][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4245 (1.3799)\tAcc@1 56.250 (60.463)\tAcc@5 93.750 (88.405)\n",
            " * Acc@1 60.666 Acc@5 88.428\n",
            "epoch 53, total time 40.03\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 2.1721 (2.1721)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.9531 (1.8445)\tAcc@1 40.625 (53.063)\tAcc@5 87.500 (81.405)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.3495 (1.8369)\tAcc@1 62.500 (52.767)\tAcc@5 87.500 (81.297)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.1153 (1.8528)\tAcc@1 43.750 (52.170)\tAcc@5 78.125 (81.426)\n",
            " * Acc@1 52.170 Acc@5 81.270\n",
            "==> training...\n",
            "Epoch: [54][0/782]\tTime 0.271 (0.271)\tData 0.195 (0.195)\tLoss 1.2424 (1.2424)\tAcc@1 67.188 (67.188)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [54][100/782]\tTime 0.053 (0.053)\tData 0.001 (0.003)\tLoss 0.9946 (1.3396)\tAcc@1 78.125 (61.742)\tAcc@5 92.188 (88.645)\n",
            "Epoch: [54][200/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7028 (1.3570)\tAcc@1 45.312 (61.350)\tAcc@5 87.500 (88.448)\n",
            "Epoch: [54][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6396 (1.3809)\tAcc@1 60.938 (60.828)\tAcc@5 85.938 (88.273)\n",
            "Epoch: [54][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6466 (1.3693)\tAcc@1 57.812 (61.265)\tAcc@5 84.375 (88.388)\n",
            "Epoch: [54][500/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 1.3253 (1.3720)\tAcc@1 68.750 (61.090)\tAcc@5 89.062 (88.351)\n",
            "Epoch: [54][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.0231 (1.3696)\tAcc@1 68.750 (61.135)\tAcc@5 92.188 (88.366)\n",
            "Epoch: [54][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2006 (1.3747)\tAcc@1 57.812 (60.975)\tAcc@5 95.312 (88.307)\n",
            " * Acc@1 60.856 Acc@5 88.226\n",
            "epoch 54, total time 39.62\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.9029 (1.9029)\tAcc@1 53.125 (53.125)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 2.0097 (1.6706)\tAcc@1 34.375 (55.260)\tAcc@5 87.500 (84.189)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.0777 (1.6809)\tAcc@1 71.875 (55.162)\tAcc@5 93.750 (84.328)\n",
            "Test: [300/313]\tTime 0.017 (0.020)\tLoss 2.1645 (1.6947)\tAcc@1 50.000 (54.589)\tAcc@5 78.125 (84.105)\n",
            " * Acc@1 54.670 Acc@5 84.120\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [55][0/782]\tTime 0.285 (0.285)\tData 0.203 (0.203)\tLoss 1.1377 (1.1377)\tAcc@1 67.188 (67.188)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [55][100/782]\tTime 0.052 (0.052)\tData 0.001 (0.003)\tLoss 1.7468 (1.3668)\tAcc@1 56.250 (61.231)\tAcc@5 82.812 (88.567)\n",
            "Epoch: [55][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3658 (1.3479)\tAcc@1 68.750 (61.606)\tAcc@5 82.812 (88.705)\n",
            "Epoch: [55][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3084 (1.3565)\tAcc@1 62.500 (61.353)\tAcc@5 89.062 (88.554)\n",
            "Epoch: [55][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1721 (1.3595)\tAcc@1 68.750 (61.117)\tAcc@5 92.188 (88.642)\n",
            "Epoch: [55][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3305 (1.3641)\tAcc@1 65.625 (60.844)\tAcc@5 84.375 (88.691)\n",
            "Epoch: [55][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5193 (1.3671)\tAcc@1 62.500 (60.766)\tAcc@5 81.250 (88.548)\n",
            "Epoch: [55][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3471 (1.3658)\tAcc@1 59.375 (60.810)\tAcc@5 85.938 (88.534)\n",
            " * Acc@1 60.702 Acc@5 88.456\n",
            "epoch 55, total time 39.70\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 2.2355 (2.2355)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.021)\tLoss 2.2037 (2.1544)\tAcc@1 46.875 (46.597)\tAcc@5 71.875 (79.177)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.8221 (2.1669)\tAcc@1 50.000 (46.440)\tAcc@5 81.250 (78.654)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.8271 (2.1761)\tAcc@1 28.125 (46.709)\tAcc@5 68.750 (78.322)\n",
            " * Acc@1 46.780 Acc@5 78.320\n",
            "==> training...\n",
            "Epoch: [56][0/782]\tTime 0.292 (0.292)\tData 0.200 (0.200)\tLoss 1.3314 (1.3314)\tAcc@1 64.062 (64.062)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [56][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.4921 (1.3062)\tAcc@1 57.812 (62.283)\tAcc@5 85.938 (89.356)\n",
            "Epoch: [56][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3978 (1.3232)\tAcc@1 56.250 (62.072)\tAcc@5 89.062 (89.156)\n",
            "Epoch: [56][300/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.4665 (1.3334)\tAcc@1 50.000 (61.607)\tAcc@5 89.062 (89.016)\n",
            "Epoch: [56][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4270 (1.3424)\tAcc@1 56.250 (61.460)\tAcc@5 85.938 (88.942)\n",
            "Epoch: [56][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2851 (1.3576)\tAcc@1 64.062 (61.097)\tAcc@5 87.500 (88.726)\n",
            "Epoch: [56][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.1552 (1.3652)\tAcc@1 65.625 (61.026)\tAcc@5 92.188 (88.527)\n",
            "Epoch: [56][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3553 (1.3672)\tAcc@1 65.625 (61.027)\tAcc@5 84.375 (88.427)\n",
            " * Acc@1 60.992 Acc@5 88.380\n",
            "epoch 56, total time 39.87\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.8251 (1.8251)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.9442 (1.8629)\tAcc@1 46.875 (52.877)\tAcc@5 84.375 (81.312)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.6987 (1.8750)\tAcc@1 50.000 (52.441)\tAcc@5 81.250 (80.737)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.3122 (1.8971)\tAcc@1 43.750 (52.045)\tAcc@5 68.750 (80.482)\n",
            " * Acc@1 52.080 Acc@5 80.410\n",
            "==> training...\n",
            "Epoch: [57][0/782]\tTime 0.262 (0.262)\tData 0.180 (0.180)\tLoss 1.1538 (1.1538)\tAcc@1 68.750 (68.750)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [57][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 1.0588 (1.2899)\tAcc@1 70.312 (62.949)\tAcc@5 89.062 (89.604)\n",
            "Epoch: [57][200/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.4889 (1.3121)\tAcc@1 60.938 (62.461)\tAcc@5 82.812 (89.234)\n",
            "Epoch: [57][300/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.5539 (1.3310)\tAcc@1 54.688 (61.872)\tAcc@5 84.375 (88.922)\n",
            "Epoch: [57][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2639 (1.3418)\tAcc@1 60.938 (61.565)\tAcc@5 93.750 (88.704)\n",
            "Epoch: [57][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.5148 (1.3573)\tAcc@1 64.062 (61.334)\tAcc@5 79.688 (88.526)\n",
            "Epoch: [57][600/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.6519 (1.3623)\tAcc@1 56.250 (61.182)\tAcc@5 84.375 (88.501)\n",
            "Epoch: [57][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.6820 (1.3652)\tAcc@1 59.375 (61.160)\tAcc@5 78.125 (88.452)\n",
            " * Acc@1 61.014 Acc@5 88.300\n",
            "epoch 57, total time 40.18\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.9541 (1.9541)\tAcc@1 56.250 (56.250)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.8229 (1.8441)\tAcc@1 50.000 (51.949)\tAcc@5 84.375 (81.838)\n",
            "Test: [200/313]\tTime 0.022 (0.019)\tLoss 1.7562 (1.8632)\tAcc@1 53.125 (51.819)\tAcc@5 84.375 (81.810)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.7861 (1.8730)\tAcc@1 59.375 (52.315)\tAcc@5 84.375 (81.561)\n",
            " * Acc@1 52.360 Acc@5 81.540\n",
            "==> training...\n",
            "Epoch: [58][0/782]\tTime 0.263 (0.263)\tData 0.177 (0.177)\tLoss 1.1525 (1.1525)\tAcc@1 68.750 (68.750)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [58][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.4586 (1.3241)\tAcc@1 57.812 (61.556)\tAcc@5 84.375 (89.016)\n",
            "Epoch: [58][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3156 (1.3400)\tAcc@1 60.938 (61.326)\tAcc@5 87.500 (88.814)\n",
            "Epoch: [58][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1528 (1.3573)\tAcc@1 62.500 (60.870)\tAcc@5 92.188 (88.673)\n",
            "Epoch: [58][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4003 (1.3567)\tAcc@1 54.688 (60.922)\tAcc@5 89.062 (88.856)\n",
            "Epoch: [58][500/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 1.2058 (1.3542)\tAcc@1 64.062 (61.115)\tAcc@5 87.500 (88.794)\n",
            "Epoch: [58][600/782]\tTime 0.068 (0.052)\tData 0.001 (0.002)\tLoss 1.4841 (1.3622)\tAcc@1 51.562 (60.966)\tAcc@5 87.500 (88.595)\n",
            "Epoch: [58][700/782]\tTime 0.055 (0.052)\tData 0.002 (0.002)\tLoss 1.2518 (1.3660)\tAcc@1 70.312 (60.857)\tAcc@5 89.062 (88.545)\n",
            " * Acc@1 60.712 Acc@5 88.440\n",
            "epoch 58, total time 40.44\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 1.8905 (1.8905)\tAcc@1 62.500 (62.500)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.9340 (1.8062)\tAcc@1 37.500 (52.661)\tAcc@5 93.750 (82.426)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 1.1417 (1.8334)\tAcc@1 62.500 (51.819)\tAcc@5 96.875 (81.856)\n",
            "Test: [300/313]\tTime 0.017 (0.020)\tLoss 2.4196 (1.8591)\tAcc@1 40.625 (51.370)\tAcc@5 78.125 (81.364)\n",
            " * Acc@1 51.440 Acc@5 81.290\n",
            "==> training...\n",
            "Epoch: [59][0/782]\tTime 0.267 (0.267)\tData 0.197 (0.197)\tLoss 1.5411 (1.5411)\tAcc@1 62.500 (62.500)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [59][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 1.0517 (1.3422)\tAcc@1 65.625 (61.402)\tAcc@5 92.188 (88.815)\n",
            "Epoch: [59][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.9009 (1.3393)\tAcc@1 68.750 (61.217)\tAcc@5 98.438 (89.101)\n",
            "Epoch: [59][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.1254 (1.3454)\tAcc@1 64.062 (61.124)\tAcc@5 90.625 (88.881)\n",
            "Epoch: [59][400/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.3119 (1.3460)\tAcc@1 65.625 (61.327)\tAcc@5 90.625 (88.778)\n",
            "Epoch: [59][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2480 (1.3520)\tAcc@1 60.938 (61.312)\tAcc@5 93.750 (88.617)\n",
            "Epoch: [59][600/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 1.4357 (1.3572)\tAcc@1 51.562 (61.182)\tAcc@5 89.062 (88.506)\n",
            "Epoch: [59][700/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3096 (1.3562)\tAcc@1 67.188 (61.229)\tAcc@5 90.625 (88.499)\n",
            " * Acc@1 61.116 Acc@5 88.378\n",
            "epoch 59, total time 40.71\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 2.2065 (2.2065)\tAcc@1 46.875 (46.875)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.6510 (1.8389)\tAcc@1 53.125 (51.516)\tAcc@5 84.375 (82.457)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.5160 (1.8620)\tAcc@1 53.125 (51.477)\tAcc@5 84.375 (81.996)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.3467 (1.8810)\tAcc@1 50.000 (51.620)\tAcc@5 90.625 (81.676)\n",
            " * Acc@1 51.650 Acc@5 81.720\n",
            "==> training...\n",
            "Epoch: [60][0/782]\tTime 0.267 (0.267)\tData 0.200 (0.200)\tLoss 1.3707 (1.3707)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Epoch: [60][100/782]\tTime 0.051 (0.052)\tData 0.001 (0.003)\tLoss 1.1795 (1.2961)\tAcc@1 65.625 (63.382)\tAcc@5 89.062 (88.985)\n",
            "Epoch: [60][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 1.2423 (1.3226)\tAcc@1 62.500 (62.687)\tAcc@5 87.500 (88.752)\n",
            "Epoch: [60][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3519 (1.3431)\tAcc@1 57.812 (61.991)\tAcc@5 85.938 (88.486)\n",
            "Epoch: [60][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4724 (1.3391)\tAcc@1 54.688 (62.017)\tAcc@5 87.500 (88.630)\n",
            "Epoch: [60][500/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.5957 (1.3472)\tAcc@1 59.375 (61.808)\tAcc@5 87.500 (88.423)\n",
            "Epoch: [60][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4490 (1.3538)\tAcc@1 56.250 (61.522)\tAcc@5 84.375 (88.358)\n",
            "Epoch: [60][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2529 (1.3541)\tAcc@1 59.375 (61.501)\tAcc@5 96.875 (88.443)\n",
            " * Acc@1 61.370 Acc@5 88.426\n",
            "epoch 60, total time 39.97\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 2.1955 (2.1955)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 2.2617 (1.7763)\tAcc@1 43.750 (53.434)\tAcc@5 81.250 (82.147)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 1.5394 (1.8001)\tAcc@1 62.500 (52.612)\tAcc@5 87.500 (82.121)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 2.0684 (1.8015)\tAcc@1 50.000 (53.032)\tAcc@5 87.500 (82.247)\n",
            " * Acc@1 53.040 Acc@5 82.310\n",
            "==> training...\n",
            "Epoch: [61][0/782]\tTime 0.279 (0.279)\tData 0.198 (0.198)\tLoss 1.4342 (1.4342)\tAcc@1 59.375 (59.375)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [61][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.5664 (1.3045)\tAcc@1 57.812 (62.980)\tAcc@5 79.688 (89.681)\n",
            "Epoch: [61][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1790 (1.3317)\tAcc@1 65.625 (62.446)\tAcc@5 92.188 (89.109)\n",
            "Epoch: [61][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4044 (1.3396)\tAcc@1 53.125 (62.266)\tAcc@5 90.625 (88.829)\n",
            "Epoch: [61][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2059 (1.3529)\tAcc@1 62.500 (61.744)\tAcc@5 93.750 (88.665)\n",
            "Epoch: [61][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.4229 (1.3500)\tAcc@1 59.375 (61.904)\tAcc@5 84.375 (88.610)\n",
            "Epoch: [61][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4025 (1.3517)\tAcc@1 60.938 (61.652)\tAcc@5 84.375 (88.608)\n",
            "Epoch: [61][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.0922 (1.3558)\tAcc@1 71.875 (61.441)\tAcc@5 92.188 (88.552)\n",
            " * Acc@1 61.298 Acc@5 88.468\n",
            "epoch 61, total time 39.95\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.8252 (1.8252)\tAcc@1 56.250 (56.250)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.5457 (1.7033)\tAcc@1 59.375 (54.548)\tAcc@5 87.500 (83.818)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.5229 (1.7146)\tAcc@1 50.000 (53.700)\tAcc@5 87.500 (83.131)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0959 (1.7359)\tAcc@1 50.000 (53.426)\tAcc@5 90.625 (82.880)\n",
            " * Acc@1 53.500 Acc@5 82.830\n",
            "==> training...\n",
            "Epoch: [62][0/782]\tTime 0.281 (0.281)\tData 0.199 (0.199)\tLoss 1.2765 (1.2765)\tAcc@1 64.062 (64.062)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [62][100/782]\tTime 0.051 (0.054)\tData 0.001 (0.003)\tLoss 1.3280 (1.3172)\tAcc@1 60.938 (62.376)\tAcc@5 92.188 (89.171)\n",
            "Epoch: [62][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1643 (1.3378)\tAcc@1 60.938 (61.606)\tAcc@5 90.625 (88.783)\n",
            "Epoch: [62][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4029 (1.3320)\tAcc@1 60.938 (62.095)\tAcc@5 85.938 (88.735)\n",
            "Epoch: [62][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.4049 (1.3319)\tAcc@1 54.688 (62.067)\tAcc@5 87.500 (88.813)\n",
            "Epoch: [62][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.1413 (1.3366)\tAcc@1 67.188 (61.917)\tAcc@5 90.625 (88.794)\n",
            "Epoch: [62][600/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 1.2384 (1.3423)\tAcc@1 64.062 (61.808)\tAcc@5 90.625 (88.756)\n",
            "Epoch: [62][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4533 (1.3515)\tAcc@1 64.062 (61.635)\tAcc@5 95.312 (88.692)\n",
            " * Acc@1 61.608 Acc@5 88.644\n",
            "epoch 62, total time 39.91\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 2.2961 (2.2961)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.2497 (1.9730)\tAcc@1 31.250 (49.969)\tAcc@5 81.250 (80.600)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.1664 (1.9494)\tAcc@1 65.625 (50.000)\tAcc@5 93.750 (80.628)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.6421 (1.9737)\tAcc@1 40.625 (49.481)\tAcc@5 75.000 (80.181)\n",
            " * Acc@1 49.540 Acc@5 80.270\n",
            "==> training...\n",
            "Epoch: [63][0/782]\tTime 0.269 (0.269)\tData 0.200 (0.200)\tLoss 1.3765 (1.3765)\tAcc@1 60.938 (60.938)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [63][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.5501 (1.3099)\tAcc@1 53.125 (62.283)\tAcc@5 84.375 (89.341)\n",
            "Epoch: [63][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1916 (1.3172)\tAcc@1 59.375 (62.010)\tAcc@5 90.625 (89.101)\n",
            "Epoch: [63][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.7996 (1.3172)\tAcc@1 79.688 (61.976)\tAcc@5 96.875 (89.146)\n",
            "Epoch: [63][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3877 (1.3211)\tAcc@1 59.375 (62.040)\tAcc@5 90.625 (89.039)\n",
            "Epoch: [63][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2547 (1.3310)\tAcc@1 57.812 (61.879)\tAcc@5 90.625 (88.910)\n",
            "Epoch: [63][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2593 (1.3437)\tAcc@1 56.250 (61.600)\tAcc@5 92.188 (88.722)\n",
            "Epoch: [63][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.0494 (1.3452)\tAcc@1 70.312 (61.475)\tAcc@5 93.750 (88.710)\n",
            " * Acc@1 61.264 Acc@5 88.588\n",
            "epoch 63, total time 39.68\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.9173 (1.9173)\tAcc@1 56.250 (56.250)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.7936 (1.7407)\tAcc@1 46.875 (53.589)\tAcc@5 84.375 (82.673)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 2.0346 (1.7392)\tAcc@1 50.000 (53.203)\tAcc@5 78.125 (83.069)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.3005 (1.7540)\tAcc@1 46.875 (53.125)\tAcc@5 78.125 (82.787)\n",
            " * Acc@1 53.200 Acc@5 82.870\n",
            "==> training...\n",
            "Epoch: [64][0/782]\tTime 0.275 (0.275)\tData 0.183 (0.183)\tLoss 1.1251 (1.1251)\tAcc@1 53.125 (53.125)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [64][100/782]\tTime 0.053 (0.053)\tData 0.001 (0.003)\tLoss 1.2449 (1.2940)\tAcc@1 59.375 (62.407)\tAcc@5 93.750 (89.774)\n",
            "Epoch: [64][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3101 (1.3326)\tAcc@1 65.625 (61.637)\tAcc@5 90.625 (89.117)\n",
            "Epoch: [64][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4063 (1.3412)\tAcc@1 57.812 (61.363)\tAcc@5 89.062 (88.896)\n",
            "Epoch: [64][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5288 (1.3422)\tAcc@1 57.812 (61.351)\tAcc@5 84.375 (88.762)\n",
            "Epoch: [64][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1928 (1.3544)\tAcc@1 68.750 (60.991)\tAcc@5 89.062 (88.635)\n",
            "Epoch: [64][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.0337 (1.3552)\tAcc@1 70.312 (61.112)\tAcc@5 93.750 (88.579)\n",
            "Epoch: [64][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2606 (1.3610)\tAcc@1 64.062 (61.056)\tAcc@5 90.625 (88.485)\n",
            " * Acc@1 61.078 Acc@5 88.468\n",
            "epoch 64, total time 39.97\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 2.3287 (2.3287)\tAcc@1 46.875 (46.875)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 2.1559 (1.6629)\tAcc@1 43.750 (54.579)\tAcc@5 78.125 (84.220)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.2845 (1.6571)\tAcc@1 65.625 (54.913)\tAcc@5 90.625 (84.235)\n",
            "Test: [300/313]\tTime 0.017 (0.017)\tLoss 1.7065 (1.6714)\tAcc@1 59.375 (54.869)\tAcc@5 84.375 (84.001)\n",
            " * Acc@1 54.900 Acc@5 83.950\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [65][0/782]\tTime 0.274 (0.274)\tData 0.189 (0.189)\tLoss 1.2857 (1.2857)\tAcc@1 60.938 (60.938)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [65][100/782]\tTime 0.051 (0.054)\tData 0.002 (0.003)\tLoss 1.2408 (1.3213)\tAcc@1 65.625 (61.757)\tAcc@5 87.500 (89.264)\n",
            "Epoch: [65][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.0070 (1.3324)\tAcc@1 70.312 (61.536)\tAcc@5 96.875 (89.179)\n",
            "Epoch: [65][300/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 1.4261 (1.3385)\tAcc@1 64.062 (61.659)\tAcc@5 81.250 (88.912)\n",
            "Epoch: [65][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3228 (1.3437)\tAcc@1 68.750 (61.397)\tAcc@5 89.062 (88.914)\n",
            "Epoch: [65][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2954 (1.3494)\tAcc@1 62.500 (61.405)\tAcc@5 87.500 (88.794)\n",
            "Epoch: [65][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.3233 (1.3539)\tAcc@1 60.938 (61.301)\tAcc@5 84.375 (88.654)\n",
            "Epoch: [65][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.8267 (1.3586)\tAcc@1 53.125 (61.154)\tAcc@5 79.688 (88.541)\n",
            " * Acc@1 61.156 Acc@5 88.518\n",
            "epoch 65, total time 39.84\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.8668 (1.8668)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.025 (0.021)\tLoss 2.1302 (1.7555)\tAcc@1 46.875 (52.197)\tAcc@5 75.000 (82.797)\n",
            "Test: [200/313]\tTime 0.024 (0.020)\tLoss 1.1993 (1.7331)\tAcc@1 62.500 (53.265)\tAcc@5 93.750 (83.022)\n",
            "Test: [300/313]\tTime 0.024 (0.020)\tLoss 2.0964 (1.7275)\tAcc@1 37.500 (53.904)\tAcc@5 84.375 (83.098)\n",
            " * Acc@1 53.900 Acc@5 83.100\n",
            "==> training...\n",
            "Epoch: [66][0/782]\tTime 0.277 (0.277)\tData 0.196 (0.196)\tLoss 1.3768 (1.3768)\tAcc@1 54.688 (54.688)\tAcc@5 81.250 (81.250)\n",
            "Epoch: [66][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.4004 (1.3137)\tAcc@1 68.750 (62.577)\tAcc@5 87.500 (89.016)\n",
            "Epoch: [66][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.9250 (1.3038)\tAcc@1 76.562 (62.881)\tAcc@5 95.312 (89.140)\n",
            "Epoch: [66][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.4189 (1.3216)\tAcc@1 57.812 (62.386)\tAcc@5 93.750 (88.990)\n",
            "Epoch: [66][400/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.3252 (1.3224)\tAcc@1 60.938 (62.391)\tAcc@5 87.500 (88.965)\n",
            "Epoch: [66][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.7385 (1.3389)\tAcc@1 57.812 (62.026)\tAcc@5 78.125 (88.719)\n",
            "Epoch: [66][600/782]\tTime 0.072 (0.052)\tData 0.001 (0.002)\tLoss 1.3318 (1.3470)\tAcc@1 59.375 (61.715)\tAcc@5 89.062 (88.574)\n",
            "Epoch: [66][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4418 (1.3582)\tAcc@1 56.250 (61.345)\tAcc@5 82.812 (88.458)\n",
            " * Acc@1 61.364 Acc@5 88.494\n",
            "epoch 66, total time 40.37\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 1.9428 (1.9428)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.024 (0.020)\tLoss 1.8356 (1.9910)\tAcc@1 53.125 (50.371)\tAcc@5 84.375 (80.476)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.4898 (2.0206)\tAcc@1 65.625 (49.984)\tAcc@5 84.375 (79.680)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.0867 (2.0428)\tAcc@1 46.875 (49.626)\tAcc@5 68.750 (79.506)\n",
            " * Acc@1 49.710 Acc@5 79.520\n",
            "==> training...\n",
            "Epoch: [67][0/782]\tTime 0.261 (0.261)\tData 0.193 (0.193)\tLoss 1.3396 (1.3396)\tAcc@1 60.938 (60.938)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [67][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.1197 (1.3002)\tAcc@1 67.188 (62.902)\tAcc@5 92.188 (89.790)\n",
            "Epoch: [67][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2900 (1.3291)\tAcc@1 59.375 (61.917)\tAcc@5 87.500 (89.412)\n",
            "Epoch: [67][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2810 (1.3329)\tAcc@1 64.062 (61.862)\tAcc@5 84.375 (89.234)\n",
            "Epoch: [67][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5755 (1.3392)\tAcc@1 51.562 (61.690)\tAcc@5 89.062 (89.105)\n",
            "Epoch: [67][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.0776 (1.3442)\tAcc@1 67.188 (61.680)\tAcc@5 96.875 (88.975)\n",
            "Epoch: [67][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3412 (1.3507)\tAcc@1 57.812 (61.637)\tAcc@5 89.062 (88.740)\n",
            "Epoch: [67][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1528 (1.3506)\tAcc@1 68.750 (61.591)\tAcc@5 95.312 (88.704)\n",
            " * Acc@1 61.386 Acc@5 88.606\n",
            "epoch 67, total time 39.71\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.6712 (1.6712)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 2.0137 (1.7486)\tAcc@1 46.875 (53.960)\tAcc@5 84.375 (83.014)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.2351 (1.7425)\tAcc@1 65.625 (54.151)\tAcc@5 96.875 (83.116)\n",
            "Test: [300/313]\tTime 0.024 (0.018)\tLoss 2.0316 (1.7485)\tAcc@1 46.875 (54.392)\tAcc@5 84.375 (82.953)\n",
            " * Acc@1 54.410 Acc@5 82.940\n",
            "==> training...\n",
            "Epoch: [68][0/782]\tTime 0.271 (0.271)\tData 0.178 (0.178)\tLoss 0.9645 (0.9645)\tAcc@1 70.312 (70.312)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [68][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.5641 (1.3170)\tAcc@1 60.938 (62.005)\tAcc@5 82.812 (89.202)\n",
            "Epoch: [68][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3808 (1.3229)\tAcc@1 57.812 (62.049)\tAcc@5 85.938 (89.094)\n",
            "Epoch: [68][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2761 (1.3242)\tAcc@1 54.688 (61.898)\tAcc@5 96.875 (89.151)\n",
            "Epoch: [68][400/782]\tTime 0.056 (0.052)\tData 0.002 (0.002)\tLoss 1.0942 (1.3390)\tAcc@1 76.562 (61.705)\tAcc@5 92.188 (88.891)\n",
            "Epoch: [68][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4684 (1.3353)\tAcc@1 60.938 (61.901)\tAcc@5 89.062 (88.910)\n",
            "Epoch: [68][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1827 (1.3426)\tAcc@1 64.062 (61.733)\tAcc@5 92.188 (88.823)\n",
            "Epoch: [68][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4549 (1.3481)\tAcc@1 59.375 (61.588)\tAcc@5 85.938 (88.742)\n",
            " * Acc@1 61.582 Acc@5 88.730\n",
            "epoch 68, total time 40.11\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 2.7560 (2.7560)\tAcc@1 43.750 (43.750)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.0819 (2.2166)\tAcc@1 40.625 (47.834)\tAcc@5 87.500 (78.156)\n",
            "Test: [200/313]\tTime 0.024 (0.018)\tLoss 2.0052 (2.1883)\tAcc@1 43.750 (48.352)\tAcc@5 78.125 (78.374)\n",
            "Test: [300/313]\tTime 0.025 (0.019)\tLoss 2.2863 (2.1865)\tAcc@1 43.750 (48.287)\tAcc@5 78.125 (78.229)\n",
            " * Acc@1 48.240 Acc@5 78.200\n",
            "==> training...\n",
            "Epoch: [69][0/782]\tTime 0.269 (0.269)\tData 0.183 (0.183)\tLoss 1.0738 (1.0738)\tAcc@1 70.312 (70.312)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [69][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 1.2269 (1.2630)\tAcc@1 67.188 (63.830)\tAcc@5 89.062 (90.114)\n",
            "Epoch: [69][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4628 (1.2727)\tAcc@1 64.062 (63.604)\tAcc@5 81.250 (89.879)\n",
            "Epoch: [69][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2474 (1.3153)\tAcc@1 59.375 (62.697)\tAcc@5 92.188 (89.073)\n",
            "Epoch: [69][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5611 (1.3224)\tAcc@1 57.812 (62.325)\tAcc@5 87.500 (88.996)\n",
            "Epoch: [69][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3797 (1.3299)\tAcc@1 62.500 (62.063)\tAcc@5 85.938 (88.907)\n",
            "Epoch: [69][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5508 (1.3375)\tAcc@1 57.812 (61.788)\tAcc@5 82.812 (88.782)\n",
            "Epoch: [69][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2091 (1.3457)\tAcc@1 59.375 (61.510)\tAcc@5 95.312 (88.713)\n",
            " * Acc@1 61.350 Acc@5 88.724\n",
            "epoch 69, total time 39.93\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.6301 (2.6301)\tAcc@1 50.000 (50.000)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.5735 (2.2780)\tAcc@1 37.500 (46.194)\tAcc@5 75.000 (78.651)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.8108 (2.2193)\tAcc@1 56.250 (47.062)\tAcc@5 84.375 (79.136)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 3.0475 (2.2550)\tAcc@1 31.250 (46.678)\tAcc@5 71.875 (78.530)\n",
            " * Acc@1 46.770 Acc@5 78.560\n",
            "==> training...\n",
            "Epoch: [70][0/782]\tTime 0.274 (0.274)\tData 0.200 (0.200)\tLoss 1.4111 (1.4111)\tAcc@1 60.938 (60.938)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [70][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.7221 (1.3183)\tAcc@1 53.125 (62.701)\tAcc@5 81.250 (88.676)\n",
            "Epoch: [70][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.2062 (1.3195)\tAcc@1 65.625 (62.624)\tAcc@5 89.062 (88.635)\n",
            "Epoch: [70][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4881 (1.3203)\tAcc@1 59.375 (62.417)\tAcc@5 87.500 (88.787)\n",
            "Epoch: [70][400/782]\tTime 0.057 (0.051)\tData 0.002 (0.002)\tLoss 1.5185 (1.3269)\tAcc@1 56.250 (62.313)\tAcc@5 85.938 (88.712)\n",
            "Epoch: [70][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4477 (1.3337)\tAcc@1 60.938 (62.123)\tAcc@5 85.938 (88.645)\n",
            "Epoch: [70][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3672 (1.3383)\tAcc@1 64.062 (61.892)\tAcc@5 84.375 (88.688)\n",
            "Epoch: [70][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4555 (1.3454)\tAcc@1 56.250 (61.613)\tAcc@5 93.750 (88.632)\n",
            " * Acc@1 61.520 Acc@5 88.526\n",
            "epoch 70, total time 39.96\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 1.9074 (1.9074)\tAcc@1 59.375 (59.375)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.7243 (1.8053)\tAcc@1 50.000 (52.351)\tAcc@5 87.500 (82.797)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.3230 (1.7839)\tAcc@1 65.625 (52.472)\tAcc@5 90.625 (83.085)\n",
            "Test: [300/313]\tTime 0.024 (0.018)\tLoss 1.8308 (1.7972)\tAcc@1 50.000 (52.575)\tAcc@5 84.375 (82.714)\n",
            " * Acc@1 52.620 Acc@5 82.670\n",
            "==> training...\n",
            "Epoch: [71][0/782]\tTime 0.281 (0.281)\tData 0.200 (0.200)\tLoss 1.2893 (1.2893)\tAcc@1 57.812 (57.812)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [71][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.1514 (1.2712)\tAcc@1 68.750 (62.995)\tAcc@5 90.625 (90.377)\n",
            "Epoch: [71][200/782]\tTime 0.052 (0.053)\tData 0.001 (0.002)\tLoss 1.5214 (1.3061)\tAcc@1 57.812 (62.243)\tAcc@5 87.500 (89.521)\n",
            "Epoch: [71][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3752 (1.3232)\tAcc@1 59.375 (61.836)\tAcc@5 89.062 (89.208)\n",
            "Epoch: [71][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1904 (1.3330)\tAcc@1 67.188 (61.740)\tAcc@5 96.875 (89.004)\n",
            "Epoch: [71][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2941 (1.3389)\tAcc@1 59.375 (61.714)\tAcc@5 92.188 (88.857)\n",
            "Epoch: [71][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2578 (1.3418)\tAcc@1 57.812 (61.559)\tAcc@5 93.750 (88.857)\n",
            "Epoch: [71][700/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.5641 (1.3480)\tAcc@1 59.375 (61.388)\tAcc@5 87.500 (88.771)\n",
            " * Acc@1 61.372 Acc@5 88.662\n",
            "epoch 71, total time 40.22\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.8838 (1.8838)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.2721 (1.7423)\tAcc@1 37.500 (54.981)\tAcc@5 71.875 (82.519)\n",
            "Test: [200/313]\tTime 0.021 (0.018)\tLoss 1.4729 (1.7359)\tAcc@1 59.375 (54.633)\tAcc@5 90.625 (83.053)\n",
            "Test: [300/313]\tTime 0.019 (0.018)\tLoss 1.6321 (1.7398)\tAcc@1 53.125 (54.599)\tAcc@5 81.250 (83.233)\n",
            " * Acc@1 54.620 Acc@5 83.300\n",
            "==> training...\n",
            "Epoch: [72][0/782]\tTime 0.267 (0.267)\tData 0.198 (0.198)\tLoss 1.1598 (1.1598)\tAcc@1 68.750 (68.750)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [72][100/782]\tTime 0.050 (0.056)\tData 0.001 (0.003)\tLoss 1.1019 (1.2917)\tAcc@1 67.188 (62.980)\tAcc@5 95.312 (89.836)\n",
            "Epoch: [72][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.1228 (1.2892)\tAcc@1 62.500 (62.889)\tAcc@5 92.188 (89.653)\n",
            "Epoch: [72][300/782]\tTime 0.055 (0.052)\tData 0.001 (0.002)\tLoss 1.8230 (1.2972)\tAcc@1 51.562 (62.619)\tAcc@5 81.250 (89.343)\n",
            "Epoch: [72][400/782]\tTime 0.057 (0.052)\tData 0.001 (0.002)\tLoss 1.3653 (1.3090)\tAcc@1 65.625 (62.270)\tAcc@5 87.500 (89.257)\n",
            "Epoch: [72][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2493 (1.3181)\tAcc@1 68.750 (62.035)\tAcc@5 92.188 (89.078)\n",
            "Epoch: [72][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6214 (1.3302)\tAcc@1 56.250 (61.795)\tAcc@5 84.375 (88.842)\n",
            "Epoch: [72][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2020 (1.3372)\tAcc@1 68.750 (61.604)\tAcc@5 87.500 (88.791)\n",
            " * Acc@1 61.624 Acc@5 88.732\n",
            "epoch 72, total time 40.13\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 2.5895 (2.5895)\tAcc@1 50.000 (50.000)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.9996 (2.0569)\tAcc@1 46.875 (47.525)\tAcc@5 78.125 (80.012)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.8187 (2.0660)\tAcc@1 56.250 (47.652)\tAcc@5 71.875 (79.244)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.9783 (2.0679)\tAcc@1 50.000 (47.456)\tAcc@5 87.500 (79.558)\n",
            " * Acc@1 47.550 Acc@5 79.530\n",
            "==> training...\n",
            "Epoch: [73][0/782]\tTime 0.285 (0.285)\tData 0.203 (0.203)\tLoss 1.1583 (1.1583)\tAcc@1 67.188 (67.188)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [73][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.3160 (1.3102)\tAcc@1 65.625 (62.531)\tAcc@5 85.938 (88.985)\n",
            "Epoch: [73][200/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.3299 (1.2994)\tAcc@1 70.312 (62.757)\tAcc@5 89.062 (89.234)\n",
            "Epoch: [73][300/782]\tTime 0.055 (0.052)\tData 0.002 (0.002)\tLoss 1.5267 (1.3204)\tAcc@1 57.812 (62.183)\tAcc@5 87.500 (89.042)\n",
            "Epoch: [73][400/782]\tTime 0.053 (0.052)\tData 0.002 (0.002)\tLoss 1.1379 (1.3187)\tAcc@1 65.625 (62.352)\tAcc@5 90.625 (89.027)\n",
            "Epoch: [73][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.5580 (1.3332)\tAcc@1 51.562 (61.945)\tAcc@5 85.938 (88.875)\n",
            "Epoch: [73][600/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3969 (1.3395)\tAcc@1 57.812 (61.764)\tAcc@5 89.062 (88.813)\n",
            "Epoch: [73][700/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3150 (1.3463)\tAcc@1 64.062 (61.568)\tAcc@5 87.500 (88.759)\n",
            " * Acc@1 61.510 Acc@5 88.690\n",
            "epoch 73, total time 40.55\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 2.1907 (2.1907)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 2.2212 (1.7889)\tAcc@1 43.750 (52.970)\tAcc@5 84.375 (82.457)\n",
            "Test: [200/313]\tTime 0.019 (0.018)\tLoss 1.4436 (1.8040)\tAcc@1 65.625 (52.721)\tAcc@5 87.500 (82.261)\n",
            "Test: [300/313]\tTime 0.020 (0.018)\tLoss 2.6439 (1.8389)\tAcc@1 34.375 (52.326)\tAcc@5 75.000 (81.696)\n",
            " * Acc@1 52.320 Acc@5 81.680\n",
            "==> training...\n",
            "Epoch: [74][0/782]\tTime 0.295 (0.295)\tData 0.202 (0.202)\tLoss 1.2349 (1.2349)\tAcc@1 62.500 (62.500)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [74][100/782]\tTime 0.051 (0.058)\tData 0.001 (0.003)\tLoss 1.2666 (1.3054)\tAcc@1 62.500 (62.423)\tAcc@5 89.062 (89.325)\n",
            "Epoch: [74][200/782]\tTime 0.051 (0.056)\tData 0.001 (0.002)\tLoss 0.8259 (1.2914)\tAcc@1 76.562 (62.741)\tAcc@5 92.188 (89.708)\n",
            "Epoch: [74][300/782]\tTime 0.055 (0.055)\tData 0.001 (0.002)\tLoss 1.3593 (1.3163)\tAcc@1 65.625 (62.147)\tAcc@5 87.500 (89.156)\n",
            "Epoch: [74][400/782]\tTime 0.052 (0.054)\tData 0.001 (0.002)\tLoss 1.0558 (1.3255)\tAcc@1 70.312 (61.943)\tAcc@5 89.062 (89.055)\n",
            "Epoch: [74][500/782]\tTime 0.051 (0.054)\tData 0.001 (0.002)\tLoss 1.4190 (1.3382)\tAcc@1 59.375 (61.564)\tAcc@5 85.938 (88.928)\n",
            "Epoch: [74][600/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.4845 (1.3389)\tAcc@1 57.812 (61.543)\tAcc@5 90.625 (88.925)\n",
            "Epoch: [74][700/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.9245 (1.3420)\tAcc@1 75.000 (61.497)\tAcc@5 93.750 (88.822)\n",
            " * Acc@1 61.524 Acc@5 88.878\n",
            "epoch 74, total time 41.05\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 2.1845 (2.1845)\tAcc@1 59.375 (59.375)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.0252 (1.8364)\tAcc@1 43.750 (52.568)\tAcc@5 75.000 (82.952)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 0.9612 (1.8509)\tAcc@1 71.875 (52.752)\tAcc@5 90.625 (82.198)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.9712 (1.8531)\tAcc@1 43.750 (52.409)\tAcc@5 84.375 (82.029)\n",
            " * Acc@1 52.470 Acc@5 82.080\n",
            "==> training...\n",
            "Epoch: [75][0/782]\tTime 0.270 (0.270)\tData 0.185 (0.185)\tLoss 1.4207 (1.4207)\tAcc@1 53.125 (53.125)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [75][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.2617 (1.2812)\tAcc@1 65.625 (63.320)\tAcc@5 89.062 (89.418)\n",
            "Epoch: [75][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2794 (1.3031)\tAcc@1 64.062 (62.624)\tAcc@5 87.500 (89.241)\n",
            "Epoch: [75][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4411 (1.3061)\tAcc@1 64.062 (62.583)\tAcc@5 89.062 (89.348)\n",
            "Epoch: [75][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.5557 (1.3274)\tAcc@1 57.812 (62.087)\tAcc@5 84.375 (88.918)\n",
            "Epoch: [75][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1755 (1.3229)\tAcc@1 70.312 (62.063)\tAcc@5 92.188 (89.081)\n",
            "Epoch: [75][600/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.6901 (1.3295)\tAcc@1 54.688 (61.983)\tAcc@5 79.688 (89.065)\n",
            "Epoch: [75][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3029 (1.3307)\tAcc@1 67.188 (61.923)\tAcc@5 87.500 (89.011)\n",
            " * Acc@1 61.828 Acc@5 88.908\n",
            "epoch 75, total time 40.16\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 2.0019 (2.0019)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.7757 (1.8480)\tAcc@1 53.125 (51.361)\tAcc@5 87.500 (82.178)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.2108 (1.8464)\tAcc@1 68.750 (51.695)\tAcc@5 90.625 (82.105)\n",
            "Test: [300/313]\tTime 0.019 (0.018)\tLoss 1.9309 (1.8765)\tAcc@1 50.000 (51.651)\tAcc@5 96.875 (82.049)\n",
            " * Acc@1 51.670 Acc@5 81.970\n",
            "==> training...\n",
            "Epoch: [76][0/782]\tTime 0.289 (0.289)\tData 0.200 (0.200)\tLoss 1.5097 (1.5097)\tAcc@1 60.938 (60.938)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [76][100/782]\tTime 0.049 (0.058)\tData 0.001 (0.003)\tLoss 1.3734 (1.2968)\tAcc@1 60.938 (62.732)\tAcc@5 92.188 (89.202)\n",
            "Epoch: [76][200/782]\tTime 0.050 (0.054)\tData 0.001 (0.002)\tLoss 1.0864 (1.2945)\tAcc@1 71.875 (63.036)\tAcc@5 93.750 (89.389)\n",
            "Epoch: [76][300/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.4092 (1.3056)\tAcc@1 60.938 (62.728)\tAcc@5 89.062 (89.239)\n",
            "Epoch: [76][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5714 (1.3169)\tAcc@1 60.938 (62.453)\tAcc@5 82.812 (89.020)\n",
            "Epoch: [76][500/782]\tTime 0.048 (0.052)\tData 0.001 (0.002)\tLoss 1.2012 (1.3218)\tAcc@1 64.062 (62.406)\tAcc@5 92.188 (88.910)\n",
            "Epoch: [76][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.6660 (1.3324)\tAcc@1 46.875 (62.100)\tAcc@5 87.500 (88.808)\n",
            "Epoch: [76][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3193 (1.3377)\tAcc@1 68.750 (61.967)\tAcc@5 90.625 (88.804)\n",
            " * Acc@1 61.802 Acc@5 88.858\n",
            "epoch 76, total time 40.26\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 2.0243 (2.0243)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.7415 (1.7888)\tAcc@1 50.000 (52.382)\tAcc@5 81.250 (81.869)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.1502 (1.7914)\tAcc@1 65.625 (52.394)\tAcc@5 96.875 (81.670)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0680 (1.8013)\tAcc@1 43.750 (52.533)\tAcc@5 84.375 (81.551)\n",
            " * Acc@1 52.560 Acc@5 81.520\n",
            "==> training...\n",
            "Epoch: [77][0/782]\tTime 0.285 (0.285)\tData 0.201 (0.201)\tLoss 1.3695 (1.3695)\tAcc@1 57.812 (57.812)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [77][100/782]\tTime 0.052 (0.052)\tData 0.001 (0.003)\tLoss 1.6004 (1.3345)\tAcc@1 51.562 (62.299)\tAcc@5 90.625 (88.537)\n",
            "Epoch: [77][200/782]\tTime 0.052 (0.053)\tData 0.001 (0.002)\tLoss 1.4857 (1.3123)\tAcc@1 62.500 (62.376)\tAcc@5 87.500 (89.140)\n",
            "Epoch: [77][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3081 (1.3190)\tAcc@1 59.375 (62.308)\tAcc@5 84.375 (89.068)\n",
            "Epoch: [77][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3943 (1.3204)\tAcc@1 56.250 (62.239)\tAcc@5 89.062 (89.051)\n",
            "Epoch: [77][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2927 (1.3279)\tAcc@1 59.375 (62.123)\tAcc@5 85.938 (89.069)\n",
            "Epoch: [77][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2379 (1.3402)\tAcc@1 68.750 (61.850)\tAcc@5 95.312 (88.940)\n",
            "Epoch: [77][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4386 (1.3439)\tAcc@1 67.188 (61.747)\tAcc@5 89.062 (88.913)\n",
            " * Acc@1 61.784 Acc@5 88.940\n",
            "epoch 77, total time 40.15\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.5946 (1.5946)\tAcc@1 65.625 (65.625)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.5360 (1.7443)\tAcc@1 56.250 (53.960)\tAcc@5 93.750 (82.859)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.4395 (1.7383)\tAcc@1 65.625 (53.933)\tAcc@5 90.625 (82.805)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.5198 (1.7642)\tAcc@1 62.500 (53.789)\tAcc@5 90.625 (82.610)\n",
            " * Acc@1 53.760 Acc@5 82.570\n",
            "==> training...\n",
            "Epoch: [78][0/782]\tTime 0.267 (0.267)\tData 0.182 (0.182)\tLoss 1.3566 (1.3566)\tAcc@1 62.500 (62.500)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [78][100/782]\tTime 0.048 (0.053)\tData 0.001 (0.003)\tLoss 1.1641 (1.2684)\tAcc@1 56.250 (63.258)\tAcc@5 93.750 (89.975)\n",
            "Epoch: [78][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4281 (1.2853)\tAcc@1 65.625 (63.192)\tAcc@5 84.375 (89.653)\n",
            "Epoch: [78][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3289 (1.3041)\tAcc@1 60.938 (62.645)\tAcc@5 85.938 (89.332)\n",
            "Epoch: [78][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2719 (1.3154)\tAcc@1 73.438 (62.597)\tAcc@5 89.062 (89.144)\n",
            "Epoch: [78][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.0029 (1.3186)\tAcc@1 70.312 (62.488)\tAcc@5 93.750 (89.103)\n",
            "Epoch: [78][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1026 (1.3317)\tAcc@1 70.312 (62.230)\tAcc@5 95.312 (88.891)\n",
            "Epoch: [78][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.5919 (1.3345)\tAcc@1 54.688 (62.088)\tAcc@5 85.938 (88.813)\n",
            " * Acc@1 61.980 Acc@5 88.784\n",
            "epoch 78, total time 39.71\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.7444 (1.7444)\tAcc@1 53.125 (53.125)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.9146 (1.7058)\tAcc@1 50.000 (54.920)\tAcc@5 84.375 (83.385)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.5401 (1.7094)\tAcc@1 53.125 (54.073)\tAcc@5 87.500 (83.458)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.4488 (1.7116)\tAcc@1 65.625 (54.215)\tAcc@5 93.750 (83.461)\n",
            " * Acc@1 54.280 Acc@5 83.520\n",
            "==> training...\n",
            "Epoch: [79][0/782]\tTime 0.283 (0.283)\tData 0.191 (0.191)\tLoss 1.0454 (1.0454)\tAcc@1 68.750 (68.750)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [79][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.3568 (1.2959)\tAcc@1 60.938 (63.196)\tAcc@5 82.812 (89.573)\n",
            "Epoch: [79][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1380 (1.3083)\tAcc@1 67.188 (62.741)\tAcc@5 90.625 (89.373)\n",
            "Epoch: [79][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2508 (1.3207)\tAcc@1 57.812 (62.292)\tAcc@5 90.625 (89.062)\n",
            "Epoch: [79][400/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 1.1905 (1.3259)\tAcc@1 62.500 (62.204)\tAcc@5 90.625 (88.942)\n",
            "Epoch: [79][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3402 (1.3380)\tAcc@1 65.625 (61.795)\tAcc@5 89.062 (88.832)\n",
            "Epoch: [79][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5561 (1.3408)\tAcc@1 56.250 (61.772)\tAcc@5 79.688 (88.805)\n",
            "Epoch: [79][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3271 (1.3404)\tAcc@1 64.062 (61.769)\tAcc@5 89.062 (88.813)\n",
            " * Acc@1 61.606 Acc@5 88.734\n",
            "epoch 79, total time 39.72\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.8474 (1.8474)\tAcc@1 62.500 (62.500)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 2.1250 (1.9439)\tAcc@1 31.250 (49.629)\tAcc@5 90.625 (80.910)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.5731 (1.9314)\tAcc@1 50.000 (50.202)\tAcc@5 87.500 (81.157)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.4821 (1.9412)\tAcc@1 28.125 (49.958)\tAcc@5 81.250 (80.845)\n",
            " * Acc@1 49.930 Acc@5 80.810\n",
            "==> training...\n",
            "Epoch: [80][0/782]\tTime 0.276 (0.276)\tData 0.194 (0.194)\tLoss 1.5349 (1.5349)\tAcc@1 50.000 (50.000)\tAcc@5 84.375 (84.375)\n",
            "Epoch: [80][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.0728 (1.2846)\tAcc@1 64.062 (63.567)\tAcc@5 93.750 (89.790)\n",
            "Epoch: [80][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.6444 (1.2975)\tAcc@1 57.812 (62.725)\tAcc@5 89.062 (89.482)\n",
            "Epoch: [80][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4531 (1.3080)\tAcc@1 56.250 (62.287)\tAcc@5 87.500 (89.395)\n",
            "Epoch: [80][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2308 (1.3216)\tAcc@1 64.062 (61.709)\tAcc@5 85.938 (89.242)\n",
            "Epoch: [80][500/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.4658 (1.3293)\tAcc@1 64.062 (61.677)\tAcc@5 79.688 (89.056)\n",
            "Epoch: [80][600/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.4512 (1.3353)\tAcc@1 57.812 (61.608)\tAcc@5 89.062 (88.849)\n",
            "Epoch: [80][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.5943 (1.3388)\tAcc@1 56.250 (61.655)\tAcc@5 90.625 (88.704)\n",
            " * Acc@1 61.592 Acc@5 88.666\n",
            "epoch 80, total time 40.04\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.8232 (1.8232)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.9673 (1.7777)\tAcc@1 56.250 (53.929)\tAcc@5 84.375 (83.416)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.3534 (1.7809)\tAcc@1 65.625 (53.109)\tAcc@5 93.750 (82.789)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.9636 (1.8004)\tAcc@1 46.875 (53.250)\tAcc@5 90.625 (82.402)\n",
            " * Acc@1 53.250 Acc@5 82.360\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [81][0/782]\tTime 0.273 (0.273)\tData 0.189 (0.189)\tLoss 1.3436 (1.3436)\tAcc@1 60.938 (60.938)\tAcc@5 82.812 (82.812)\n",
            "Epoch: [81][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.2328 (1.2738)\tAcc@1 68.750 (63.970)\tAcc@5 90.625 (89.712)\n",
            "Epoch: [81][200/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1277 (1.2730)\tAcc@1 67.188 (63.604)\tAcc@5 92.188 (89.832)\n",
            "Epoch: [81][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2525 (1.2982)\tAcc@1 64.062 (63.081)\tAcc@5 87.500 (89.343)\n",
            "Epoch: [81][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4047 (1.3056)\tAcc@1 60.938 (62.905)\tAcc@5 90.625 (89.281)\n",
            "Epoch: [81][500/782]\tTime 0.054 (0.051)\tData 0.002 (0.002)\tLoss 1.5933 (1.3180)\tAcc@1 53.125 (62.463)\tAcc@5 84.375 (89.165)\n",
            "Epoch: [81][600/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.2776 (1.3238)\tAcc@1 59.375 (62.172)\tAcc@5 87.500 (89.083)\n",
            "Epoch: [81][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3585 (1.3356)\tAcc@1 57.812 (61.845)\tAcc@5 87.500 (88.884)\n",
            " * Acc@1 61.846 Acc@5 88.930\n",
            "epoch 81, total time 39.63\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 1.8947 (1.8947)\tAcc@1 56.250 (56.250)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4401 (1.6503)\tAcc@1 56.250 (55.848)\tAcc@5 90.625 (84.499)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 1.2697 (1.6500)\tAcc@1 62.500 (55.815)\tAcc@5 90.625 (84.624)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.9479 (1.6673)\tAcc@1 46.875 (55.689)\tAcc@5 90.625 (84.230)\n",
            " * Acc@1 55.760 Acc@5 84.250\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [82][0/782]\tTime 0.287 (0.287)\tData 0.205 (0.205)\tLoss 1.3394 (1.3394)\tAcc@1 54.688 (54.688)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [82][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.2363 (1.3298)\tAcc@1 64.062 (62.345)\tAcc@5 89.062 (88.815)\n",
            "Epoch: [82][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1386 (1.3061)\tAcc@1 59.375 (63.021)\tAcc@5 92.188 (88.938)\n",
            "Epoch: [82][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4356 (1.3201)\tAcc@1 57.812 (62.313)\tAcc@5 89.062 (89.011)\n",
            "Epoch: [82][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4222 (1.3282)\tAcc@1 59.375 (62.009)\tAcc@5 89.062 (88.918)\n",
            "Epoch: [82][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3353 (1.3331)\tAcc@1 64.062 (61.861)\tAcc@5 85.938 (88.825)\n",
            "Epoch: [82][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.9969 (1.3389)\tAcc@1 67.188 (61.681)\tAcc@5 92.188 (88.743)\n",
            "Epoch: [82][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4172 (1.3418)\tAcc@1 53.125 (61.617)\tAcc@5 92.188 (88.688)\n",
            " * Acc@1 61.648 Acc@5 88.668\n",
            "epoch 82, total time 40.02\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 2.0894 (2.0894)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.7428 (1.7662)\tAcc@1 46.875 (53.558)\tAcc@5 84.375 (84.746)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.6193 (1.7656)\tAcc@1 68.750 (53.607)\tAcc@5 87.500 (84.437)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.2474 (1.7764)\tAcc@1 37.500 (53.353)\tAcc@5 75.000 (83.877)\n",
            " * Acc@1 53.320 Acc@5 83.900\n",
            "==> training...\n",
            "Epoch: [83][0/782]\tTime 0.256 (0.256)\tData 0.176 (0.176)\tLoss 1.2157 (1.2157)\tAcc@1 67.188 (67.188)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [83][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 0.9295 (1.2754)\tAcc@1 64.062 (63.537)\tAcc@5 95.312 (89.790)\n",
            "Epoch: [83][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.2553 (1.2979)\tAcc@1 62.500 (62.819)\tAcc@5 92.188 (89.583)\n",
            "Epoch: [83][300/782]\tTime 0.067 (0.052)\tData 0.001 (0.002)\tLoss 1.3374 (1.3154)\tAcc@1 60.938 (62.344)\tAcc@5 84.375 (89.099)\n",
            "Epoch: [83][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2306 (1.3194)\tAcc@1 65.625 (62.348)\tAcc@5 90.625 (89.066)\n",
            "Epoch: [83][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2304 (1.3263)\tAcc@1 68.750 (62.188)\tAcc@5 92.188 (88.913)\n",
            "Epoch: [83][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 1.4677 (1.3298)\tAcc@1 62.500 (62.014)\tAcc@5 84.375 (88.935)\n",
            "Epoch: [83][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1045 (1.3324)\tAcc@1 67.188 (61.990)\tAcc@5 90.625 (88.929)\n",
            " * Acc@1 61.970 Acc@5 88.928\n",
            "epoch 83, total time 39.95\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 2.0388 (2.0388)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.024 (0.020)\tLoss 1.9928 (1.8578)\tAcc@1 43.750 (51.330)\tAcc@5 81.250 (81.931)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.4344 (1.8439)\tAcc@1 59.375 (52.083)\tAcc@5 78.125 (81.872)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.9435 (1.8624)\tAcc@1 43.750 (51.900)\tAcc@5 84.375 (81.645)\n",
            " * Acc@1 51.860 Acc@5 81.590\n",
            "==> training...\n",
            "Epoch: [84][0/782]\tTime 0.272 (0.272)\tData 0.196 (0.196)\tLoss 0.9687 (0.9687)\tAcc@1 70.312 (70.312)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [84][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.5193 (1.2888)\tAcc@1 57.812 (62.918)\tAcc@5 84.375 (89.310)\n",
            "Epoch: [84][200/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 1.2444 (1.3072)\tAcc@1 65.625 (62.578)\tAcc@5 87.500 (89.202)\n",
            "Epoch: [84][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2894 (1.3121)\tAcc@1 64.062 (62.526)\tAcc@5 90.625 (89.057)\n",
            "Epoch: [84][400/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.3342 (1.3170)\tAcc@1 65.625 (62.231)\tAcc@5 90.625 (88.977)\n",
            "Epoch: [84][500/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 2.0026 (1.3270)\tAcc@1 50.000 (61.879)\tAcc@5 78.125 (88.903)\n",
            "Epoch: [84][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.7147 (1.3290)\tAcc@1 48.438 (61.892)\tAcc@5 82.812 (88.821)\n",
            "Epoch: [84][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2213 (1.3313)\tAcc@1 68.750 (61.825)\tAcc@5 89.062 (88.860)\n",
            " * Acc@1 61.686 Acc@5 88.774\n",
            "epoch 84, total time 39.65\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.9627 (1.9627)\tAcc@1 50.000 (50.000)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.6953 (1.7035)\tAcc@1 53.125 (54.517)\tAcc@5 87.500 (83.632)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.1046 (1.7286)\tAcc@1 71.875 (54.120)\tAcc@5 93.750 (83.022)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.0284 (1.7494)\tAcc@1 50.000 (53.779)\tAcc@5 87.500 (82.641)\n",
            " * Acc@1 53.770 Acc@5 82.510\n",
            "==> training...\n",
            "Epoch: [85][0/782]\tTime 0.287 (0.287)\tData 0.201 (0.201)\tLoss 1.2705 (1.2705)\tAcc@1 64.062 (64.062)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [85][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.1917 (1.2990)\tAcc@1 60.938 (63.227)\tAcc@5 95.312 (89.186)\n",
            "Epoch: [85][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4295 (1.2933)\tAcc@1 56.250 (62.795)\tAcc@5 79.688 (89.459)\n",
            "Epoch: [85][300/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.4815 (1.2978)\tAcc@1 62.500 (62.760)\tAcc@5 90.625 (89.441)\n",
            "Epoch: [85][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.5165 (1.3109)\tAcc@1 53.125 (62.609)\tAcc@5 84.375 (89.207)\n",
            "Epoch: [85][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.8304 (1.3123)\tAcc@1 48.438 (62.584)\tAcc@5 84.375 (89.134)\n",
            "Epoch: [85][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5438 (1.3234)\tAcc@1 67.188 (62.235)\tAcc@5 85.938 (89.047)\n",
            "Epoch: [85][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3724 (1.3249)\tAcc@1 62.500 (62.170)\tAcc@5 89.062 (89.078)\n",
            " * Acc@1 62.062 Acc@5 88.968\n",
            "epoch 85, total time 39.86\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 1.6850 (1.6850)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.024 (0.020)\tLoss 2.2178 (1.7336)\tAcc@1 40.625 (52.970)\tAcc@5 78.125 (82.797)\n",
            "Test: [200/313]\tTime 0.024 (0.020)\tLoss 1.2672 (1.7178)\tAcc@1 65.625 (53.980)\tAcc@5 93.750 (82.649)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.9121 (1.7396)\tAcc@1 46.875 (53.738)\tAcc@5 81.250 (82.454)\n",
            " * Acc@1 53.780 Acc@5 82.450\n",
            "==> training...\n",
            "Epoch: [86][0/782]\tTime 0.263 (0.263)\tData 0.195 (0.195)\tLoss 1.1607 (1.1607)\tAcc@1 64.062 (64.062)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [86][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.2473 (1.2671)\tAcc@1 68.750 (63.691)\tAcc@5 90.625 (89.666)\n",
            "Epoch: [86][200/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.2460 (1.3021)\tAcc@1 67.188 (62.826)\tAcc@5 89.062 (89.249)\n",
            "Epoch: [86][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4082 (1.3187)\tAcc@1 62.500 (62.303)\tAcc@5 85.938 (89.037)\n",
            "Epoch: [86][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.0337 (1.3243)\tAcc@1 70.312 (62.227)\tAcc@5 90.625 (88.942)\n",
            "Epoch: [86][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4553 (1.3201)\tAcc@1 56.250 (62.272)\tAcc@5 82.812 (89.003)\n",
            "Epoch: [86][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6819 (1.3279)\tAcc@1 53.125 (62.092)\tAcc@5 81.250 (88.844)\n",
            "Epoch: [86][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4996 (1.3326)\tAcc@1 57.812 (62.010)\tAcc@5 84.375 (88.791)\n",
            " * Acc@1 61.868 Acc@5 88.802\n",
            "epoch 86, total time 39.62\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 2.0066 (2.0066)\tAcc@1 56.250 (56.250)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.024 (0.020)\tLoss 1.9248 (1.7725)\tAcc@1 50.000 (52.290)\tAcc@5 78.125 (81.498)\n",
            "Test: [200/313]\tTime 0.025 (0.020)\tLoss 1.8105 (1.8061)\tAcc@1 59.375 (51.959)\tAcc@5 75.000 (81.032)\n",
            "Test: [300/313]\tTime 0.020 (0.019)\tLoss 2.4069 (1.8077)\tAcc@1 34.375 (52.191)\tAcc@5 62.500 (81.105)\n",
            " * Acc@1 52.150 Acc@5 81.090\n",
            "==> training...\n",
            "Epoch: [87][0/782]\tTime 0.282 (0.282)\tData 0.197 (0.197)\tLoss 1.1488 (1.1488)\tAcc@1 70.312 (70.312)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [87][100/782]\tTime 0.056 (0.057)\tData 0.001 (0.003)\tLoss 1.0616 (1.2728)\tAcc@1 65.625 (63.382)\tAcc@5 92.188 (89.975)\n",
            "Epoch: [87][200/782]\tTime 0.050 (0.054)\tData 0.001 (0.002)\tLoss 0.9249 (1.2818)\tAcc@1 70.312 (63.215)\tAcc@5 96.875 (89.964)\n",
            "Epoch: [87][300/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.1317 (1.2994)\tAcc@1 67.188 (62.671)\tAcc@5 93.750 (89.649)\n",
            "Epoch: [87][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5072 (1.3135)\tAcc@1 57.812 (62.344)\tAcc@5 85.938 (89.401)\n",
            "Epoch: [87][500/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.0945 (1.3184)\tAcc@1 75.000 (62.322)\tAcc@5 89.062 (89.253)\n",
            "Epoch: [87][600/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2112 (1.3205)\tAcc@1 67.188 (62.219)\tAcc@5 89.062 (89.179)\n",
            "Epoch: [87][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4877 (1.3276)\tAcc@1 64.062 (62.001)\tAcc@5 85.938 (89.087)\n",
            " * Acc@1 61.934 Acc@5 89.056\n",
            "epoch 87, total time 40.16\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.8898 (1.8898)\tAcc@1 56.250 (56.250)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4540 (1.7292)\tAcc@1 53.125 (54.270)\tAcc@5 93.750 (83.354)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.7528 (1.7252)\tAcc@1 56.250 (54.493)\tAcc@5 81.250 (83.551)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0080 (1.7246)\tAcc@1 46.875 (54.402)\tAcc@5 81.250 (83.451)\n",
            " * Acc@1 54.610 Acc@5 83.430\n",
            "==> training...\n",
            "Epoch: [88][0/782]\tTime 0.264 (0.264)\tData 0.178 (0.178)\tLoss 1.9258 (1.9258)\tAcc@1 50.000 (50.000)\tAcc@5 84.375 (84.375)\n",
            "Epoch: [88][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.1691 (1.2921)\tAcc@1 70.312 (63.444)\tAcc@5 90.625 (89.666)\n",
            "Epoch: [88][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5091 (1.2898)\tAcc@1 54.688 (63.215)\tAcc@5 82.812 (89.747)\n",
            "Epoch: [88][300/782]\tTime 0.069 (0.052)\tData 0.001 (0.002)\tLoss 1.4330 (1.2987)\tAcc@1 56.250 (62.837)\tAcc@5 85.938 (89.478)\n",
            "Epoch: [88][400/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.4666 (1.3002)\tAcc@1 64.062 (62.738)\tAcc@5 87.500 (89.417)\n",
            "Epoch: [88][500/782]\tTime 0.067 (0.053)\tData 0.001 (0.002)\tLoss 1.2296 (1.3059)\tAcc@1 65.625 (62.572)\tAcc@5 93.750 (89.349)\n",
            "Epoch: [88][600/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.4189 (1.3113)\tAcc@1 65.625 (62.414)\tAcc@5 87.500 (89.263)\n",
            "Epoch: [88][700/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.1615 (1.3210)\tAcc@1 71.875 (62.152)\tAcc@5 90.625 (89.078)\n",
            " * Acc@1 62.108 Acc@5 89.046\n",
            "epoch 88, total time 41.23\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.0611 (2.0611)\tAcc@1 46.875 (46.875)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.6787 (1.8389)\tAcc@1 37.500 (52.816)\tAcc@5 87.500 (81.869)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.5598 (1.8314)\tAcc@1 56.250 (52.488)\tAcc@5 90.625 (82.121)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.3654 (1.8335)\tAcc@1 37.500 (52.263)\tAcc@5 71.875 (82.164)\n",
            " * Acc@1 52.360 Acc@5 82.210\n",
            "==> training...\n",
            "Epoch: [89][0/782]\tTime 0.278 (0.278)\tData 0.199 (0.199)\tLoss 0.9328 (0.9328)\tAcc@1 76.562 (76.562)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [89][100/782]\tTime 0.055 (0.053)\tData 0.001 (0.003)\tLoss 1.3587 (1.2640)\tAcc@1 57.812 (63.877)\tAcc@5 87.500 (89.821)\n",
            "Epoch: [89][200/782]\tTime 0.050 (0.052)\tData 0.002 (0.002)\tLoss 1.0482 (1.2655)\tAcc@1 67.188 (63.697)\tAcc@5 93.750 (89.902)\n",
            "Epoch: [89][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4569 (1.2891)\tAcc@1 64.062 (63.102)\tAcc@5 85.938 (89.613)\n",
            "Epoch: [89][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5597 (1.2978)\tAcc@1 54.688 (62.851)\tAcc@5 92.188 (89.604)\n",
            "Epoch: [89][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2898 (1.3101)\tAcc@1 71.875 (62.444)\tAcc@5 87.500 (89.480)\n",
            "Epoch: [89][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3963 (1.3185)\tAcc@1 57.812 (62.258)\tAcc@5 85.938 (89.335)\n",
            "Epoch: [89][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.5790 (1.3238)\tAcc@1 54.688 (62.181)\tAcc@5 82.812 (89.250)\n",
            " * Acc@1 61.982 Acc@5 89.120\n",
            "epoch 89, total time 39.77\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.9318 (1.9318)\tAcc@1 56.250 (56.250)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.6550 (1.8772)\tAcc@1 53.125 (52.630)\tAcc@5 87.500 (82.580)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.6198 (1.8917)\tAcc@1 62.500 (51.866)\tAcc@5 84.375 (81.981)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.8818 (1.9039)\tAcc@1 46.875 (51.651)\tAcc@5 84.375 (81.914)\n",
            " * Acc@1 51.660 Acc@5 81.850\n",
            "==> training...\n",
            "Epoch: [90][0/782]\tTime 0.254 (0.254)\tData 0.179 (0.179)\tLoss 1.2957 (1.2957)\tAcc@1 62.500 (62.500)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [90][100/782]\tTime 0.051 (0.052)\tData 0.001 (0.003)\tLoss 1.0895 (1.2461)\tAcc@1 75.000 (63.722)\tAcc@5 96.875 (90.300)\n",
            "Epoch: [90][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4896 (1.3027)\tAcc@1 56.250 (62.624)\tAcc@5 85.938 (89.692)\n",
            "Epoch: [90][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2626 (1.3039)\tAcc@1 62.500 (62.443)\tAcc@5 90.625 (89.509)\n",
            "Epoch: [90][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3653 (1.3036)\tAcc@1 60.938 (62.492)\tAcc@5 85.938 (89.487)\n",
            "Epoch: [90][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3155 (1.3138)\tAcc@1 65.625 (62.403)\tAcc@5 89.062 (89.284)\n",
            "Epoch: [90][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6498 (1.3172)\tAcc@1 50.000 (62.256)\tAcc@5 81.250 (89.187)\n",
            "Epoch: [90][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5215 (1.3214)\tAcc@1 57.812 (62.210)\tAcc@5 82.812 (89.114)\n",
            " * Acc@1 62.190 Acc@5 89.076\n",
            "epoch 90, total time 39.76\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.8440 (1.8440)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.8568 (1.6752)\tAcc@1 46.875 (54.363)\tAcc@5 81.250 (84.344)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.5902 (1.7195)\tAcc@1 62.500 (53.156)\tAcc@5 84.375 (83.629)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.8276 (1.7116)\tAcc@1 56.250 (53.665)\tAcc@5 81.250 (83.264)\n",
            " * Acc@1 53.560 Acc@5 83.180\n",
            "==> training...\n",
            "Epoch: [91][0/782]\tTime 0.269 (0.269)\tData 0.200 (0.200)\tLoss 1.3047 (1.3047)\tAcc@1 59.375 (59.375)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [91][100/782]\tTime 0.054 (0.053)\tData 0.001 (0.003)\tLoss 1.2328 (1.2947)\tAcc@1 62.500 (62.593)\tAcc@5 90.625 (89.279)\n",
            "Epoch: [91][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3872 (1.2938)\tAcc@1 59.375 (62.547)\tAcc@5 84.375 (89.428)\n",
            "Epoch: [91][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1122 (1.3027)\tAcc@1 64.062 (62.593)\tAcc@5 95.312 (89.244)\n",
            "Epoch: [91][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4509 (1.3205)\tAcc@1 57.812 (62.138)\tAcc@5 85.938 (89.031)\n",
            "Epoch: [91][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2705 (1.3253)\tAcc@1 62.500 (62.135)\tAcc@5 92.188 (88.975)\n",
            "Epoch: [91][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 1.2402 (1.3290)\tAcc@1 67.188 (62.110)\tAcc@5 85.938 (88.925)\n",
            "Epoch: [91][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2567 (1.3349)\tAcc@1 62.500 (61.994)\tAcc@5 92.188 (88.835)\n",
            " * Acc@1 61.922 Acc@5 88.812\n",
            "epoch 91, total time 39.80\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 2.0249 (2.0249)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.022)\tLoss 1.5967 (1.6359)\tAcc@1 56.250 (56.281)\tAcc@5 90.625 (84.220)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.5888 (1.6024)\tAcc@1 59.375 (56.437)\tAcc@5 87.500 (84.686)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.9851 (1.6251)\tAcc@1 53.125 (56.229)\tAcc@5 84.375 (84.479)\n",
            " * Acc@1 56.400 Acc@5 84.510\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [92][0/782]\tTime 0.274 (0.274)\tData 0.204 (0.204)\tLoss 1.2881 (1.2881)\tAcc@1 68.750 (68.750)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [92][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.1427 (1.2954)\tAcc@1 67.188 (62.732)\tAcc@5 92.188 (89.155)\n",
            "Epoch: [92][200/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.6258 (1.3013)\tAcc@1 53.125 (62.150)\tAcc@5 85.938 (89.342)\n",
            "Epoch: [92][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4915 (1.3130)\tAcc@1 60.938 (62.261)\tAcc@5 82.812 (89.172)\n",
            "Epoch: [92][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2853 (1.3112)\tAcc@1 60.938 (62.255)\tAcc@5 93.750 (89.273)\n",
            "Epoch: [92][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4678 (1.3184)\tAcc@1 68.750 (62.210)\tAcc@5 85.938 (89.134)\n",
            "Epoch: [92][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2172 (1.3215)\tAcc@1 68.750 (62.032)\tAcc@5 89.062 (89.122)\n",
            "Epoch: [92][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2861 (1.3218)\tAcc@1 56.250 (62.065)\tAcc@5 93.750 (89.134)\n",
            " * Acc@1 61.872 Acc@5 89.112\n",
            "epoch 92, total time 39.98\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.8582 (1.8582)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.1536 (1.6433)\tAcc@1 50.000 (55.476)\tAcc@5 78.125 (84.066)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.4655 (1.6420)\tAcc@1 59.375 (55.597)\tAcc@5 87.500 (84.624)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.2203 (1.6492)\tAcc@1 46.875 (55.534)\tAcc@5 75.000 (84.468)\n",
            " * Acc@1 55.610 Acc@5 84.450\n",
            "==> training...\n",
            "Epoch: [93][0/782]\tTime 0.277 (0.277)\tData 0.199 (0.199)\tLoss 1.0679 (1.0679)\tAcc@1 65.625 (65.625)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [93][100/782]\tTime 0.049 (0.052)\tData 0.001 (0.003)\tLoss 1.4044 (1.2874)\tAcc@1 59.375 (62.825)\tAcc@5 85.938 (89.480)\n",
            "Epoch: [93][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1432 (1.2755)\tAcc@1 67.188 (63.542)\tAcc@5 93.750 (89.607)\n",
            "Epoch: [93][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.0815 (1.2991)\tAcc@1 67.188 (62.920)\tAcc@5 93.750 (89.457)\n",
            "Epoch: [93][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5941 (1.3046)\tAcc@1 56.250 (62.784)\tAcc@5 84.375 (89.327)\n",
            "Epoch: [93][500/782]\tTime 0.056 (0.051)\tData 0.001 (0.002)\tLoss 1.4112 (1.3178)\tAcc@1 60.938 (62.375)\tAcc@5 89.062 (89.119)\n",
            "Epoch: [93][600/782]\tTime 0.062 (0.051)\tData 0.001 (0.002)\tLoss 1.1567 (1.3204)\tAcc@1 65.625 (62.321)\tAcc@5 90.625 (89.075)\n",
            "Epoch: [93][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.0502 (1.3266)\tAcc@1 64.062 (62.168)\tAcc@5 92.188 (88.991)\n",
            " * Acc@1 62.188 Acc@5 88.996\n",
            "epoch 93, total time 39.93\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.9592 (1.9592)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.9099 (1.7769)\tAcc@1 53.125 (52.785)\tAcc@5 84.375 (82.457)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.5195 (1.7399)\tAcc@1 56.250 (53.654)\tAcc@5 87.500 (82.914)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.7936 (1.7513)\tAcc@1 43.750 (53.634)\tAcc@5 78.125 (82.683)\n",
            " * Acc@1 53.540 Acc@5 82.630\n",
            "==> training...\n",
            "Epoch: [94][0/782]\tTime 0.262 (0.262)\tData 0.191 (0.191)\tLoss 1.0900 (1.0900)\tAcc@1 59.375 (59.375)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [94][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.3788 (1.2568)\tAcc@1 65.625 (64.016)\tAcc@5 90.625 (89.619)\n",
            "Epoch: [94][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.4006 (1.2883)\tAcc@1 62.500 (63.060)\tAcc@5 89.062 (89.436)\n",
            "Epoch: [94][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.6820 (1.3002)\tAcc@1 50.000 (62.749)\tAcc@5 82.812 (89.358)\n",
            "Epoch: [94][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.2158 (1.3088)\tAcc@1 70.312 (62.399)\tAcc@5 87.500 (89.331)\n",
            "Epoch: [94][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3411 (1.3164)\tAcc@1 60.938 (62.141)\tAcc@5 90.625 (89.206)\n",
            "Epoch: [94][600/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 1.7030 (1.3195)\tAcc@1 48.438 (62.053)\tAcc@5 85.938 (89.153)\n",
            "Epoch: [94][700/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3799 (1.3196)\tAcc@1 64.062 (62.101)\tAcc@5 89.062 (89.127)\n",
            " * Acc@1 61.948 Acc@5 89.040\n",
            "epoch 94, total time 40.44\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 2.0125 (2.0125)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 2.2421 (1.7575)\tAcc@1 43.750 (54.548)\tAcc@5 84.375 (82.797)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.4113 (1.7410)\tAcc@1 56.250 (54.353)\tAcc@5 84.375 (83.022)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.8636 (1.7538)\tAcc@1 56.250 (54.153)\tAcc@5 78.125 (82.838)\n",
            " * Acc@1 54.250 Acc@5 82.910\n",
            "==> training...\n",
            "Epoch: [95][0/782]\tTime 0.275 (0.275)\tData 0.182 (0.182)\tLoss 1.0921 (1.0921)\tAcc@1 60.938 (60.938)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [95][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 2.0124 (1.2905)\tAcc@1 50.000 (63.335)\tAcc@5 68.750 (89.233)\n",
            "Epoch: [95][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1492 (1.2884)\tAcc@1 68.750 (63.277)\tAcc@5 93.750 (89.373)\n",
            "Epoch: [95][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1482 (1.2895)\tAcc@1 64.062 (63.019)\tAcc@5 92.188 (89.400)\n",
            "Epoch: [95][400/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 1.1212 (1.2972)\tAcc@1 70.312 (62.765)\tAcc@5 89.062 (89.331)\n",
            "Epoch: [95][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.1501 (1.3036)\tAcc@1 67.188 (62.647)\tAcc@5 92.188 (89.306)\n",
            "Epoch: [95][600/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3255 (1.3076)\tAcc@1 62.500 (62.474)\tAcc@5 92.188 (89.234)\n",
            "Epoch: [95][700/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.2601 (1.3150)\tAcc@1 64.062 (62.337)\tAcc@5 85.938 (89.051)\n",
            " * Acc@1 62.242 Acc@5 88.948\n",
            "epoch 95, total time 40.46\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 2.0806 (2.0806)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 2.0616 (1.7031)\tAcc@1 46.875 (54.332)\tAcc@5 81.250 (83.385)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.6502 (1.6903)\tAcc@1 59.375 (54.680)\tAcc@5 84.375 (83.567)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.0543 (1.6976)\tAcc@1 40.625 (54.952)\tAcc@5 75.000 (83.295)\n",
            " * Acc@1 54.910 Acc@5 83.370\n",
            "==> training...\n",
            "Epoch: [96][0/782]\tTime 0.272 (0.272)\tData 0.203 (0.203)\tLoss 1.2851 (1.2851)\tAcc@1 62.500 (62.500)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [96][100/782]\tTime 0.052 (0.055)\tData 0.001 (0.003)\tLoss 1.2330 (1.2611)\tAcc@1 75.000 (63.877)\tAcc@5 85.938 (89.604)\n",
            "Epoch: [96][200/782]\tTime 0.052 (0.054)\tData 0.001 (0.002)\tLoss 1.0210 (1.2714)\tAcc@1 68.750 (63.503)\tAcc@5 95.312 (89.669)\n",
            "Epoch: [96][300/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.2854 (1.2995)\tAcc@1 60.938 (62.941)\tAcc@5 93.750 (89.239)\n",
            "Epoch: [96][400/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.5312 (1.3140)\tAcc@1 59.375 (62.562)\tAcc@5 87.500 (89.098)\n",
            "Epoch: [96][500/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.2688 (1.3161)\tAcc@1 62.500 (62.388)\tAcc@5 87.500 (89.075)\n",
            "Epoch: [96][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2871 (1.3182)\tAcc@1 56.250 (62.227)\tAcc@5 95.312 (89.073)\n",
            "Epoch: [96][700/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3375 (1.3249)\tAcc@1 60.938 (62.083)\tAcc@5 85.938 (88.922)\n",
            " * Acc@1 61.988 Acc@5 88.896\n",
            "epoch 96, total time 40.49\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.7566 (1.7566)\tAcc@1 59.375 (59.375)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.018)\tLoss 1.4034 (1.7241)\tAcc@1 59.375 (53.620)\tAcc@5 96.875 (83.354)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.5101 (1.7325)\tAcc@1 56.250 (53.856)\tAcc@5 84.375 (82.867)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.5724 (1.7554)\tAcc@1 31.250 (53.883)\tAcc@5 71.875 (82.745)\n",
            " * Acc@1 53.930 Acc@5 82.680\n",
            "==> training...\n",
            "Epoch: [97][0/782]\tTime 0.282 (0.282)\tData 0.197 (0.197)\tLoss 1.3019 (1.3019)\tAcc@1 65.625 (65.625)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [97][100/782]\tTime 0.058 (0.054)\tData 0.001 (0.003)\tLoss 1.1622 (1.2595)\tAcc@1 70.312 (64.387)\tAcc@5 92.188 (89.805)\n",
            "Epoch: [97][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.2530 (1.2742)\tAcc@1 65.625 (63.612)\tAcc@5 90.625 (89.646)\n",
            "Epoch: [97][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5157 (1.2890)\tAcc@1 56.250 (62.983)\tAcc@5 84.375 (89.524)\n",
            "Epoch: [97][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.6103 (1.3005)\tAcc@1 57.812 (62.555)\tAcc@5 89.062 (89.296)\n",
            "Epoch: [97][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4522 (1.3013)\tAcc@1 62.500 (62.550)\tAcc@5 84.375 (89.259)\n",
            "Epoch: [97][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2006 (1.3102)\tAcc@1 59.375 (62.360)\tAcc@5 93.750 (89.156)\n",
            "Epoch: [97][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3628 (1.3167)\tAcc@1 64.062 (62.152)\tAcc@5 85.938 (89.051)\n",
            " * Acc@1 62.040 Acc@5 88.958\n",
            "epoch 97, total time 40.09\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.7443 (1.7443)\tAcc@1 56.250 (56.250)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.026 (0.020)\tLoss 2.1053 (1.7140)\tAcc@1 46.875 (54.084)\tAcc@5 81.250 (83.292)\n",
            "Test: [200/313]\tTime 0.025 (0.020)\tLoss 1.5074 (1.7129)\tAcc@1 59.375 (53.918)\tAcc@5 81.250 (83.442)\n",
            "Test: [300/313]\tTime 0.024 (0.020)\tLoss 2.1519 (1.7482)\tAcc@1 43.750 (53.270)\tAcc@5 78.125 (82.901)\n",
            " * Acc@1 53.190 Acc@5 82.970\n",
            "==> training...\n",
            "Epoch: [98][0/782]\tTime 0.268 (0.268)\tData 0.198 (0.198)\tLoss 1.2043 (1.2043)\tAcc@1 68.750 (68.750)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [98][100/782]\tTime 0.051 (0.052)\tData 0.001 (0.003)\tLoss 1.3021 (1.3212)\tAcc@1 62.500 (62.036)\tAcc@5 92.188 (89.449)\n",
            "Epoch: [98][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2119 (1.3052)\tAcc@1 68.750 (62.096)\tAcc@5 85.938 (89.591)\n",
            "Epoch: [98][300/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.0100 (1.3060)\tAcc@1 70.312 (62.209)\tAcc@5 95.312 (89.514)\n",
            "Epoch: [98][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2108 (1.3065)\tAcc@1 59.375 (62.243)\tAcc@5 90.625 (89.522)\n",
            "Epoch: [98][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.0714 (1.2988)\tAcc@1 65.625 (62.556)\tAcc@5 89.062 (89.599)\n",
            "Epoch: [98][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4421 (1.3103)\tAcc@1 56.250 (62.292)\tAcc@5 89.062 (89.403)\n",
            "Epoch: [98][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.8703 (1.3138)\tAcc@1 48.438 (62.192)\tAcc@5 89.062 (89.352)\n",
            " * Acc@1 62.114 Acc@5 89.314\n",
            "epoch 98, total time 40.10\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 1.6862 (1.6862)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.020 (0.019)\tLoss 1.5928 (1.6302)\tAcc@1 43.750 (56.590)\tAcc@5 87.500 (84.623)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.2129 (1.6509)\tAcc@1 59.375 (56.110)\tAcc@5 90.625 (84.204)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.9758 (1.6630)\tAcc@1 50.000 (56.198)\tAcc@5 84.375 (83.804)\n",
            " * Acc@1 56.280 Acc@5 83.850\n",
            "==> training...\n",
            "Epoch: [99][0/782]\tTime 0.267 (0.267)\tData 0.198 (0.198)\tLoss 1.5039 (1.5039)\tAcc@1 59.375 (59.375)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [99][100/782]\tTime 0.051 (0.054)\tData 0.001 (0.003)\tLoss 1.3403 (1.2892)\tAcc@1 62.500 (63.041)\tAcc@5 81.250 (89.295)\n",
            "Epoch: [99][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2843 (1.2980)\tAcc@1 67.188 (62.795)\tAcc@5 89.062 (89.513)\n",
            "Epoch: [99][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.9058 (1.3047)\tAcc@1 68.750 (62.562)\tAcc@5 93.750 (89.353)\n",
            "Epoch: [99][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4221 (1.3106)\tAcc@1 65.625 (62.566)\tAcc@5 87.500 (89.211)\n",
            "Epoch: [99][500/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 1.1481 (1.3039)\tAcc@1 70.312 (62.687)\tAcc@5 93.750 (89.253)\n",
            "Epoch: [99][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.3950 (1.3082)\tAcc@1 60.938 (62.588)\tAcc@5 87.500 (89.286)\n",
            "Epoch: [99][700/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.6033 (1.3121)\tAcc@1 54.688 (62.509)\tAcc@5 84.375 (89.243)\n",
            " * Acc@1 62.446 Acc@5 89.180\n",
            "epoch 99, total time 40.12\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.6679 (1.6679)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.9623 (1.8792)\tAcc@1 50.000 (51.485)\tAcc@5 87.500 (81.095)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.6582 (1.8580)\tAcc@1 59.375 (52.472)\tAcc@5 87.500 (81.421)\n",
            "Test: [300/313]\tTime 0.019 (0.018)\tLoss 2.0678 (1.8740)\tAcc@1 50.000 (52.014)\tAcc@5 87.500 (81.624)\n",
            " * Acc@1 51.970 Acc@5 81.590\n",
            "==> training...\n",
            "Epoch: [100][0/782]\tTime 0.280 (0.280)\tData 0.197 (0.197)\tLoss 1.2411 (1.2411)\tAcc@1 62.500 (62.500)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [100][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 1.4855 (1.2498)\tAcc@1 56.250 (64.001)\tAcc@5 85.938 (90.176)\n",
            "Epoch: [100][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.9659 (1.2768)\tAcc@1 75.000 (63.588)\tAcc@5 98.438 (89.677)\n",
            "Epoch: [100][300/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.3377 (1.2869)\tAcc@1 54.688 (63.305)\tAcc@5 90.625 (89.556)\n",
            "Epoch: [100][400/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.5570 (1.2993)\tAcc@1 64.062 (62.781)\tAcc@5 85.938 (89.347)\n",
            "Epoch: [100][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4744 (1.3083)\tAcc@1 57.812 (62.550)\tAcc@5 82.812 (89.209)\n",
            "Epoch: [100][600/782]\tTime 0.048 (0.052)\tData 0.001 (0.002)\tLoss 1.0921 (1.3177)\tAcc@1 62.500 (62.326)\tAcc@5 92.188 (89.083)\n",
            "Epoch: [100][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3728 (1.3202)\tAcc@1 62.500 (62.204)\tAcc@5 82.812 (89.054)\n",
            " * Acc@1 62.126 Acc@5 88.936\n",
            "epoch 100, total time 40.42\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.6873 (1.6873)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.019 (0.018)\tLoss 2.1851 (1.6501)\tAcc@1 46.875 (55.322)\tAcc@5 78.125 (84.777)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.3153 (1.6685)\tAcc@1 65.625 (55.690)\tAcc@5 87.500 (84.453)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.9079 (1.6813)\tAcc@1 59.375 (55.233)\tAcc@5 84.375 (84.406)\n",
            " * Acc@1 55.330 Acc@5 84.430\n",
            "==> training...\n",
            "Epoch: [101][0/782]\tTime 0.284 (0.284)\tData 0.199 (0.199)\tLoss 1.1739 (1.1739)\tAcc@1 67.188 (67.188)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [101][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.1846 (1.2799)\tAcc@1 62.500 (63.119)\tAcc@5 92.188 (89.759)\n",
            "Epoch: [101][200/782]\tTime 0.050 (0.054)\tData 0.001 (0.002)\tLoss 1.0715 (1.2890)\tAcc@1 62.500 (63.021)\tAcc@5 95.312 (89.692)\n",
            "Epoch: [101][300/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.2290 (1.2891)\tAcc@1 65.625 (63.045)\tAcc@5 89.062 (89.608)\n",
            "Epoch: [101][400/782]\tTime 0.069 (0.053)\tData 0.001 (0.002)\tLoss 1.4709 (1.3038)\tAcc@1 62.500 (62.660)\tAcc@5 85.938 (89.269)\n",
            "Epoch: [101][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3412 (1.3068)\tAcc@1 64.062 (62.494)\tAcc@5 87.500 (89.321)\n",
            "Epoch: [101][600/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.0374 (1.3122)\tAcc@1 68.750 (62.505)\tAcc@5 95.312 (89.208)\n",
            "Epoch: [101][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4106 (1.3206)\tAcc@1 67.188 (62.435)\tAcc@5 89.062 (89.056)\n",
            " * Acc@1 62.318 Acc@5 88.980\n",
            "epoch 101, total time 40.19\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.7085 (1.7085)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.9090 (1.7958)\tAcc@1 40.625 (53.620)\tAcc@5 81.250 (82.952)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.3147 (1.7972)\tAcc@1 56.250 (53.358)\tAcc@5 90.625 (82.789)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0004 (1.7913)\tAcc@1 46.875 (53.530)\tAcc@5 84.375 (82.703)\n",
            " * Acc@1 53.500 Acc@5 82.700\n",
            "==> training...\n",
            "Epoch: [102][0/782]\tTime 0.268 (0.268)\tData 0.198 (0.198)\tLoss 1.1534 (1.1534)\tAcc@1 64.062 (64.062)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [102][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.2749 (1.2847)\tAcc@1 62.500 (63.011)\tAcc@5 90.625 (89.372)\n",
            "Epoch: [102][200/782]\tTime 0.056 (0.052)\tData 0.001 (0.002)\tLoss 1.4493 (1.2946)\tAcc@1 62.500 (62.725)\tAcc@5 85.938 (89.358)\n",
            "Epoch: [102][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3891 (1.3016)\tAcc@1 60.938 (62.510)\tAcc@5 87.500 (89.249)\n",
            "Epoch: [102][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.6707 (1.3062)\tAcc@1 50.000 (62.399)\tAcc@5 87.500 (89.316)\n",
            "Epoch: [102][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5709 (1.3072)\tAcc@1 59.375 (62.363)\tAcc@5 87.500 (89.309)\n",
            "Epoch: [102][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3150 (1.3163)\tAcc@1 57.812 (62.250)\tAcc@5 87.500 (89.122)\n",
            "Epoch: [102][700/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 0.9909 (1.3145)\tAcc@1 76.562 (62.346)\tAcc@5 93.750 (89.112)\n",
            " * Acc@1 62.250 Acc@5 89.066\n",
            "epoch 102, total time 39.76\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.4515 (2.4515)\tAcc@1 46.875 (46.875)\tAcc@5 65.625 (65.625)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.8199 (1.7548)\tAcc@1 53.125 (53.713)\tAcc@5 81.250 (82.271)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.3793 (1.7642)\tAcc@1 59.375 (52.767)\tAcc@5 84.375 (82.416)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.8327 (1.7739)\tAcc@1 43.750 (52.627)\tAcc@5 84.375 (82.330)\n",
            " * Acc@1 52.650 Acc@5 82.290\n",
            "==> training...\n",
            "Epoch: [103][0/782]\tTime 0.260 (0.260)\tData 0.183 (0.183)\tLoss 1.1303 (1.1303)\tAcc@1 65.625 (65.625)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [103][100/782]\tTime 0.054 (0.053)\tData 0.001 (0.003)\tLoss 0.7516 (1.2730)\tAcc@1 82.812 (63.413)\tAcc@5 95.312 (89.573)\n",
            "Epoch: [103][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1382 (1.2757)\tAcc@1 65.625 (63.518)\tAcc@5 92.188 (89.576)\n",
            "Epoch: [103][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1334 (1.2859)\tAcc@1 64.062 (63.331)\tAcc@5 92.188 (89.265)\n",
            "Epoch: [103][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2122 (1.2917)\tAcc@1 67.188 (63.127)\tAcc@5 90.625 (89.281)\n",
            "Epoch: [103][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3759 (1.2972)\tAcc@1 54.688 (62.946)\tAcc@5 85.938 (89.175)\n",
            "Epoch: [103][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4496 (1.3059)\tAcc@1 48.438 (62.700)\tAcc@5 89.062 (89.052)\n",
            "Epoch: [103][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.1589 (1.3109)\tAcc@1 64.062 (62.565)\tAcc@5 93.750 (89.060)\n",
            " * Acc@1 62.526 Acc@5 89.078\n",
            "epoch 103, total time 39.92\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.9814 (1.9814)\tAcc@1 59.375 (59.375)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.6732 (1.8770)\tAcc@1 56.250 (52.692)\tAcc@5 87.500 (81.343)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.2813 (1.9091)\tAcc@1 56.250 (51.679)\tAcc@5 93.750 (80.877)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.2326 (1.9154)\tAcc@1 53.125 (51.381)\tAcc@5 75.000 (80.939)\n",
            " * Acc@1 51.420 Acc@5 80.880\n",
            "==> training...\n",
            "Epoch: [104][0/782]\tTime 0.276 (0.276)\tData 0.198 (0.198)\tLoss 1.5523 (1.5523)\tAcc@1 57.812 (57.812)\tAcc@5 84.375 (84.375)\n",
            "Epoch: [104][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.1986 (1.3091)\tAcc@1 64.062 (62.809)\tAcc@5 90.625 (89.171)\n",
            "Epoch: [104][200/782]\tTime 0.056 (0.052)\tData 0.001 (0.002)\tLoss 1.1561 (1.2876)\tAcc@1 64.062 (63.464)\tAcc@5 89.062 (89.661)\n",
            "Epoch: [104][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5568 (1.3048)\tAcc@1 54.688 (62.843)\tAcc@5 81.250 (89.493)\n",
            "Epoch: [104][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4112 (1.3089)\tAcc@1 62.500 (62.769)\tAcc@5 87.500 (89.351)\n",
            "Epoch: [104][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4777 (1.3123)\tAcc@1 56.250 (62.587)\tAcc@5 87.500 (89.312)\n",
            "Epoch: [104][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3790 (1.3148)\tAcc@1 59.375 (62.373)\tAcc@5 89.062 (89.278)\n",
            "Epoch: [104][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1168 (1.3177)\tAcc@1 65.625 (62.262)\tAcc@5 95.312 (89.270)\n",
            " * Acc@1 62.254 Acc@5 89.174\n",
            "epoch 104, total time 40.04\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.8869 (1.8869)\tAcc@1 56.250 (56.250)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.6839 (1.6564)\tAcc@1 46.875 (54.765)\tAcc@5 87.500 (85.087)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.2374 (1.6614)\tAcc@1 56.250 (54.571)\tAcc@5 87.500 (84.344)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.8489 (1.6696)\tAcc@1 59.375 (54.475)\tAcc@5 87.500 (84.095)\n",
            " * Acc@1 54.410 Acc@5 84.050\n",
            "==> training...\n",
            "Epoch: [105][0/782]\tTime 0.263 (0.263)\tData 0.181 (0.181)\tLoss 1.0884 (1.0884)\tAcc@1 71.875 (71.875)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [105][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 1.2042 (1.2929)\tAcc@1 62.500 (63.088)\tAcc@5 92.188 (89.743)\n",
            "Epoch: [105][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.6012 (1.2840)\tAcc@1 46.875 (63.161)\tAcc@5 87.500 (89.848)\n",
            "Epoch: [105][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.1664 (1.2977)\tAcc@1 59.375 (62.832)\tAcc@5 93.750 (89.711)\n",
            "Epoch: [105][400/782]\tTime 0.056 (0.052)\tData 0.001 (0.002)\tLoss 1.2581 (1.3058)\tAcc@1 60.938 (62.578)\tAcc@5 93.750 (89.538)\n",
            "Epoch: [105][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3660 (1.3115)\tAcc@1 56.250 (62.291)\tAcc@5 89.062 (89.449)\n",
            "Epoch: [105][600/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.5614 (1.3134)\tAcc@1 56.250 (62.232)\tAcc@5 89.062 (89.372)\n",
            "Epoch: [105][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3230 (1.3182)\tAcc@1 64.062 (62.121)\tAcc@5 87.500 (89.263)\n",
            " * Acc@1 62.008 Acc@5 89.164\n",
            "epoch 105, total time 40.29\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 1.7763 (1.7763)\tAcc@1 53.125 (53.125)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.4384 (1.6567)\tAcc@1 62.500 (53.589)\tAcc@5 100.000 (85.798)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.2736 (1.6796)\tAcc@1 56.250 (53.607)\tAcc@5 93.750 (84.779)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0556 (1.6759)\tAcc@1 50.000 (53.831)\tAcc@5 71.875 (84.853)\n",
            " * Acc@1 53.780 Acc@5 84.800\n",
            "==> training...\n",
            "Epoch: [106][0/782]\tTime 0.285 (0.285)\tData 0.198 (0.198)\tLoss 1.1542 (1.1542)\tAcc@1 64.062 (64.062)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [106][100/782]\tTime 0.051 (0.053)\tData 0.002 (0.003)\tLoss 0.9780 (1.2552)\tAcc@1 73.438 (63.521)\tAcc@5 96.875 (90.130)\n",
            "Epoch: [106][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.6282 (1.2941)\tAcc@1 51.562 (62.539)\tAcc@5 87.500 (89.436)\n",
            "Epoch: [106][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.1858 (1.3013)\tAcc@1 65.625 (62.588)\tAcc@5 90.625 (89.338)\n",
            "Epoch: [106][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.4956 (1.3025)\tAcc@1 51.562 (62.679)\tAcc@5 90.625 (89.296)\n",
            "Epoch: [106][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3584 (1.3118)\tAcc@1 62.500 (62.419)\tAcc@5 87.500 (89.162)\n",
            "Epoch: [106][600/782]\tTime 0.058 (0.051)\tData 0.001 (0.002)\tLoss 1.6733 (1.3208)\tAcc@1 54.688 (62.185)\tAcc@5 82.812 (89.026)\n",
            "Epoch: [106][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.7857 (1.3182)\tAcc@1 57.812 (62.197)\tAcc@5 82.812 (89.016)\n",
            " * Acc@1 62.290 Acc@5 89.030\n",
            "epoch 106, total time 39.93\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.6412 (1.6412)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.5066 (1.6637)\tAcc@1 46.875 (56.064)\tAcc@5 90.625 (84.839)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.5169 (1.6729)\tAcc@1 56.250 (56.219)\tAcc@5 84.375 (84.422)\n",
            "Test: [300/313]\tTime 0.017 (0.020)\tLoss 2.1503 (1.6824)\tAcc@1 40.625 (55.855)\tAcc@5 81.250 (84.167)\n",
            " * Acc@1 55.850 Acc@5 84.240\n",
            "==> training...\n",
            "Epoch: [107][0/782]\tTime 0.294 (0.294)\tData 0.216 (0.216)\tLoss 0.9428 (0.9428)\tAcc@1 78.125 (78.125)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [107][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.0922 (1.2360)\tAcc@1 65.625 (64.465)\tAcc@5 93.750 (90.068)\n",
            "Epoch: [107][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.4913 (1.2558)\tAcc@1 59.375 (63.915)\tAcc@5 82.812 (89.941)\n",
            "Epoch: [107][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2363 (1.2707)\tAcc@1 64.062 (63.632)\tAcc@5 87.500 (89.758)\n",
            "Epoch: [107][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2970 (1.2871)\tAcc@1 57.812 (63.174)\tAcc@5 89.062 (89.511)\n",
            "Epoch: [107][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.0821 (1.2950)\tAcc@1 70.312 (62.930)\tAcc@5 92.188 (89.343)\n",
            "Epoch: [107][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4379 (1.3075)\tAcc@1 56.250 (62.612)\tAcc@5 87.500 (89.125)\n",
            "Epoch: [107][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7337 (1.3126)\tAcc@1 54.688 (62.455)\tAcc@5 84.375 (89.100)\n",
            " * Acc@1 62.296 Acc@5 89.156\n",
            "epoch 107, total time 40.00\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 1.8194 (1.8194)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4459 (1.6454)\tAcc@1 53.125 (55.167)\tAcc@5 87.500 (84.932)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.2473 (1.6642)\tAcc@1 65.625 (54.322)\tAcc@5 87.500 (84.562)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.9162 (1.6828)\tAcc@1 50.000 (54.153)\tAcc@5 84.375 (84.126)\n",
            " * Acc@1 54.230 Acc@5 84.170\n",
            "==> training...\n",
            "Epoch: [108][0/782]\tTime 0.298 (0.298)\tData 0.207 (0.207)\tLoss 0.8876 (0.8876)\tAcc@1 78.125 (78.125)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [108][100/782]\tTime 0.048 (0.053)\tData 0.001 (0.003)\tLoss 1.5035 (1.2865)\tAcc@1 54.688 (63.861)\tAcc@5 90.625 (89.573)\n",
            "Epoch: [108][200/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1582 (1.2811)\tAcc@1 62.500 (63.386)\tAcc@5 93.750 (89.638)\n",
            "Epoch: [108][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4007 (1.2949)\tAcc@1 59.375 (62.993)\tAcc@5 92.188 (89.218)\n",
            "Epoch: [108][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4955 (1.2952)\tAcc@1 53.125 (62.890)\tAcc@5 92.188 (89.273)\n",
            "Epoch: [108][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1387 (1.2963)\tAcc@1 62.500 (62.865)\tAcc@5 98.438 (89.343)\n",
            "Epoch: [108][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5540 (1.3036)\tAcc@1 56.250 (62.653)\tAcc@5 85.938 (89.341)\n",
            "Epoch: [108][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4653 (1.3099)\tAcc@1 62.500 (62.518)\tAcc@5 87.500 (89.265)\n",
            " * Acc@1 62.192 Acc@5 89.176\n",
            "epoch 108, total time 39.72\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.0400 (2.0400)\tAcc@1 59.375 (59.375)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 2.0285 (1.8898)\tAcc@1 43.750 (50.928)\tAcc@5 78.125 (80.507)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.5248 (1.9035)\tAcc@1 56.250 (50.435)\tAcc@5 90.625 (80.037)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.5436 (1.9239)\tAcc@1 43.750 (50.145)\tAcc@5 75.000 (79.869)\n",
            " * Acc@1 50.290 Acc@5 79.900\n",
            "==> training...\n",
            "Epoch: [109][0/782]\tTime 0.277 (0.277)\tData 0.186 (0.186)\tLoss 1.2769 (1.2769)\tAcc@1 60.938 (60.938)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [109][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.2690 (1.2567)\tAcc@1 64.062 (63.738)\tAcc@5 93.750 (90.161)\n",
            "Epoch: [109][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3191 (1.2819)\tAcc@1 62.500 (62.865)\tAcc@5 92.188 (89.840)\n",
            "Epoch: [109][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.9904 (1.2904)\tAcc@1 68.750 (62.998)\tAcc@5 95.312 (89.571)\n",
            "Epoch: [109][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3322 (1.2966)\tAcc@1 59.375 (62.664)\tAcc@5 90.625 (89.452)\n",
            "Epoch: [109][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2805 (1.3001)\tAcc@1 64.062 (62.503)\tAcc@5 92.188 (89.362)\n",
            "Epoch: [109][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2248 (1.3092)\tAcc@1 64.062 (62.154)\tAcc@5 90.625 (89.192)\n",
            "Epoch: [109][700/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.9585 (1.3110)\tAcc@1 71.875 (62.204)\tAcc@5 93.750 (89.047)\n",
            " * Acc@1 62.200 Acc@5 89.042\n",
            "epoch 109, total time 39.81\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.7996 (1.7996)\tAcc@1 62.500 (62.500)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.024 (0.020)\tLoss 1.9114 (1.6475)\tAcc@1 46.875 (54.579)\tAcc@5 93.750 (84.684)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.5477 (1.6565)\tAcc@1 56.250 (54.555)\tAcc@5 87.500 (84.406)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.6199 (1.6810)\tAcc@1 50.000 (54.662)\tAcc@5 87.500 (83.856)\n",
            " * Acc@1 54.700 Acc@5 83.850\n",
            "==> training...\n",
            "Epoch: [110][0/782]\tTime 0.262 (0.262)\tData 0.180 (0.180)\tLoss 0.9089 (0.9089)\tAcc@1 71.875 (71.875)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [110][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.3000 (1.2610)\tAcc@1 56.250 (64.202)\tAcc@5 92.188 (89.944)\n",
            "Epoch: [110][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3463 (1.2569)\tAcc@1 62.500 (64.055)\tAcc@5 87.500 (89.832)\n",
            "Epoch: [110][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5377 (1.2820)\tAcc@1 64.062 (63.305)\tAcc@5 84.375 (89.618)\n",
            "Epoch: [110][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3066 (1.2908)\tAcc@1 62.500 (63.069)\tAcc@5 87.500 (89.472)\n",
            "Epoch: [110][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.9733 (1.2950)\tAcc@1 75.000 (62.912)\tAcc@5 90.625 (89.406)\n",
            "Epoch: [110][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3517 (1.2975)\tAcc@1 65.625 (62.841)\tAcc@5 90.625 (89.393)\n",
            "Epoch: [110][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3204 (1.3032)\tAcc@1 62.500 (62.600)\tAcc@5 84.375 (89.328)\n",
            " * Acc@1 62.508 Acc@5 89.220\n",
            "epoch 110, total time 39.69\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.4465 (1.4465)\tAcc@1 62.500 (62.500)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4552 (1.7504)\tAcc@1 56.250 (52.970)\tAcc@5 93.750 (82.302)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.2719 (1.7315)\tAcc@1 65.625 (53.591)\tAcc@5 84.375 (82.743)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.9057 (1.7481)\tAcc@1 56.250 (53.478)\tAcc@5 84.375 (82.558)\n",
            " * Acc@1 53.590 Acc@5 82.590\n",
            "==> training...\n",
            "Epoch: [111][0/782]\tTime 0.259 (0.259)\tData 0.185 (0.185)\tLoss 1.2025 (1.2025)\tAcc@1 71.875 (71.875)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [111][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.3296 (1.2714)\tAcc@1 62.500 (63.800)\tAcc@5 89.062 (89.743)\n",
            "Epoch: [111][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5418 (1.2883)\tAcc@1 62.500 (63.153)\tAcc@5 85.938 (89.498)\n",
            "Epoch: [111][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.0808 (1.2901)\tAcc@1 65.625 (62.879)\tAcc@5 92.188 (89.421)\n",
            "Epoch: [111][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.4483 (1.3057)\tAcc@1 57.812 (62.679)\tAcc@5 85.938 (89.203)\n",
            "Epoch: [111][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3752 (1.3084)\tAcc@1 62.500 (62.522)\tAcc@5 89.062 (89.240)\n",
            "Epoch: [111][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4628 (1.3146)\tAcc@1 67.188 (62.349)\tAcc@5 89.062 (89.153)\n",
            "Epoch: [111][700/782]\tTime 0.058 (0.051)\tData 0.001 (0.002)\tLoss 1.2930 (1.3193)\tAcc@1 57.812 (62.255)\tAcc@5 90.625 (89.107)\n",
            " * Acc@1 62.142 Acc@5 89.112\n",
            "epoch 111, total time 40.05\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 1.7183 (1.7183)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.6629 (1.6716)\tAcc@1 46.875 (56.405)\tAcc@5 84.375 (83.818)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.1693 (1.6586)\tAcc@1 68.750 (55.986)\tAcc@5 93.750 (83.986)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0514 (1.6827)\tAcc@1 43.750 (55.357)\tAcc@5 84.375 (83.752)\n",
            " * Acc@1 55.480 Acc@5 83.790\n",
            "==> training...\n",
            "Epoch: [112][0/782]\tTime 0.254 (0.254)\tData 0.183 (0.183)\tLoss 1.0989 (1.0989)\tAcc@1 68.750 (68.750)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [112][100/782]\tTime 0.051 (0.054)\tData 0.001 (0.003)\tLoss 1.1364 (1.2605)\tAcc@1 67.188 (63.861)\tAcc@5 92.188 (89.991)\n",
            "Epoch: [112][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3952 (1.2602)\tAcc@1 57.812 (63.720)\tAcc@5 90.625 (90.003)\n",
            "Epoch: [112][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2517 (1.2830)\tAcc@1 68.750 (63.331)\tAcc@5 92.188 (89.556)\n",
            "Epoch: [112][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4305 (1.2922)\tAcc@1 62.500 (63.018)\tAcc@5 89.062 (89.378)\n",
            "Epoch: [112][500/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.4656 (1.3014)\tAcc@1 56.250 (62.983)\tAcc@5 87.500 (89.362)\n",
            "Epoch: [112][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2502 (1.3090)\tAcc@1 71.875 (62.711)\tAcc@5 87.500 (89.268)\n",
            "Epoch: [112][700/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3691 (1.3097)\tAcc@1 62.500 (62.643)\tAcc@5 90.625 (89.232)\n",
            " * Acc@1 62.682 Acc@5 89.282\n",
            "epoch 112, total time 40.32\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.7901 (1.7901)\tAcc@1 59.375 (59.375)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.021)\tLoss 1.6701 (1.7597)\tAcc@1 53.125 (54.208)\tAcc@5 87.500 (83.261)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.4766 (1.7820)\tAcc@1 56.250 (53.545)\tAcc@5 84.375 (83.007)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 2.0202 (1.8099)\tAcc@1 37.500 (53.198)\tAcc@5 87.500 (82.755)\n",
            " * Acc@1 53.230 Acc@5 82.780\n",
            "==> training...\n",
            "Epoch: [113][0/782]\tTime 0.283 (0.283)\tData 0.199 (0.199)\tLoss 1.0847 (1.0847)\tAcc@1 64.062 (64.062)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [113][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.5619 (1.2320)\tAcc@1 51.562 (64.341)\tAcc@5 93.750 (91.166)\n",
            "Epoch: [113][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1384 (1.2377)\tAcc@1 67.188 (64.047)\tAcc@5 90.625 (90.804)\n",
            "Epoch: [113][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.4401 (1.2754)\tAcc@1 57.812 (62.988)\tAcc@5 87.500 (90.230)\n",
            "Epoch: [113][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4358 (1.2922)\tAcc@1 57.812 (62.812)\tAcc@5 87.500 (89.826)\n",
            "Epoch: [113][500/782]\tTime 0.060 (0.052)\tData 0.001 (0.002)\tLoss 1.5558 (1.2922)\tAcc@1 53.125 (62.815)\tAcc@5 82.812 (89.827)\n",
            "Epoch: [113][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.8053 (1.2971)\tAcc@1 48.438 (62.781)\tAcc@5 84.375 (89.627)\n",
            "Epoch: [113][700/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 1.4812 (1.3012)\tAcc@1 60.938 (62.676)\tAcc@5 85.938 (89.528)\n",
            " * Acc@1 62.596 Acc@5 89.388\n",
            "epoch 113, total time 40.12\n",
            "Test: [0/313]\tTime 0.126 (0.126)\tLoss 2.0944 (2.0944)\tAcc@1 59.375 (59.375)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.8040 (1.6443)\tAcc@1 50.000 (56.405)\tAcc@5 87.500 (84.406)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.5080 (1.6693)\tAcc@1 62.500 (55.799)\tAcc@5 90.625 (83.971)\n",
            "Test: [300/313]\tTime 0.024 (0.019)\tLoss 2.2663 (1.6792)\tAcc@1 53.125 (55.440)\tAcc@5 78.125 (83.648)\n",
            " * Acc@1 55.550 Acc@5 83.750\n",
            "==> training...\n",
            "Epoch: [114][0/782]\tTime 0.278 (0.278)\tData 0.192 (0.192)\tLoss 1.4112 (1.4112)\tAcc@1 57.812 (57.812)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [114][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.6144 (1.2426)\tAcc@1 54.688 (63.645)\tAcc@5 89.062 (90.501)\n",
            "Epoch: [114][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 1.7177 (1.2707)\tAcc@1 54.688 (62.780)\tAcc@5 84.375 (89.956)\n",
            "Epoch: [114][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2738 (1.2865)\tAcc@1 64.062 (62.760)\tAcc@5 90.625 (89.608)\n",
            "Epoch: [114][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2737 (1.2907)\tAcc@1 62.500 (62.761)\tAcc@5 90.625 (89.565)\n",
            "Epoch: [114][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.1310 (1.3019)\tAcc@1 67.188 (62.494)\tAcc@5 93.750 (89.328)\n",
            "Epoch: [114][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.9555 (1.3057)\tAcc@1 73.438 (62.458)\tAcc@5 90.625 (89.268)\n",
            "Epoch: [114][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2328 (1.3067)\tAcc@1 62.500 (62.451)\tAcc@5 89.062 (89.250)\n",
            " * Acc@1 62.288 Acc@5 89.152\n",
            "epoch 114, total time 40.23\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 2.2173 (2.2173)\tAcc@1 50.000 (50.000)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.7754 (1.7330)\tAcc@1 53.125 (55.322)\tAcc@5 90.625 (83.694)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.5878 (1.7176)\tAcc@1 62.500 (54.882)\tAcc@5 87.500 (83.862)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.2503 (1.7275)\tAcc@1 37.500 (54.765)\tAcc@5 75.000 (83.316)\n",
            " * Acc@1 54.860 Acc@5 83.290\n",
            "==> training...\n",
            "Epoch: [115][0/782]\tTime 0.272 (0.272)\tData 0.196 (0.196)\tLoss 1.3127 (1.3127)\tAcc@1 62.500 (62.500)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [115][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.2480 (1.2723)\tAcc@1 64.062 (63.351)\tAcc@5 87.500 (90.347)\n",
            "Epoch: [115][200/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 1.0464 (1.2860)\tAcc@1 65.625 (63.083)\tAcc@5 93.750 (89.941)\n",
            "Epoch: [115][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.0906 (1.2874)\tAcc@1 67.188 (62.905)\tAcc@5 96.875 (89.732)\n",
            "Epoch: [115][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5700 (1.2939)\tAcc@1 60.938 (62.890)\tAcc@5 81.250 (89.561)\n",
            "Epoch: [115][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3286 (1.2988)\tAcc@1 62.500 (62.737)\tAcc@5 89.062 (89.490)\n",
            "Epoch: [115][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.0204 (1.3039)\tAcc@1 67.188 (62.638)\tAcc@5 93.750 (89.377)\n",
            "Epoch: [115][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.6729 (1.3136)\tAcc@1 53.125 (62.415)\tAcc@5 82.812 (89.172)\n",
            " * Acc@1 62.472 Acc@5 89.182\n",
            "epoch 115, total time 39.84\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 2.2271 (2.2271)\tAcc@1 62.500 (62.500)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.022 (0.020)\tLoss 2.2217 (1.6832)\tAcc@1 40.625 (55.631)\tAcc@5 78.125 (84.158)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 1.2539 (1.6944)\tAcc@1 65.625 (55.504)\tAcc@5 90.625 (84.111)\n",
            "Test: [300/313]\tTime 0.018 (0.020)\tLoss 2.1208 (1.7057)\tAcc@1 40.625 (55.316)\tAcc@5 90.625 (83.929)\n",
            " * Acc@1 55.270 Acc@5 83.860\n",
            "==> training...\n",
            "Epoch: [116][0/782]\tTime 0.263 (0.263)\tData 0.195 (0.195)\tLoss 0.8534 (0.8534)\tAcc@1 67.188 (67.188)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [116][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.2213 (1.2680)\tAcc@1 68.750 (63.846)\tAcc@5 90.625 (89.511)\n",
            "Epoch: [116][200/782]\tTime 0.049 (0.054)\tData 0.001 (0.002)\tLoss 1.1747 (1.2819)\tAcc@1 65.625 (63.340)\tAcc@5 93.750 (89.568)\n",
            "Epoch: [116][300/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.3341 (1.2765)\tAcc@1 57.812 (63.491)\tAcc@5 90.625 (89.680)\n",
            "Epoch: [116][400/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.1125 (1.2824)\tAcc@1 65.625 (63.303)\tAcc@5 93.750 (89.682)\n",
            "Epoch: [116][500/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.1520 (1.2896)\tAcc@1 67.188 (63.055)\tAcc@5 92.188 (89.518)\n",
            "Epoch: [116][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3566 (1.3071)\tAcc@1 59.375 (62.627)\tAcc@5 90.625 (89.268)\n",
            "Epoch: [116][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1455 (1.3139)\tAcc@1 64.062 (62.464)\tAcc@5 90.625 (89.163)\n",
            " * Acc@1 62.528 Acc@5 89.126\n",
            "epoch 116, total time 40.21\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 2.1417 (2.1417)\tAcc@1 56.250 (56.250)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.7709 (1.7851)\tAcc@1 53.125 (53.403)\tAcc@5 87.500 (83.354)\n",
            "Test: [200/313]\tTime 0.026 (0.019)\tLoss 1.2002 (1.7428)\tAcc@1 71.875 (54.027)\tAcc@5 90.625 (83.489)\n",
            "Test: [300/313]\tTime 0.029 (0.019)\tLoss 1.8545 (1.7460)\tAcc@1 53.125 (54.101)\tAcc@5 84.375 (83.378)\n",
            " * Acc@1 54.190 Acc@5 83.460\n",
            "==> training...\n",
            "Epoch: [117][0/782]\tTime 0.283 (0.283)\tData 0.198 (0.198)\tLoss 1.0823 (1.0823)\tAcc@1 67.188 (67.188)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [117][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 1.1134 (1.2670)\tAcc@1 67.188 (63.459)\tAcc@5 95.312 (90.377)\n",
            "Epoch: [117][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.8306 (1.2548)\tAcc@1 53.125 (63.814)\tAcc@5 81.250 (90.571)\n",
            "Epoch: [117][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.0871 (1.2744)\tAcc@1 62.500 (63.268)\tAcc@5 93.750 (90.116)\n",
            "Epoch: [117][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1027 (1.2923)\tAcc@1 65.625 (62.862)\tAcc@5 96.875 (89.846)\n",
            "Epoch: [117][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3835 (1.2935)\tAcc@1 62.500 (62.943)\tAcc@5 89.062 (89.742)\n",
            "Epoch: [117][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1428 (1.2980)\tAcc@1 60.938 (62.877)\tAcc@5 93.750 (89.616)\n",
            "Epoch: [117][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5229 (1.3059)\tAcc@1 59.375 (62.743)\tAcc@5 82.812 (89.441)\n",
            " * Acc@1 62.738 Acc@5 89.356\n",
            "epoch 117, total time 39.77\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 2.2187 (2.2187)\tAcc@1 53.125 (53.125)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.018 (0.021)\tLoss 2.0599 (1.9382)\tAcc@1 46.875 (51.083)\tAcc@5 68.750 (79.486)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 1.6453 (1.9353)\tAcc@1 59.375 (50.793)\tAcc@5 81.250 (79.866)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 2.6152 (1.9555)\tAcc@1 37.500 (50.301)\tAcc@5 71.875 (79.485)\n",
            " * Acc@1 50.160 Acc@5 79.510\n",
            "==> training...\n",
            "Epoch: [118][0/782]\tTime 0.277 (0.277)\tData 0.200 (0.200)\tLoss 1.2535 (1.2535)\tAcc@1 57.812 (57.812)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [118][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.5564 (1.2404)\tAcc@1 54.688 (64.186)\tAcc@5 85.938 (89.991)\n",
            "Epoch: [118][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3387 (1.2664)\tAcc@1 56.250 (63.720)\tAcc@5 89.062 (89.677)\n",
            "Epoch: [118][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3727 (1.2863)\tAcc@1 60.938 (63.242)\tAcc@5 84.375 (89.519)\n",
            "Epoch: [118][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4148 (1.2924)\tAcc@1 54.688 (63.322)\tAcc@5 87.500 (89.320)\n",
            "Epoch: [118][500/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.3715 (1.2978)\tAcc@1 68.750 (63.220)\tAcc@5 89.062 (89.312)\n",
            "Epoch: [118][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2494 (1.3108)\tAcc@1 62.500 (62.830)\tAcc@5 90.625 (89.107)\n",
            "Epoch: [118][700/782]\tTime 0.056 (0.051)\tData 0.001 (0.002)\tLoss 1.0820 (1.3122)\tAcc@1 67.188 (62.767)\tAcc@5 95.312 (89.091)\n",
            " * Acc@1 62.612 Acc@5 89.058\n",
            "epoch 118, total time 39.81\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 1.6092 (1.6092)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.1300 (1.9711)\tAcc@1 40.625 (49.629)\tAcc@5 84.375 (81.436)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.6247 (1.9514)\tAcc@1 62.500 (50.575)\tAcc@5 84.375 (80.986)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.2975 (1.9639)\tAcc@1 46.875 (50.363)\tAcc@5 84.375 (80.637)\n",
            " * Acc@1 50.430 Acc@5 80.610\n",
            "==> training...\n",
            "Epoch: [119][0/782]\tTime 0.266 (0.266)\tData 0.195 (0.195)\tLoss 1.2079 (1.2079)\tAcc@1 67.188 (67.188)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [119][100/782]\tTime 0.052 (0.054)\tData 0.001 (0.003)\tLoss 1.4975 (1.2693)\tAcc@1 60.938 (63.304)\tAcc@5 84.375 (89.681)\n",
            "Epoch: [119][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5803 (1.2815)\tAcc@1 56.250 (63.301)\tAcc@5 81.250 (89.599)\n",
            "Epoch: [119][300/782]\tTime 0.059 (0.052)\tData 0.001 (0.002)\tLoss 1.5269 (1.2808)\tAcc@1 57.812 (63.279)\tAcc@5 82.812 (89.628)\n",
            "Epoch: [119][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5859 (1.2910)\tAcc@1 60.938 (62.983)\tAcc@5 84.375 (89.596)\n",
            "Epoch: [119][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2762 (1.2904)\tAcc@1 68.750 (62.974)\tAcc@5 84.375 (89.627)\n",
            "Epoch: [119][600/782]\tTime 0.050 (0.052)\tData 0.002 (0.002)\tLoss 1.0150 (1.2963)\tAcc@1 67.188 (62.825)\tAcc@5 96.875 (89.424)\n",
            "Epoch: [119][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.6740 (1.3037)\tAcc@1 48.438 (62.629)\tAcc@5 85.938 (89.265)\n",
            " * Acc@1 62.274 Acc@5 89.082\n",
            "epoch 119, total time 40.31\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.7978 (1.7978)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.8478 (1.7533)\tAcc@1 46.875 (53.558)\tAcc@5 87.500 (83.230)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 2.1748 (1.7654)\tAcc@1 43.750 (53.327)\tAcc@5 71.875 (82.929)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.1279 (1.7854)\tAcc@1 43.750 (53.301)\tAcc@5 81.250 (82.693)\n",
            " * Acc@1 53.330 Acc@5 82.620\n",
            "==> training...\n",
            "Epoch: [120][0/782]\tTime 0.257 (0.257)\tData 0.186 (0.186)\tLoss 1.3656 (1.3656)\tAcc@1 59.375 (59.375)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [120][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.4698 (1.2788)\tAcc@1 59.375 (63.289)\tAcc@5 85.938 (89.774)\n",
            "Epoch: [120][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.6382 (1.2721)\tAcc@1 56.250 (63.635)\tAcc@5 85.938 (89.770)\n",
            "Epoch: [120][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.9660 (1.2821)\tAcc@1 73.438 (63.445)\tAcc@5 93.750 (89.649)\n",
            "Epoch: [120][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.0825 (1.2862)\tAcc@1 70.312 (63.373)\tAcc@5 92.188 (89.604)\n",
            "Epoch: [120][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4040 (1.2974)\tAcc@1 60.938 (63.096)\tAcc@5 85.938 (89.406)\n",
            "Epoch: [120][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3373 (1.3004)\tAcc@1 62.500 (62.994)\tAcc@5 84.375 (89.413)\n",
            "Epoch: [120][700/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.9161 (1.3018)\tAcc@1 73.438 (62.979)\tAcc@5 93.750 (89.410)\n",
            " * Acc@1 62.968 Acc@5 89.332\n",
            "epoch 120, total time 40.02\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.0086 (2.0086)\tAcc@1 62.500 (62.500)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.8228 (1.8599)\tAcc@1 53.125 (51.918)\tAcc@5 87.500 (81.095)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.8364 (1.8562)\tAcc@1 53.125 (51.835)\tAcc@5 71.875 (81.063)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.0120 (1.8520)\tAcc@1 40.625 (52.014)\tAcc@5 87.500 (81.032)\n",
            " * Acc@1 52.070 Acc@5 81.060\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [121][0/782]\tTime 0.286 (0.286)\tData 0.203 (0.203)\tLoss 1.7015 (1.7015)\tAcc@1 48.438 (48.438)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [121][100/782]\tTime 0.051 (0.055)\tData 0.001 (0.003)\tLoss 1.1903 (1.2331)\tAcc@1 67.188 (64.233)\tAcc@5 87.500 (90.254)\n",
            "Epoch: [121][200/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.7121 (1.2686)\tAcc@1 59.375 (63.643)\tAcc@5 82.812 (89.918)\n",
            "Epoch: [121][300/782]\tTime 0.069 (0.052)\tData 0.001 (0.002)\tLoss 1.0823 (1.2842)\tAcc@1 70.312 (63.273)\tAcc@5 92.188 (89.649)\n",
            "Epoch: [121][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2049 (1.2796)\tAcc@1 59.375 (63.373)\tAcc@5 92.188 (89.663)\n",
            "Epoch: [121][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1917 (1.2901)\tAcc@1 62.500 (63.002)\tAcc@5 90.625 (89.505)\n",
            "Epoch: [121][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5698 (1.3026)\tAcc@1 54.688 (62.711)\tAcc@5 84.375 (89.395)\n",
            "Epoch: [121][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2127 (1.3088)\tAcc@1 59.375 (62.636)\tAcc@5 90.625 (89.187)\n",
            " * Acc@1 62.502 Acc@5 89.066\n",
            "epoch 121, total time 40.19\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 2.2774 (2.2774)\tAcc@1 50.000 (50.000)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.7911 (1.9327)\tAcc@1 56.250 (51.578)\tAcc@5 81.250 (81.250)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.4349 (1.9420)\tAcc@1 56.250 (50.684)\tAcc@5 87.500 (80.799)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.4646 (1.9380)\tAcc@1 46.875 (50.664)\tAcc@5 71.875 (80.700)\n",
            " * Acc@1 50.790 Acc@5 80.710\n",
            "==> training...\n",
            "Epoch: [122][0/782]\tTime 0.266 (0.266)\tData 0.184 (0.184)\tLoss 1.4105 (1.4105)\tAcc@1 57.812 (57.812)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [122][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.1580 (1.2646)\tAcc@1 60.938 (63.119)\tAcc@5 87.500 (90.161)\n",
            "Epoch: [122][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2368 (1.2634)\tAcc@1 67.188 (63.301)\tAcc@5 84.375 (90.127)\n",
            "Epoch: [122][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3450 (1.2669)\tAcc@1 62.500 (63.367)\tAcc@5 87.500 (89.961)\n",
            "Epoch: [122][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2044 (1.2922)\tAcc@1 64.062 (62.971)\tAcc@5 87.500 (89.561)\n",
            "Epoch: [122][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3327 (1.2980)\tAcc@1 70.312 (62.687)\tAcc@5 89.062 (89.533)\n",
            "Epoch: [122][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2503 (1.2990)\tAcc@1 64.062 (62.705)\tAcc@5 90.625 (89.504)\n",
            "Epoch: [122][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2018 (1.3018)\tAcc@1 67.188 (62.736)\tAcc@5 89.062 (89.408)\n",
            " * Acc@1 62.606 Acc@5 89.350\n",
            "epoch 122, total time 39.91\n",
            "Test: [0/313]\tTime 0.132 (0.132)\tLoss 2.0349 (2.0349)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 2.2948 (1.9965)\tAcc@1 43.750 (51.238)\tAcc@5 71.875 (81.033)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 2.0463 (2.0146)\tAcc@1 43.750 (50.902)\tAcc@5 84.375 (80.379)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0467 (2.0264)\tAcc@1 53.125 (50.592)\tAcc@5 75.000 (80.201)\n",
            " * Acc@1 50.510 Acc@5 80.200\n",
            "==> training...\n",
            "Epoch: [123][0/782]\tTime 0.274 (0.274)\tData 0.199 (0.199)\tLoss 0.9074 (0.9074)\tAcc@1 73.438 (73.438)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [123][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 1.1964 (1.2235)\tAcc@1 65.625 (64.743)\tAcc@5 95.312 (90.826)\n",
            "Epoch: [123][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3589 (1.2512)\tAcc@1 65.625 (64.241)\tAcc@5 82.812 (90.221)\n",
            "Epoch: [123][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2966 (1.2592)\tAcc@1 57.812 (63.834)\tAcc@5 85.938 (90.007)\n",
            "Epoch: [123][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.5025 (1.2768)\tAcc@1 57.812 (63.505)\tAcc@5 84.375 (89.760)\n",
            "Epoch: [123][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.7026 (1.2903)\tAcc@1 50.000 (63.130)\tAcc@5 84.375 (89.596)\n",
            "Epoch: [123][600/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 1.0794 (1.2994)\tAcc@1 68.750 (62.877)\tAcc@5 89.062 (89.377)\n",
            "Epoch: [123][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2511 (1.3034)\tAcc@1 65.625 (62.701)\tAcc@5 90.625 (89.323)\n",
            " * Acc@1 62.784 Acc@5 89.264\n",
            "epoch 123, total time 39.93\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.0467 (2.0467)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5117 (1.7123)\tAcc@1 59.375 (53.620)\tAcc@5 90.625 (84.870)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.3624 (1.7096)\tAcc@1 59.375 (53.933)\tAcc@5 87.500 (84.406)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0831 (1.7056)\tAcc@1 53.125 (53.945)\tAcc@5 81.250 (84.188)\n",
            " * Acc@1 54.070 Acc@5 84.190\n",
            "==> training...\n",
            "Epoch: [124][0/782]\tTime 0.267 (0.267)\tData 0.182 (0.182)\tLoss 1.3550 (1.3550)\tAcc@1 57.812 (57.812)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [124][100/782]\tTime 0.064 (0.055)\tData 0.001 (0.003)\tLoss 1.1966 (1.2919)\tAcc@1 60.938 (63.134)\tAcc@5 89.062 (89.496)\n",
            "Epoch: [124][200/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.1937 (1.2839)\tAcc@1 67.188 (63.417)\tAcc@5 89.062 (89.381)\n",
            "Epoch: [124][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4251 (1.2900)\tAcc@1 60.938 (63.382)\tAcc@5 90.625 (89.374)\n",
            "Epoch: [124][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.9970 (1.2943)\tAcc@1 73.438 (63.081)\tAcc@5 90.625 (89.339)\n",
            "Epoch: [124][500/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 1.1953 (1.3018)\tAcc@1 67.188 (62.784)\tAcc@5 87.500 (89.306)\n",
            "Epoch: [124][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3099 (1.3086)\tAcc@1 67.188 (62.594)\tAcc@5 84.375 (89.247)\n",
            "Epoch: [124][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3077 (1.3098)\tAcc@1 64.062 (62.489)\tAcc@5 89.062 (89.183)\n",
            " * Acc@1 62.450 Acc@5 89.084\n",
            "epoch 124, total time 40.11\n",
            "Test: [0/313]\tTime 0.130 (0.130)\tLoss 1.6450 (1.6450)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.9722 (1.7431)\tAcc@1 59.375 (53.558)\tAcc@5 81.250 (83.045)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.4869 (1.7246)\tAcc@1 62.500 (54.540)\tAcc@5 87.500 (82.945)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0528 (1.7393)\tAcc@1 43.750 (54.184)\tAcc@5 84.375 (83.233)\n",
            " * Acc@1 54.130 Acc@5 83.200\n",
            "==> training...\n",
            "Epoch: [125][0/782]\tTime 0.268 (0.268)\tData 0.185 (0.185)\tLoss 1.3917 (1.3917)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Epoch: [125][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.0244 (1.2468)\tAcc@1 71.875 (64.774)\tAcc@5 96.875 (89.882)\n",
            "Epoch: [125][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5290 (1.2668)\tAcc@1 50.000 (64.164)\tAcc@5 82.812 (89.475)\n",
            "Epoch: [125][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3924 (1.2775)\tAcc@1 53.125 (63.450)\tAcc@5 90.625 (89.623)\n",
            "Epoch: [125][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3194 (1.2907)\tAcc@1 62.500 (62.921)\tAcc@5 93.750 (89.616)\n",
            "Epoch: [125][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.4048 (1.2966)\tAcc@1 64.062 (62.725)\tAcc@5 89.062 (89.512)\n",
            "Epoch: [125][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3991 (1.2972)\tAcc@1 60.938 (62.872)\tAcc@5 89.062 (89.421)\n",
            "Epoch: [125][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.6080 (1.3002)\tAcc@1 56.250 (62.727)\tAcc@5 84.375 (89.350)\n",
            " * Acc@1 62.784 Acc@5 89.326\n",
            "epoch 125, total time 40.16\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 2.0877 (2.0877)\tAcc@1 50.000 (50.000)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.024 (0.021)\tLoss 1.8323 (1.5997)\tAcc@1 50.000 (57.209)\tAcc@5 84.375 (84.158)\n",
            "Test: [200/313]\tTime 0.024 (0.020)\tLoss 1.3387 (1.6034)\tAcc@1 59.375 (56.763)\tAcc@5 87.500 (84.328)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.5029 (1.6046)\tAcc@1 56.250 (57.143)\tAcc@5 90.625 (84.250)\n",
            " * Acc@1 56.980 Acc@5 84.220\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [126][0/782]\tTime 0.280 (0.280)\tData 0.205 (0.205)\tLoss 1.4422 (1.4422)\tAcc@1 57.812 (57.812)\tAcc@5 84.375 (84.375)\n",
            "Epoch: [126][100/782]\tTime 0.049 (0.052)\tData 0.001 (0.003)\tLoss 1.3842 (1.2715)\tAcc@1 56.250 (63.335)\tAcc@5 89.062 (89.635)\n",
            "Epoch: [126][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2055 (1.2540)\tAcc@1 62.500 (63.860)\tAcc@5 90.625 (90.026)\n",
            "Epoch: [126][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1498 (1.2839)\tAcc@1 67.188 (63.341)\tAcc@5 92.188 (89.639)\n",
            "Epoch: [126][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2114 (1.2950)\tAcc@1 64.062 (62.909)\tAcc@5 92.188 (89.627)\n",
            "Epoch: [126][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1258 (1.2964)\tAcc@1 67.188 (62.940)\tAcc@5 92.188 (89.586)\n",
            "Epoch: [126][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.1612 (1.3009)\tAcc@1 65.625 (62.809)\tAcc@5 92.188 (89.452)\n",
            "Epoch: [126][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3817 (1.3098)\tAcc@1 60.938 (62.496)\tAcc@5 87.500 (89.348)\n",
            " * Acc@1 62.438 Acc@5 89.280\n",
            "epoch 126, total time 40.01\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.9402 (1.9402)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5378 (1.8038)\tAcc@1 53.125 (53.496)\tAcc@5 84.375 (82.519)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.3441 (1.8072)\tAcc@1 62.500 (53.343)\tAcc@5 87.500 (82.556)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.3677 (1.8312)\tAcc@1 34.375 (52.855)\tAcc@5 75.000 (82.081)\n",
            " * Acc@1 52.780 Acc@5 82.010\n",
            "==> training...\n",
            "Epoch: [127][0/782]\tTime 0.271 (0.271)\tData 0.197 (0.197)\tLoss 1.2116 (1.2116)\tAcc@1 65.625 (65.625)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [127][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.3104 (1.2358)\tAcc@1 60.938 (64.233)\tAcc@5 87.500 (89.836)\n",
            "Epoch: [127][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1685 (1.2631)\tAcc@1 68.750 (64.000)\tAcc@5 90.625 (89.677)\n",
            "Epoch: [127][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2585 (1.2841)\tAcc@1 56.250 (63.170)\tAcc@5 92.188 (89.634)\n",
            "Epoch: [127][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2988 (1.2899)\tAcc@1 62.500 (63.108)\tAcc@5 87.500 (89.460)\n",
            "Epoch: [127][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.4175 (1.2942)\tAcc@1 64.062 (62.974)\tAcc@5 92.188 (89.402)\n",
            "Epoch: [127][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3598 (1.3000)\tAcc@1 64.062 (62.903)\tAcc@5 87.500 (89.328)\n",
            "Epoch: [127][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.2813 (1.3055)\tAcc@1 59.375 (62.723)\tAcc@5 85.938 (89.207)\n",
            " * Acc@1 62.602 Acc@5 89.154\n",
            "epoch 127, total time 39.99\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 2.2063 (2.2063)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.7645 (1.8269)\tAcc@1 59.375 (53.125)\tAcc@5 81.250 (81.838)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.6540 (1.8079)\tAcc@1 59.375 (53.063)\tAcc@5 81.250 (82.121)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.0607 (1.8158)\tAcc@1 40.625 (52.824)\tAcc@5 81.250 (82.070)\n",
            " * Acc@1 52.920 Acc@5 82.100\n",
            "==> training...\n",
            "Epoch: [128][0/782]\tTime 0.280 (0.280)\tData 0.197 (0.197)\tLoss 1.1571 (1.1571)\tAcc@1 67.188 (67.188)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [128][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.6895 (1.2471)\tAcc@1 46.875 (63.815)\tAcc@5 89.062 (90.455)\n",
            "Epoch: [128][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3386 (1.2551)\tAcc@1 68.750 (63.565)\tAcc@5 89.062 (90.275)\n",
            "Epoch: [128][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3128 (1.2819)\tAcc@1 62.500 (62.941)\tAcc@5 89.062 (89.919)\n",
            "Epoch: [128][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1532 (1.2826)\tAcc@1 68.750 (63.007)\tAcc@5 89.062 (89.787)\n",
            "Epoch: [128][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.4670 (1.2946)\tAcc@1 57.812 (62.687)\tAcc@5 85.938 (89.655)\n",
            "Epoch: [128][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.3982 (1.3008)\tAcc@1 62.500 (62.484)\tAcc@5 87.500 (89.455)\n",
            "Epoch: [128][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3311 (1.3039)\tAcc@1 65.625 (62.415)\tAcc@5 87.500 (89.464)\n",
            " * Acc@1 62.342 Acc@5 89.392\n",
            "epoch 128, total time 40.00\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.2736 (2.2736)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.9851 (1.7939)\tAcc@1 43.750 (52.351)\tAcc@5 78.125 (82.952)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.7116 (1.7873)\tAcc@1 50.000 (52.596)\tAcc@5 78.125 (82.634)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.7545 (1.7946)\tAcc@1 56.250 (52.627)\tAcc@5 84.375 (82.496)\n",
            " * Acc@1 52.750 Acc@5 82.530\n",
            "==> training...\n",
            "Epoch: [129][0/782]\tTime 0.264 (0.264)\tData 0.182 (0.182)\tLoss 1.3383 (1.3383)\tAcc@1 64.062 (64.062)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [129][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.1405 (1.2143)\tAcc@1 65.625 (64.851)\tAcc@5 93.750 (90.347)\n",
            "Epoch: [129][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.4453 (1.2367)\tAcc@1 60.938 (63.930)\tAcc@5 85.938 (90.306)\n",
            "Epoch: [129][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4167 (1.2557)\tAcc@1 64.062 (63.684)\tAcc@5 87.500 (89.815)\n",
            "Epoch: [129][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1656 (1.2717)\tAcc@1 60.938 (63.217)\tAcc@5 89.062 (89.631)\n",
            "Epoch: [129][500/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.6613 (1.2789)\tAcc@1 50.000 (63.136)\tAcc@5 87.500 (89.490)\n",
            "Epoch: [129][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4102 (1.2831)\tAcc@1 57.812 (63.064)\tAcc@5 92.188 (89.476)\n",
            "Epoch: [129][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4158 (1.2970)\tAcc@1 56.250 (62.658)\tAcc@5 84.375 (89.357)\n",
            " * Acc@1 62.536 Acc@5 89.286\n",
            "epoch 129, total time 39.74\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 2.1569 (2.1569)\tAcc@1 56.250 (56.250)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.6359 (1.9214)\tAcc@1 53.125 (51.269)\tAcc@5 87.500 (80.910)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.8922 (1.8834)\tAcc@1 53.125 (52.208)\tAcc@5 87.500 (81.203)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.4710 (1.8871)\tAcc@1 56.250 (52.357)\tAcc@5 87.500 (81.022)\n",
            " * Acc@1 52.410 Acc@5 81.100\n",
            "==> training...\n",
            "Epoch: [130][0/782]\tTime 0.261 (0.261)\tData 0.179 (0.179)\tLoss 1.0656 (1.0656)\tAcc@1 71.875 (71.875)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [130][100/782]\tTime 0.052 (0.055)\tData 0.001 (0.003)\tLoss 1.2468 (1.2745)\tAcc@1 67.188 (63.892)\tAcc@5 87.500 (89.743)\n",
            "Epoch: [130][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.9373 (1.2827)\tAcc@1 71.875 (63.340)\tAcc@5 92.188 (89.358)\n",
            "Epoch: [130][300/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 1.4226 (1.2957)\tAcc@1 64.062 (62.931)\tAcc@5 89.062 (89.322)\n",
            "Epoch: [130][400/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.2847 (1.3008)\tAcc@1 57.812 (62.773)\tAcc@5 92.188 (89.269)\n",
            "Epoch: [130][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2096 (1.3017)\tAcc@1 67.188 (62.852)\tAcc@5 92.188 (89.222)\n",
            "Epoch: [130][600/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3498 (1.3032)\tAcc@1 62.500 (62.737)\tAcc@5 90.625 (89.242)\n",
            "Epoch: [130][700/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2612 (1.3013)\tAcc@1 62.500 (62.716)\tAcc@5 90.625 (89.265)\n",
            " * Acc@1 62.600 Acc@5 89.244\n",
            "epoch 130, total time 40.96\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.9020 (1.9020)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.6188 (1.8590)\tAcc@1 59.375 (51.887)\tAcc@5 84.375 (81.374)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.8339 (1.8840)\tAcc@1 65.625 (51.648)\tAcc@5 78.125 (80.892)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.5143 (1.8833)\tAcc@1 59.375 (52.004)\tAcc@5 87.500 (80.855)\n",
            " * Acc@1 52.050 Acc@5 80.950\n",
            "==> training...\n",
            "Epoch: [131][0/782]\tTime 0.266 (0.266)\tData 0.197 (0.197)\tLoss 1.2405 (1.2405)\tAcc@1 67.188 (67.188)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [131][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.0898 (1.2579)\tAcc@1 76.562 (63.629)\tAcc@5 92.188 (90.068)\n",
            "Epoch: [131][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2911 (1.2668)\tAcc@1 65.625 (63.884)\tAcc@5 87.500 (89.855)\n",
            "Epoch: [131][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5595 (1.2844)\tAcc@1 57.812 (63.201)\tAcc@5 84.375 (89.717)\n",
            "Epoch: [131][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.2189 (1.2906)\tAcc@1 68.750 (63.061)\tAcc@5 87.500 (89.507)\n",
            "Epoch: [131][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.0149 (1.2880)\tAcc@1 70.312 (63.096)\tAcc@5 92.188 (89.471)\n",
            "Epoch: [131][600/782]\tTime 0.053 (0.051)\tData 0.002 (0.002)\tLoss 1.7133 (1.2979)\tAcc@1 51.562 (62.770)\tAcc@5 84.375 (89.403)\n",
            "Epoch: [131][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.2163 (1.3066)\tAcc@1 64.062 (62.567)\tAcc@5 92.188 (89.259)\n",
            " * Acc@1 62.584 Acc@5 89.260\n",
            "epoch 131, total time 39.84\n",
            "Test: [0/313]\tTime 0.126 (0.126)\tLoss 1.7596 (1.7596)\tAcc@1 68.750 (68.750)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4215 (1.5609)\tAcc@1 56.250 (58.447)\tAcc@5 90.625 (85.118)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.2187 (1.5341)\tAcc@1 71.875 (59.157)\tAcc@5 87.500 (85.417)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.4212 (1.5545)\tAcc@1 59.375 (58.378)\tAcc@5 96.875 (85.195)\n",
            " * Acc@1 58.380 Acc@5 85.270\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [132][0/782]\tTime 0.262 (0.262)\tData 0.192 (0.192)\tLoss 1.0073 (1.0073)\tAcc@1 68.750 (68.750)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [132][100/782]\tTime 0.055 (0.053)\tData 0.002 (0.003)\tLoss 1.1971 (1.2169)\tAcc@1 59.375 (64.356)\tAcc@5 98.438 (90.888)\n",
            "Epoch: [132][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.0041 (1.2503)\tAcc@1 71.875 (63.868)\tAcc@5 95.312 (90.244)\n",
            "Epoch: [132][300/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.3013 (1.2668)\tAcc@1 64.062 (63.632)\tAcc@5 92.188 (89.909)\n",
            "Epoch: [132][400/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 1.1607 (1.2723)\tAcc@1 64.062 (63.509)\tAcc@5 92.188 (89.916)\n",
            "Epoch: [132][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3738 (1.2816)\tAcc@1 57.812 (63.433)\tAcc@5 87.500 (89.717)\n",
            "Epoch: [132][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4777 (1.2922)\tAcc@1 53.125 (63.145)\tAcc@5 84.375 (89.551)\n",
            "Epoch: [132][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.9946 (1.2926)\tAcc@1 68.750 (63.111)\tAcc@5 96.875 (89.495)\n",
            " * Acc@1 62.920 Acc@5 89.420\n",
            "epoch 132, total time 40.08\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 2.0762 (2.0762)\tAcc@1 53.125 (53.125)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.8338 (2.0404)\tAcc@1 53.125 (49.196)\tAcc@5 81.250 (78.868)\n",
            "Test: [200/313]\tTime 0.025 (0.019)\tLoss 1.6816 (2.0771)\tAcc@1 56.250 (48.678)\tAcc@5 84.375 (78.809)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.6494 (2.0855)\tAcc@1 50.000 (48.816)\tAcc@5 90.625 (78.426)\n",
            " * Acc@1 48.750 Acc@5 78.430\n",
            "==> training...\n",
            "Epoch: [133][0/782]\tTime 0.263 (0.263)\tData 0.191 (0.191)\tLoss 1.3141 (1.3141)\tAcc@1 67.188 (67.188)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [133][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.2622 (1.2745)\tAcc@1 60.938 (63.397)\tAcc@5 92.188 (90.037)\n",
            "Epoch: [133][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3059 (1.2753)\tAcc@1 60.938 (63.526)\tAcc@5 90.625 (90.205)\n",
            "Epoch: [133][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2175 (1.2897)\tAcc@1 67.188 (63.128)\tAcc@5 89.062 (89.857)\n",
            "Epoch: [133][400/782]\tTime 0.058 (0.052)\tData 0.002 (0.002)\tLoss 1.1085 (1.2890)\tAcc@1 65.625 (62.964)\tAcc@5 93.750 (89.896)\n",
            "Epoch: [133][500/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.1744 (1.2977)\tAcc@1 64.062 (62.734)\tAcc@5 90.625 (89.586)\n",
            "Epoch: [133][600/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.9777 (1.2978)\tAcc@1 73.438 (62.859)\tAcc@5 98.438 (89.549)\n",
            "Epoch: [133][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5487 (1.3038)\tAcc@1 51.562 (62.727)\tAcc@5 84.375 (89.399)\n",
            " * Acc@1 62.652 Acc@5 89.380\n",
            "epoch 133, total time 40.11\n",
            "Test: [0/313]\tTime 0.130 (0.130)\tLoss 1.9749 (1.9749)\tAcc@1 43.750 (43.750)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.017 (0.022)\tLoss 1.2811 (1.7726)\tAcc@1 62.500 (52.692)\tAcc@5 96.875 (82.828)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.8199 (1.8027)\tAcc@1 59.375 (52.146)\tAcc@5 81.250 (82.136)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.6652 (1.7997)\tAcc@1 53.125 (52.658)\tAcc@5 81.250 (82.018)\n",
            " * Acc@1 52.600 Acc@5 81.980\n",
            "==> training...\n",
            "Epoch: [134][0/782]\tTime 0.255 (0.255)\tData 0.185 (0.185)\tLoss 0.8515 (0.8515)\tAcc@1 73.438 (73.438)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [134][100/782]\tTime 0.051 (0.054)\tData 0.001 (0.003)\tLoss 1.1949 (1.2385)\tAcc@1 59.375 (64.697)\tAcc@5 93.750 (89.944)\n",
            "Epoch: [134][200/782]\tTime 0.050 (0.053)\tData 0.002 (0.002)\tLoss 1.1579 (1.2529)\tAcc@1 62.500 (64.272)\tAcc@5 92.188 (89.762)\n",
            "Epoch: [134][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.5912 (1.2673)\tAcc@1 62.500 (63.943)\tAcc@5 84.375 (89.602)\n",
            "Epoch: [134][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.2385 (1.2786)\tAcc@1 62.500 (63.560)\tAcc@5 89.062 (89.468)\n",
            "Epoch: [134][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2078 (1.2832)\tAcc@1 64.062 (63.373)\tAcc@5 92.188 (89.418)\n",
            "Epoch: [134][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1351 (1.2904)\tAcc@1 70.312 (63.236)\tAcc@5 90.625 (89.333)\n",
            "Epoch: [134][700/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.7675 (1.2985)\tAcc@1 56.250 (63.084)\tAcc@5 79.688 (89.263)\n",
            " * Acc@1 62.936 Acc@5 89.214\n",
            "epoch 134, total time 40.37\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 2.0829 (2.0829)\tAcc@1 56.250 (56.250)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 2.0595 (1.8772)\tAcc@1 43.750 (51.795)\tAcc@5 81.250 (81.281)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.7033 (1.8601)\tAcc@1 65.625 (51.850)\tAcc@5 81.250 (81.281)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.7962 (1.8622)\tAcc@1 56.250 (52.087)\tAcc@5 81.250 (81.292)\n",
            " * Acc@1 52.200 Acc@5 81.360\n",
            "==> training...\n",
            "Epoch: [135][0/782]\tTime 0.264 (0.264)\tData 0.179 (0.179)\tLoss 1.2314 (1.2314)\tAcc@1 67.188 (67.188)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [135][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.1344 (1.2672)\tAcc@1 70.312 (63.954)\tAcc@5 92.188 (90.161)\n",
            "Epoch: [135][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2290 (1.2491)\tAcc@1 64.062 (64.747)\tAcc@5 89.062 (90.205)\n",
            "Epoch: [135][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2708 (1.2724)\tAcc@1 68.750 (63.782)\tAcc@5 93.750 (89.846)\n",
            "Epoch: [135][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.9009 (1.2752)\tAcc@1 71.875 (63.583)\tAcc@5 95.312 (89.690)\n",
            "Epoch: [135][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4721 (1.2798)\tAcc@1 59.375 (63.464)\tAcc@5 85.938 (89.636)\n",
            "Epoch: [135][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.3964 (1.2859)\tAcc@1 54.688 (63.335)\tAcc@5 85.938 (89.471)\n",
            "Epoch: [135][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5374 (1.2901)\tAcc@1 59.375 (63.149)\tAcc@5 87.500 (89.401)\n",
            " * Acc@1 62.898 Acc@5 89.380\n",
            "epoch 135, total time 40.04\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 2.0624 (2.0624)\tAcc@1 53.125 (53.125)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.7619 (1.8164)\tAcc@1 46.875 (53.960)\tAcc@5 90.625 (83.725)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 1.8462 (1.7766)\tAcc@1 56.250 (54.244)\tAcc@5 84.375 (83.769)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.9380 (1.7816)\tAcc@1 50.000 (54.132)\tAcc@5 81.250 (83.451)\n",
            " * Acc@1 54.050 Acc@5 83.360\n",
            "==> training...\n",
            "Epoch: [136][0/782]\tTime 0.278 (0.278)\tData 0.195 (0.195)\tLoss 1.0491 (1.0491)\tAcc@1 75.000 (75.000)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [136][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.3586 (1.2595)\tAcc@1 64.062 (64.124)\tAcc@5 89.062 (89.728)\n",
            "Epoch: [136][200/782]\tTime 0.068 (0.053)\tData 0.001 (0.002)\tLoss 1.4555 (1.2455)\tAcc@1 56.250 (64.529)\tAcc@5 85.938 (89.863)\n",
            "Epoch: [136][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.7304 (1.2603)\tAcc@1 53.125 (64.005)\tAcc@5 85.938 (89.753)\n",
            "Epoch: [136][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.8371 (1.2678)\tAcc@1 71.875 (63.735)\tAcc@5 98.438 (89.725)\n",
            "Epoch: [136][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.3913 (1.2864)\tAcc@1 64.062 (63.292)\tAcc@5 84.375 (89.455)\n",
            "Epoch: [136][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2962 (1.2931)\tAcc@1 68.750 (63.033)\tAcc@5 87.500 (89.400)\n",
            "Epoch: [136][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4186 (1.3003)\tAcc@1 59.375 (62.868)\tAcc@5 82.812 (89.285)\n",
            " * Acc@1 62.826 Acc@5 89.320\n",
            "epoch 136, total time 40.07\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.5308 (1.5308)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.0528 (1.6344)\tAcc@1 46.875 (55.972)\tAcc@5 87.500 (84.715)\n",
            "Test: [200/313]\tTime 0.020 (0.019)\tLoss 1.0805 (1.6349)\tAcc@1 71.875 (56.281)\tAcc@5 90.625 (84.624)\n",
            "Test: [300/313]\tTime 0.019 (0.019)\tLoss 1.7568 (1.6624)\tAcc@1 56.250 (56.146)\tAcc@5 87.500 (84.240)\n",
            " * Acc@1 56.160 Acc@5 84.280\n",
            "==> training...\n",
            "Epoch: [137][0/782]\tTime 0.281 (0.281)\tData 0.197 (0.197)\tLoss 1.0018 (1.0018)\tAcc@1 68.750 (68.750)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [137][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 1.5413 (1.2695)\tAcc@1 53.125 (63.598)\tAcc@5 87.500 (90.161)\n",
            "Epoch: [137][200/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 1.1396 (1.2378)\tAcc@1 67.188 (64.513)\tAcc@5 90.625 (90.501)\n",
            "Epoch: [137][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.5226 (1.2716)\tAcc@1 56.250 (63.720)\tAcc@5 82.812 (89.857)\n",
            "Epoch: [137][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3874 (1.2740)\tAcc@1 57.812 (63.591)\tAcc@5 89.062 (89.702)\n",
            "Epoch: [137][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3534 (1.2776)\tAcc@1 62.500 (63.641)\tAcc@5 85.938 (89.555)\n",
            "Epoch: [137][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.4524 (1.2861)\tAcc@1 60.938 (63.524)\tAcc@5 89.062 (89.460)\n",
            "Epoch: [137][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.2795 (1.2941)\tAcc@1 68.750 (63.320)\tAcc@5 90.625 (89.397)\n",
            " * Acc@1 63.096 Acc@5 89.318\n",
            "epoch 137, total time 39.96\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.8462 (1.8462)\tAcc@1 62.500 (62.500)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.2548 (2.0378)\tAcc@1 50.000 (50.681)\tAcc@5 81.250 (80.136)\n",
            "Test: [200/313]\tTime 0.025 (0.019)\tLoss 0.9854 (2.0288)\tAcc@1 75.000 (51.119)\tAcc@5 84.375 (79.555)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 2.6926 (2.0302)\tAcc@1 31.250 (51.132)\tAcc@5 71.875 (79.475)\n",
            " * Acc@1 51.090 Acc@5 79.410\n",
            "==> training...\n",
            "Epoch: [138][0/782]\tTime 0.258 (0.258)\tData 0.184 (0.184)\tLoss 1.3888 (1.3888)\tAcc@1 56.250 (56.250)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [138][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.0240 (1.2570)\tAcc@1 68.750 (64.759)\tAcc@5 92.188 (89.836)\n",
            "Epoch: [138][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.2077 (1.2934)\tAcc@1 64.062 (63.308)\tAcc@5 90.625 (89.513)\n",
            "Epoch: [138][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1037 (1.2775)\tAcc@1 68.750 (63.497)\tAcc@5 95.312 (89.608)\n",
            "Epoch: [138][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.1693 (1.2885)\tAcc@1 68.750 (63.194)\tAcc@5 92.188 (89.546)\n",
            "Epoch: [138][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 1.4045 (1.2926)\tAcc@1 57.812 (63.114)\tAcc@5 90.625 (89.477)\n",
            "Epoch: [138][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.7640 (1.2988)\tAcc@1 53.125 (63.025)\tAcc@5 81.250 (89.367)\n",
            "Epoch: [138][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.3576 (1.3014)\tAcc@1 60.938 (62.977)\tAcc@5 85.938 (89.283)\n",
            " * Acc@1 62.946 Acc@5 89.270\n",
            "epoch 138, total time 40.04\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.8438 (1.8438)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.7679 (1.5376)\tAcc@1 53.125 (58.385)\tAcc@5 84.375 (86.231)\n",
            "Test: [200/313]\tTime 0.019 (0.019)\tLoss 1.0358 (1.5335)\tAcc@1 62.500 (57.976)\tAcc@5 93.750 (86.023)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.5585 (1.5317)\tAcc@1 53.125 (57.901)\tAcc@5 84.375 (85.963)\n",
            " * Acc@1 57.970 Acc@5 85.870\n",
            "==> training...\n",
            "Epoch: [139][0/782]\tTime 0.281 (0.281)\tData 0.198 (0.198)\tLoss 1.2367 (1.2367)\tAcc@1 68.750 (68.750)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [139][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.3409 (1.2315)\tAcc@1 60.938 (64.325)\tAcc@5 84.375 (90.718)\n",
            "Epoch: [139][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.1026 (1.2765)\tAcc@1 64.062 (63.262)\tAcc@5 96.875 (89.715)\n",
            "Epoch: [139][300/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.2630 (1.2971)\tAcc@1 65.625 (62.687)\tAcc@5 89.062 (89.462)\n",
            "Epoch: [139][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.4323 (1.2942)\tAcc@1 54.688 (62.921)\tAcc@5 92.188 (89.437)\n",
            "Epoch: [139][500/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 1.1199 (1.2949)\tAcc@1 71.875 (62.880)\tAcc@5 85.938 (89.459)\n",
            "Epoch: [139][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.3291 (1.2997)\tAcc@1 62.500 (62.760)\tAcc@5 92.188 (89.421)\n",
            "Epoch: [139][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.5416 (1.3056)\tAcc@1 56.250 (62.623)\tAcc@5 84.375 (89.350)\n",
            " * Acc@1 62.672 Acc@5 89.364\n",
            "epoch 139, total time 40.38\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.0276 (2.0276)\tAcc@1 43.750 (43.750)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.9141 (1.8288)\tAcc@1 50.000 (52.754)\tAcc@5 84.375 (82.704)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.6560 (1.8078)\tAcc@1 56.250 (52.861)\tAcc@5 87.500 (83.287)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.4791 (1.8153)\tAcc@1 46.875 (53.032)\tAcc@5 84.375 (83.160)\n",
            " * Acc@1 52.970 Acc@5 83.240\n",
            "==> training...\n",
            "Epoch: [140][0/782]\tTime 0.277 (0.277)\tData 0.185 (0.185)\tLoss 1.3826 (1.3826)\tAcc@1 59.375 (59.375)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [140][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.3805 (1.2510)\tAcc@1 57.812 (63.676)\tAcc@5 89.062 (90.037)\n",
            "Epoch: [140][200/782]\tTime 0.053 (0.053)\tData 0.002 (0.002)\tLoss 1.1215 (1.2711)\tAcc@1 65.625 (63.270)\tAcc@5 90.625 (89.677)\n",
            "Epoch: [140][300/782]\tTime 0.052 (0.053)\tData 0.001 (0.002)\tLoss 1.4659 (1.2657)\tAcc@1 62.500 (63.533)\tAcc@5 87.500 (89.898)\n",
            "Epoch: [140][400/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.5611 (1.2724)\tAcc@1 51.562 (63.501)\tAcc@5 90.625 (89.822)\n",
            "Epoch: [140][500/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 1.5156 (1.2816)\tAcc@1 57.812 (63.264)\tAcc@5 89.062 (89.633)\n",
            "Epoch: [140][600/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.3807 (1.2854)\tAcc@1 56.250 (63.210)\tAcc@5 87.500 (89.689)\n",
            "Epoch: [140][700/782]\tTime 0.056 (0.053)\tData 0.001 (0.002)\tLoss 1.5782 (1.2875)\tAcc@1 56.250 (63.115)\tAcc@5 90.625 (89.644)\n",
            " * Acc@1 62.912 Acc@5 89.554\n",
            "epoch 140, total time 40.98\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 1.5233 (1.5233)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5732 (1.7512)\tAcc@1 46.875 (54.301)\tAcc@5 84.375 (83.880)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.2605 (1.7690)\tAcc@1 59.375 (54.509)\tAcc@5 90.625 (83.131)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.7517 (1.7810)\tAcc@1 46.875 (54.215)\tAcc@5 87.500 (83.056)\n",
            " * Acc@1 54.230 Acc@5 83.090\n",
            "==> training...\n",
            "Epoch: [141][0/782]\tTime 0.284 (0.284)\tData 0.200 (0.200)\tLoss 1.5708 (1.5708)\tAcc@1 53.125 (53.125)\tAcc@5 82.812 (82.812)\n",
            "Epoch: [141][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.3017 (1.2697)\tAcc@1 62.500 (63.335)\tAcc@5 89.062 (90.068)\n",
            "Epoch: [141][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.1389 (1.2662)\tAcc@1 68.750 (63.347)\tAcc@5 92.188 (90.135)\n",
            "Epoch: [141][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.6136 (1.2811)\tAcc@1 48.438 (62.905)\tAcc@5 85.938 (89.992)\n",
            "Epoch: [141][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.0721 (1.2861)\tAcc@1 68.750 (63.139)\tAcc@5 92.188 (89.865)\n",
            "Epoch: [141][500/782]\tTime 0.050 (0.052)\tData 0.002 (0.002)\tLoss 1.4278 (1.2861)\tAcc@1 57.812 (62.990)\tAcc@5 82.812 (89.917)\n",
            "Epoch: [141][600/782]\tTime 0.053 (0.052)\tData 0.002 (0.002)\tLoss 1.1574 (1.2868)\tAcc@1 67.188 (63.093)\tAcc@5 89.062 (89.746)\n",
            "Epoch: [141][700/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 1.2291 (1.2948)\tAcc@1 64.062 (62.910)\tAcc@5 93.750 (89.582)\n",
            " * Acc@1 62.598 Acc@5 89.460\n",
            "epoch 141, total time 40.58\n",
            "Test: [0/313]\tTime 0.126 (0.126)\tLoss 2.0003 (2.0003)\tAcc@1 50.000 (50.000)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.7098 (1.6822)\tAcc@1 50.000 (55.415)\tAcc@5 84.375 (83.756)\n",
            "Test: [200/313]\tTime 0.019 (0.019)\tLoss 1.1378 (1.7051)\tAcc@1 71.875 (55.084)\tAcc@5 90.625 (83.753)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.3885 (1.7189)\tAcc@1 65.625 (54.931)\tAcc@5 84.375 (83.441)\n",
            " * Acc@1 54.910 Acc@5 83.510\n",
            "==> training...\n",
            "Epoch: [142][0/782]\tTime 0.277 (0.277)\tData 0.202 (0.202)\tLoss 0.9675 (0.9675)\tAcc@1 76.562 (76.562)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [142][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 1.0700 (1.2675)\tAcc@1 68.750 (62.670)\tAcc@5 93.750 (89.975)\n",
            "Epoch: [142][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.0723 (1.2644)\tAcc@1 67.188 (63.277)\tAcc@5 87.500 (90.073)\n",
            "Epoch: [142][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3832 (1.2628)\tAcc@1 59.375 (63.611)\tAcc@5 87.500 (90.054)\n",
            "Epoch: [142][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4944 (1.2701)\tAcc@1 56.250 (63.505)\tAcc@5 84.375 (89.791)\n",
            "Epoch: [142][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.3055 (1.2795)\tAcc@1 60.938 (63.423)\tAcc@5 90.625 (89.639)\n",
            "Epoch: [142][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.1228 (1.2889)\tAcc@1 70.312 (63.160)\tAcc@5 93.750 (89.564)\n",
            "Epoch: [142][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3090 (1.2955)\tAcc@1 64.062 (62.946)\tAcc@5 85.938 (89.419)\n",
            " * Acc@1 62.874 Acc@5 89.398\n",
            "epoch 142, total time 39.86\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.6106 (1.6106)\tAcc@1 65.625 (65.625)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.018)\tLoss 1.8931 (1.5505)\tAcc@1 37.500 (57.209)\tAcc@5 84.375 (86.324)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.2359 (1.5425)\tAcc@1 59.375 (57.603)\tAcc@5 90.625 (85.883)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.6064 (1.5481)\tAcc@1 43.750 (57.849)\tAcc@5 93.750 (85.652)\n",
            " * Acc@1 57.770 Acc@5 85.600\n",
            "==> training...\n",
            "Epoch: [143][0/782]\tTime 0.279 (0.279)\tData 0.196 (0.196)\tLoss 0.8530 (0.8530)\tAcc@1 76.562 (76.562)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [143][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.5682 (1.2479)\tAcc@1 54.688 (64.155)\tAcc@5 84.375 (90.176)\n",
            "Epoch: [143][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 1.5409 (1.2563)\tAcc@1 53.125 (64.078)\tAcc@5 85.938 (90.143)\n",
            "Epoch: [143][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.9582 (1.2687)\tAcc@1 73.438 (63.580)\tAcc@5 96.875 (89.919)\n",
            "Epoch: [143][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.1190 (1.2664)\tAcc@1 73.438 (63.848)\tAcc@5 90.625 (89.811)\n",
            "Epoch: [143][500/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 1.5355 (1.2816)\tAcc@1 54.688 (63.467)\tAcc@5 89.062 (89.646)\n",
            "Epoch: [143][600/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3428 (1.2870)\tAcc@1 62.500 (63.361)\tAcc@5 89.062 (89.543)\n",
            "Epoch: [143][700/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3316 (1.2906)\tAcc@1 54.688 (63.267)\tAcc@5 90.625 (89.457)\n",
            " * Acc@1 63.060 Acc@5 89.400\n",
            "epoch 143, total time 40.68\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.7188 (1.7188)\tAcc@1 68.750 (68.750)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.019 (0.021)\tLoss 1.6927 (1.9019)\tAcc@1 53.125 (50.402)\tAcc@5 90.625 (81.188)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.4974 (1.9317)\tAcc@1 59.375 (50.560)\tAcc@5 81.250 (79.944)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 2.1739 (1.9360)\tAcc@1 43.750 (50.613)\tAcc@5 75.000 (79.620)\n",
            " * Acc@1 50.570 Acc@5 79.620\n",
            "==> training...\n",
            "Epoch: [144][0/782]\tTime 0.257 (0.257)\tData 0.186 (0.186)\tLoss 1.0157 (1.0157)\tAcc@1 67.188 (67.188)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [144][100/782]\tTime 0.054 (0.055)\tData 0.001 (0.003)\tLoss 1.3541 (1.2261)\tAcc@1 67.188 (64.542)\tAcc@5 89.062 (90.548)\n",
            "Epoch: [144][200/782]\tTime 0.052 (0.054)\tData 0.001 (0.002)\tLoss 1.5507 (1.2562)\tAcc@1 56.250 (63.682)\tAcc@5 87.500 (90.236)\n",
            "Epoch: [144][300/782]\tTime 0.053 (0.054)\tData 0.002 (0.002)\tLoss 1.7008 (1.2574)\tAcc@1 46.875 (63.928)\tAcc@5 79.688 (90.116)\n",
            "Epoch: [144][400/782]\tTime 0.053 (0.054)\tData 0.002 (0.002)\tLoss 1.5134 (1.2601)\tAcc@1 54.688 (63.809)\tAcc@5 85.938 (90.087)\n",
            "Epoch: [144][500/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 1.4384 (1.2700)\tAcc@1 59.375 (63.457)\tAcc@5 85.938 (89.883)\n",
            "Epoch: [144][600/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.1599 (1.2813)\tAcc@1 64.062 (63.220)\tAcc@5 93.750 (89.790)\n",
            "Epoch: [144][700/782]\tTime 0.059 (0.053)\tData 0.001 (0.002)\tLoss 1.6041 (1.2917)\tAcc@1 59.375 (62.964)\tAcc@5 84.375 (89.600)\n",
            " * Acc@1 62.814 Acc@5 89.500\n",
            "epoch 144, total time 41.05\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 1.8083 (1.8083)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.2873 (1.6062)\tAcc@1 56.250 (56.312)\tAcc@5 100.000 (85.953)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.1874 (1.6089)\tAcc@1 65.625 (55.721)\tAcc@5 93.750 (85.479)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.9396 (1.6221)\tAcc@1 46.875 (55.554)\tAcc@5 87.500 (85.247)\n",
            " * Acc@1 55.600 Acc@5 85.170\n",
            "==> training...\n",
            "Epoch: [145][0/782]\tTime 0.284 (0.284)\tData 0.196 (0.196)\tLoss 1.0072 (1.0072)\tAcc@1 70.312 (70.312)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [145][100/782]\tTime 0.050 (0.057)\tData 0.001 (0.003)\tLoss 1.1880 (1.2430)\tAcc@1 64.062 (63.769)\tAcc@5 93.750 (90.331)\n",
            "Epoch: [145][200/782]\tTime 0.051 (0.055)\tData 0.001 (0.002)\tLoss 1.3281 (1.2536)\tAcc@1 60.938 (63.347)\tAcc@5 90.625 (90.291)\n",
            "Epoch: [145][300/782]\tTime 0.052 (0.055)\tData 0.001 (0.003)\tLoss 1.1257 (1.2632)\tAcc@1 65.625 (63.351)\tAcc@5 90.625 (90.038)\n",
            "Epoch: [145][400/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.0144 (1.2695)\tAcc@1 79.688 (63.318)\tAcc@5 90.625 (89.966)\n",
            "Epoch: [145][500/782]\tTime 0.056 (0.053)\tData 0.001 (0.002)\tLoss 1.1742 (1.2795)\tAcc@1 68.750 (63.202)\tAcc@5 92.188 (89.814)\n",
            "Epoch: [145][600/782]\tTime 0.055 (0.053)\tData 0.001 (0.002)\tLoss 1.1358 (1.2841)\tAcc@1 71.875 (63.004)\tAcc@5 92.188 (89.751)\n",
            "Epoch: [145][700/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.1522 (1.2901)\tAcc@1 53.125 (62.903)\tAcc@5 92.188 (89.651)\n",
            " * Acc@1 62.740 Acc@5 89.500\n",
            "epoch 145, total time 41.20\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 1.6399 (1.6399)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.0104 (1.7604)\tAcc@1 56.250 (53.001)\tAcc@5 78.125 (82.580)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.2652 (1.7623)\tAcc@1 68.750 (52.736)\tAcc@5 90.625 (82.727)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.9892 (1.7794)\tAcc@1 50.000 (52.616)\tAcc@5 75.000 (82.735)\n",
            " * Acc@1 52.710 Acc@5 82.770\n",
            "==> training...\n",
            "Epoch: [146][0/782]\tTime 0.275 (0.275)\tData 0.189 (0.189)\tLoss 1.4823 (1.4823)\tAcc@1 60.938 (60.938)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [146][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 1.2137 (1.2736)\tAcc@1 64.062 (63.707)\tAcc@5 95.312 (89.650)\n",
            "Epoch: [146][200/782]\tTime 0.052 (0.053)\tData 0.002 (0.002)\tLoss 1.3146 (1.2582)\tAcc@1 60.938 (64.125)\tAcc@5 90.625 (89.964)\n",
            "Epoch: [146][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3146 (1.2593)\tAcc@1 65.625 (64.062)\tAcc@5 82.812 (90.007)\n",
            "Epoch: [146][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.5579 (1.2667)\tAcc@1 59.375 (63.700)\tAcc@5 78.125 (89.924)\n",
            "Epoch: [146][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3063 (1.2759)\tAcc@1 70.312 (63.358)\tAcc@5 87.500 (89.730)\n",
            "Epoch: [146][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.5531 (1.2827)\tAcc@1 56.250 (63.111)\tAcc@5 90.625 (89.653)\n",
            "Epoch: [146][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.2609 (1.2917)\tAcc@1 68.750 (62.883)\tAcc@5 92.188 (89.493)\n",
            " * Acc@1 62.620 Acc@5 89.452\n",
            "epoch 146, total time 40.27\n",
            "Test: [0/313]\tTime 0.131 (0.131)\tLoss 2.0054 (2.0054)\tAcc@1 68.750 (68.750)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.5067 (1.6328)\tAcc@1 56.250 (56.467)\tAcc@5 90.625 (85.118)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.2715 (1.6086)\tAcc@1 71.875 (57.229)\tAcc@5 90.625 (85.152)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.8097 (1.6193)\tAcc@1 56.250 (57.143)\tAcc@5 78.125 (84.780)\n",
            " * Acc@1 57.120 Acc@5 84.760\n",
            "==> training...\n",
            "Epoch: [147][0/782]\tTime 0.266 (0.266)\tData 0.196 (0.196)\tLoss 1.3082 (1.3082)\tAcc@1 59.375 (59.375)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [147][100/782]\tTime 0.054 (0.053)\tData 0.001 (0.003)\tLoss 1.0539 (1.2317)\tAcc@1 67.188 (64.325)\tAcc@5 95.312 (90.486)\n",
            "Epoch: [147][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 1.3210 (1.2468)\tAcc@1 60.938 (63.985)\tAcc@5 90.625 (90.353)\n",
            "Epoch: [147][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.9809 (1.2765)\tAcc@1 65.625 (63.398)\tAcc@5 93.750 (89.852)\n",
            "Epoch: [147][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.4793 (1.2862)\tAcc@1 57.812 (63.131)\tAcc@5 89.062 (89.776)\n",
            "Epoch: [147][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.5154 (1.2945)\tAcc@1 56.250 (62.905)\tAcc@5 82.812 (89.636)\n",
            "Epoch: [147][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 1.4750 (1.2942)\tAcc@1 51.562 (62.981)\tAcc@5 92.188 (89.572)\n",
            "Epoch: [147][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 1.3039 (1.3020)\tAcc@1 57.812 (62.808)\tAcc@5 89.062 (89.461)\n",
            " * Acc@1 62.700 Acc@5 89.454\n",
            "epoch 147, total time 39.82\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 2.7394 (2.7394)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 2.1929 (1.6753)\tAcc@1 43.750 (56.002)\tAcc@5 75.000 (84.004)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.1569 (1.6641)\tAcc@1 71.875 (55.970)\tAcc@5 87.500 (83.955)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.6074 (1.6696)\tAcc@1 59.375 (55.887)\tAcc@5 87.500 (83.929)\n",
            " * Acc@1 55.930 Acc@5 84.010\n",
            "==> training...\n",
            "Epoch: [148][0/782]\tTime 0.265 (0.265)\tData 0.189 (0.189)\tLoss 1.3652 (1.3652)\tAcc@1 59.375 (59.375)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [148][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 1.3168 (1.2138)\tAcc@1 64.062 (65.006)\tAcc@5 89.062 (90.532)\n",
            "Epoch: [148][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.2609 (1.2324)\tAcc@1 62.500 (64.708)\tAcc@5 92.188 (90.353)\n",
            "Epoch: [148][300/782]\tTime 0.053 (0.052)\tData 0.002 (0.002)\tLoss 1.4879 (1.2456)\tAcc@1 57.812 (64.156)\tAcc@5 84.375 (90.127)\n",
            "Epoch: [148][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.3172 (1.2579)\tAcc@1 59.375 (63.934)\tAcc@5 84.375 (89.994)\n",
            "Epoch: [148][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1539 (1.2695)\tAcc@1 65.625 (63.679)\tAcc@5 90.625 (89.867)\n",
            "Epoch: [148][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4569 (1.2766)\tAcc@1 59.375 (63.462)\tAcc@5 82.812 (89.809)\n",
            "Epoch: [148][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.0119 (1.2845)\tAcc@1 73.438 (63.383)\tAcc@5 96.875 (89.613)\n",
            " * Acc@1 63.238 Acc@5 89.522\n",
            "epoch 148, total time 40.00\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.9378 (1.9378)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5601 (1.8301)\tAcc@1 62.500 (53.682)\tAcc@5 90.625 (82.611)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 1.2942 (1.8364)\tAcc@1 65.625 (53.094)\tAcc@5 90.625 (82.183)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 2.0685 (1.8295)\tAcc@1 46.875 (53.250)\tAcc@5 84.375 (82.216)\n",
            " * Acc@1 53.320 Acc@5 82.160\n",
            "==> training...\n",
            "Epoch: [149][0/782]\tTime 0.280 (0.280)\tData 0.195 (0.195)\tLoss 1.0505 (1.0505)\tAcc@1 70.312 (70.312)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [149][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 1.4528 (1.2484)\tAcc@1 56.250 (63.165)\tAcc@5 84.375 (90.532)\n",
            "Epoch: [149][200/782]\tTime 0.053 (0.053)\tData 0.001 (0.002)\tLoss 1.0862 (1.2681)\tAcc@1 68.750 (63.044)\tAcc@5 89.062 (90.034)\n",
            "Epoch: [149][300/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 1.2021 (1.2859)\tAcc@1 59.375 (62.531)\tAcc@5 93.750 (89.701)\n",
            "Epoch: [149][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.0840 (1.2938)\tAcc@1 67.188 (62.391)\tAcc@5 90.625 (89.581)\n",
            "Epoch: [149][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 1.1723 (1.2919)\tAcc@1 64.062 (62.537)\tAcc@5 92.188 (89.530)\n",
            "Epoch: [149][600/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 0.9164 (1.2897)\tAcc@1 68.750 (62.669)\tAcc@5 95.312 (89.562)\n",
            "Epoch: [149][700/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 1.3247 (1.2945)\tAcc@1 60.938 (62.649)\tAcc@5 89.062 (89.479)\n",
            " * Acc@1 62.504 Acc@5 89.456\n",
            "epoch 149, total time 40.32\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.7533 (1.7533)\tAcc@1 56.250 (56.250)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.019 (0.019)\tLoss 1.6944 (1.7332)\tAcc@1 46.875 (54.734)\tAcc@5 87.500 (82.426)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.4752 (1.7520)\tAcc@1 50.000 (54.213)\tAcc@5 84.375 (82.447)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.9630 (1.7503)\tAcc@1 40.625 (54.132)\tAcc@5 84.375 (82.569)\n",
            " * Acc@1 54.140 Acc@5 82.590\n",
            "==> training...\n",
            "Epoch: [150][0/782]\tTime 0.269 (0.269)\tData 0.194 (0.194)\tLoss 1.1235 (1.1235)\tAcc@1 68.750 (68.750)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [150][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 1.0222 (1.2564)\tAcc@1 68.750 (63.877)\tAcc@5 92.188 (89.681)\n",
            "Epoch: [150][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 1.1695 (1.2626)\tAcc@1 62.500 (63.798)\tAcc@5 93.750 (89.840)\n",
            "Epoch: [150][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.3180 (1.2660)\tAcc@1 59.375 (63.741)\tAcc@5 89.062 (89.691)\n",
            "Epoch: [150][400/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 1.2535 (1.2744)\tAcc@1 60.938 (63.459)\tAcc@5 87.500 (89.530)\n",
            "Epoch: [150][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.4258 (1.2845)\tAcc@1 60.938 (63.174)\tAcc@5 84.375 (89.527)\n",
            "Epoch: [150][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 1.1348 (1.2914)\tAcc@1 70.312 (62.986)\tAcc@5 93.750 (89.517)\n",
            "Epoch: [150][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.8230 (1.2946)\tAcc@1 78.125 (62.948)\tAcc@5 95.312 (89.448)\n",
            " * Acc@1 62.836 Acc@5 89.398\n",
            "epoch 150, total time 40.07\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 2.0358 (2.0358)\tAcc@1 59.375 (59.375)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.019 (0.019)\tLoss 2.2643 (1.9183)\tAcc@1 40.625 (51.269)\tAcc@5 78.125 (80.693)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 1.2865 (1.8668)\tAcc@1 68.750 (52.161)\tAcc@5 90.625 (81.483)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 2.1615 (1.8771)\tAcc@1 43.750 (52.108)\tAcc@5 78.125 (81.105)\n",
            " * Acc@1 52.080 Acc@5 81.050\n",
            "==> training...\n",
            "Epoch: [151][0/782]\tTime 0.289 (0.289)\tData 0.199 (0.199)\tLoss 1.5676 (1.5676)\tAcc@1 59.375 (59.375)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [151][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.9680 (1.0746)\tAcc@1 73.438 (69.090)\tAcc@5 93.750 (92.373)\n",
            "Epoch: [151][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.7234 (0.9940)\tAcc@1 85.938 (71.455)\tAcc@5 90.625 (93.151)\n",
            "Epoch: [151][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.7223 (0.9398)\tAcc@1 78.125 (72.789)\tAcc@5 98.438 (93.812)\n",
            "Epoch: [151][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.9756 (0.9082)\tAcc@1 70.312 (73.683)\tAcc@5 93.750 (94.159)\n",
            "Epoch: [151][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.8013 (0.8836)\tAcc@1 71.875 (74.301)\tAcc@5 98.438 (94.461)\n",
            "Epoch: [151][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.8313 (0.8647)\tAcc@1 78.125 (74.839)\tAcc@5 96.875 (94.629)\n",
            "Epoch: [151][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.6783 (0.8473)\tAcc@1 78.125 (75.310)\tAcc@5 96.875 (94.780)\n",
            " * Acc@1 75.470 Acc@5 94.826\n",
            "epoch 151, total time 40.15\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.5876 (1.5876)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 0.8705 (1.0098)\tAcc@1 71.875 (71.411)\tAcc@5 96.875 (92.358)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 0.6740 (0.9949)\tAcc@1 78.125 (71.611)\tAcc@5 96.875 (92.662)\n",
            "Test: [300/313]\tTime 0.017 (0.020)\tLoss 1.0053 (1.0046)\tAcc@1 75.000 (71.460)\tAcc@5 90.625 (92.639)\n",
            " * Acc@1 71.460 Acc@5 92.640\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [152][0/782]\tTime 0.289 (0.289)\tData 0.206 (0.206)\tLoss 0.6238 (0.6238)\tAcc@1 78.125 (78.125)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [152][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.6438 (0.7054)\tAcc@1 82.812 (78.775)\tAcc@5 98.438 (96.101)\n",
            "Epoch: [152][200/782]\tTime 0.048 (0.052)\tData 0.001 (0.002)\tLoss 0.5319 (0.7138)\tAcc@1 84.375 (78.669)\tAcc@5 96.875 (96.160)\n",
            "Epoch: [152][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.6230 (0.7181)\tAcc@1 78.125 (78.400)\tAcc@5 98.438 (96.086)\n",
            "Epoch: [152][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.7233 (0.7063)\tAcc@1 76.562 (78.752)\tAcc@5 96.875 (96.135)\n",
            "Epoch: [152][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.4570 (0.7034)\tAcc@1 90.625 (78.936)\tAcc@5 98.438 (96.161)\n",
            "Epoch: [152][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.8399 (0.6998)\tAcc@1 71.875 (79.001)\tAcc@5 95.312 (96.189)\n",
            "Epoch: [152][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.8732 (0.6978)\tAcc@1 78.125 (79.101)\tAcc@5 92.188 (96.229)\n",
            " * Acc@1 79.222 Acc@5 96.258\n",
            "epoch 152, total time 39.94\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.4160 (1.4160)\tAcc@1 68.750 (68.750)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.019 (0.019)\tLoss 0.7790 (1.0038)\tAcc@1 71.875 (72.463)\tAcc@5 96.875 (92.729)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 0.7418 (0.9986)\tAcc@1 75.000 (71.999)\tAcc@5 93.750 (92.739)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 0.9780 (1.0080)\tAcc@1 78.125 (71.771)\tAcc@5 93.750 (92.743)\n",
            " * Acc@1 71.850 Acc@5 92.790\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [153][0/782]\tTime 0.288 (0.288)\tData 0.201 (0.201)\tLoss 0.6476 (0.6476)\tAcc@1 76.562 (76.562)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [153][100/782]\tTime 0.051 (0.054)\tData 0.001 (0.003)\tLoss 0.7045 (0.6187)\tAcc@1 78.125 (81.204)\tAcc@5 96.875 (96.736)\n",
            "Epoch: [153][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.4727 (0.6182)\tAcc@1 85.938 (81.522)\tAcc@5 96.875 (96.883)\n",
            "Epoch: [153][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.6536 (0.6237)\tAcc@1 76.562 (81.297)\tAcc@5 100.000 (96.808)\n",
            "Epoch: [153][400/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.5868 (0.6319)\tAcc@1 84.375 (80.969)\tAcc@5 100.000 (96.700)\n",
            "Epoch: [153][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.6058 (0.6335)\tAcc@1 76.562 (80.926)\tAcc@5 95.312 (96.756)\n",
            "Epoch: [153][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.5541 (0.6356)\tAcc@1 84.375 (80.883)\tAcc@5 93.750 (96.729)\n",
            "Epoch: [153][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.8572 (0.6383)\tAcc@1 75.000 (80.809)\tAcc@5 93.750 (96.648)\n",
            " * Acc@1 80.766 Acc@5 96.688\n",
            "epoch 153, total time 39.98\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.3261 (1.3261)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 0.8965 (1.0118)\tAcc@1 65.625 (71.720)\tAcc@5 96.875 (92.853)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.7538 (0.9967)\tAcc@1 81.250 (71.999)\tAcc@5 100.000 (93.097)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.0062 (1.0031)\tAcc@1 68.750 (71.667)\tAcc@5 93.750 (93.013)\n",
            " * Acc@1 71.710 Acc@5 93.070\n",
            "==> training...\n",
            "Epoch: [154][0/782]\tTime 0.289 (0.289)\tData 0.198 (0.198)\tLoss 0.6900 (0.6900)\tAcc@1 78.125 (78.125)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [154][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.5559 (0.5884)\tAcc@1 82.812 (82.426)\tAcc@5 98.438 (97.463)\n",
            "Epoch: [154][200/782]\tTime 0.058 (0.052)\tData 0.001 (0.002)\tLoss 0.5928 (0.5914)\tAcc@1 78.125 (82.346)\tAcc@5 98.438 (97.341)\n",
            "Epoch: [154][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.4817 (0.5970)\tAcc@1 84.375 (82.075)\tAcc@5 98.438 (97.233)\n",
            "Epoch: [154][400/782]\tTime 0.071 (0.052)\tData 0.001 (0.002)\tLoss 0.5600 (0.6038)\tAcc@1 82.812 (81.760)\tAcc@5 95.312 (97.230)\n",
            "Epoch: [154][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.5832 (0.6010)\tAcc@1 81.250 (81.871)\tAcc@5 100.000 (97.240)\n",
            "Epoch: [154][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.7424 (0.5976)\tAcc@1 79.688 (81.942)\tAcc@5 95.312 (97.301)\n",
            "Epoch: [154][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.5274 (0.5972)\tAcc@1 82.812 (81.986)\tAcc@5 98.438 (97.312)\n",
            " * Acc@1 82.030 Acc@5 97.294\n",
            "epoch 154, total time 40.15\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.4133 (1.4133)\tAcc@1 75.000 (75.000)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 0.9011 (0.9863)\tAcc@1 65.625 (71.906)\tAcc@5 96.875 (93.255)\n",
            "Test: [200/313]\tTime 0.025 (0.019)\tLoss 0.7905 (0.9722)\tAcc@1 78.125 (72.264)\tAcc@5 96.875 (93.408)\n",
            "Test: [300/313]\tTime 0.024 (0.019)\tLoss 1.1335 (0.9734)\tAcc@1 71.875 (72.155)\tAcc@5 96.875 (93.439)\n",
            " * Acc@1 72.220 Acc@5 93.490\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [155][0/782]\tTime 0.297 (0.297)\tData 0.213 (0.213)\tLoss 0.7184 (0.7184)\tAcc@1 87.500 (87.500)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [155][100/782]\tTime 0.053 (0.055)\tData 0.001 (0.003)\tLoss 0.6562 (0.5379)\tAcc@1 81.250 (83.710)\tAcc@5 96.875 (97.649)\n",
            "Epoch: [155][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.4110 (0.5405)\tAcc@1 85.938 (83.738)\tAcc@5 96.875 (97.691)\n",
            "Epoch: [155][300/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.5056 (0.5493)\tAcc@1 84.375 (83.311)\tAcc@5 100.000 (97.602)\n",
            "Epoch: [155][400/782]\tTime 0.059 (0.052)\tData 0.002 (0.002)\tLoss 0.5841 (0.5527)\tAcc@1 85.938 (83.253)\tAcc@5 98.438 (97.534)\n",
            "Epoch: [155][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.5603 (0.5545)\tAcc@1 84.375 (83.115)\tAcc@5 95.312 (97.530)\n",
            "Epoch: [155][600/782]\tTime 0.055 (0.052)\tData 0.001 (0.002)\tLoss 0.6739 (0.5526)\tAcc@1 78.125 (83.096)\tAcc@5 96.875 (97.522)\n",
            "Epoch: [155][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.5220 (0.5561)\tAcc@1 84.375 (83.024)\tAcc@5 98.438 (97.517)\n",
            " * Acc@1 82.960 Acc@5 97.478\n",
            "epoch 155, total time 40.26\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.3891 (1.3891)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.021)\tLoss 0.9832 (1.0014)\tAcc@1 68.750 (73.020)\tAcc@5 96.875 (92.884)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 0.5450 (0.9823)\tAcc@1 81.250 (72.901)\tAcc@5 96.875 (93.315)\n",
            "Test: [300/313]\tTime 0.018 (0.020)\tLoss 1.1459 (0.9842)\tAcc@1 68.750 (72.664)\tAcc@5 93.750 (93.376)\n",
            " * Acc@1 72.660 Acc@5 93.410\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [156][0/782]\tTime 0.278 (0.278)\tData 0.198 (0.198)\tLoss 0.5723 (0.5723)\tAcc@1 81.250 (81.250)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [156][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.6000 (0.4958)\tAcc@1 79.688 (85.412)\tAcc@5 96.875 (98.283)\n",
            "Epoch: [156][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.5283 (0.5043)\tAcc@1 85.938 (85.012)\tAcc@5 100.000 (98.064)\n",
            "Epoch: [156][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.7413 (0.5113)\tAcc@1 84.375 (84.707)\tAcc@5 95.312 (97.965)\n",
            "Epoch: [156][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.7283 (0.5156)\tAcc@1 79.688 (84.492)\tAcc@5 95.312 (97.919)\n",
            "Epoch: [156][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.6423 (0.5194)\tAcc@1 76.562 (84.328)\tAcc@5 98.438 (97.889)\n",
            "Epoch: [156][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.5601 (0.5235)\tAcc@1 82.812 (84.229)\tAcc@5 100.000 (97.860)\n",
            "Epoch: [156][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.4755 (0.5260)\tAcc@1 87.500 (84.103)\tAcc@5 98.438 (97.798)\n",
            " * Acc@1 84.030 Acc@5 97.814\n",
            "epoch 156, total time 39.92\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.2647 (1.2647)\tAcc@1 71.875 (71.875)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 0.9473 (1.0171)\tAcc@1 71.875 (72.710)\tAcc@5 96.875 (93.007)\n",
            "Test: [200/313]\tTime 0.022 (0.019)\tLoss 0.6337 (0.9923)\tAcc@1 81.250 (72.901)\tAcc@5 100.000 (93.237)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.0119 (1.0044)\tAcc@1 75.000 (72.560)\tAcc@5 100.000 (93.262)\n",
            " * Acc@1 72.650 Acc@5 93.300\n",
            "==> training...\n",
            "Epoch: [157][0/782]\tTime 0.272 (0.272)\tData 0.197 (0.197)\tLoss 0.4699 (0.4699)\tAcc@1 89.062 (89.062)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [157][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.6634 (0.4914)\tAcc@1 73.438 (84.576)\tAcc@5 100.000 (97.989)\n",
            "Epoch: [157][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.5019 (0.4919)\tAcc@1 81.250 (84.694)\tAcc@5 98.438 (98.033)\n",
            "Epoch: [157][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.5380 (0.4959)\tAcc@1 82.812 (84.603)\tAcc@5 96.875 (97.944)\n",
            "Epoch: [157][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.4498 (0.4983)\tAcc@1 85.938 (84.585)\tAcc@5 98.438 (97.970)\n",
            "Epoch: [157][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.5306 (0.5010)\tAcc@1 84.375 (84.581)\tAcc@5 98.438 (97.942)\n",
            "Epoch: [157][600/782]\tTime 0.058 (0.051)\tData 0.001 (0.002)\tLoss 0.4957 (0.5021)\tAcc@1 85.938 (84.583)\tAcc@5 96.875 (97.936)\n",
            "Epoch: [157][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.6119 (0.5019)\tAcc@1 82.812 (84.571)\tAcc@5 95.312 (97.909)\n",
            " * Acc@1 84.498 Acc@5 97.916\n",
            "epoch 157, total time 40.19\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.2018 (1.2018)\tAcc@1 75.000 (75.000)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 0.8867 (1.0310)\tAcc@1 68.750 (72.246)\tAcc@5 96.875 (92.481)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.7232 (1.0060)\tAcc@1 75.000 (72.077)\tAcc@5 100.000 (92.926)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 0.9702 (1.0074)\tAcc@1 78.125 (72.083)\tAcc@5 100.000 (93.065)\n",
            " * Acc@1 72.150 Acc@5 93.110\n",
            "==> training...\n",
            "Epoch: [158][0/782]\tTime 0.283 (0.283)\tData 0.198 (0.198)\tLoss 0.4319 (0.4319)\tAcc@1 84.375 (84.375)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [158][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 0.6040 (0.4458)\tAcc@1 81.250 (86.402)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [158][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.4253 (0.4597)\tAcc@1 87.500 (86.186)\tAcc@5 96.875 (98.220)\n",
            "Epoch: [158][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.3384 (0.4636)\tAcc@1 89.062 (85.917)\tAcc@5 98.438 (98.178)\n",
            "Epoch: [158][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.5099 (0.4669)\tAcc@1 84.375 (85.739)\tAcc@5 98.438 (98.200)\n",
            "Epoch: [158][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3122 (0.4706)\tAcc@1 92.188 (85.563)\tAcc@5 98.438 (98.176)\n",
            "Epoch: [158][600/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.4977 (0.4795)\tAcc@1 84.375 (85.256)\tAcc@5 98.438 (98.102)\n",
            "Epoch: [158][700/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.5026 (0.4828)\tAcc@1 84.375 (85.160)\tAcc@5 95.312 (98.114)\n",
            " * Acc@1 85.114 Acc@5 98.100\n",
            "epoch 158, total time 40.33\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.1850 (1.1850)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 0.9001 (1.0336)\tAcc@1 75.000 (72.741)\tAcc@5 96.875 (93.038)\n",
            "Test: [200/313]\tTime 0.019 (0.018)\tLoss 0.6317 (1.0044)\tAcc@1 84.375 (72.715)\tAcc@5 100.000 (93.361)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.2432 (1.0171)\tAcc@1 75.000 (72.384)\tAcc@5 96.875 (93.210)\n",
            " * Acc@1 72.480 Acc@5 93.250\n",
            "==> training...\n",
            "Epoch: [159][0/782]\tTime 0.276 (0.276)\tData 0.200 (0.200)\tLoss 0.3591 (0.3591)\tAcc@1 85.938 (85.938)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [159][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.4517 (0.4363)\tAcc@1 85.938 (86.665)\tAcc@5 98.438 (98.314)\n",
            "Epoch: [159][200/782]\tTime 0.068 (0.053)\tData 0.002 (0.002)\tLoss 0.5560 (0.4372)\tAcc@1 81.250 (86.536)\tAcc@5 98.438 (98.554)\n",
            "Epoch: [159][300/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.4859 (0.4445)\tAcc@1 84.375 (86.187)\tAcc@5 95.312 (98.443)\n",
            "Epoch: [159][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.4312 (0.4514)\tAcc@1 85.938 (86.000)\tAcc@5 100.000 (98.360)\n",
            "Epoch: [159][500/782]\tTime 0.057 (0.052)\tData 0.001 (0.002)\tLoss 0.4933 (0.4588)\tAcc@1 82.812 (85.744)\tAcc@5 96.875 (98.331)\n",
            "Epoch: [159][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.3895 (0.4589)\tAcc@1 85.938 (85.704)\tAcc@5 98.438 (98.334)\n",
            "Epoch: [159][700/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.3785 (0.4634)\tAcc@1 84.375 (85.539)\tAcc@5 100.000 (98.293)\n",
            " * Acc@1 85.456 Acc@5 98.274\n",
            "epoch 159, total time 40.37\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.4975 (1.4975)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.2134 (1.0587)\tAcc@1 71.875 (72.030)\tAcc@5 90.625 (92.543)\n",
            "Test: [200/313]\tTime 0.024 (0.019)\tLoss 0.8058 (1.0352)\tAcc@1 81.250 (72.248)\tAcc@5 96.875 (92.957)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.0163 (1.0432)\tAcc@1 75.000 (72.155)\tAcc@5 93.750 (92.919)\n",
            " * Acc@1 72.200 Acc@5 92.940\n",
            "==> training...\n",
            "Epoch: [160][0/782]\tTime 0.273 (0.273)\tData 0.198 (0.198)\tLoss 0.4412 (0.4412)\tAcc@1 82.812 (82.812)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [160][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 0.5226 (0.4144)\tAcc@1 81.250 (87.283)\tAcc@5 98.438 (98.731)\n",
            "Epoch: [160][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.4355 (0.4185)\tAcc@1 89.062 (86.964)\tAcc@5 96.875 (98.554)\n",
            "Epoch: [160][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.4967 (0.4260)\tAcc@1 84.375 (86.789)\tAcc@5 96.875 (98.500)\n",
            "Epoch: [160][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.6348 (0.4337)\tAcc@1 78.125 (86.475)\tAcc@5 98.438 (98.383)\n",
            "Epoch: [160][500/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 0.3677 (0.4410)\tAcc@1 89.062 (86.240)\tAcc@5 98.438 (98.341)\n",
            "Epoch: [160][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.4023 (0.4428)\tAcc@1 85.938 (86.164)\tAcc@5 98.438 (98.383)\n",
            "Epoch: [160][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.4972 (0.4451)\tAcc@1 87.500 (86.158)\tAcc@5 98.438 (98.400)\n",
            " * Acc@1 86.040 Acc@5 98.394\n",
            "epoch 160, total time 39.98\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.4865 (1.4865)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.0373 (1.0687)\tAcc@1 68.750 (72.587)\tAcc@5 96.875 (92.915)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 0.5672 (1.0404)\tAcc@1 87.500 (72.590)\tAcc@5 100.000 (93.237)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1941 (1.0538)\tAcc@1 78.125 (72.508)\tAcc@5 100.000 (92.992)\n",
            " * Acc@1 72.590 Acc@5 93.020\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [161][0/782]\tTime 0.259 (0.259)\tData 0.190 (0.190)\tLoss 0.4993 (0.4993)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [161][100/782]\tTime 0.053 (0.054)\tData 0.001 (0.003)\tLoss 0.5651 (0.4232)\tAcc@1 82.812 (86.788)\tAcc@5 98.438 (98.747)\n",
            "Epoch: [161][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.2665 (0.4150)\tAcc@1 92.188 (87.072)\tAcc@5 100.000 (98.826)\n",
            "Epoch: [161][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.3764 (0.4174)\tAcc@1 92.188 (87.105)\tAcc@5 100.000 (98.744)\n",
            "Epoch: [161][400/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.3559 (0.4164)\tAcc@1 89.062 (87.208)\tAcc@5 100.000 (98.695)\n",
            "Epoch: [161][500/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.4560 (0.4187)\tAcc@1 89.062 (87.138)\tAcc@5 100.000 (98.650)\n",
            "Epoch: [161][600/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.2890 (0.4225)\tAcc@1 92.188 (87.027)\tAcc@5 100.000 (98.632)\n",
            "Epoch: [161][700/782]\tTime 0.057 (0.052)\tData 0.001 (0.002)\tLoss 0.5767 (0.4305)\tAcc@1 81.250 (86.760)\tAcc@5 95.312 (98.594)\n",
            " * Acc@1 86.720 Acc@5 98.592\n",
            "epoch 161, total time 40.46\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.4285 (1.4285)\tAcc@1 78.125 (78.125)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.1514 (1.0837)\tAcc@1 65.625 (72.246)\tAcc@5 96.875 (92.110)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.8840 (1.0654)\tAcc@1 75.000 (72.062)\tAcc@5 93.750 (92.631)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1851 (1.0697)\tAcc@1 59.375 (71.813)\tAcc@5 100.000 (92.691)\n",
            " * Acc@1 71.910 Acc@5 92.760\n",
            "==> training...\n",
            "Epoch: [162][0/782]\tTime 0.262 (0.262)\tData 0.188 (0.188)\tLoss 0.4799 (0.4799)\tAcc@1 82.812 (82.812)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [162][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.2872 (0.3948)\tAcc@1 93.750 (88.274)\tAcc@5 98.438 (98.716)\n",
            "Epoch: [162][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.3351 (0.4124)\tAcc@1 92.188 (87.663)\tAcc@5 98.438 (98.577)\n",
            "Epoch: [162][300/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.3734 (0.4096)\tAcc@1 89.062 (87.505)\tAcc@5 100.000 (98.692)\n",
            "Epoch: [162][400/782]\tTime 0.060 (0.052)\tData 0.001 (0.002)\tLoss 0.6719 (0.4098)\tAcc@1 81.250 (87.465)\tAcc@5 98.438 (98.640)\n",
            "Epoch: [162][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.6700 (0.4121)\tAcc@1 82.812 (87.319)\tAcc@5 96.875 (98.640)\n",
            "Epoch: [162][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.7137 (0.4184)\tAcc@1 79.688 (87.146)\tAcc@5 95.312 (98.606)\n",
            "Epoch: [162][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.5413 (0.4211)\tAcc@1 82.812 (87.056)\tAcc@5 96.875 (98.602)\n",
            " * Acc@1 87.052 Acc@5 98.624\n",
            "epoch 162, total time 40.03\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 1.3481 (1.3481)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 0.9032 (1.1099)\tAcc@1 68.750 (71.163)\tAcc@5 96.875 (92.358)\n",
            "Test: [200/313]\tTime 0.019 (0.018)\tLoss 0.8917 (1.1038)\tAcc@1 75.000 (71.113)\tAcc@5 96.875 (92.662)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2596 (1.1208)\tAcc@1 65.625 (70.868)\tAcc@5 93.750 (92.400)\n",
            " * Acc@1 71.020 Acc@5 92.500\n",
            "==> training...\n",
            "Epoch: [163][0/782]\tTime 0.285 (0.285)\tData 0.202 (0.202)\tLoss 0.3133 (0.3133)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [163][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 0.2169 (0.3701)\tAcc@1 90.625 (88.567)\tAcc@5 100.000 (98.933)\n",
            "Epoch: [163][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 0.3635 (0.3871)\tAcc@1 90.625 (87.920)\tAcc@5 96.875 (98.974)\n",
            "Epoch: [163][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.4445 (0.3938)\tAcc@1 85.938 (87.739)\tAcc@5 98.438 (98.879)\n",
            "Epoch: [163][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.3014 (0.3978)\tAcc@1 90.625 (87.671)\tAcc@5 98.438 (98.815)\n",
            "Epoch: [163][500/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 0.3003 (0.4030)\tAcc@1 92.188 (87.516)\tAcc@5 100.000 (98.768)\n",
            "Epoch: [163][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.3154 (0.4064)\tAcc@1 89.062 (87.370)\tAcc@5 100.000 (98.744)\n",
            "Epoch: [163][700/782]\tTime 0.055 (0.052)\tData 0.002 (0.002)\tLoss 0.4585 (0.4069)\tAcc@1 82.812 (87.324)\tAcc@5 100.000 (98.754)\n",
            " * Acc@1 87.136 Acc@5 98.746\n",
            "epoch 163, total time 40.53\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.4306 (1.4306)\tAcc@1 62.500 (62.500)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.0099 (1.1078)\tAcc@1 71.875 (71.658)\tAcc@5 96.875 (92.822)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.6593 (1.0866)\tAcc@1 84.375 (71.813)\tAcc@5 93.750 (92.988)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.5071 (1.0882)\tAcc@1 65.625 (71.792)\tAcc@5 90.625 (92.930)\n",
            " * Acc@1 71.870 Acc@5 93.000\n",
            "==> training...\n",
            "Epoch: [164][0/782]\tTime 0.286 (0.286)\tData 0.204 (0.204)\tLoss 0.2875 (0.2875)\tAcc@1 92.188 (92.188)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [164][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.3845 (0.3805)\tAcc@1 85.938 (88.041)\tAcc@5 100.000 (98.840)\n",
            "Epoch: [164][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.7995 (0.3917)\tAcc@1 75.000 (87.826)\tAcc@5 93.750 (98.780)\n",
            "Epoch: [164][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.6811 (0.3943)\tAcc@1 76.562 (87.671)\tAcc@5 98.438 (98.837)\n",
            "Epoch: [164][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.3487 (0.3942)\tAcc@1 87.500 (87.718)\tAcc@5 98.438 (98.901)\n",
            "Epoch: [164][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.4654 (0.3977)\tAcc@1 84.375 (87.578)\tAcc@5 98.438 (98.846)\n",
            "Epoch: [164][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.5050 (0.3991)\tAcc@1 85.938 (87.510)\tAcc@5 98.438 (98.853)\n",
            "Epoch: [164][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.5573 (0.4020)\tAcc@1 84.375 (87.380)\tAcc@5 98.438 (98.803)\n",
            " * Acc@1 87.216 Acc@5 98.758\n",
            "epoch 164, total time 39.84\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.4603 (1.4603)\tAcc@1 75.000 (75.000)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.1943 (1.1271)\tAcc@1 71.875 (71.318)\tAcc@5 96.875 (92.265)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.6698 (1.1121)\tAcc@1 81.250 (71.642)\tAcc@5 96.875 (92.444)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 0.8842 (1.1167)\tAcc@1 78.125 (71.491)\tAcc@5 96.875 (92.411)\n",
            " * Acc@1 71.470 Acc@5 92.480\n",
            "==> training...\n",
            "Epoch: [165][0/782]\tTime 0.269 (0.269)\tData 0.185 (0.185)\tLoss 0.2220 (0.2220)\tAcc@1 90.625 (90.625)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [165][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 0.3760 (0.3625)\tAcc@1 85.938 (88.629)\tAcc@5 98.438 (99.134)\n",
            "Epoch: [165][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.3394 (0.3575)\tAcc@1 92.188 (88.822)\tAcc@5 98.438 (99.137)\n",
            "Epoch: [165][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.3041 (0.3631)\tAcc@1 95.312 (88.543)\tAcc@5 96.875 (99.102)\n",
            "Epoch: [165][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.5831 (0.3679)\tAcc@1 85.938 (88.498)\tAcc@5 96.875 (99.049)\n",
            "Epoch: [165][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.4451 (0.3804)\tAcc@1 87.500 (88.195)\tAcc@5 100.000 (98.946)\n",
            "Epoch: [165][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.3390 (0.3851)\tAcc@1 92.188 (88.030)\tAcc@5 100.000 (98.931)\n",
            "Epoch: [165][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.4017 (0.3892)\tAcc@1 87.500 (87.917)\tAcc@5 98.438 (98.910)\n",
            " * Acc@1 87.814 Acc@5 98.860\n",
            "epoch 165, total time 39.75\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.3932 (1.3932)\tAcc@1 68.750 (68.750)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.2929 (1.1441)\tAcc@1 68.750 (70.885)\tAcc@5 96.875 (92.389)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.6168 (1.1118)\tAcc@1 84.375 (71.549)\tAcc@5 93.750 (92.677)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.3597 (1.1147)\tAcc@1 65.625 (71.595)\tAcc@5 90.625 (92.556)\n",
            " * Acc@1 71.650 Acc@5 92.570\n",
            "==> training...\n",
            "Epoch: [166][0/782]\tTime 0.284 (0.284)\tData 0.192 (0.192)\tLoss 0.4703 (0.4703)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [166][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.2994 (0.3596)\tAcc@1 87.500 (88.629)\tAcc@5 100.000 (99.196)\n",
            "Epoch: [166][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.4485 (0.3598)\tAcc@1 84.375 (88.689)\tAcc@5 100.000 (99.145)\n",
            "Epoch: [166][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.3865 (0.3623)\tAcc@1 89.062 (88.647)\tAcc@5 100.000 (99.102)\n",
            "Epoch: [166][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.3947 (0.3692)\tAcc@1 87.500 (88.513)\tAcc@5 100.000 (99.084)\n",
            "Epoch: [166][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.2832 (0.3771)\tAcc@1 92.188 (88.183)\tAcc@5 100.000 (99.080)\n",
            "Epoch: [166][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.2446 (0.3803)\tAcc@1 92.188 (88.049)\tAcc@5 100.000 (99.046)\n",
            "Epoch: [166][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3165 (0.3869)\tAcc@1 92.188 (87.788)\tAcc@5 98.438 (98.988)\n",
            " * Acc@1 87.736 Acc@5 98.946\n",
            "epoch 166, total time 40.00\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.8157 (1.8157)\tAcc@1 71.875 (71.875)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.1566 (1.1749)\tAcc@1 75.000 (71.225)\tAcc@5 96.875 (91.368)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.6158 (1.1408)\tAcc@1 84.375 (71.440)\tAcc@5 96.875 (91.760)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 0.9678 (1.1514)\tAcc@1 75.000 (71.314)\tAcc@5 96.875 (91.819)\n",
            " * Acc@1 71.400 Acc@5 91.900\n",
            "==> training...\n",
            "Epoch: [167][0/782]\tTime 0.270 (0.270)\tData 0.199 (0.199)\tLoss 0.1766 (0.1766)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [167][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.3100 (0.3440)\tAcc@1 85.938 (89.264)\tAcc@5 100.000 (99.149)\n",
            "Epoch: [167][200/782]\tTime 0.057 (0.052)\tData 0.001 (0.002)\tLoss 0.3467 (0.3524)\tAcc@1 90.625 (88.969)\tAcc@5 98.438 (99.145)\n",
            "Epoch: [167][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.4865 (0.3658)\tAcc@1 87.500 (88.611)\tAcc@5 95.312 (99.040)\n",
            "Epoch: [167][400/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.4431 (0.3723)\tAcc@1 82.812 (88.455)\tAcc@5 100.000 (98.983)\n",
            "Epoch: [167][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.6078 (0.3745)\tAcc@1 81.250 (88.255)\tAcc@5 100.000 (99.030)\n",
            "Epoch: [167][600/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.3157 (0.3799)\tAcc@1 92.188 (88.160)\tAcc@5 98.438 (98.976)\n",
            "Epoch: [167][700/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.3525 (0.3844)\tAcc@1 87.500 (87.995)\tAcc@5 100.000 (98.966)\n",
            " * Acc@1 87.764 Acc@5 98.942\n",
            "epoch 167, total time 40.64\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.3880 (1.3880)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.3356 (1.1538)\tAcc@1 65.625 (71.256)\tAcc@5 93.750 (92.450)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.8525 (1.1417)\tAcc@1 78.125 (71.346)\tAcc@5 96.875 (92.304)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.4067 (1.1526)\tAcc@1 59.375 (71.065)\tAcc@5 90.625 (92.172)\n",
            " * Acc@1 71.140 Acc@5 92.220\n",
            "==> training...\n",
            "Epoch: [168][0/782]\tTime 0.278 (0.278)\tData 0.194 (0.194)\tLoss 0.3572 (0.3572)\tAcc@1 90.625 (90.625)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [168][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.3102 (0.3350)\tAcc@1 92.188 (89.790)\tAcc@5 98.438 (99.226)\n",
            "Epoch: [168][200/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3345 (0.3489)\tAcc@1 90.625 (89.303)\tAcc@5 96.875 (99.153)\n",
            "Epoch: [168][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.4337 (0.3565)\tAcc@1 85.938 (88.995)\tAcc@5 100.000 (99.123)\n",
            "Epoch: [168][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3042 (0.3662)\tAcc@1 90.625 (88.540)\tAcc@5 98.438 (99.092)\n",
            "Epoch: [168][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.4246 (0.3715)\tAcc@1 85.938 (88.317)\tAcc@5 100.000 (99.108)\n",
            "Epoch: [168][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.4627 (0.3780)\tAcc@1 85.938 (88.147)\tAcc@5 100.000 (99.030)\n",
            "Epoch: [168][700/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 0.4246 (0.3792)\tAcc@1 85.938 (88.086)\tAcc@5 98.438 (99.013)\n",
            " * Acc@1 87.970 Acc@5 99.000\n",
            "epoch 168, total time 39.77\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.4284 (1.4284)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.2729 (1.1931)\tAcc@1 65.625 (70.575)\tAcc@5 96.875 (91.955)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.9092 (1.1695)\tAcc@1 78.125 (70.771)\tAcc@5 96.875 (92.211)\n",
            "Test: [300/313]\tTime 0.025 (0.019)\tLoss 1.4450 (1.1794)\tAcc@1 62.500 (70.795)\tAcc@5 90.625 (92.203)\n",
            " * Acc@1 70.790 Acc@5 92.230\n",
            "==> training...\n",
            "Epoch: [169][0/782]\tTime 0.266 (0.266)\tData 0.181 (0.181)\tLoss 0.4938 (0.4938)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [169][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.4647 (0.3638)\tAcc@1 87.500 (88.939)\tAcc@5 98.438 (99.226)\n",
            "Epoch: [169][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.3065 (0.3651)\tAcc@1 92.188 (88.938)\tAcc@5 96.875 (99.137)\n",
            "Epoch: [169][300/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.3017 (0.3656)\tAcc@1 92.188 (88.746)\tAcc@5 98.438 (99.112)\n",
            "Epoch: [169][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.3433 (0.3709)\tAcc@1 85.938 (88.595)\tAcc@5 100.000 (99.049)\n",
            "Epoch: [169][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.2621 (0.3727)\tAcc@1 92.188 (88.510)\tAcc@5 100.000 (99.027)\n",
            "Epoch: [169][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3020 (0.3762)\tAcc@1 93.750 (88.350)\tAcc@5 98.438 (98.981)\n",
            "Epoch: [169][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.3183 (0.3801)\tAcc@1 89.062 (88.171)\tAcc@5 100.000 (98.966)\n",
            " * Acc@1 88.012 Acc@5 98.952\n",
            "epoch 169, total time 39.71\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 1.4013 (1.4013)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.4162 (1.2216)\tAcc@1 65.625 (70.328)\tAcc@5 90.625 (91.491)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.9445 (1.1844)\tAcc@1 78.125 (70.678)\tAcc@5 96.875 (91.807)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2027 (1.1976)\tAcc@1 68.750 (70.390)\tAcc@5 93.750 (91.736)\n",
            " * Acc@1 70.380 Acc@5 91.770\n",
            "==> training...\n",
            "Epoch: [170][0/782]\tTime 0.269 (0.269)\tData 0.186 (0.186)\tLoss 0.3140 (0.3140)\tAcc@1 85.938 (85.938)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [170][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 0.3103 (0.3388)\tAcc@1 87.500 (89.279)\tAcc@5 98.438 (99.319)\n",
            "Epoch: [170][200/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.4121 (0.3498)\tAcc@1 89.062 (88.938)\tAcc@5 98.438 (99.300)\n",
            "Epoch: [170][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.2880 (0.3529)\tAcc@1 93.750 (88.803)\tAcc@5 100.000 (99.263)\n",
            "Epoch: [170][400/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 0.3397 (0.3514)\tAcc@1 92.188 (88.727)\tAcc@5 98.438 (99.228)\n",
            "Epoch: [170][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3735 (0.3583)\tAcc@1 87.500 (88.604)\tAcc@5 100.000 (99.170)\n",
            "Epoch: [170][600/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 0.2840 (0.3610)\tAcc@1 93.750 (88.545)\tAcc@5 100.000 (99.132)\n",
            "Epoch: [170][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.4417 (0.3672)\tAcc@1 81.250 (88.401)\tAcc@5 98.438 (99.086)\n",
            " * Acc@1 88.180 Acc@5 99.062\n",
            "epoch 170, total time 39.95\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.3792 (1.3792)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.1063 (1.1897)\tAcc@1 71.875 (70.142)\tAcc@5 90.625 (91.553)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.9278 (1.1780)\tAcc@1 75.000 (70.460)\tAcc@5 93.750 (91.713)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.4832 (1.1730)\tAcc@1 59.375 (70.401)\tAcc@5 90.625 (91.809)\n",
            " * Acc@1 70.500 Acc@5 91.850\n",
            "==> training...\n",
            "Epoch: [171][0/782]\tTime 0.281 (0.281)\tData 0.200 (0.200)\tLoss 0.4813 (0.4813)\tAcc@1 87.500 (87.500)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [171][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.2303 (0.3628)\tAcc@1 93.750 (88.583)\tAcc@5 100.000 (99.242)\n",
            "Epoch: [171][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.2254 (0.3500)\tAcc@1 90.625 (88.993)\tAcc@5 100.000 (99.262)\n",
            "Epoch: [171][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.4098 (0.3468)\tAcc@1 85.938 (89.135)\tAcc@5 98.438 (99.237)\n",
            "Epoch: [171][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.5731 (0.3528)\tAcc@1 85.938 (88.817)\tAcc@5 98.438 (99.232)\n",
            "Epoch: [171][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.3833 (0.3593)\tAcc@1 89.062 (88.567)\tAcc@5 98.438 (99.192)\n",
            "Epoch: [171][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.2608 (0.3675)\tAcc@1 90.625 (88.384)\tAcc@5 100.000 (99.121)\n",
            "Epoch: [171][700/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 0.3756 (0.3736)\tAcc@1 90.625 (88.200)\tAcc@5 98.438 (99.066)\n",
            " * Acc@1 88.092 Acc@5 99.062\n",
            "epoch 171, total time 40.14\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.4374 (1.4374)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.3427 (1.2469)\tAcc@1 65.625 (70.204)\tAcc@5 93.750 (91.089)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.9231 (1.2132)\tAcc@1 81.250 (70.336)\tAcc@5 93.750 (91.667)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.5206 (1.2122)\tAcc@1 59.375 (70.152)\tAcc@5 90.625 (91.684)\n",
            " * Acc@1 70.240 Acc@5 91.740\n",
            "==> training...\n",
            "Epoch: [172][0/782]\tTime 0.274 (0.274)\tData 0.204 (0.204)\tLoss 0.3631 (0.3631)\tAcc@1 90.625 (90.625)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [172][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.3158 (0.3509)\tAcc@1 90.625 (89.248)\tAcc@5 98.438 (99.196)\n",
            "Epoch: [172][200/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.2136 (0.3492)\tAcc@1 92.188 (89.086)\tAcc@5 100.000 (99.176)\n",
            "Epoch: [172][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.4357 (0.3495)\tAcc@1 85.938 (89.182)\tAcc@5 100.000 (99.211)\n",
            "Epoch: [172][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.5244 (0.3523)\tAcc@1 76.562 (89.117)\tAcc@5 98.438 (99.186)\n",
            "Epoch: [172][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3356 (0.3560)\tAcc@1 90.625 (88.894)\tAcc@5 100.000 (99.167)\n",
            "Epoch: [172][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.3842 (0.3603)\tAcc@1 87.500 (88.709)\tAcc@5 100.000 (99.145)\n",
            "Epoch: [172][700/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.6251 (0.3645)\tAcc@1 84.375 (88.541)\tAcc@5 96.875 (99.104)\n",
            " * Acc@1 88.416 Acc@5 99.088\n",
            "epoch 172, total time 40.07\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.5162 (1.5162)\tAcc@1 71.875 (71.875)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.3081 (1.2054)\tAcc@1 68.750 (70.761)\tAcc@5 96.875 (91.522)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 1.1896 (1.2133)\tAcc@1 75.000 (70.180)\tAcc@5 93.750 (91.573)\n",
            "Test: [300/313]\tTime 0.025 (0.020)\tLoss 1.4914 (1.2345)\tAcc@1 56.250 (69.861)\tAcc@5 93.750 (91.424)\n",
            " * Acc@1 69.870 Acc@5 91.490\n",
            "==> training...\n",
            "Epoch: [173][0/782]\tTime 0.280 (0.280)\tData 0.204 (0.204)\tLoss 0.2472 (0.2472)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [173][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.3596 (0.3518)\tAcc@1 85.938 (89.171)\tAcc@5 100.000 (99.211)\n",
            "Epoch: [173][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.3440 (0.3432)\tAcc@1 89.062 (89.319)\tAcc@5 98.438 (99.246)\n",
            "Epoch: [173][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.4076 (0.3524)\tAcc@1 92.188 (89.099)\tAcc@5 100.000 (99.195)\n",
            "Epoch: [173][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.5651 (0.3541)\tAcc@1 82.812 (89.066)\tAcc@5 100.000 (99.190)\n",
            "Epoch: [173][500/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.4378 (0.3570)\tAcc@1 82.812 (88.928)\tAcc@5 100.000 (99.174)\n",
            "Epoch: [173][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.6170 (0.3631)\tAcc@1 79.688 (88.706)\tAcc@5 98.438 (99.147)\n",
            "Epoch: [173][700/782]\tTime 0.072 (0.051)\tData 0.002 (0.002)\tLoss 0.4504 (0.3672)\tAcc@1 81.250 (88.597)\tAcc@5 100.000 (99.111)\n",
            " * Acc@1 88.488 Acc@5 99.114\n",
            "epoch 173, total time 40.13\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.7574 (1.7574)\tAcc@1 68.750 (68.750)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 0.9936 (1.2633)\tAcc@1 75.000 (70.390)\tAcc@5 96.875 (91.337)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.9708 (1.2559)\tAcc@1 78.125 (69.947)\tAcc@5 90.625 (91.325)\n",
            "Test: [300/313]\tTime 0.017 (0.017)\tLoss 1.4966 (1.2627)\tAcc@1 59.375 (69.695)\tAcc@5 90.625 (91.424)\n",
            " * Acc@1 69.750 Acc@5 91.470\n",
            "==> training...\n",
            "Epoch: [174][0/782]\tTime 0.286 (0.286)\tData 0.197 (0.197)\tLoss 0.3165 (0.3165)\tAcc@1 89.062 (89.062)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [174][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.1397 (0.3391)\tAcc@1 96.875 (89.217)\tAcc@5 100.000 (99.350)\n",
            "Epoch: [174][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.3515 (0.3440)\tAcc@1 89.062 (89.210)\tAcc@5 98.438 (99.254)\n",
            "Epoch: [174][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.3476 (0.3435)\tAcc@1 87.500 (89.244)\tAcc@5 100.000 (99.201)\n",
            "Epoch: [174][400/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 0.3365 (0.3456)\tAcc@1 89.062 (89.160)\tAcc@5 98.438 (99.186)\n",
            "Epoch: [174][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3152 (0.3546)\tAcc@1 92.188 (88.900)\tAcc@5 100.000 (99.086)\n",
            "Epoch: [174][600/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 0.3226 (0.3624)\tAcc@1 84.375 (88.576)\tAcc@5 100.000 (99.064)\n",
            "Epoch: [174][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.4055 (0.3674)\tAcc@1 85.938 (88.385)\tAcc@5 98.438 (99.066)\n",
            " * Acc@1 88.270 Acc@5 99.054\n",
            "epoch 174, total time 39.99\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.3650 (1.3650)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.3741 (1.2479)\tAcc@1 59.375 (69.988)\tAcc@5 93.750 (91.182)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.7972 (1.2247)\tAcc@1 75.000 (70.382)\tAcc@5 100.000 (91.822)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.3742 (1.2234)\tAcc@1 56.250 (70.380)\tAcc@5 90.625 (91.809)\n",
            " * Acc@1 70.430 Acc@5 91.850\n",
            "==> training...\n",
            "Epoch: [175][0/782]\tTime 0.282 (0.282)\tData 0.199 (0.199)\tLoss 0.4006 (0.4006)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [175][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 0.3248 (0.3571)\tAcc@1 92.188 (88.722)\tAcc@5 98.438 (99.211)\n",
            "Epoch: [175][200/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1208 (0.3434)\tAcc@1 98.438 (89.241)\tAcc@5 100.000 (99.316)\n",
            "Epoch: [175][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.3150 (0.3480)\tAcc@1 90.625 (89.078)\tAcc@5 100.000 (99.310)\n",
            "Epoch: [175][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.3150 (0.3503)\tAcc@1 93.750 (88.981)\tAcc@5 98.438 (99.303)\n",
            "Epoch: [175][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.3408 (0.3578)\tAcc@1 85.938 (88.729)\tAcc@5 100.000 (99.261)\n",
            "Epoch: [175][600/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.3696 (0.3652)\tAcc@1 85.938 (88.493)\tAcc@5 98.438 (99.233)\n",
            "Epoch: [175][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.3687 (0.3667)\tAcc@1 90.625 (88.418)\tAcc@5 100.000 (99.186)\n",
            " * Acc@1 88.242 Acc@5 99.138\n",
            "epoch 175, total time 39.74\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.5524 (1.5524)\tAcc@1 75.000 (75.000)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4309 (1.2528)\tAcc@1 56.250 (70.514)\tAcc@5 90.625 (90.842)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 0.7207 (1.2347)\tAcc@1 78.125 (70.211)\tAcc@5 96.875 (90.983)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 0.8756 (1.2255)\tAcc@1 62.500 (70.193)\tAcc@5 100.000 (91.300)\n",
            " * Acc@1 70.330 Acc@5 91.410\n",
            "==> training...\n",
            "Epoch: [176][0/782]\tTime 0.275 (0.275)\tData 0.191 (0.191)\tLoss 0.3394 (0.3394)\tAcc@1 90.625 (90.625)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [176][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.2378 (0.3362)\tAcc@1 89.062 (89.604)\tAcc@5 100.000 (99.366)\n",
            "Epoch: [176][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.4578 (0.3346)\tAcc@1 90.625 (89.646)\tAcc@5 100.000 (99.386)\n",
            "Epoch: [176][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.3992 (0.3420)\tAcc@1 85.938 (89.353)\tAcc@5 98.438 (99.310)\n",
            "Epoch: [176][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.4441 (0.3489)\tAcc@1 92.188 (89.024)\tAcc@5 96.875 (99.252)\n",
            "Epoch: [176][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.4478 (0.3541)\tAcc@1 89.062 (88.816)\tAcc@5 96.875 (99.198)\n",
            "Epoch: [176][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.4289 (0.3593)\tAcc@1 82.812 (88.644)\tAcc@5 100.000 (99.173)\n",
            "Epoch: [176][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3363 (0.3621)\tAcc@1 93.750 (88.554)\tAcc@5 98.438 (99.160)\n",
            " * Acc@1 88.420 Acc@5 99.168\n",
            "epoch 176, total time 39.91\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.6966 (1.6966)\tAcc@1 71.875 (71.875)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.4060 (1.2624)\tAcc@1 62.500 (69.895)\tAcc@5 96.875 (91.553)\n",
            "Test: [200/313]\tTime 0.019 (0.019)\tLoss 0.7517 (1.2362)\tAcc@1 71.875 (69.558)\tAcc@5 96.875 (91.822)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.3064 (1.2327)\tAcc@1 62.500 (69.518)\tAcc@5 96.875 (91.715)\n",
            " * Acc@1 69.720 Acc@5 91.780\n",
            "==> training...\n",
            "Epoch: [177][0/782]\tTime 0.268 (0.268)\tData 0.199 (0.199)\tLoss 0.2653 (0.2653)\tAcc@1 92.188 (92.188)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [177][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.4130 (0.3372)\tAcc@1 85.938 (89.465)\tAcc@5 98.438 (99.196)\n",
            "Epoch: [177][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.3616 (0.3356)\tAcc@1 87.500 (89.412)\tAcc@5 100.000 (99.199)\n",
            "Epoch: [177][300/782]\tTime 0.050 (0.052)\tData 0.002 (0.002)\tLoss 0.3446 (0.3413)\tAcc@1 87.500 (89.177)\tAcc@5 100.000 (99.227)\n",
            "Epoch: [177][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.4851 (0.3407)\tAcc@1 85.938 (89.179)\tAcc@5 98.438 (99.248)\n",
            "Epoch: [177][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.1779 (0.3450)\tAcc@1 96.875 (89.075)\tAcc@5 100.000 (99.198)\n",
            "Epoch: [177][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3119 (0.3509)\tAcc@1 93.750 (88.873)\tAcc@5 98.438 (99.178)\n",
            "Epoch: [177][700/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 0.3290 (0.3561)\tAcc@1 85.938 (88.715)\tAcc@5 100.000 (99.153)\n",
            " * Acc@1 88.558 Acc@5 99.120\n",
            "epoch 177, total time 39.99\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.8196 (1.8196)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.3094 (1.3109)\tAcc@1 68.750 (69.183)\tAcc@5 93.750 (91.027)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.9616 (1.2926)\tAcc@1 75.000 (68.983)\tAcc@5 90.625 (91.216)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.3049 (1.2856)\tAcc@1 65.625 (69.010)\tAcc@5 93.750 (91.217)\n",
            " * Acc@1 69.150 Acc@5 91.300\n",
            "==> training...\n",
            "Epoch: [178][0/782]\tTime 0.283 (0.283)\tData 0.196 (0.196)\tLoss 0.4070 (0.4070)\tAcc@1 81.250 (81.250)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [178][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.2672 (0.3293)\tAcc@1 93.750 (89.527)\tAcc@5 100.000 (99.335)\n",
            "Epoch: [178][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.3803 (0.3265)\tAcc@1 89.062 (89.778)\tAcc@5 98.438 (99.293)\n",
            "Epoch: [178][300/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.3119 (0.3381)\tAcc@1 89.062 (89.338)\tAcc@5 100.000 (99.242)\n",
            "Epoch: [178][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.4171 (0.3480)\tAcc@1 87.500 (89.109)\tAcc@5 98.438 (99.147)\n",
            "Epoch: [178][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.4766 (0.3515)\tAcc@1 84.375 (89.028)\tAcc@5 98.438 (99.149)\n",
            "Epoch: [178][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.3429 (0.3553)\tAcc@1 92.188 (88.914)\tAcc@5 100.000 (99.119)\n",
            "Epoch: [178][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.5199 (0.3634)\tAcc@1 79.688 (88.630)\tAcc@5 96.875 (99.064)\n",
            " * Acc@1 88.472 Acc@5 99.064\n",
            "epoch 178, total time 39.99\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.6943 (1.6943)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.3427 (1.3343)\tAcc@1 71.875 (69.338)\tAcc@5 96.875 (90.501)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.7325 (1.3322)\tAcc@1 75.000 (68.781)\tAcc@5 96.875 (90.858)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.5636 (1.3410)\tAcc@1 56.250 (68.553)\tAcc@5 87.500 (90.750)\n",
            " * Acc@1 68.690 Acc@5 90.880\n",
            "==> training...\n",
            "Epoch: [179][0/782]\tTime 0.275 (0.275)\tData 0.198 (0.198)\tLoss 0.3502 (0.3502)\tAcc@1 92.188 (92.188)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [179][100/782]\tTime 0.051 (0.055)\tData 0.001 (0.003)\tLoss 0.5739 (0.3553)\tAcc@1 82.812 (89.032)\tAcc@5 98.438 (99.165)\n",
            "Epoch: [179][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.3748 (0.3456)\tAcc@1 90.625 (89.552)\tAcc@5 98.438 (99.090)\n",
            "Epoch: [179][300/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.4342 (0.3467)\tAcc@1 85.938 (89.410)\tAcc@5 96.875 (99.118)\n",
            "Epoch: [179][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.3121 (0.3577)\tAcc@1 90.625 (88.973)\tAcc@5 98.438 (99.100)\n",
            "Epoch: [179][500/782]\tTime 0.055 (0.052)\tData 0.001 (0.002)\tLoss 0.4515 (0.3601)\tAcc@1 85.938 (88.882)\tAcc@5 96.875 (99.092)\n",
            "Epoch: [179][600/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.5016 (0.3622)\tAcc@1 85.938 (88.816)\tAcc@5 100.000 (99.061)\n",
            "Epoch: [179][700/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.3464 (0.3660)\tAcc@1 87.500 (88.664)\tAcc@5 100.000 (99.055)\n",
            " * Acc@1 88.540 Acc@5 99.054\n",
            "epoch 179, total time 40.42\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 2.0369 (2.0369)\tAcc@1 62.500 (62.500)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.2296 (1.3305)\tAcc@1 78.125 (68.286)\tAcc@5 93.750 (90.470)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 1.0844 (1.3021)\tAcc@1 71.875 (68.688)\tAcc@5 90.625 (91.014)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2133 (1.3062)\tAcc@1 75.000 (68.522)\tAcc@5 96.875 (90.905)\n",
            " * Acc@1 68.660 Acc@5 90.970\n",
            "==> training...\n",
            "Epoch: [180][0/782]\tTime 0.255 (0.255)\tData 0.183 (0.183)\tLoss 0.2625 (0.2625)\tAcc@1 92.188 (92.188)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [180][100/782]\tTime 0.052 (0.054)\tData 0.001 (0.003)\tLoss 0.1521 (0.3284)\tAcc@1 96.875 (89.867)\tAcc@5 100.000 (99.366)\n",
            "Epoch: [180][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.2124 (0.3301)\tAcc@1 93.750 (89.739)\tAcc@5 98.438 (99.355)\n",
            "Epoch: [180][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.3070 (0.3309)\tAcc@1 87.500 (89.618)\tAcc@5 100.000 (99.346)\n",
            "Epoch: [180][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.3513 (0.3369)\tAcc@1 87.500 (89.355)\tAcc@5 98.438 (99.318)\n",
            "Epoch: [180][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.6141 (0.3423)\tAcc@1 73.438 (89.144)\tAcc@5 98.438 (99.283)\n",
            "Epoch: [180][600/782]\tTime 0.053 (0.051)\tData 0.002 (0.002)\tLoss 0.4310 (0.3499)\tAcc@1 90.625 (88.870)\tAcc@5 100.000 (99.230)\n",
            "Epoch: [180][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.3214 (0.3576)\tAcc@1 89.062 (88.592)\tAcc@5 100.000 (99.184)\n",
            " * Acc@1 88.410 Acc@5 99.172\n",
            "epoch 180, total time 40.23\n",
            "Test: [0/313]\tTime 0.126 (0.126)\tLoss 1.9018 (1.9018)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5428 (1.3109)\tAcc@1 59.375 (68.967)\tAcc@5 93.750 (90.656)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 1.0565 (1.2806)\tAcc@1 71.875 (69.030)\tAcc@5 93.750 (91.014)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.4457 (1.2763)\tAcc@1 65.625 (69.134)\tAcc@5 96.875 (91.196)\n",
            " * Acc@1 69.280 Acc@5 91.280\n",
            "==> training...\n",
            "Epoch: [181][0/782]\tTime 0.279 (0.279)\tData 0.203 (0.203)\tLoss 0.2974 (0.2974)\tAcc@1 87.500 (87.500)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [181][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.1988 (0.3040)\tAcc@1 93.750 (90.439)\tAcc@5 100.000 (99.397)\n",
            "Epoch: [181][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.2145 (0.2814)\tAcc@1 92.188 (91.426)\tAcc@5 100.000 (99.456)\n",
            "Epoch: [181][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1349 (0.2650)\tAcc@1 96.875 (92.068)\tAcc@5 100.000 (99.543)\n",
            "Epoch: [181][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1732 (0.2550)\tAcc@1 93.750 (92.410)\tAcc@5 100.000 (99.587)\n",
            "Epoch: [181][500/782]\tTime 0.053 (0.051)\tData 0.002 (0.002)\tLoss 0.2017 (0.2483)\tAcc@1 95.312 (92.690)\tAcc@5 100.000 (99.613)\n",
            "Epoch: [181][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1320 (0.2422)\tAcc@1 95.312 (92.913)\tAcc@5 100.000 (99.626)\n",
            "Epoch: [181][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.2921 (0.2371)\tAcc@1 85.938 (93.086)\tAcc@5 100.000 (99.655)\n",
            " * Acc@1 93.212 Acc@5 99.670\n",
            "epoch 181, total time 39.75\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 1.4732 (1.4732)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.2310 (1.1184)\tAcc@1 68.750 (72.958)\tAcc@5 93.750 (92.512)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 0.6478 (1.0908)\tAcc@1 81.250 (73.088)\tAcc@5 96.875 (92.895)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.2959 (1.0904)\tAcc@1 62.500 (73.245)\tAcc@5 90.625 (92.868)\n",
            " * Acc@1 73.470 Acc@5 92.910\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [182][0/782]\tTime 0.285 (0.285)\tData 0.193 (0.193)\tLoss 0.1458 (0.1458)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [182][100/782]\tTime 0.051 (0.054)\tData 0.001 (0.003)\tLoss 0.1842 (0.1864)\tAcc@1 96.875 (94.740)\tAcc@5 100.000 (99.892)\n",
            "Epoch: [182][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1807 (0.1866)\tAcc@1 93.750 (94.862)\tAcc@5 100.000 (99.845)\n",
            "Epoch: [182][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0894 (0.1858)\tAcc@1 98.438 (94.892)\tAcc@5 100.000 (99.839)\n",
            "Epoch: [182][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.2322 (0.1836)\tAcc@1 92.188 (94.977)\tAcc@5 100.000 (99.829)\n",
            "Epoch: [182][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.2043 (0.1826)\tAcc@1 93.750 (95.019)\tAcc@5 100.000 (99.819)\n",
            "Epoch: [182][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1574 (0.1820)\tAcc@1 95.312 (95.040)\tAcc@5 100.000 (99.834)\n",
            "Epoch: [182][700/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 0.2145 (0.1809)\tAcc@1 95.312 (95.049)\tAcc@5 100.000 (99.831)\n",
            " * Acc@1 95.060 Acc@5 99.826\n",
            "epoch 182, total time 40.07\n",
            "Test: [0/313]\tTime 0.131 (0.131)\tLoss 1.5767 (1.5767)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.2193 (1.1211)\tAcc@1 68.750 (73.948)\tAcc@5 93.750 (92.791)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5871 (1.0910)\tAcc@1 84.375 (74.036)\tAcc@5 100.000 (93.019)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1670 (1.0875)\tAcc@1 65.625 (73.920)\tAcc@5 96.875 (93.044)\n",
            " * Acc@1 74.080 Acc@5 93.090\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [183][0/782]\tTime 0.274 (0.274)\tData 0.205 (0.205)\tLoss 0.1499 (0.1499)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [183][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.1271 (0.1577)\tAcc@1 95.312 (96.040)\tAcc@5 100.000 (99.845)\n",
            "Epoch: [183][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1604 (0.1618)\tAcc@1 95.312 (95.826)\tAcc@5 100.000 (99.860)\n",
            "Epoch: [183][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1042 (0.1621)\tAcc@1 96.875 (95.826)\tAcc@5 100.000 (99.865)\n",
            "Epoch: [183][400/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.1462 (0.1608)\tAcc@1 96.875 (95.866)\tAcc@5 100.000 (99.871)\n",
            "Epoch: [183][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1147 (0.1618)\tAcc@1 96.875 (95.790)\tAcc@5 100.000 (99.866)\n",
            "Epoch: [183][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1520 (0.1614)\tAcc@1 95.312 (95.780)\tAcc@5 100.000 (99.852)\n",
            "Epoch: [183][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1540 (0.1594)\tAcc@1 95.312 (95.794)\tAcc@5 100.000 (99.864)\n",
            " * Acc@1 95.766 Acc@5 99.858\n",
            "epoch 183, total time 39.93\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 1.5430 (1.5430)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.2622 (1.1184)\tAcc@1 68.750 (74.041)\tAcc@5 93.750 (92.698)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.6515 (1.0943)\tAcc@1 81.250 (73.974)\tAcc@5 100.000 (93.144)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1849 (1.0956)\tAcc@1 62.500 (73.951)\tAcc@5 96.875 (93.096)\n",
            " * Acc@1 74.120 Acc@5 93.160\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [184][0/782]\tTime 0.275 (0.275)\tData 0.191 (0.191)\tLoss 0.1271 (0.1271)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [184][100/782]\tTime 0.053 (0.054)\tData 0.001 (0.003)\tLoss 0.1585 (0.1471)\tAcc@1 93.750 (96.086)\tAcc@5 100.000 (99.876)\n",
            "Epoch: [184][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1855 (0.1481)\tAcc@1 92.188 (96.222)\tAcc@5 100.000 (99.891)\n",
            "Epoch: [184][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1666 (0.1486)\tAcc@1 95.312 (96.237)\tAcc@5 100.000 (99.865)\n",
            "Epoch: [184][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1407 (0.1479)\tAcc@1 96.875 (96.228)\tAcc@5 100.000 (99.871)\n",
            "Epoch: [184][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.1133 (0.1489)\tAcc@1 98.438 (96.164)\tAcc@5 100.000 (99.875)\n",
            "Epoch: [184][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1325 (0.1490)\tAcc@1 96.875 (96.150)\tAcc@5 100.000 (99.870)\n",
            "Epoch: [184][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1402 (0.1489)\tAcc@1 96.875 (96.142)\tAcc@5 100.000 (99.871)\n",
            " * Acc@1 96.114 Acc@5 99.878\n",
            "epoch 184, total time 39.98\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.6426 (1.6426)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.2308 (1.1367)\tAcc@1 71.875 (73.577)\tAcc@5 93.750 (92.203)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.6376 (1.1085)\tAcc@1 81.250 (73.710)\tAcc@5 100.000 (92.724)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.0586 (1.1059)\tAcc@1 75.000 (73.598)\tAcc@5 93.750 (92.826)\n",
            " * Acc@1 73.740 Acc@5 92.880\n",
            "==> training...\n",
            "Epoch: [185][0/782]\tTime 0.280 (0.280)\tData 0.203 (0.203)\tLoss 0.1213 (0.1213)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [185][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 0.1957 (0.1407)\tAcc@1 93.750 (96.426)\tAcc@5 100.000 (99.892)\n",
            "Epoch: [185][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0901 (0.1439)\tAcc@1 96.875 (96.284)\tAcc@5 100.000 (99.876)\n",
            "Epoch: [185][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.2038 (0.1420)\tAcc@1 90.625 (96.392)\tAcc@5 100.000 (99.891)\n",
            "Epoch: [185][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0720 (0.1405)\tAcc@1 98.438 (96.411)\tAcc@5 100.000 (99.903)\n",
            "Epoch: [185][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1894 (0.1415)\tAcc@1 95.312 (96.307)\tAcc@5 100.000 (99.894)\n",
            "Epoch: [185][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0751 (0.1421)\tAcc@1 100.000 (96.274)\tAcc@5 100.000 (99.893)\n",
            "Epoch: [185][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0714 (0.1422)\tAcc@1 100.000 (96.249)\tAcc@5 100.000 (99.897)\n",
            " * Acc@1 96.204 Acc@5 99.900\n",
            "epoch 185, total time 40.00\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.5677 (1.5677)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.2126 (1.1465)\tAcc@1 71.875 (73.577)\tAcc@5 93.750 (92.450)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5916 (1.1162)\tAcc@1 84.375 (73.881)\tAcc@5 100.000 (92.973)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.2019 (1.1124)\tAcc@1 62.500 (73.681)\tAcc@5 93.750 (92.899)\n",
            " * Acc@1 73.870 Acc@5 92.950\n",
            "==> training...\n",
            "Epoch: [186][0/782]\tTime 0.278 (0.278)\tData 0.192 (0.192)\tLoss 0.1229 (0.1229)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [186][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.2742 (0.1392)\tAcc@1 89.062 (96.581)\tAcc@5 98.438 (99.923)\n",
            "Epoch: [186][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0692 (0.1359)\tAcc@1 100.000 (96.580)\tAcc@5 100.000 (99.891)\n",
            "Epoch: [186][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0815 (0.1340)\tAcc@1 98.438 (96.589)\tAcc@5 100.000 (99.891)\n",
            "Epoch: [186][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1276 (0.1325)\tAcc@1 96.875 (96.610)\tAcc@5 100.000 (99.906)\n",
            "Epoch: [186][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0965 (0.1323)\tAcc@1 96.875 (96.641)\tAcc@5 100.000 (99.903)\n",
            "Epoch: [186][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1799 (0.1321)\tAcc@1 93.750 (96.638)\tAcc@5 100.000 (99.904)\n",
            "Epoch: [186][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0848 (0.1327)\tAcc@1 96.875 (96.590)\tAcc@5 100.000 (99.909)\n",
            " * Acc@1 96.594 Acc@5 99.910\n",
            "epoch 186, total time 39.99\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.6317 (1.6317)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.1917 (1.1443)\tAcc@1 68.750 (73.762)\tAcc@5 93.750 (92.481)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 0.5601 (1.1193)\tAcc@1 87.500 (74.083)\tAcc@5 100.000 (92.988)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1828 (1.1153)\tAcc@1 68.750 (73.837)\tAcc@5 93.750 (92.940)\n",
            " * Acc@1 74.010 Acc@5 93.020\n",
            "==> training...\n",
            "Epoch: [187][0/782]\tTime 0.270 (0.270)\tData 0.185 (0.185)\tLoss 0.2074 (0.2074)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [187][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 0.1533 (0.1270)\tAcc@1 92.188 (96.906)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [187][200/782]\tTime 0.055 (0.051)\tData 0.001 (0.002)\tLoss 0.0864 (0.1239)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (99.946)\n",
            "Epoch: [187][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0910 (0.1232)\tAcc@1 100.000 (96.911)\tAcc@5 100.000 (99.943)\n",
            "Epoch: [187][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1037 (0.1237)\tAcc@1 96.875 (96.910)\tAcc@5 100.000 (99.934)\n",
            "Epoch: [187][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0956 (0.1253)\tAcc@1 98.438 (96.869)\tAcc@5 100.000 (99.938)\n",
            "Epoch: [187][600/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.0704 (0.1261)\tAcc@1 100.000 (96.833)\tAcc@5 100.000 (99.927)\n",
            "Epoch: [187][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0510 (0.1270)\tAcc@1 100.000 (96.797)\tAcc@5 100.000 (99.918)\n",
            " * Acc@1 96.780 Acc@5 99.912\n",
            "epoch 187, total time 39.83\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.6676 (1.6676)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.2681 (1.1542)\tAcc@1 68.750 (73.515)\tAcc@5 93.750 (92.636)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.6176 (1.1301)\tAcc@1 84.375 (73.756)\tAcc@5 100.000 (93.066)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1269 (1.1256)\tAcc@1 75.000 (73.775)\tAcc@5 96.875 (93.075)\n",
            " * Acc@1 73.930 Acc@5 93.130\n",
            "==> training...\n",
            "Epoch: [188][0/782]\tTime 0.266 (0.266)\tData 0.180 (0.180)\tLoss 0.1209 (0.1209)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [188][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.1017 (0.1223)\tAcc@1 96.875 (97.200)\tAcc@5 100.000 (99.876)\n",
            "Epoch: [188][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1103 (0.1235)\tAcc@1 95.312 (96.992)\tAcc@5 100.000 (99.922)\n",
            "Epoch: [188][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1593 (0.1221)\tAcc@1 92.188 (97.057)\tAcc@5 98.438 (99.927)\n",
            "Epoch: [188][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1460 (0.1228)\tAcc@1 93.750 (97.011)\tAcc@5 100.000 (99.930)\n",
            "Epoch: [188][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1090 (0.1222)\tAcc@1 98.438 (96.990)\tAcc@5 100.000 (99.941)\n",
            "Epoch: [188][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0818 (0.1222)\tAcc@1 98.438 (96.989)\tAcc@5 100.000 (99.943)\n",
            "Epoch: [188][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1664 (0.1225)\tAcc@1 92.188 (96.984)\tAcc@5 100.000 (99.935)\n",
            " * Acc@1 96.972 Acc@5 99.928\n",
            "epoch 188, total time 40.06\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.7011 (1.7011)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.3616 (1.1790)\tAcc@1 68.750 (73.608)\tAcc@5 93.750 (92.017)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.6314 (1.1398)\tAcc@1 84.375 (73.896)\tAcc@5 100.000 (92.724)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1223 (1.1367)\tAcc@1 75.000 (73.899)\tAcc@5 93.750 (92.764)\n",
            " * Acc@1 74.050 Acc@5 92.820\n",
            "==> training...\n",
            "Epoch: [189][0/782]\tTime 0.270 (0.270)\tData 0.183 (0.183)\tLoss 0.1887 (0.1887)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [189][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.0633 (0.1182)\tAcc@1 100.000 (97.123)\tAcc@5 100.000 (99.938)\n",
            "Epoch: [189][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1042 (0.1188)\tAcc@1 96.875 (97.069)\tAcc@5 100.000 (99.922)\n",
            "Epoch: [189][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1572 (0.1175)\tAcc@1 95.312 (97.046)\tAcc@5 100.000 (99.917)\n",
            "Epoch: [189][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0989 (0.1163)\tAcc@1 98.438 (97.136)\tAcc@5 100.000 (99.934)\n",
            "Epoch: [189][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.1178 (0.1177)\tAcc@1 98.438 (97.093)\tAcc@5 100.000 (99.931)\n",
            "Epoch: [189][600/782]\tTime 0.053 (0.051)\tData 0.002 (0.002)\tLoss 0.2225 (0.1174)\tAcc@1 93.750 (97.138)\tAcc@5 100.000 (99.927)\n",
            "Epoch: [189][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1187 (0.1181)\tAcc@1 95.312 (97.116)\tAcc@5 100.000 (99.929)\n",
            " * Acc@1 97.100 Acc@5 99.924\n",
            "epoch 189, total time 39.81\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.6824 (1.6824)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.2834 (1.1783)\tAcc@1 71.875 (73.824)\tAcc@5 93.750 (92.203)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 0.6215 (1.1492)\tAcc@1 84.375 (73.756)\tAcc@5 100.000 (92.739)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.2071 (1.1441)\tAcc@1 71.875 (73.661)\tAcc@5 96.875 (92.795)\n",
            " * Acc@1 73.860 Acc@5 92.870\n",
            "==> training...\n",
            "Epoch: [190][0/782]\tTime 0.284 (0.284)\tData 0.205 (0.205)\tLoss 0.1195 (0.1195)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [190][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 0.1566 (0.1095)\tAcc@1 93.750 (97.602)\tAcc@5 100.000 (99.938)\n",
            "Epoch: [190][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0606 (0.1129)\tAcc@1 98.438 (97.334)\tAcc@5 100.000 (99.930)\n",
            "Epoch: [190][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0649 (0.1143)\tAcc@1 100.000 (97.238)\tAcc@5 100.000 (99.938)\n",
            "Epoch: [190][400/782]\tTime 0.055 (0.051)\tData 0.002 (0.002)\tLoss 0.1534 (0.1143)\tAcc@1 93.750 (97.249)\tAcc@5 100.000 (99.930)\n",
            "Epoch: [190][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1120 (0.1134)\tAcc@1 96.875 (97.199)\tAcc@5 100.000 (99.935)\n",
            "Epoch: [190][600/782]\tTime 0.052 (0.051)\tData 0.002 (0.002)\tLoss 0.1439 (0.1136)\tAcc@1 98.438 (97.179)\tAcc@5 100.000 (99.940)\n",
            "Epoch: [190][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0825 (0.1127)\tAcc@1 98.438 (97.236)\tAcc@5 100.000 (99.942)\n",
            " * Acc@1 97.214 Acc@5 99.942\n",
            "epoch 190, total time 40.02\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.6087 (1.6087)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.3112 (1.1724)\tAcc@1 71.875 (73.484)\tAcc@5 93.750 (92.296)\n",
            "Test: [200/313]\tTime 0.019 (0.018)\tLoss 0.5812 (1.1366)\tAcc@1 84.375 (73.678)\tAcc@5 100.000 (92.802)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1522 (1.1335)\tAcc@1 71.875 (73.588)\tAcc@5 93.750 (92.784)\n",
            " * Acc@1 73.770 Acc@5 92.800\n",
            "==> training...\n",
            "Epoch: [191][0/782]\tTime 0.284 (0.284)\tData 0.201 (0.201)\tLoss 0.0935 (0.0935)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [191][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.1044 (0.1073)\tAcc@1 100.000 (97.324)\tAcc@5 100.000 (99.938)\n",
            "Epoch: [191][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1013 (0.1065)\tAcc@1 98.438 (97.373)\tAcc@5 100.000 (99.953)\n",
            "Epoch: [191][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0452 (0.1063)\tAcc@1 100.000 (97.425)\tAcc@5 100.000 (99.948)\n",
            "Epoch: [191][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0409 (0.1086)\tAcc@1 100.000 (97.350)\tAcc@5 100.000 (99.926)\n",
            "Epoch: [191][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0842 (0.1084)\tAcc@1 95.312 (97.355)\tAcc@5 100.000 (99.919)\n",
            "Epoch: [191][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0635 (0.1088)\tAcc@1 100.000 (97.351)\tAcc@5 100.000 (99.930)\n",
            "Epoch: [191][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0747 (0.1089)\tAcc@1 96.875 (97.345)\tAcc@5 100.000 (99.929)\n",
            " * Acc@1 97.316 Acc@5 99.928\n",
            "epoch 191, total time 40.09\n",
            "Test: [0/313]\tTime 0.128 (0.128)\tLoss 1.6223 (1.6223)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.3738 (1.1902)\tAcc@1 68.750 (73.484)\tAcc@5 93.750 (92.420)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 0.5647 (1.1604)\tAcc@1 87.500 (73.678)\tAcc@5 100.000 (92.833)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.3355 (1.1554)\tAcc@1 75.000 (73.681)\tAcc@5 96.875 (92.878)\n",
            " * Acc@1 73.870 Acc@5 92.950\n",
            "==> training...\n",
            "Epoch: [192][0/782]\tTime 0.271 (0.271)\tData 0.196 (0.196)\tLoss 0.1009 (0.1009)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [192][100/782]\tTime 0.051 (0.054)\tData 0.001 (0.003)\tLoss 0.1195 (0.1079)\tAcc@1 96.875 (97.370)\tAcc@5 100.000 (99.938)\n",
            "Epoch: [192][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.1191 (0.1057)\tAcc@1 95.312 (97.536)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [192][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1588 (0.1072)\tAcc@1 95.312 (97.456)\tAcc@5 100.000 (99.958)\n",
            "Epoch: [192][400/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 0.0574 (0.1059)\tAcc@1 100.000 (97.510)\tAcc@5 100.000 (99.942)\n",
            "Epoch: [192][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1080 (0.1066)\tAcc@1 98.438 (97.396)\tAcc@5 100.000 (99.950)\n",
            "Epoch: [192][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0894 (0.1064)\tAcc@1 98.438 (97.411)\tAcc@5 100.000 (99.951)\n",
            "Epoch: [192][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0430 (0.1070)\tAcc@1 100.000 (97.381)\tAcc@5 100.000 (99.951)\n",
            " * Acc@1 97.326 Acc@5 99.946\n",
            "epoch 192, total time 40.04\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.6313 (1.6313)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.2919 (1.1819)\tAcc@1 68.750 (73.546)\tAcc@5 93.750 (92.234)\n",
            "Test: [200/313]\tTime 0.024 (0.018)\tLoss 0.5938 (1.1496)\tAcc@1 81.250 (73.896)\tAcc@5 100.000 (92.786)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2907 (1.1412)\tAcc@1 71.875 (73.972)\tAcc@5 93.750 (92.753)\n",
            " * Acc@1 74.100 Acc@5 92.780\n",
            "==> training...\n",
            "Epoch: [193][0/782]\tTime 0.266 (0.266)\tData 0.182 (0.182)\tLoss 0.0983 (0.0983)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [193][100/782]\tTime 0.049 (0.052)\tData 0.001 (0.003)\tLoss 0.1609 (0.1017)\tAcc@1 92.188 (97.726)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [193][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0933 (0.1057)\tAcc@1 98.438 (97.411)\tAcc@5 100.000 (99.946)\n",
            "Epoch: [193][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0839 (0.1053)\tAcc@1 98.438 (97.441)\tAcc@5 100.000 (99.948)\n",
            "Epoch: [193][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1096 (0.1057)\tAcc@1 98.438 (97.491)\tAcc@5 100.000 (99.942)\n",
            "Epoch: [193][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1554 (0.1052)\tAcc@1 95.312 (97.517)\tAcc@5 100.000 (99.947)\n",
            "Epoch: [193][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.2542 (0.1045)\tAcc@1 93.750 (97.546)\tAcc@5 98.438 (99.945)\n",
            "Epoch: [193][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0879 (0.1057)\tAcc@1 98.438 (97.459)\tAcc@5 100.000 (99.942)\n",
            " * Acc@1 97.504 Acc@5 99.946\n",
            "epoch 193, total time 39.52\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.6747 (1.6747)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.024 (0.019)\tLoss 1.4184 (1.1977)\tAcc@1 71.875 (73.236)\tAcc@5 93.750 (92.172)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.5232 (1.1664)\tAcc@1 87.500 (73.663)\tAcc@5 100.000 (92.522)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2289 (1.1568)\tAcc@1 75.000 (73.785)\tAcc@5 93.750 (92.639)\n",
            " * Acc@1 73.940 Acc@5 92.690\n",
            "==> training...\n",
            "Epoch: [194][0/782]\tTime 0.265 (0.265)\tData 0.183 (0.183)\tLoss 0.1460 (0.1460)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [194][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.0397 (0.0954)\tAcc@1 98.438 (97.881)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [194][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0678 (0.0954)\tAcc@1 98.438 (97.893)\tAcc@5 100.000 (99.961)\n",
            "Epoch: [194][300/782]\tTime 0.048 (0.052)\tData 0.001 (0.002)\tLoss 0.1012 (0.0943)\tAcc@1 98.438 (97.934)\tAcc@5 100.000 (99.953)\n",
            "Epoch: [194][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0950 (0.0958)\tAcc@1 96.875 (97.849)\tAcc@5 100.000 (99.957)\n",
            "Epoch: [194][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1923 (0.0973)\tAcc@1 95.312 (97.839)\tAcc@5 100.000 (99.966)\n",
            "Epoch: [194][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0631 (0.0974)\tAcc@1 100.000 (97.832)\tAcc@5 100.000 (99.956)\n",
            "Epoch: [194][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0957 (0.0973)\tAcc@1 98.438 (97.780)\tAcc@5 100.000 (99.962)\n",
            " * Acc@1 97.764 Acc@5 99.964\n",
            "epoch 194, total time 39.79\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.4272 (1.4272)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.3695 (1.1992)\tAcc@1 71.875 (73.391)\tAcc@5 93.750 (92.110)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.5514 (1.1707)\tAcc@1 90.625 (73.912)\tAcc@5 100.000 (92.522)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.1189 (1.1615)\tAcc@1 71.875 (73.910)\tAcc@5 96.875 (92.546)\n",
            " * Acc@1 74.090 Acc@5 92.600\n",
            "==> training...\n",
            "Epoch: [195][0/782]\tTime 0.272 (0.272)\tData 0.188 (0.188)\tLoss 0.0967 (0.0967)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [195][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 0.0840 (0.0892)\tAcc@1 98.438 (98.004)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [195][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1359 (0.0944)\tAcc@1 95.312 (97.722)\tAcc@5 98.438 (99.961)\n",
            "Epoch: [195][300/782]\tTime 0.067 (0.053)\tData 0.001 (0.002)\tLoss 0.1528 (0.0956)\tAcc@1 93.750 (97.706)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [195][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0413 (0.0971)\tAcc@1 100.000 (97.717)\tAcc@5 100.000 (99.965)\n",
            "Epoch: [195][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1263 (0.0980)\tAcc@1 96.875 (97.701)\tAcc@5 100.000 (99.963)\n",
            "Epoch: [195][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0561 (0.0982)\tAcc@1 100.000 (97.699)\tAcc@5 100.000 (99.961)\n",
            "Epoch: [195][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1022 (0.0981)\tAcc@1 96.875 (97.724)\tAcc@5 100.000 (99.960)\n",
            " * Acc@1 97.728 Acc@5 99.962\n",
            "epoch 195, total time 40.24\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.5596 (1.5596)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.3616 (1.1946)\tAcc@1 71.875 (73.298)\tAcc@5 93.750 (92.172)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5149 (1.1638)\tAcc@1 84.375 (73.787)\tAcc@5 100.000 (92.802)\n",
            "Test: [300/313]\tTime 0.019 (0.018)\tLoss 1.2105 (1.1543)\tAcc@1 78.125 (73.754)\tAcc@5 93.750 (92.909)\n",
            " * Acc@1 73.890 Acc@5 92.940\n",
            "==> training...\n",
            "Epoch: [196][0/782]\tTime 0.275 (0.275)\tData 0.204 (0.204)\tLoss 0.0890 (0.0890)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [196][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.0566 (0.0946)\tAcc@1 100.000 (97.896)\tAcc@5 100.000 (99.923)\n",
            "Epoch: [196][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0653 (0.0917)\tAcc@1 98.438 (98.010)\tAcc@5 100.000 (99.946)\n",
            "Epoch: [196][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0740 (0.0914)\tAcc@1 98.438 (98.022)\tAcc@5 100.000 (99.933)\n",
            "Epoch: [196][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 0.0882 (0.0928)\tAcc@1 98.438 (97.954)\tAcc@5 100.000 (99.942)\n",
            "Epoch: [196][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0934 (0.0936)\tAcc@1 95.312 (97.876)\tAcc@5 100.000 (99.950)\n",
            "Epoch: [196][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1142 (0.0943)\tAcc@1 95.312 (97.842)\tAcc@5 100.000 (99.948)\n",
            "Epoch: [196][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0620 (0.0941)\tAcc@1 100.000 (97.867)\tAcc@5 100.000 (99.949)\n",
            " * Acc@1 97.852 Acc@5 99.950\n",
            "epoch 196, total time 39.91\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.5937 (1.5937)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.3694 (1.2028)\tAcc@1 71.875 (73.329)\tAcc@5 93.750 (92.358)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5514 (1.1788)\tAcc@1 87.500 (73.803)\tAcc@5 100.000 (92.631)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2428 (1.1693)\tAcc@1 71.875 (73.796)\tAcc@5 96.875 (92.681)\n",
            " * Acc@1 73.980 Acc@5 92.730\n",
            "==> training...\n",
            "Epoch: [197][0/782]\tTime 0.276 (0.276)\tData 0.194 (0.194)\tLoss 0.0853 (0.0853)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [197][100/782]\tTime 0.051 (0.053)\tData 0.001 (0.003)\tLoss 0.0348 (0.0817)\tAcc@1 100.000 (98.097)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [197][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0613 (0.0879)\tAcc@1 100.000 (97.963)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [197][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0596 (0.0884)\tAcc@1 100.000 (97.950)\tAcc@5 100.000 (99.974)\n",
            "Epoch: [197][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0648 (0.0893)\tAcc@1 100.000 (97.919)\tAcc@5 100.000 (99.965)\n",
            "Epoch: [197][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0975 (0.0910)\tAcc@1 96.875 (97.870)\tAcc@5 100.000 (99.950)\n",
            "Epoch: [197][600/782]\tTime 0.056 (0.051)\tData 0.001 (0.002)\tLoss 0.0560 (0.0900)\tAcc@1 100.000 (97.928)\tAcc@5 100.000 (99.953)\n",
            "Epoch: [197][700/782]\tTime 0.055 (0.051)\tData 0.001 (0.002)\tLoss 0.0651 (0.0915)\tAcc@1 100.000 (97.867)\tAcc@5 100.000 (99.947)\n",
            " * Acc@1 97.856 Acc@5 99.950\n",
            "epoch 197, total time 39.65\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.5068 (1.5068)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.3031 (1.1979)\tAcc@1 71.875 (73.731)\tAcc@5 96.875 (92.141)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 0.6246 (1.1647)\tAcc@1 81.250 (73.974)\tAcc@5 100.000 (92.522)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2200 (1.1580)\tAcc@1 78.125 (73.931)\tAcc@5 93.750 (92.722)\n",
            " * Acc@1 74.030 Acc@5 92.760\n",
            "==> training...\n",
            "Epoch: [198][0/782]\tTime 0.276 (0.276)\tData 0.194 (0.194)\tLoss 0.1231 (0.1231)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [198][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.1343 (0.0903)\tAcc@1 95.312 (98.097)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [198][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0785 (0.0871)\tAcc@1 96.875 (98.197)\tAcc@5 100.000 (99.961)\n",
            "Epoch: [198][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0816 (0.0877)\tAcc@1 98.438 (98.121)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [198][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0801 (0.0885)\tAcc@1 98.438 (98.134)\tAcc@5 100.000 (99.957)\n",
            "Epoch: [198][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0763 (0.0902)\tAcc@1 100.000 (98.010)\tAcc@5 100.000 (99.959)\n",
            "Epoch: [198][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0693 (0.0904)\tAcc@1 100.000 (98.016)\tAcc@5 100.000 (99.961)\n",
            "Epoch: [198][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0570 (0.0899)\tAcc@1 98.438 (98.014)\tAcc@5 100.000 (99.967)\n",
            " * Acc@1 97.980 Acc@5 99.968\n",
            "epoch 198, total time 39.95\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 1.5737 (1.5737)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.3786 (1.2082)\tAcc@1 71.875 (73.948)\tAcc@5 93.750 (92.203)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5203 (1.1744)\tAcc@1 87.500 (74.160)\tAcc@5 100.000 (92.584)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2069 (1.1675)\tAcc@1 71.875 (74.149)\tAcc@5 96.875 (92.660)\n",
            " * Acc@1 74.250 Acc@5 92.720\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [199][0/782]\tTime 0.279 (0.279)\tData 0.193 (0.193)\tLoss 0.0632 (0.0632)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [199][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 0.1068 (0.0885)\tAcc@1 95.312 (97.834)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [199][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.2487 (0.0899)\tAcc@1 92.188 (97.878)\tAcc@5 98.438 (99.953)\n",
            "Epoch: [199][300/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0498 (0.0915)\tAcc@1 100.000 (97.783)\tAcc@5 100.000 (99.958)\n",
            "Epoch: [199][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0756 (0.0897)\tAcc@1 98.438 (97.869)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [199][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0643 (0.0891)\tAcc@1 98.438 (97.923)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [199][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0973 (0.0896)\tAcc@1 98.438 (97.907)\tAcc@5 100.000 (99.961)\n",
            "Epoch: [199][700/782]\tTime 0.055 (0.051)\tData 0.002 (0.002)\tLoss 0.0941 (0.0887)\tAcc@1 100.000 (97.965)\tAcc@5 100.000 (99.964)\n",
            " * Acc@1 97.990 Acc@5 99.968\n",
            "epoch 199, total time 40.12\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.5313 (1.5313)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.3436 (1.2136)\tAcc@1 68.750 (73.608)\tAcc@5 93.750 (92.110)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5262 (1.1874)\tAcc@1 90.625 (73.958)\tAcc@5 100.000 (92.537)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.3383 (1.1808)\tAcc@1 71.875 (73.723)\tAcc@5 96.875 (92.618)\n",
            " * Acc@1 73.870 Acc@5 92.650\n",
            "==> training...\n",
            "Epoch: [200][0/782]\tTime 0.273 (0.273)\tData 0.204 (0.204)\tLoss 0.0607 (0.0607)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [200][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 0.0764 (0.0820)\tAcc@1 98.438 (98.113)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [200][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0842 (0.0849)\tAcc@1 98.438 (98.103)\tAcc@5 100.000 (99.961)\n",
            "Epoch: [200][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0690 (0.0851)\tAcc@1 96.875 (98.100)\tAcc@5 100.000 (99.964)\n",
            "Epoch: [200][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0600 (0.0853)\tAcc@1 98.438 (98.141)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [200][500/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.1552 (0.0846)\tAcc@1 95.312 (98.166)\tAcc@5 100.000 (99.975)\n",
            "Epoch: [200][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1133 (0.0839)\tAcc@1 95.312 (98.206)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [200][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0425 (0.0834)\tAcc@1 100.000 (98.226)\tAcc@5 100.000 (99.980)\n",
            " * Acc@1 98.200 Acc@5 99.978\n",
            "epoch 200, total time 40.18\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.5841 (1.5841)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.4432 (1.2134)\tAcc@1 68.750 (73.205)\tAcc@5 93.750 (91.986)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5357 (1.1927)\tAcc@1 87.500 (73.554)\tAcc@5 100.000 (92.491)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1481 (1.1867)\tAcc@1 78.125 (73.650)\tAcc@5 96.875 (92.577)\n",
            " * Acc@1 73.790 Acc@5 92.630\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [201][0/782]\tTime 0.273 (0.273)\tData 0.188 (0.188)\tLoss 0.0768 (0.0768)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [201][100/782]\tTime 0.051 (0.055)\tData 0.001 (0.003)\tLoss 0.0801 (0.0783)\tAcc@1 98.438 (98.376)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [201][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0306 (0.0830)\tAcc@1 100.000 (98.119)\tAcc@5 100.000 (99.953)\n",
            "Epoch: [201][300/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.1230 (0.0836)\tAcc@1 98.438 (98.100)\tAcc@5 100.000 (99.958)\n",
            "Epoch: [201][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1114 (0.0825)\tAcc@1 96.875 (98.180)\tAcc@5 100.000 (99.965)\n",
            "Epoch: [201][500/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.1115 (0.0831)\tAcc@1 96.875 (98.144)\tAcc@5 100.000 (99.966)\n",
            "Epoch: [201][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1648 (0.0841)\tAcc@1 93.750 (98.081)\tAcc@5 100.000 (99.966)\n",
            "Epoch: [201][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1097 (0.0846)\tAcc@1 98.438 (98.079)\tAcc@5 100.000 (99.962)\n",
            " * Acc@1 98.032 Acc@5 99.962\n",
            "epoch 201, total time 40.38\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.5920 (1.5920)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.4125 (1.2178)\tAcc@1 68.750 (73.360)\tAcc@5 93.750 (92.203)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5368 (1.1958)\tAcc@1 84.375 (73.663)\tAcc@5 100.000 (92.522)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.2388 (1.1894)\tAcc@1 68.750 (73.723)\tAcc@5 93.750 (92.598)\n",
            " * Acc@1 73.910 Acc@5 92.640\n",
            "==> training...\n",
            "Epoch: [202][0/782]\tTime 0.274 (0.274)\tData 0.197 (0.197)\tLoss 0.0492 (0.0492)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [202][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.0573 (0.0792)\tAcc@1 98.438 (98.221)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [202][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1166 (0.0794)\tAcc@1 96.875 (98.305)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [202][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1130 (0.0802)\tAcc@1 96.875 (98.287)\tAcc@5 100.000 (99.974)\n",
            "Epoch: [202][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.1231 (0.0796)\tAcc@1 95.312 (98.328)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [202][500/782]\tTime 0.055 (0.051)\tData 0.001 (0.002)\tLoss 0.0808 (0.0811)\tAcc@1 100.000 (98.278)\tAcc@5 100.000 (99.972)\n",
            "Epoch: [202][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0785 (0.0806)\tAcc@1 98.438 (98.297)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [202][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0800 (0.0812)\tAcc@1 98.438 (98.273)\tAcc@5 100.000 (99.971)\n",
            " * Acc@1 98.244 Acc@5 99.970\n",
            "epoch 202, total time 39.97\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.5732 (1.5732)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.5350 (1.2171)\tAcc@1 68.750 (73.298)\tAcc@5 93.750 (92.172)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 0.5664 (1.1896)\tAcc@1 81.250 (73.507)\tAcc@5 100.000 (92.646)\n",
            "Test: [300/313]\tTime 0.022 (0.019)\tLoss 1.1683 (1.1824)\tAcc@1 68.750 (73.578)\tAcc@5 96.875 (92.743)\n",
            " * Acc@1 73.730 Acc@5 92.800\n",
            "==> training...\n",
            "Epoch: [203][0/782]\tTime 0.263 (0.263)\tData 0.194 (0.194)\tLoss 0.0677 (0.0677)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [203][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.1070 (0.0810)\tAcc@1 98.438 (98.314)\tAcc@5 100.000 (99.938)\n",
            "Epoch: [203][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0621 (0.0797)\tAcc@1 98.438 (98.414)\tAcc@5 100.000 (99.961)\n",
            "Epoch: [203][300/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0476 (0.0799)\tAcc@1 98.438 (98.328)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [203][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0354 (0.0789)\tAcc@1 98.438 (98.332)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [203][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0903 (0.0791)\tAcc@1 98.438 (98.310)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [203][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0856 (0.0795)\tAcc@1 98.438 (98.292)\tAcc@5 100.000 (99.971)\n",
            "Epoch: [203][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0757 (0.0798)\tAcc@1 100.000 (98.279)\tAcc@5 100.000 (99.973)\n",
            " * Acc@1 98.262 Acc@5 99.972\n",
            "epoch 203, total time 40.19\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.6340 (1.6340)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.4390 (1.2240)\tAcc@1 68.750 (73.267)\tAcc@5 93.750 (92.327)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.5697 (1.1940)\tAcc@1 84.375 (73.818)\tAcc@5 100.000 (92.631)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.3421 (1.1918)\tAcc@1 78.125 (73.983)\tAcc@5 93.750 (92.515)\n",
            " * Acc@1 74.130 Acc@5 92.550\n",
            "==> training...\n",
            "Epoch: [204][0/782]\tTime 0.268 (0.268)\tData 0.183 (0.183)\tLoss 0.0737 (0.0737)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [204][100/782]\tTime 0.049 (0.054)\tData 0.001 (0.003)\tLoss 0.0933 (0.0777)\tAcc@1 96.875 (98.236)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [204][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0912 (0.0804)\tAcc@1 96.875 (98.080)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [204][300/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.1500 (0.0796)\tAcc@1 96.875 (98.209)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [204][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0655 (0.0781)\tAcc@1 98.438 (98.286)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [204][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.1442 (0.0785)\tAcc@1 95.312 (98.307)\tAcc@5 100.000 (99.975)\n",
            "Epoch: [204][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0821 (0.0793)\tAcc@1 96.875 (98.253)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [204][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0842 (0.0788)\tAcc@1 100.000 (98.288)\tAcc@5 100.000 (99.978)\n",
            " * Acc@1 98.272 Acc@5 99.978\n",
            "epoch 204, total time 39.79\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.6409 (1.6409)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.022)\tLoss 1.5391 (1.2294)\tAcc@1 68.750 (73.453)\tAcc@5 90.625 (92.017)\n",
            "Test: [200/313]\tTime 0.018 (0.022)\tLoss 0.5768 (1.1989)\tAcc@1 84.375 (73.694)\tAcc@5 100.000 (92.475)\n",
            "Test: [300/313]\tTime 0.018 (0.021)\tLoss 1.1674 (1.1939)\tAcc@1 75.000 (73.754)\tAcc@5 96.875 (92.504)\n",
            " * Acc@1 73.910 Acc@5 92.560\n",
            "==> training...\n",
            "Epoch: [205][0/782]\tTime 0.293 (0.293)\tData 0.202 (0.202)\tLoss 0.1244 (0.1244)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [205][100/782]\tTime 0.049 (0.055)\tData 0.001 (0.003)\tLoss 0.1076 (0.0763)\tAcc@1 96.875 (98.422)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [205][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0556 (0.0764)\tAcc@1 98.438 (98.360)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [205][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0434 (0.0751)\tAcc@1 98.438 (98.370)\tAcc@5 100.000 (99.974)\n",
            "Epoch: [205][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0531 (0.0739)\tAcc@1 100.000 (98.402)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [205][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0576 (0.0750)\tAcc@1 98.438 (98.400)\tAcc@5 100.000 (99.978)\n",
            "Epoch: [205][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0655 (0.0758)\tAcc@1 98.438 (98.365)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [205][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0405 (0.0763)\tAcc@1 100.000 (98.353)\tAcc@5 100.000 (99.975)\n",
            " * Acc@1 98.296 Acc@5 99.974\n",
            "epoch 205, total time 40.13\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.6614 (1.6614)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.4971 (1.2290)\tAcc@1 71.875 (73.484)\tAcc@5 93.750 (92.358)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.6484 (1.2011)\tAcc@1 90.625 (73.989)\tAcc@5 100.000 (92.724)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2283 (1.1958)\tAcc@1 68.750 (73.640)\tAcc@5 100.000 (92.774)\n",
            " * Acc@1 73.880 Acc@5 92.810\n",
            "==> training...\n",
            "Epoch: [206][0/782]\tTime 0.289 (0.289)\tData 0.191 (0.191)\tLoss 0.0294 (0.0294)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [206][100/782]\tTime 0.068 (0.054)\tData 0.001 (0.003)\tLoss 0.0360 (0.0738)\tAcc@1 100.000 (98.314)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [206][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 0.0679 (0.0767)\tAcc@1 98.438 (98.274)\tAcc@5 100.000 (99.953)\n",
            "Epoch: [206][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0949 (0.0756)\tAcc@1 96.875 (98.328)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [206][400/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 0.0890 (0.0755)\tAcc@1 96.875 (98.325)\tAcc@5 100.000 (99.973)\n",
            "Epoch: [206][500/782]\tTime 0.067 (0.051)\tData 0.001 (0.002)\tLoss 0.0664 (0.0748)\tAcc@1 100.000 (98.384)\tAcc@5 100.000 (99.975)\n",
            "Epoch: [206][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0757 (0.0745)\tAcc@1 96.875 (98.401)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [206][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.1054 (0.0749)\tAcc@1 96.875 (98.397)\tAcc@5 100.000 (99.975)\n",
            " * Acc@1 98.400 Acc@5 99.978\n",
            "epoch 206, total time 39.97\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.6420 (1.6420)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.4357 (1.2336)\tAcc@1 68.750 (73.670)\tAcc@5 93.750 (92.265)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.6179 (1.2035)\tAcc@1 84.375 (73.943)\tAcc@5 100.000 (92.786)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.2115 (1.1974)\tAcc@1 75.000 (73.816)\tAcc@5 96.875 (92.753)\n",
            " * Acc@1 73.980 Acc@5 92.790\n",
            "==> training...\n",
            "Epoch: [207][0/782]\tTime 0.268 (0.268)\tData 0.182 (0.182)\tLoss 0.1245 (0.1245)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [207][100/782]\tTime 0.050 (0.054)\tData 0.002 (0.003)\tLoss 0.1174 (0.0750)\tAcc@1 98.438 (98.329)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [207][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0856 (0.0768)\tAcc@1 96.875 (98.259)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [207][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0596 (0.0772)\tAcc@1 100.000 (98.282)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [207][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0239 (0.0750)\tAcc@1 100.000 (98.379)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [207][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0949 (0.0752)\tAcc@1 98.438 (98.375)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [207][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0768 (0.0742)\tAcc@1 98.438 (98.409)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [207][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0554 (0.0743)\tAcc@1 100.000 (98.397)\tAcc@5 100.000 (99.978)\n",
            " * Acc@1 98.402 Acc@5 99.978\n",
            "epoch 207, total time 39.97\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.6702 (1.6702)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.4884 (1.2467)\tAcc@1 68.750 (73.267)\tAcc@5 93.750 (92.110)\n",
            "Test: [200/313]\tTime 0.020 (0.018)\tLoss 0.5871 (1.2171)\tAcc@1 90.625 (73.570)\tAcc@5 100.000 (92.584)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.2289 (1.2075)\tAcc@1 68.750 (73.630)\tAcc@5 96.875 (92.535)\n",
            " * Acc@1 73.790 Acc@5 92.570\n",
            "==> training...\n",
            "Epoch: [208][0/782]\tTime 0.274 (0.274)\tData 0.198 (0.198)\tLoss 0.1048 (0.1048)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [208][100/782]\tTime 0.055 (0.053)\tData 0.001 (0.003)\tLoss 0.0544 (0.0683)\tAcc@1 100.000 (98.654)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [208][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0487 (0.0707)\tAcc@1 98.438 (98.655)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [208][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0450 (0.0715)\tAcc@1 100.000 (98.624)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [208][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0526 (0.0719)\tAcc@1 96.875 (98.574)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [208][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.1464 (0.0714)\tAcc@1 95.312 (98.587)\tAcc@5 98.438 (99.981)\n",
            "Epoch: [208][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0672 (0.0731)\tAcc@1 98.438 (98.536)\tAcc@5 100.000 (99.974)\n",
            "Epoch: [208][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0669 (0.0732)\tAcc@1 98.438 (98.513)\tAcc@5 100.000 (99.973)\n",
            " * Acc@1 98.470 Acc@5 99.972\n",
            "epoch 208, total time 39.70\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.6846 (1.6846)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4858 (1.2390)\tAcc@1 68.750 (73.546)\tAcc@5 93.750 (92.265)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 0.6018 (1.2151)\tAcc@1 87.500 (73.865)\tAcc@5 100.000 (92.475)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1634 (1.2059)\tAcc@1 71.875 (73.951)\tAcc@5 100.000 (92.473)\n",
            " * Acc@1 74.140 Acc@5 92.490\n",
            "==> training...\n",
            "Epoch: [209][0/782]\tTime 0.285 (0.285)\tData 0.197 (0.197)\tLoss 0.0560 (0.0560)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [209][100/782]\tTime 0.055 (0.054)\tData 0.001 (0.003)\tLoss 0.0564 (0.0690)\tAcc@1 100.000 (98.577)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [209][200/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 0.0971 (0.0687)\tAcc@1 96.875 (98.515)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [209][300/782]\tTime 0.054 (0.053)\tData 0.001 (0.002)\tLoss 0.1152 (0.0691)\tAcc@1 95.312 (98.510)\tAcc@5 100.000 (99.974)\n",
            "Epoch: [209][400/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0509 (0.0686)\tAcc@1 100.000 (98.550)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [209][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0418 (0.0697)\tAcc@1 100.000 (98.531)\tAcc@5 100.000 (99.972)\n",
            "Epoch: [209][600/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.0639 (0.0701)\tAcc@1 98.438 (98.515)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [209][700/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0873 (0.0705)\tAcc@1 100.000 (98.511)\tAcc@5 100.000 (99.973)\n",
            " * Acc@1 98.484 Acc@5 99.972\n",
            "epoch 209, total time 40.62\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.7918 (1.7918)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.5251 (1.2579)\tAcc@1 71.875 (73.453)\tAcc@5 93.750 (92.481)\n",
            "Test: [200/313]\tTime 0.029 (0.018)\tLoss 0.5949 (1.2256)\tAcc@1 87.500 (73.881)\tAcc@5 100.000 (92.677)\n",
            "Test: [300/313]\tTime 0.024 (0.019)\tLoss 1.1030 (1.2165)\tAcc@1 71.875 (73.723)\tAcc@5 96.875 (92.701)\n",
            " * Acc@1 73.890 Acc@5 92.730\n",
            "==> training...\n",
            "Epoch: [210][0/782]\tTime 0.273 (0.273)\tData 0.179 (0.179)\tLoss 0.1196 (0.1196)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [210][100/782]\tTime 0.052 (0.054)\tData 0.001 (0.003)\tLoss 0.1119 (0.0698)\tAcc@1 93.750 (98.499)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [210][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.1198 (0.0691)\tAcc@1 95.312 (98.523)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [210][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.1010 (0.0700)\tAcc@1 95.312 (98.500)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [210][400/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.0825 (0.0706)\tAcc@1 96.875 (98.473)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [210][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1044 (0.0707)\tAcc@1 96.875 (98.506)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [210][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0609 (0.0707)\tAcc@1 98.438 (98.489)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [210][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0497 (0.0707)\tAcc@1 100.000 (98.493)\tAcc@5 100.000 (99.984)\n",
            " * Acc@1 98.492 Acc@5 99.986\n",
            "epoch 210, total time 40.26\n",
            "Test: [0/313]\tTime 0.127 (0.127)\tLoss 1.6706 (1.6706)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.021)\tLoss 1.4756 (1.2484)\tAcc@1 71.875 (73.700)\tAcc@5 93.750 (92.234)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.5618 (1.2231)\tAcc@1 87.500 (73.896)\tAcc@5 100.000 (92.646)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1858 (1.2121)\tAcc@1 75.000 (73.910)\tAcc@5 96.875 (92.525)\n",
            " * Acc@1 74.110 Acc@5 92.570\n",
            "==> training...\n",
            "Epoch: [211][0/782]\tTime 0.273 (0.273)\tData 0.195 (0.195)\tLoss 0.0784 (0.0784)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [211][100/782]\tTime 0.052 (0.053)\tData 0.001 (0.003)\tLoss 0.0744 (0.0654)\tAcc@1 98.438 (98.886)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [211][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0554 (0.0684)\tAcc@1 98.438 (98.655)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [211][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0472 (0.0671)\tAcc@1 100.000 (98.671)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [211][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0574 (0.0670)\tAcc@1 100.000 (98.656)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [211][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0657 (0.0670)\tAcc@1 96.875 (98.640)\tAcc@5 100.000 (99.991)\n",
            "Epoch: [211][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0700 (0.0669)\tAcc@1 98.438 (98.661)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [211][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0387 (0.0670)\tAcc@1 100.000 (98.672)\tAcc@5 100.000 (99.989)\n",
            " * Acc@1 98.678 Acc@5 99.990\n",
            "epoch 211, total time 39.65\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.6417 (1.6417)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.4756 (1.2299)\tAcc@1 71.875 (73.453)\tAcc@5 93.750 (92.017)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5514 (1.2073)\tAcc@1 84.375 (73.663)\tAcc@5 100.000 (92.568)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1201 (1.1984)\tAcc@1 71.875 (73.681)\tAcc@5 96.875 (92.598)\n",
            " * Acc@1 73.880 Acc@5 92.640\n",
            "==> training...\n",
            "Epoch: [212][0/782]\tTime 0.287 (0.287)\tData 0.196 (0.196)\tLoss 0.0557 (0.0557)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [212][100/782]\tTime 0.051 (0.052)\tData 0.002 (0.003)\tLoss 0.0423 (0.0705)\tAcc@1 100.000 (98.608)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [212][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0249 (0.0697)\tAcc@1 100.000 (98.577)\tAcc@5 100.000 (99.953)\n",
            "Epoch: [212][300/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0570 (0.0686)\tAcc@1 98.438 (98.635)\tAcc@5 100.000 (99.958)\n",
            "Epoch: [212][400/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 0.0247 (0.0672)\tAcc@1 100.000 (98.706)\tAcc@5 100.000 (99.965)\n",
            "Epoch: [212][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0754 (0.0673)\tAcc@1 98.438 (98.706)\tAcc@5 100.000 (99.972)\n",
            "Epoch: [212][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0946 (0.0678)\tAcc@1 96.875 (98.674)\tAcc@5 100.000 (99.971)\n",
            "Epoch: [212][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0918 (0.0669)\tAcc@1 96.875 (98.698)\tAcc@5 100.000 (99.973)\n",
            " * Acc@1 98.710 Acc@5 99.976\n",
            "epoch 212, total time 39.61\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.6587 (1.6587)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.4861 (1.2428)\tAcc@1 71.875 (73.762)\tAcc@5 93.750 (92.327)\n",
            "Test: [200/313]\tTime 0.025 (0.019)\tLoss 0.5648 (1.2197)\tAcc@1 87.500 (73.818)\tAcc@5 100.000 (92.662)\n",
            "Test: [300/313]\tTime 0.018 (0.020)\tLoss 1.1906 (1.2094)\tAcc@1 68.750 (73.661)\tAcc@5 96.875 (92.535)\n",
            " * Acc@1 73.890 Acc@5 92.580\n",
            "==> training...\n",
            "Epoch: [213][0/782]\tTime 0.277 (0.277)\tData 0.194 (0.194)\tLoss 0.0454 (0.0454)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [213][100/782]\tTime 0.051 (0.052)\tData 0.001 (0.003)\tLoss 0.0351 (0.0621)\tAcc@1 100.000 (98.762)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [213][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0348 (0.0620)\tAcc@1 100.000 (98.772)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [213][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0282 (0.0623)\tAcc@1 100.000 (98.754)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [213][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0921 (0.0633)\tAcc@1 96.875 (98.714)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [213][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0436 (0.0634)\tAcc@1 100.000 (98.721)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [213][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0460 (0.0642)\tAcc@1 100.000 (98.695)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [213][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0662 (0.0648)\tAcc@1 100.000 (98.676)\tAcc@5 100.000 (99.984)\n",
            " * Acc@1 98.670 Acc@5 99.982\n",
            "epoch 213, total time 39.81\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.7312 (1.7312)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.025 (0.020)\tLoss 1.5436 (1.2423)\tAcc@1 68.750 (73.762)\tAcc@5 93.750 (92.420)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.5779 (1.2205)\tAcc@1 87.500 (74.005)\tAcc@5 100.000 (92.755)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.0969 (1.2111)\tAcc@1 71.875 (74.055)\tAcc@5 96.875 (92.691)\n",
            " * Acc@1 74.210 Acc@5 92.750\n",
            "==> training...\n",
            "Epoch: [214][0/782]\tTime 0.286 (0.286)\tData 0.203 (0.203)\tLoss 0.0587 (0.0587)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [214][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.0430 (0.0628)\tAcc@1 100.000 (98.731)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [214][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0646 (0.0654)\tAcc@1 100.000 (98.671)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [214][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0796 (0.0650)\tAcc@1 98.438 (98.671)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [214][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0523 (0.0645)\tAcc@1 100.000 (98.702)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [214][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0595 (0.0644)\tAcc@1 98.438 (98.715)\tAcc@5 100.000 (99.991)\n",
            "Epoch: [214][600/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 0.0449 (0.0635)\tAcc@1 100.000 (98.752)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [214][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0329 (0.0640)\tAcc@1 100.000 (98.752)\tAcc@5 100.000 (99.989)\n",
            " * Acc@1 98.776 Acc@5 99.990\n",
            "epoch 214, total time 39.89\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.6902 (1.6902)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.5108 (1.2433)\tAcc@1 68.750 (73.608)\tAcc@5 93.750 (91.863)\n",
            "Test: [200/313]\tTime 0.019 (0.020)\tLoss 0.6036 (1.2245)\tAcc@1 84.375 (73.694)\tAcc@5 100.000 (92.351)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.1091 (1.2170)\tAcc@1 71.875 (73.723)\tAcc@5 96.875 (92.338)\n",
            " * Acc@1 73.890 Acc@5 92.400\n",
            "==> training...\n",
            "Epoch: [215][0/782]\tTime 0.293 (0.293)\tData 0.201 (0.201)\tLoss 0.0548 (0.0548)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [215][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.1255 (0.0625)\tAcc@1 95.312 (98.762)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [215][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0694 (0.0617)\tAcc@1 98.438 (98.834)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [215][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0331 (0.0614)\tAcc@1 100.000 (98.858)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [215][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0728 (0.0629)\tAcc@1 98.438 (98.823)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [215][500/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0418 (0.0625)\tAcc@1 100.000 (98.824)\tAcc@5 100.000 (99.978)\n",
            "Epoch: [215][600/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0474 (0.0621)\tAcc@1 100.000 (98.827)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [215][700/782]\tTime 0.057 (0.051)\tData 0.001 (0.002)\tLoss 0.0908 (0.0627)\tAcc@1 96.875 (98.803)\tAcc@5 100.000 (99.975)\n",
            " * Acc@1 98.804 Acc@5 99.978\n",
            "epoch 215, total time 40.04\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.7096 (1.7096)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.5197 (1.2442)\tAcc@1 71.875 (73.577)\tAcc@5 93.750 (91.986)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5716 (1.2195)\tAcc@1 87.500 (73.834)\tAcc@5 100.000 (92.475)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1304 (1.2085)\tAcc@1 78.125 (73.931)\tAcc@5 96.875 (92.483)\n",
            " * Acc@1 74.110 Acc@5 92.550\n",
            "==> training...\n",
            "Epoch: [216][0/782]\tTime 0.275 (0.275)\tData 0.191 (0.191)\tLoss 0.0443 (0.0443)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [216][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 0.1067 (0.0559)\tAcc@1 96.875 (99.025)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [216][200/782]\tTime 0.049 (0.054)\tData 0.001 (0.002)\tLoss 0.1224 (0.0589)\tAcc@1 95.312 (99.005)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [216][300/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.0471 (0.0614)\tAcc@1 100.000 (98.946)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [216][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0774 (0.0627)\tAcc@1 98.438 (98.839)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [216][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0569 (0.0632)\tAcc@1 100.000 (98.830)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [216][600/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0879 (0.0626)\tAcc@1 96.875 (98.864)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [216][700/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0840 (0.0625)\tAcc@1 95.312 (98.886)\tAcc@5 100.000 (99.987)\n",
            " * Acc@1 98.890 Acc@5 99.984\n",
            "epoch 216, total time 40.26\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.7125 (1.7125)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.5158 (1.2421)\tAcc@1 68.750 (73.577)\tAcc@5 93.750 (92.048)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5862 (1.2169)\tAcc@1 84.375 (73.694)\tAcc@5 100.000 (92.662)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.1445 (1.2076)\tAcc@1 71.875 (73.733)\tAcc@5 96.875 (92.556)\n",
            " * Acc@1 73.930 Acc@5 92.610\n",
            "==> training...\n",
            "Epoch: [217][0/782]\tTime 0.286 (0.286)\tData 0.201 (0.201)\tLoss 0.0400 (0.0400)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [217][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.0512 (0.0636)\tAcc@1 98.438 (98.685)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [217][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.0418 (0.0638)\tAcc@1 98.438 (98.710)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [217][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0409 (0.0626)\tAcc@1 100.000 (98.744)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [217][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.1060 (0.0630)\tAcc@1 96.875 (98.741)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [217][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0412 (0.0636)\tAcc@1 100.000 (98.693)\tAcc@5 100.000 (99.994)\n",
            "Epoch: [217][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0843 (0.0641)\tAcc@1 98.438 (98.697)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [217][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0739 (0.0645)\tAcc@1 96.875 (98.689)\tAcc@5 100.000 (99.987)\n",
            " * Acc@1 98.702 Acc@5 99.986\n",
            "epoch 217, total time 40.62\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.6590 (1.6590)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5654 (1.2411)\tAcc@1 68.750 (73.577)\tAcc@5 93.750 (92.048)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 0.6164 (1.2190)\tAcc@1 81.250 (73.694)\tAcc@5 100.000 (92.475)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1789 (1.2112)\tAcc@1 65.625 (73.671)\tAcc@5 96.875 (92.525)\n",
            " * Acc@1 73.860 Acc@5 92.560\n",
            "==> training...\n",
            "Epoch: [218][0/782]\tTime 0.278 (0.278)\tData 0.196 (0.196)\tLoss 0.0674 (0.0674)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [218][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.0506 (0.0624)\tAcc@1 100.000 (98.731)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [218][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0623 (0.0619)\tAcc@1 98.438 (98.733)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [218][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0237 (0.0613)\tAcc@1 100.000 (98.749)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [218][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0997 (0.0627)\tAcc@1 98.438 (98.718)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [218][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0794 (0.0624)\tAcc@1 96.875 (98.706)\tAcc@5 100.000 (99.991)\n",
            "Epoch: [218][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0903 (0.0626)\tAcc@1 100.000 (98.742)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [218][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0492 (0.0617)\tAcc@1 100.000 (98.787)\tAcc@5 100.000 (99.989)\n",
            " * Acc@1 98.766 Acc@5 99.986\n",
            "epoch 218, total time 39.77\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 1.6751 (1.6751)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5158 (1.2487)\tAcc@1 71.875 (73.886)\tAcc@5 93.750 (91.986)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.6048 (1.2189)\tAcc@1 84.375 (73.943)\tAcc@5 100.000 (92.568)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1421 (1.2115)\tAcc@1 71.875 (73.816)\tAcc@5 100.000 (92.463)\n",
            " * Acc@1 74.000 Acc@5 92.520\n",
            "==> training...\n",
            "Epoch: [219][0/782]\tTime 0.277 (0.277)\tData 0.182 (0.182)\tLoss 0.0333 (0.0333)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [219][100/782]\tTime 0.048 (0.052)\tData 0.001 (0.003)\tLoss 0.0718 (0.0589)\tAcc@1 98.438 (99.025)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [219][200/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 0.0442 (0.0610)\tAcc@1 98.438 (98.857)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [219][300/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 0.0574 (0.0598)\tAcc@1 100.000 (98.920)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [219][400/782]\tTime 0.070 (0.051)\tData 0.001 (0.002)\tLoss 0.0413 (0.0614)\tAcc@1 98.438 (98.843)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [219][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0362 (0.0613)\tAcc@1 100.000 (98.824)\tAcc@5 100.000 (99.991)\n",
            "Epoch: [219][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0774 (0.0617)\tAcc@1 98.438 (98.804)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [219][700/782]\tTime 0.049 (0.050)\tData 0.001 (0.002)\tLoss 0.0562 (0.0615)\tAcc@1 98.438 (98.808)\tAcc@5 100.000 (99.984)\n",
            " * Acc@1 98.800 Acc@5 99.986\n",
            "epoch 219, total time 39.50\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.6467 (1.6467)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.5240 (1.2559)\tAcc@1 68.750 (73.546)\tAcc@5 93.750 (91.894)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.5562 (1.2280)\tAcc@1 87.500 (73.896)\tAcc@5 100.000 (92.568)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1614 (1.2178)\tAcc@1 65.625 (73.879)\tAcc@5 96.875 (92.525)\n",
            " * Acc@1 74.050 Acc@5 92.600\n",
            "==> training...\n",
            "Epoch: [220][0/782]\tTime 0.248 (0.248)\tData 0.177 (0.177)\tLoss 0.1061 (0.1061)\tAcc@1 93.750 (93.750)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [220][100/782]\tTime 0.050 (0.052)\tData 0.001 (0.003)\tLoss 0.0362 (0.0628)\tAcc@1 100.000 (98.716)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [220][200/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0243 (0.0619)\tAcc@1 100.000 (98.803)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [220][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0557 (0.0616)\tAcc@1 100.000 (98.749)\tAcc@5 100.000 (99.995)\n",
            "Epoch: [220][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0713 (0.0622)\tAcc@1 96.875 (98.730)\tAcc@5 100.000 (99.996)\n",
            "Epoch: [220][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0523 (0.0627)\tAcc@1 98.438 (98.724)\tAcc@5 100.000 (99.991)\n",
            "Epoch: [220][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0956 (0.0622)\tAcc@1 98.438 (98.768)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [220][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0294 (0.0623)\tAcc@1 100.000 (98.774)\tAcc@5 100.000 (99.984)\n",
            " * Acc@1 98.786 Acc@5 99.986\n",
            "epoch 220, total time 39.54\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.7480 (1.7480)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.024 (0.020)\tLoss 1.5641 (1.2447)\tAcc@1 68.750 (73.855)\tAcc@5 93.750 (91.925)\n",
            "Test: [200/313]\tTime 0.025 (0.020)\tLoss 0.6435 (1.2232)\tAcc@1 81.250 (73.989)\tAcc@5 100.000 (92.351)\n",
            "Test: [300/313]\tTime 0.024 (0.020)\tLoss 1.0791 (1.2142)\tAcc@1 71.875 (73.993)\tAcc@5 96.875 (92.390)\n",
            " * Acc@1 74.180 Acc@5 92.450\n",
            "==> training...\n",
            "Epoch: [221][0/782]\tTime 0.266 (0.266)\tData 0.179 (0.179)\tLoss 0.0359 (0.0359)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [221][100/782]\tTime 0.049 (0.052)\tData 0.001 (0.003)\tLoss 0.1044 (0.0646)\tAcc@1 98.438 (98.824)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [221][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0267 (0.0606)\tAcc@1 100.000 (98.951)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [221][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0757 (0.0606)\tAcc@1 96.875 (98.925)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [221][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0204 (0.0612)\tAcc@1 100.000 (98.889)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [221][500/782]\tTime 0.053 (0.051)\tData 0.001 (0.002)\tLoss 0.0562 (0.0620)\tAcc@1 96.875 (98.827)\tAcc@5 100.000 (99.994)\n",
            "Epoch: [221][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0637 (0.0625)\tAcc@1 98.438 (98.781)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [221][700/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 0.0745 (0.0624)\tAcc@1 96.875 (98.772)\tAcc@5 100.000 (99.991)\n",
            " * Acc@1 98.792 Acc@5 99.992\n",
            "epoch 221, total time 39.75\n",
            "Test: [0/313]\tTime 0.115 (0.115)\tLoss 1.6989 (1.6989)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.5045 (1.2433)\tAcc@1 68.750 (73.700)\tAcc@5 93.750 (92.327)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5552 (1.2160)\tAcc@1 90.625 (73.989)\tAcc@5 100.000 (92.786)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.0987 (1.2044)\tAcc@1 75.000 (74.034)\tAcc@5 96.875 (92.753)\n",
            " * Acc@1 74.190 Acc@5 92.790\n",
            "==> training...\n",
            "Epoch: [222][0/782]\tTime 0.276 (0.276)\tData 0.184 (0.184)\tLoss 0.0962 (0.0962)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [222][100/782]\tTime 0.053 (0.053)\tData 0.001 (0.003)\tLoss 0.0394 (0.0625)\tAcc@1 98.438 (98.778)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [222][200/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0573 (0.0619)\tAcc@1 96.875 (98.811)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [222][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0569 (0.0613)\tAcc@1 100.000 (98.848)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [222][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0570 (0.0610)\tAcc@1 98.438 (98.862)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [222][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.2349 (0.0617)\tAcc@1 93.750 (98.806)\tAcc@5 98.438 (99.978)\n",
            "Epoch: [222][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0607 (0.0615)\tAcc@1 100.000 (98.820)\tAcc@5 100.000 (99.982)\n",
            "Epoch: [222][700/782]\tTime 0.058 (0.051)\tData 0.001 (0.002)\tLoss 0.0510 (0.0613)\tAcc@1 98.438 (98.830)\tAcc@5 100.000 (99.984)\n",
            " * Acc@1 98.828 Acc@5 99.982\n",
            "epoch 222, total time 39.80\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.7255 (1.7255)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.5399 (1.2414)\tAcc@1 68.750 (73.700)\tAcc@5 93.750 (92.234)\n",
            "Test: [200/313]\tTime 0.021 (0.018)\tLoss 0.5818 (1.2151)\tAcc@1 87.500 (73.818)\tAcc@5 100.000 (92.662)\n",
            "Test: [300/313]\tTime 0.019 (0.018)\tLoss 1.1640 (1.2056)\tAcc@1 71.875 (73.754)\tAcc@5 100.000 (92.660)\n",
            " * Acc@1 73.930 Acc@5 92.690\n",
            "==> training...\n",
            "Epoch: [223][0/782]\tTime 0.266 (0.266)\tData 0.184 (0.184)\tLoss 0.0556 (0.0556)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [223][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.0240 (0.0610)\tAcc@1 100.000 (98.963)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [223][200/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0936 (0.0614)\tAcc@1 98.438 (98.873)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [223][300/782]\tTime 0.048 (0.051)\tData 0.001 (0.002)\tLoss 0.0637 (0.0594)\tAcc@1 100.000 (98.931)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [223][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0775 (0.0610)\tAcc@1 96.875 (98.866)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [223][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0664 (0.0610)\tAcc@1 96.875 (98.846)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [223][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0411 (0.0610)\tAcc@1 100.000 (98.877)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [223][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1869 (0.0602)\tAcc@1 96.875 (98.923)\tAcc@5 100.000 (99.987)\n",
            " * Acc@1 98.922 Acc@5 99.988\n",
            "epoch 223, total time 39.59\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.7346 (1.7346)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.5444 (1.2465)\tAcc@1 68.750 (73.731)\tAcc@5 93.750 (91.863)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 0.6193 (1.2209)\tAcc@1 84.375 (73.881)\tAcc@5 100.000 (92.397)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.0559 (1.2080)\tAcc@1 75.000 (73.899)\tAcc@5 96.875 (92.473)\n",
            " * Acc@1 74.070 Acc@5 92.510\n",
            "==> training...\n",
            "Epoch: [224][0/782]\tTime 0.294 (0.294)\tData 0.209 (0.209)\tLoss 0.0457 (0.0457)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [224][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.0938 (0.0629)\tAcc@1 95.312 (98.762)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [224][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0693 (0.0622)\tAcc@1 100.000 (98.873)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [224][300/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0328 (0.0625)\tAcc@1 100.000 (98.801)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [224][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0472 (0.0617)\tAcc@1 100.000 (98.870)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [224][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0451 (0.0616)\tAcc@1 98.438 (98.862)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [224][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0520 (0.0611)\tAcc@1 98.438 (98.879)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [224][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.1709 (0.0616)\tAcc@1 95.312 (98.870)\tAcc@5 100.000 (99.989)\n",
            " * Acc@1 98.890 Acc@5 99.990\n",
            "epoch 224, total time 39.84\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.7216 (1.7216)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.019 (0.020)\tLoss 1.5413 (1.2564)\tAcc@1 68.750 (73.360)\tAcc@5 93.750 (92.017)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.6119 (1.2227)\tAcc@1 84.375 (74.005)\tAcc@5 100.000 (92.506)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1520 (1.2150)\tAcc@1 78.125 (74.045)\tAcc@5 96.875 (92.473)\n",
            " * Acc@1 74.180 Acc@5 92.530\n",
            "==> training...\n",
            "Epoch: [225][0/782]\tTime 0.284 (0.284)\tData 0.206 (0.206)\tLoss 0.0516 (0.0516)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [225][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.0412 (0.0591)\tAcc@1 100.000 (98.917)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [225][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0797 (0.0584)\tAcc@1 98.438 (98.982)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [225][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0676 (0.0594)\tAcc@1 98.438 (98.931)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [225][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0491 (0.0597)\tAcc@1 98.438 (98.921)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [225][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0906 (0.0594)\tAcc@1 98.438 (98.952)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [225][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0467 (0.0594)\tAcc@1 100.000 (98.937)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [225][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0653 (0.0599)\tAcc@1 100.000 (98.921)\tAcc@5 100.000 (99.989)\n",
            " * Acc@1 98.960 Acc@5 99.990\n",
            "epoch 225, total time 39.80\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 1.6846 (1.6846)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.5215 (1.2494)\tAcc@1 68.750 (73.453)\tAcc@5 93.750 (92.110)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.6120 (1.2260)\tAcc@1 78.125 (73.678)\tAcc@5 100.000 (92.600)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.2545 (1.2185)\tAcc@1 71.875 (73.733)\tAcc@5 96.875 (92.556)\n",
            " * Acc@1 73.930 Acc@5 92.610\n",
            "==> training...\n",
            "Epoch: [226][0/782]\tTime 0.285 (0.285)\tData 0.214 (0.214)\tLoss 0.0323 (0.0323)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [226][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 0.1242 (0.0614)\tAcc@1 98.438 (98.855)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [226][200/782]\tTime 0.051 (0.052)\tData 0.002 (0.002)\tLoss 0.0375 (0.0610)\tAcc@1 98.438 (98.811)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [226][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0573 (0.0605)\tAcc@1 100.000 (98.863)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [226][400/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0223 (0.0599)\tAcc@1 100.000 (98.909)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [226][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0430 (0.0607)\tAcc@1 98.438 (98.862)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [226][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0950 (0.0617)\tAcc@1 96.875 (98.820)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [226][700/782]\tTime 0.052 (0.051)\tData 0.001 (0.002)\tLoss 0.0480 (0.0623)\tAcc@1 100.000 (98.785)\tAcc@5 100.000 (99.984)\n",
            " * Acc@1 98.800 Acc@5 99.986\n",
            "epoch 226, total time 39.81\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.7347 (1.7347)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.5289 (1.2461)\tAcc@1 68.750 (74.010)\tAcc@5 93.750 (91.894)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 0.5666 (1.2209)\tAcc@1 84.375 (74.052)\tAcc@5 100.000 (92.460)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.1613 (1.2123)\tAcc@1 75.000 (74.034)\tAcc@5 100.000 (92.442)\n",
            " * Acc@1 74.250 Acc@5 92.490\n",
            "==> training...\n",
            "Epoch: [227][0/782]\tTime 0.269 (0.269)\tData 0.187 (0.187)\tLoss 0.0884 (0.0884)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [227][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 0.0672 (0.0598)\tAcc@1 98.438 (98.979)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [227][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0524 (0.0604)\tAcc@1 98.438 (98.873)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [227][300/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0641 (0.0586)\tAcc@1 98.438 (98.941)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [227][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0719 (0.0581)\tAcc@1 96.875 (98.948)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [227][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0346 (0.0583)\tAcc@1 100.000 (98.952)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [227][600/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0638 (0.0583)\tAcc@1 98.438 (98.939)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [227][700/782]\tTime 0.054 (0.052)\tData 0.001 (0.002)\tLoss 0.0803 (0.0589)\tAcc@1 98.438 (98.919)\tAcc@5 100.000 (99.984)\n",
            " * Acc@1 98.872 Acc@5 99.986\n",
            "epoch 227, total time 40.38\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 1.7494 (1.7494)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.5094 (1.2577)\tAcc@1 71.875 (73.360)\tAcc@5 93.750 (91.955)\n",
            "Test: [200/313]\tTime 0.021 (0.018)\tLoss 0.6263 (1.2325)\tAcc@1 84.375 (73.632)\tAcc@5 100.000 (92.382)\n",
            "Test: [300/313]\tTime 0.018 (0.018)\tLoss 1.1631 (1.2276)\tAcc@1 75.000 (73.526)\tAcc@5 96.875 (92.380)\n",
            " * Acc@1 73.690 Acc@5 92.420\n",
            "==> training...\n",
            "Epoch: [228][0/782]\tTime 0.281 (0.281)\tData 0.195 (0.195)\tLoss 0.0670 (0.0670)\tAcc@1 95.312 (95.312)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [228][100/782]\tTime 0.052 (0.054)\tData 0.001 (0.003)\tLoss 0.0243 (0.0550)\tAcc@1 100.000 (99.041)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [228][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0992 (0.0582)\tAcc@1 98.438 (98.943)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [228][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0293 (0.0613)\tAcc@1 100.000 (98.822)\tAcc@5 100.000 (99.974)\n",
            "Epoch: [228][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0261 (0.0624)\tAcc@1 100.000 (98.761)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [228][500/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0371 (0.0615)\tAcc@1 100.000 (98.784)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [228][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0729 (0.0616)\tAcc@1 98.438 (98.781)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [228][700/782]\tTime 0.073 (0.051)\tData 0.001 (0.002)\tLoss 0.1115 (0.0614)\tAcc@1 96.875 (98.785)\tAcc@5 98.438 (99.982)\n",
            " * Acc@1 98.796 Acc@5 99.980\n",
            "epoch 228, total time 40.20\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 1.7865 (1.7865)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.4949 (1.2602)\tAcc@1 71.875 (73.639)\tAcc@5 93.750 (91.863)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.6445 (1.2290)\tAcc@1 81.250 (73.927)\tAcc@5 100.000 (92.475)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1377 (1.2232)\tAcc@1 71.875 (73.796)\tAcc@5 96.875 (92.421)\n",
            " * Acc@1 73.960 Acc@5 92.460\n",
            "==> training...\n",
            "Epoch: [229][0/782]\tTime 0.277 (0.277)\tData 0.195 (0.195)\tLoss 0.0758 (0.0758)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [229][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 0.0588 (0.0565)\tAcc@1 100.000 (99.056)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [229][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0482 (0.0589)\tAcc@1 98.438 (98.881)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [229][300/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0423 (0.0590)\tAcc@1 100.000 (98.874)\tAcc@5 100.000 (99.995)\n",
            "Epoch: [229][400/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0724 (0.0597)\tAcc@1 100.000 (98.839)\tAcc@5 100.000 (99.996)\n",
            "Epoch: [229][500/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0470 (0.0593)\tAcc@1 100.000 (98.877)\tAcc@5 100.000 (99.991)\n",
            "Epoch: [229][600/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0686 (0.0591)\tAcc@1 98.438 (98.921)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [229][700/782]\tTime 0.074 (0.052)\tData 0.001 (0.002)\tLoss 0.0431 (0.0596)\tAcc@1 100.000 (98.901)\tAcc@5 100.000 (99.991)\n",
            " * Acc@1 98.886 Acc@5 99.990\n",
            "epoch 229, total time 40.56\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 1.7248 (1.7248)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 1.4796 (1.2500)\tAcc@1 71.875 (73.422)\tAcc@5 93.750 (91.986)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.6212 (1.2252)\tAcc@1 87.500 (73.772)\tAcc@5 100.000 (92.506)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.1903 (1.2185)\tAcc@1 71.875 (73.702)\tAcc@5 96.875 (92.483)\n",
            " * Acc@1 73.880 Acc@5 92.540\n",
            "==> training...\n",
            "Epoch: [230][0/782]\tTime 0.293 (0.293)\tData 0.211 (0.211)\tLoss 0.1018 (0.1018)\tAcc@1 96.875 (96.875)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [230][100/782]\tTime 0.051 (0.055)\tData 0.001 (0.003)\tLoss 0.0235 (0.0580)\tAcc@1 100.000 (98.762)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [230][200/782]\tTime 0.052 (0.054)\tData 0.001 (0.002)\tLoss 0.0357 (0.0602)\tAcc@1 98.438 (98.717)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [230][300/782]\tTime 0.052 (0.053)\tData 0.001 (0.002)\tLoss 0.0812 (0.0607)\tAcc@1 96.875 (98.728)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [230][400/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.0436 (0.0598)\tAcc@1 100.000 (98.804)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [230][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0521 (0.0597)\tAcc@1 100.000 (98.784)\tAcc@5 100.000 (99.991)\n",
            "Epoch: [230][600/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0824 (0.0598)\tAcc@1 98.438 (98.773)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [230][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1017 (0.0601)\tAcc@1 96.875 (98.763)\tAcc@5 100.000 (99.987)\n",
            " * Acc@1 98.770 Acc@5 99.986\n",
            "epoch 230, total time 40.43\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.7807 (1.7807)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.5202 (1.2515)\tAcc@1 68.750 (73.670)\tAcc@5 93.750 (92.017)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.6303 (1.2254)\tAcc@1 81.250 (73.912)\tAcc@5 100.000 (92.397)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1499 (1.2161)\tAcc@1 75.000 (73.983)\tAcc@5 96.875 (92.338)\n",
            " * Acc@1 74.120 Acc@5 92.400\n",
            "==> training...\n",
            "Epoch: [231][0/782]\tTime 0.268 (0.268)\tData 0.181 (0.181)\tLoss 0.0422 (0.0422)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [231][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.0586 (0.0612)\tAcc@1 100.000 (98.855)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [231][200/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0584 (0.0600)\tAcc@1 98.438 (98.873)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [231][300/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0535 (0.0601)\tAcc@1 100.000 (98.874)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [231][400/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0416 (0.0596)\tAcc@1 100.000 (98.921)\tAcc@5 100.000 (99.977)\n",
            "Epoch: [231][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0420 (0.0595)\tAcc@1 100.000 (98.930)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [231][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0831 (0.0589)\tAcc@1 98.438 (98.934)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [231][700/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0778 (0.0598)\tAcc@1 98.438 (98.874)\tAcc@5 100.000 (99.987)\n",
            " * Acc@1 98.858 Acc@5 99.988\n",
            "epoch 231, total time 40.18\n",
            "Test: [0/313]\tTime 0.124 (0.124)\tLoss 1.7215 (1.7215)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4472 (1.2481)\tAcc@1 68.750 (73.670)\tAcc@5 93.750 (92.048)\n",
            "Test: [200/313]\tTime 0.017 (0.019)\tLoss 0.6172 (1.2199)\tAcc@1 87.500 (73.974)\tAcc@5 100.000 (92.646)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 1.1419 (1.2092)\tAcc@1 71.875 (73.899)\tAcc@5 96.875 (92.618)\n",
            " * Acc@1 74.070 Acc@5 92.650\n",
            "==> training...\n",
            "Epoch: [232][0/782]\tTime 0.270 (0.270)\tData 0.185 (0.185)\tLoss 0.0295 (0.0295)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [232][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.0903 (0.0588)\tAcc@1 98.438 (98.948)\tAcc@5 100.000 (99.954)\n",
            "Epoch: [232][200/782]\tTime 0.051 (0.054)\tData 0.001 (0.002)\tLoss 0.0360 (0.0592)\tAcc@1 100.000 (98.873)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [232][300/782]\tTime 0.049 (0.054)\tData 0.001 (0.002)\tLoss 0.0444 (0.0580)\tAcc@1 100.000 (98.951)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [232][400/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 0.0451 (0.0583)\tAcc@1 100.000 (98.944)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [232][500/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 0.0672 (0.0593)\tAcc@1 98.438 (98.890)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [232][600/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0578 (0.0590)\tAcc@1 98.438 (98.887)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [232][700/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0299 (0.0594)\tAcc@1 100.000 (98.888)\tAcc@5 100.000 (99.989)\n",
            " * Acc@1 98.884 Acc@5 99.990\n",
            "epoch 232, total time 41.24\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.7535 (1.7535)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5426 (1.2606)\tAcc@1 68.750 (73.762)\tAcc@5 93.750 (92.017)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.6509 (1.2327)\tAcc@1 81.250 (73.865)\tAcc@5 100.000 (92.491)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.0827 (1.2248)\tAcc@1 75.000 (73.816)\tAcc@5 96.875 (92.369)\n",
            " * Acc@1 73.980 Acc@5 92.430\n",
            "==> training...\n",
            "Epoch: [233][0/782]\tTime 0.279 (0.279)\tData 0.187 (0.187)\tLoss 0.0526 (0.0526)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [233][100/782]\tTime 0.050 (0.056)\tData 0.001 (0.003)\tLoss 0.0773 (0.0589)\tAcc@1 98.438 (98.855)\tAcc@5 100.000 (99.985)\n",
            "Epoch: [233][200/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0552 (0.0618)\tAcc@1 100.000 (98.803)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [233][300/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.0537 (0.0602)\tAcc@1 100.000 (98.842)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [233][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0608 (0.0601)\tAcc@1 98.438 (98.823)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [233][500/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0593 (0.0601)\tAcc@1 98.438 (98.834)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [233][600/782]\tTime 0.052 (0.052)\tData 0.002 (0.002)\tLoss 0.0566 (0.0598)\tAcc@1 98.438 (98.848)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [233][700/782]\tTime 0.057 (0.052)\tData 0.001 (0.002)\tLoss 0.0158 (0.0601)\tAcc@1 100.000 (98.834)\tAcc@5 100.000 (99.987)\n",
            " * Acc@1 98.806 Acc@5 99.988\n",
            "epoch 233, total time 40.50\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.7815 (1.7815)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.5564 (1.2524)\tAcc@1 68.750 (73.422)\tAcc@5 93.750 (92.172)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5653 (1.2213)\tAcc@1 90.625 (73.943)\tAcc@5 100.000 (92.553)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.0832 (1.2097)\tAcc@1 75.000 (74.003)\tAcc@5 96.875 (92.473)\n",
            " * Acc@1 74.170 Acc@5 92.490\n",
            "==> training...\n",
            "Epoch: [234][0/782]\tTime 0.283 (0.283)\tData 0.202 (0.202)\tLoss 0.0678 (0.0678)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [234][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.2052 (0.0632)\tAcc@1 93.750 (98.685)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [234][200/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0604 (0.0605)\tAcc@1 98.438 (98.834)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [234][300/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0457 (0.0600)\tAcc@1 98.438 (98.884)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [234][400/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0307 (0.0595)\tAcc@1 100.000 (98.960)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [234][500/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0371 (0.0596)\tAcc@1 100.000 (98.971)\tAcc@5 100.000 (99.991)\n",
            "Epoch: [234][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0647 (0.0596)\tAcc@1 98.438 (98.942)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [234][700/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0782 (0.0594)\tAcc@1 100.000 (98.946)\tAcc@5 100.000 (99.991)\n",
            " * Acc@1 98.916 Acc@5 99.988\n",
            "epoch 234, total time 39.90\n",
            "Test: [0/313]\tTime 0.118 (0.118)\tLoss 1.7022 (1.7022)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.5708 (1.2652)\tAcc@1 68.750 (73.205)\tAcc@5 93.750 (92.296)\n",
            "Test: [200/313]\tTime 0.018 (0.018)\tLoss 0.6189 (1.2383)\tAcc@1 84.375 (73.616)\tAcc@5 100.000 (92.631)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1722 (1.2278)\tAcc@1 68.750 (73.609)\tAcc@5 96.875 (92.515)\n",
            " * Acc@1 73.770 Acc@5 92.550\n",
            "==> training...\n",
            "Epoch: [235][0/782]\tTime 0.270 (0.270)\tData 0.184 (0.184)\tLoss 0.0496 (0.0496)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [235][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.0230 (0.0591)\tAcc@1 100.000 (99.025)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [235][200/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0523 (0.0589)\tAcc@1 96.875 (98.927)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [235][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0250 (0.0594)\tAcc@1 100.000 (98.848)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [235][400/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0688 (0.0595)\tAcc@1 100.000 (98.827)\tAcc@5 100.000 (99.992)\n",
            "Epoch: [235][500/782]\tTime 0.051 (0.051)\tData 0.002 (0.002)\tLoss 0.0828 (0.0593)\tAcc@1 96.875 (98.837)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [235][600/782]\tTime 0.050 (0.051)\tData 0.001 (0.002)\tLoss 0.0440 (0.0595)\tAcc@1 100.000 (98.835)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [235][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0708 (0.0597)\tAcc@1 96.875 (98.814)\tAcc@5 100.000 (99.987)\n",
            " * Acc@1 98.834 Acc@5 99.988\n",
            "epoch 235, total time 39.85\n",
            "Test: [0/313]\tTime 0.121 (0.121)\tLoss 1.7631 (1.7631)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.021)\tLoss 1.5243 (1.2549)\tAcc@1 68.750 (73.917)\tAcc@5 93.750 (92.048)\n",
            "Test: [200/313]\tTime 0.018 (0.020)\tLoss 0.5980 (1.2291)\tAcc@1 87.500 (74.098)\tAcc@5 100.000 (92.491)\n",
            "Test: [300/313]\tTime 0.019 (0.020)\tLoss 1.1611 (1.2211)\tAcc@1 71.875 (73.910)\tAcc@5 96.875 (92.473)\n",
            " * Acc@1 74.060 Acc@5 92.520\n",
            "==> training...\n",
            "Epoch: [236][0/782]\tTime 0.281 (0.281)\tData 0.198 (0.198)\tLoss 0.0445 (0.0445)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [236][100/782]\tTime 0.068 (0.054)\tData 0.001 (0.003)\tLoss 0.0827 (0.0587)\tAcc@1 98.438 (98.886)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [236][200/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0223 (0.0585)\tAcc@1 100.000 (98.935)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [236][300/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0478 (0.0587)\tAcc@1 100.000 (98.905)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [236][400/782]\tTime 0.051 (0.052)\tData 0.001 (0.002)\tLoss 0.0630 (0.0576)\tAcc@1 96.875 (98.948)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [236][500/782]\tTime 0.054 (0.051)\tData 0.001 (0.002)\tLoss 0.0551 (0.0579)\tAcc@1 98.438 (98.955)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [236][600/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0740 (0.0579)\tAcc@1 98.438 (98.957)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [236][700/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0662 (0.0577)\tAcc@1 96.875 (98.970)\tAcc@5 100.000 (99.989)\n",
            " * Acc@1 98.968 Acc@5 99.990\n",
            "epoch 236, total time 40.14\n",
            "Test: [0/313]\tTime 0.120 (0.120)\tLoss 1.7245 (1.7245)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.018 (0.019)\tLoss 1.5499 (1.2649)\tAcc@1 71.875 (73.360)\tAcc@5 93.750 (91.863)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.6230 (1.2376)\tAcc@1 81.250 (73.710)\tAcc@5 100.000 (92.366)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1978 (1.2313)\tAcc@1 71.875 (73.567)\tAcc@5 96.875 (92.276)\n",
            " * Acc@1 73.730 Acc@5 92.340\n",
            "==> training...\n",
            "Epoch: [237][0/782]\tTime 0.290 (0.290)\tData 0.209 (0.209)\tLoss 0.0861 (0.0861)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [237][100/782]\tTime 0.050 (0.055)\tData 0.001 (0.003)\tLoss 0.0366 (0.0569)\tAcc@1 98.438 (98.963)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [237][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.0757 (0.0577)\tAcc@1 98.438 (98.943)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [237][300/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 0.0832 (0.0585)\tAcc@1 98.438 (98.977)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [237][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0278 (0.0575)\tAcc@1 100.000 (99.030)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [237][500/782]\tTime 0.074 (0.052)\tData 0.002 (0.002)\tLoss 0.0802 (0.0577)\tAcc@1 100.000 (99.033)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [237][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0584 (0.0584)\tAcc@1 100.000 (98.978)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [237][700/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0722 (0.0588)\tAcc@1 100.000 (98.959)\tAcc@5 100.000 (99.982)\n",
            " * Acc@1 98.940 Acc@5 99.984\n",
            "epoch 237, total time 40.31\n",
            "Test: [0/313]\tTime 0.122 (0.122)\tLoss 1.6763 (1.6763)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.5675 (1.2481)\tAcc@1 68.750 (73.515)\tAcc@5 93.750 (92.141)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.5600 (1.2249)\tAcc@1 87.500 (73.834)\tAcc@5 100.000 (92.553)\n",
            "Test: [300/313]\tTime 0.018 (0.019)\tLoss 1.1441 (1.2179)\tAcc@1 68.750 (73.692)\tAcc@5 96.875 (92.546)\n",
            " * Acc@1 73.900 Acc@5 92.600\n",
            "==> training...\n",
            "Epoch: [238][0/782]\tTime 0.266 (0.266)\tData 0.198 (0.198)\tLoss 0.0633 (0.0633)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [238][100/782]\tTime 0.049 (0.055)\tData 0.001 (0.003)\tLoss 0.0423 (0.0592)\tAcc@1 98.438 (98.886)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [238][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 0.0505 (0.0612)\tAcc@1 96.875 (98.881)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [238][300/782]\tTime 0.056 (0.052)\tData 0.001 (0.002)\tLoss 0.0915 (0.0599)\tAcc@1 96.875 (98.868)\tAcc@5 100.000 (99.990)\n",
            "Epoch: [238][400/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0928 (0.0598)\tAcc@1 96.875 (98.870)\tAcc@5 100.000 (99.988)\n",
            "Epoch: [238][500/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.1062 (0.0606)\tAcc@1 95.312 (98.815)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [238][600/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0473 (0.0603)\tAcc@1 100.000 (98.812)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [238][700/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 0.0713 (0.0595)\tAcc@1 98.438 (98.839)\tAcc@5 100.000 (99.984)\n",
            " * Acc@1 98.868 Acc@5 99.986\n",
            "epoch 238, total time 40.33\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 1.7707 (1.7707)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.018)\tLoss 1.5267 (1.2527)\tAcc@1 68.750 (73.731)\tAcc@5 93.750 (91.770)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5535 (1.2248)\tAcc@1 87.500 (74.083)\tAcc@5 100.000 (92.475)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1172 (1.2160)\tAcc@1 71.875 (74.024)\tAcc@5 96.875 (92.494)\n",
            " * Acc@1 74.160 Acc@5 92.540\n",
            "==> training...\n",
            "Epoch: [239][0/782]\tTime 0.265 (0.265)\tData 0.198 (0.198)\tLoss 0.0740 (0.0740)\tAcc@1 98.438 (98.438)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [239][100/782]\tTime 0.050 (0.053)\tData 0.001 (0.003)\tLoss 0.1329 (0.0582)\tAcc@1 96.875 (98.917)\tAcc@5 98.438 (99.954)\n",
            "Epoch: [239][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0407 (0.0593)\tAcc@1 100.000 (98.896)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [239][300/782]\tTime 0.049 (0.051)\tData 0.001 (0.002)\tLoss 0.0615 (0.0601)\tAcc@1 98.438 (98.889)\tAcc@5 100.000 (99.974)\n",
            "Epoch: [239][400/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0200 (0.0587)\tAcc@1 100.000 (98.932)\tAcc@5 100.000 (99.973)\n",
            "Epoch: [239][500/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.1164 (0.0611)\tAcc@1 95.312 (98.840)\tAcc@5 100.000 (99.975)\n",
            "Epoch: [239][600/782]\tTime 0.051 (0.051)\tData 0.001 (0.002)\tLoss 0.0374 (0.0606)\tAcc@1 100.000 (98.856)\tAcc@5 100.000 (99.979)\n",
            "Epoch: [239][700/782]\tTime 0.055 (0.051)\tData 0.001 (0.002)\tLoss 0.0317 (0.0602)\tAcc@1 100.000 (98.863)\tAcc@5 100.000 (99.980)\n",
            " * Acc@1 98.882 Acc@5 99.982\n",
            "epoch 239, total time 39.91\n",
            "Test: [0/313]\tTime 0.123 (0.123)\tLoss 1.6903 (1.6903)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.019)\tLoss 1.5330 (1.2561)\tAcc@1 68.750 (73.422)\tAcc@5 93.750 (91.925)\n",
            "Test: [200/313]\tTime 0.017 (0.018)\tLoss 0.5777 (1.2264)\tAcc@1 87.500 (73.803)\tAcc@5 100.000 (92.397)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.1360 (1.2183)\tAcc@1 78.125 (73.827)\tAcc@5 96.875 (92.400)\n",
            " * Acc@1 74.000 Acc@5 92.470\n",
            "==> training...\n",
            "Epoch: [240][0/782]\tTime 0.270 (0.270)\tData 0.202 (0.202)\tLoss 0.0472 (0.0472)\tAcc@1 100.000 (100.000)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [240][100/782]\tTime 0.050 (0.054)\tData 0.001 (0.003)\tLoss 0.0384 (0.0606)\tAcc@1 98.438 (98.963)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [240][200/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0557 (0.0596)\tAcc@1 100.000 (98.989)\tAcc@5 100.000 (99.969)\n",
            "Epoch: [240][300/782]\tTime 0.053 (0.052)\tData 0.001 (0.002)\tLoss 0.0638 (0.0581)\tAcc@1 96.875 (99.009)\tAcc@5 100.000 (99.974)\n",
            "Epoch: [240][400/782]\tTime 0.053 (0.052)\tData 0.002 (0.002)\tLoss 0.0683 (0.0581)\tAcc@1 96.875 (99.002)\tAcc@5 100.000 (99.981)\n",
            "Epoch: [240][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0368 (0.0574)\tAcc@1 100.000 (98.996)\tAcc@5 100.000 (99.984)\n",
            "Epoch: [240][600/782]\tTime 0.050 (0.052)\tData 0.001 (0.002)\tLoss 0.0588 (0.0572)\tAcc@1 98.438 (98.994)\tAcc@5 100.000 (99.987)\n",
            "Epoch: [240][700/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 0.0570 (0.0571)\tAcc@1 98.438 (99.010)\tAcc@5 100.000 (99.989)\n",
            " * Acc@1 98.970 Acc@5 99.988\n",
            "epoch 240, total time 40.32\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 1.7862 (1.7862)\tAcc@1 71.875 (71.875)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.017 (0.020)\tLoss 1.4953 (1.2502)\tAcc@1 71.875 (73.236)\tAcc@5 93.750 (92.079)\n",
            "Test: [200/313]\tTime 0.018 (0.019)\tLoss 0.6030 (1.2213)\tAcc@1 87.500 (73.772)\tAcc@5 100.000 (92.491)\n",
            "Test: [300/313]\tTime 0.017 (0.018)\tLoss 1.0980 (1.2125)\tAcc@1 78.125 (73.609)\tAcc@5 96.875 (92.483)\n",
            " * Acc@1 73.800 Acc@5 92.540\n",
            "==> Saving...\n",
            "best accuracy: tensor(74.2500, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD-DCKD/Cifar100/train_teacher.py \\\n",
        "    --model resnet32x4 \\\n",
        "    --trial 0\n"
      ],
      "metadata": {
        "id": "7AS2-YpCZaMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD-DCKD/Cifar100/train_teacher.py \\\n",
        "    --model resnet32x4 \\\n",
        "    --trial 0 \\\n",
        "    --epochs 100 \\\n",
        "    --save_freq 20\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P78vDtmaALe",
        "outputId": "54feba63-e071-4b95-a013-ddebf285e0ae"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-19 22:56:05.040670: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750373765.061811   85672 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750373765.068197   85672 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "==> training...\n",
            "Epoch: [1][0/782]\tTime 1.049 (1.049)\tData 0.188 (0.188)\tLoss 4.9952 (4.9952)\tAcc@1 1.562 (1.562)\tAcc@5 3.125 (3.125)\n",
            "Epoch: [1][100/782]\tTime 0.043 (0.050)\tData 0.001 (0.003)\tLoss 4.5197 (4.7088)\tAcc@1 0.000 (2.212)\tAcc@5 14.062 (10.040)\n",
            "Epoch: [1][200/782]\tTime 0.044 (0.045)\tData 0.001 (0.002)\tLoss 3.9886 (4.4869)\tAcc@1 7.812 (3.296)\tAcc@5 28.125 (13.549)\n",
            "Epoch: [1][300/782]\tTime 0.039 (0.043)\tData 0.001 (0.002)\tLoss 3.9278 (4.3612)\tAcc@1 7.812 (4.236)\tAcc@5 32.812 (16.959)\n",
            "Epoch: [1][400/782]\tTime 0.040 (0.042)\tData 0.001 (0.002)\tLoss 3.7324 (4.2733)\tAcc@1 12.500 (4.902)\tAcc@5 28.125 (19.147)\n",
            "Epoch: [1][500/782]\tTime 0.039 (0.042)\tData 0.001 (0.002)\tLoss 3.8762 (4.2042)\tAcc@1 7.812 (5.611)\tAcc@5 28.125 (20.977)\n",
            "Epoch: [1][600/782]\tTime 0.040 (0.042)\tData 0.001 (0.002)\tLoss 4.1091 (4.1518)\tAcc@1 7.812 (6.232)\tAcc@5 18.750 (22.457)\n",
            "Epoch: [1][700/782]\tTime 0.040 (0.041)\tData 0.001 (0.002)\tLoss 3.9052 (4.0997)\tAcc@1 7.812 (6.805)\tAcc@5 29.688 (23.908)\n",
            " * Acc@1 7.140 Acc@5 24.830\n",
            "epoch 1, total time 32.44\n",
            "Test: [0/313]\tTime 0.171 (0.171)\tLoss 3.8953 (3.8953)\tAcc@1 12.500 (12.500)\tAcc@5 31.250 (31.250)\n",
            "Test: [100/313]\tTime 0.007 (0.011)\tLoss 3.5154 (3.8593)\tAcc@1 12.500 (9.530)\tAcc@5 40.625 (33.014)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 3.5835 (3.8409)\tAcc@1 9.375 (9.655)\tAcc@5 40.625 (32.914)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 4.1037 (3.8412)\tAcc@1 6.250 (9.946)\tAcc@5 18.750 (32.807)\n",
            " * Acc@1 10.040 Acc@5 32.910\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [2][0/782]\tTime 0.261 (0.261)\tData 0.208 (0.208)\tLoss 3.5330 (3.5330)\tAcc@1 10.938 (10.938)\tAcc@5 39.062 (39.062)\n",
            "Epoch: [2][100/782]\tTime 0.040 (0.042)\tData 0.001 (0.003)\tLoss 3.5420 (3.6933)\tAcc@1 6.250 (12.098)\tAcc@5 37.500 (36.185)\n",
            "Epoch: [2][200/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 3.7128 (3.6643)\tAcc@1 17.188 (12.562)\tAcc@5 40.625 (37.212)\n",
            "Epoch: [2][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 3.4108 (3.6341)\tAcc@1 14.062 (13.237)\tAcc@5 45.312 (37.744)\n",
            "Epoch: [2][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 3.5626 (3.6088)\tAcc@1 9.375 (13.778)\tAcc@5 35.938 (38.517)\n",
            "Epoch: [2][500/782]\tTime 0.044 (0.040)\tData 0.001 (0.002)\tLoss 3.2174 (3.5767)\tAcc@1 21.875 (14.374)\tAcc@5 48.438 (39.540)\n",
            "Epoch: [2][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 2.9405 (3.5409)\tAcc@1 20.312 (14.941)\tAcc@5 59.375 (40.628)\n",
            "Epoch: [2][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 3.2102 (3.4995)\tAcc@1 18.750 (15.545)\tAcc@5 50.000 (41.911)\n",
            " * Acc@1 16.136 Acc@5 42.768\n",
            "epoch 2, total time 31.27\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 3.3537 (3.3537)\tAcc@1 34.375 (34.375)\tAcc@5 53.125 (53.125)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 3.7226 (3.4934)\tAcc@1 18.750 (19.647)\tAcc@5 53.125 (46.380)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 3.1561 (3.5187)\tAcc@1 21.875 (19.108)\tAcc@5 56.250 (46.035)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 3.5867 (3.5168)\tAcc@1 15.625 (18.760)\tAcc@5 43.750 (45.837)\n",
            " * Acc@1 18.870 Acc@5 45.880\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [3][0/782]\tTime 0.246 (0.246)\tData 0.202 (0.202)\tLoss 3.2978 (3.2978)\tAcc@1 12.500 (12.500)\tAcc@5 48.438 (48.438)\n",
            "Epoch: [3][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 3.1200 (3.1075)\tAcc@1 26.562 (22.138)\tAcc@5 46.875 (52.088)\n",
            "Epoch: [3][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 2.8703 (3.0775)\tAcc@1 25.000 (22.738)\tAcc@5 51.562 (53.055)\n",
            "Epoch: [3][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 2.8796 (3.0223)\tAcc@1 25.000 (23.842)\tAcc@5 54.688 (54.521)\n",
            "Epoch: [3][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 2.8601 (2.9803)\tAcc@1 26.562 (24.614)\tAcc@5 54.688 (55.595)\n",
            "Epoch: [3][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 2.5972 (2.9447)\tAcc@1 35.938 (25.468)\tAcc@5 65.625 (56.456)\n",
            "Epoch: [3][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 2.8153 (2.9122)\tAcc@1 34.375 (26.043)\tAcc@5 60.938 (57.173)\n",
            "Epoch: [3][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 2.3381 (2.8703)\tAcc@1 35.938 (26.850)\tAcc@5 68.750 (58.276)\n",
            " * Acc@1 27.502 Acc@5 59.076\n",
            "epoch 3, total time 31.18\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 2.7222 (2.7222)\tAcc@1 40.625 (40.625)\tAcc@5 68.750 (68.750)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 3.5676 (2.7832)\tAcc@1 12.500 (29.889)\tAcc@5 62.500 (62.717)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 2.0815 (2.7861)\tAcc@1 40.625 (30.255)\tAcc@5 78.125 (62.671)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 2.8780 (2.8107)\tAcc@1 37.500 (29.828)\tAcc@5 53.125 (62.386)\n",
            " * Acc@1 29.810 Acc@5 62.430\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [4][0/782]\tTime 0.242 (0.242)\tData 0.205 (0.205)\tLoss 2.7477 (2.7477)\tAcc@1 29.688 (29.688)\tAcc@5 60.938 (60.938)\n",
            "Epoch: [4][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 2.3042 (2.5161)\tAcc@1 37.500 (34.220)\tAcc@5 73.438 (67.048)\n",
            "Epoch: [4][200/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 2.3970 (2.4719)\tAcc@1 32.812 (35.020)\tAcc@5 71.875 (68.167)\n",
            "Epoch: [4][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 2.3881 (2.4535)\tAcc@1 40.625 (35.392)\tAcc@5 70.312 (68.475)\n",
            "Epoch: [4][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 2.3242 (2.4282)\tAcc@1 35.938 (35.700)\tAcc@5 68.750 (69.038)\n",
            "Epoch: [4][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 2.2115 (2.4041)\tAcc@1 34.375 (36.146)\tAcc@5 75.000 (69.720)\n",
            "Epoch: [4][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 2.2623 (2.3857)\tAcc@1 39.062 (36.548)\tAcc@5 71.875 (69.998)\n",
            "Epoch: [4][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 2.0908 (2.3608)\tAcc@1 45.312 (37.163)\tAcc@5 73.438 (70.593)\n",
            " * Acc@1 37.656 Acc@5 71.004\n",
            "epoch 4, total time 31.32\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 2.3652 (2.3652)\tAcc@1 40.625 (40.625)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 2.3484 (2.2132)\tAcc@1 28.125 (40.439)\tAcc@5 75.000 (74.072)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.6034 (2.2257)\tAcc@1 56.250 (39.956)\tAcc@5 84.375 (74.114)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.4335 (2.2334)\tAcc@1 28.125 (39.649)\tAcc@5 81.250 (73.931)\n",
            " * Acc@1 39.600 Acc@5 73.990\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [5][0/782]\tTime 0.240 (0.240)\tData 0.200 (0.200)\tLoss 2.1261 (2.1261)\tAcc@1 42.188 (42.188)\tAcc@5 78.125 (78.125)\n",
            "Epoch: [5][100/782]\tTime 0.040 (0.042)\tData 0.001 (0.003)\tLoss 1.9974 (2.0889)\tAcc@1 39.062 (43.085)\tAcc@5 82.812 (76.269)\n",
            "Epoch: [5][200/782]\tTime 0.039 (0.041)\tData 0.001 (0.002)\tLoss 1.9641 (2.0620)\tAcc@1 43.750 (43.392)\tAcc@5 81.250 (76.640)\n",
            "Epoch: [5][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 2.4006 (2.0605)\tAcc@1 32.812 (43.703)\tAcc@5 71.875 (76.547)\n",
            "Epoch: [5][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.7702 (2.0484)\tAcc@1 53.125 (43.941)\tAcc@5 82.812 (76.711)\n",
            "Epoch: [5][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 2.5578 (2.0394)\tAcc@1 35.938 (44.380)\tAcc@5 70.312 (76.837)\n",
            "Epoch: [5][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.9716 (2.0245)\tAcc@1 48.438 (44.655)\tAcc@5 84.375 (77.337)\n",
            "Epoch: [5][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.8343 (2.0097)\tAcc@1 45.312 (44.969)\tAcc@5 76.562 (77.615)\n",
            " * Acc@1 44.994 Acc@5 77.760\n",
            "epoch 5, total time 31.30\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.7760 (1.7760)\tAcc@1 53.125 (53.125)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.008 (0.010)\tLoss 2.4098 (2.1255)\tAcc@1 37.500 (43.595)\tAcc@5 71.875 (77.011)\n",
            "Test: [200/313]\tTime 0.008 (0.008)\tLoss 1.7797 (2.1015)\tAcc@1 50.000 (44.232)\tAcc@5 84.375 (76.617)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.6368 (2.1085)\tAcc@1 28.125 (43.937)\tAcc@5 71.875 (76.630)\n",
            " * Acc@1 43.930 Acc@5 76.640\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [6][0/782]\tTime 0.260 (0.260)\tData 0.222 (0.222)\tLoss 1.7767 (1.7767)\tAcc@1 56.250 (56.250)\tAcc@5 84.375 (84.375)\n",
            "Epoch: [6][100/782]\tTime 0.040 (0.041)\tData 0.002 (0.004)\tLoss 1.4820 (1.8028)\tAcc@1 53.125 (49.799)\tAcc@5 89.062 (81.761)\n",
            "Epoch: [6][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.003)\tLoss 1.7800 (1.8064)\tAcc@1 53.125 (49.464)\tAcc@5 82.812 (81.716)\n",
            "Epoch: [6][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.7180 (1.8158)\tAcc@1 48.438 (49.315)\tAcc@5 87.500 (81.484)\n",
            "Epoch: [6][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.7253 (1.8155)\tAcc@1 43.750 (49.256)\tAcc@5 82.812 (81.371)\n",
            "Epoch: [6][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.5091 (1.8106)\tAcc@1 54.688 (49.420)\tAcc@5 92.188 (81.465)\n",
            "Epoch: [6][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.5077 (1.8065)\tAcc@1 56.250 (49.574)\tAcc@5 89.062 (81.601)\n",
            "Epoch: [6][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.6108 (1.7980)\tAcc@1 51.562 (49.806)\tAcc@5 82.812 (81.716)\n",
            " * Acc@1 49.932 Acc@5 81.792\n",
            "epoch 6, total time 31.12\n",
            "Test: [0/313]\tTime 0.109 (0.109)\tLoss 1.7317 (1.7317)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.013 (0.010)\tLoss 2.3150 (2.0360)\tAcc@1 40.625 (46.380)\tAcc@5 78.125 (79.270)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.8257 (2.0041)\tAcc@1 46.875 (46.020)\tAcc@5 87.500 (79.307)\n",
            "Test: [300/313]\tTime 0.013 (0.009)\tLoss 2.1499 (2.0142)\tAcc@1 43.750 (46.211)\tAcc@5 78.125 (78.852)\n",
            " * Acc@1 46.180 Acc@5 78.870\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [7][0/782]\tTime 0.251 (0.251)\tData 0.211 (0.211)\tLoss 1.4737 (1.4737)\tAcc@1 64.062 (64.062)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [7][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.7241 (1.6754)\tAcc@1 54.688 (53.682)\tAcc@5 84.375 (83.834)\n",
            "Epoch: [7][200/782]\tTime 0.039 (0.041)\tData 0.001 (0.002)\tLoss 1.8500 (1.6539)\tAcc@1 46.875 (53.809)\tAcc@5 75.000 (84.033)\n",
            "Epoch: [7][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.6778 (1.6532)\tAcc@1 48.438 (53.680)\tAcc@5 87.500 (83.975)\n",
            "Epoch: [7][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.3197 (1.6560)\tAcc@1 60.938 (53.573)\tAcc@5 90.625 (83.935)\n",
            "Epoch: [7][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.9620 (1.6593)\tAcc@1 40.625 (53.365)\tAcc@5 76.562 (83.932)\n",
            "Epoch: [7][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.5362 (1.6633)\tAcc@1 62.500 (53.271)\tAcc@5 87.500 (83.855)\n",
            "Epoch: [7][700/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 2.0373 (1.6596)\tAcc@1 42.188 (53.424)\tAcc@5 78.125 (83.951)\n",
            " * Acc@1 53.702 Acc@5 84.106\n",
            "epoch 7, total time 31.22\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.9344 (1.9344)\tAcc@1 59.375 (59.375)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 2.2612 (2.0233)\tAcc@1 43.750 (47.463)\tAcc@5 71.875 (77.970)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.6863 (2.0093)\tAcc@1 53.125 (47.699)\tAcc@5 81.250 (78.218)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 2.1905 (2.0075)\tAcc@1 46.875 (47.633)\tAcc@5 81.250 (78.115)\n",
            " * Acc@1 47.700 Acc@5 78.110\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [8][0/782]\tTime 0.260 (0.260)\tData 0.223 (0.223)\tLoss 1.5723 (1.5723)\tAcc@1 46.875 (46.875)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [8][100/782]\tTime 0.039 (0.042)\tData 0.001 (0.004)\tLoss 1.2071 (1.5256)\tAcc@1 65.625 (56.513)\tAcc@5 95.312 (86.974)\n",
            "Epoch: [8][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.003)\tLoss 1.6768 (1.5547)\tAcc@1 57.812 (55.978)\tAcc@5 78.125 (85.969)\n",
            "Epoch: [8][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.7753 (1.5670)\tAcc@1 43.750 (55.721)\tAcc@5 82.812 (85.704)\n",
            "Epoch: [8][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.5158 (1.5557)\tAcc@1 59.375 (56.051)\tAcc@5 90.625 (85.770)\n",
            "Epoch: [8][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.5465 (1.5525)\tAcc@1 59.375 (56.085)\tAcc@5 85.938 (85.866)\n",
            "Epoch: [8][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.8290 (1.5563)\tAcc@1 50.000 (55.891)\tAcc@5 79.688 (85.839)\n",
            "Epoch: [8][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.4696 (1.5568)\tAcc@1 59.375 (55.831)\tAcc@5 85.938 (85.835)\n",
            " * Acc@1 55.874 Acc@5 85.776\n",
            "epoch 8, total time 31.16\n",
            "Test: [0/313]\tTime 0.108 (0.108)\tLoss 1.7344 (1.7344)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.8076 (1.8266)\tAcc@1 43.750 (50.371)\tAcc@5 81.250 (82.116)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.6853 (1.8521)\tAcc@1 56.250 (49.705)\tAcc@5 84.375 (81.872)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.0517 (1.8548)\tAcc@1 43.750 (49.896)\tAcc@5 84.375 (81.779)\n",
            " * Acc@1 49.920 Acc@5 81.850\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [9][0/782]\tTime 0.244 (0.244)\tData 0.200 (0.200)\tLoss 1.3518 (1.3518)\tAcc@1 60.938 (60.938)\tAcc@5 87.500 (87.500)\n",
            "Epoch: [9][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.2682 (1.4469)\tAcc@1 62.500 (58.648)\tAcc@5 85.938 (87.330)\n",
            "Epoch: [9][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.8272 (1.4589)\tAcc@1 48.438 (58.294)\tAcc@5 79.688 (87.251)\n",
            "Epoch: [9][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3036 (1.4698)\tAcc@1 60.938 (57.859)\tAcc@5 93.750 (87.147)\n",
            "Epoch: [9][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.7858 (1.4774)\tAcc@1 56.250 (58.042)\tAcc@5 82.812 (86.861)\n",
            "Epoch: [9][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1155 (1.4831)\tAcc@1 65.625 (57.928)\tAcc@5 92.188 (86.758)\n",
            "Epoch: [9][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.5412 (1.4820)\tAcc@1 53.125 (57.893)\tAcc@5 89.062 (86.741)\n",
            "Epoch: [9][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2946 (1.4856)\tAcc@1 59.375 (57.654)\tAcc@5 95.312 (86.787)\n",
            " * Acc@1 57.668 Acc@5 86.830\n",
            "epoch 9, total time 31.05\n",
            "Test: [0/313]\tTime 0.105 (0.105)\tLoss 1.7185 (1.7185)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.8457 (1.6887)\tAcc@1 53.125 (53.280)\tAcc@5 78.125 (83.478)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1479 (1.6833)\tAcc@1 59.375 (53.405)\tAcc@5 93.750 (83.473)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.5423 (1.6991)\tAcc@1 50.000 (53.353)\tAcc@5 87.500 (83.347)\n",
            " * Acc@1 53.330 Acc@5 83.270\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [10][0/782]\tTime 0.249 (0.249)\tData 0.213 (0.213)\tLoss 1.0369 (1.0369)\tAcc@1 67.188 (67.188)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [10][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.0492 (1.3769)\tAcc@1 67.188 (60.984)\tAcc@5 92.188 (88.645)\n",
            "Epoch: [10][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.7663 (1.3833)\tAcc@1 57.812 (61.007)\tAcc@5 84.375 (88.363)\n",
            "Epoch: [10][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.6849 (1.3902)\tAcc@1 56.250 (60.631)\tAcc@5 85.938 (88.403)\n",
            "Epoch: [10][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.6121 (1.3995)\tAcc@1 59.375 (60.380)\tAcc@5 87.500 (88.120)\n",
            "Epoch: [10][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.4799 (1.4074)\tAcc@1 56.250 (60.195)\tAcc@5 84.375 (87.909)\n",
            "Epoch: [10][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3106 (1.4144)\tAcc@1 60.938 (59.822)\tAcc@5 93.750 (87.885)\n",
            "Epoch: [10][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.4527 (1.4157)\tAcc@1 57.812 (59.736)\tAcc@5 87.500 (87.812)\n",
            " * Acc@1 59.632 Acc@5 87.802\n",
            "epoch 10, total time 31.01\n",
            "Test: [0/313]\tTime 0.103 (0.103)\tLoss 1.5858 (1.5858)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 2.0093 (1.6207)\tAcc@1 40.625 (55.941)\tAcc@5 78.125 (84.870)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.5912 (1.6245)\tAcc@1 56.250 (55.457)\tAcc@5 81.250 (84.857)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 2.1314 (1.6362)\tAcc@1 46.875 (55.388)\tAcc@5 81.250 (84.520)\n",
            " * Acc@1 55.430 Acc@5 84.500\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [11][0/782]\tTime 0.260 (0.260)\tData 0.222 (0.222)\tLoss 1.4733 (1.4733)\tAcc@1 53.125 (53.125)\tAcc@5 84.375 (84.375)\n",
            "Epoch: [11][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.004)\tLoss 1.5213 (1.3035)\tAcc@1 56.250 (62.283)\tAcc@5 93.750 (89.790)\n",
            "Epoch: [11][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.003)\tLoss 1.2110 (1.3163)\tAcc@1 62.500 (61.901)\tAcc@5 93.750 (89.467)\n",
            "Epoch: [11][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2450 (1.3325)\tAcc@1 64.062 (61.727)\tAcc@5 85.938 (89.146)\n",
            "Epoch: [11][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.5144 (1.3434)\tAcc@1 56.250 (61.389)\tAcc@5 84.375 (89.020)\n",
            "Epoch: [11][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.7546 (1.3508)\tAcc@1 46.875 (61.271)\tAcc@5 81.250 (88.907)\n",
            "Epoch: [11][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.7620 (1.3595)\tAcc@1 48.438 (60.974)\tAcc@5 81.250 (88.777)\n",
            "Epoch: [11][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.4947 (1.3633)\tAcc@1 60.938 (60.837)\tAcc@5 84.375 (88.733)\n",
            " * Acc@1 60.796 Acc@5 88.622\n",
            "epoch 11, total time 30.99\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.7145 (1.7145)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 2.0328 (1.6893)\tAcc@1 40.625 (55.198)\tAcc@5 75.000 (83.632)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.3660 (1.6898)\tAcc@1 59.375 (54.820)\tAcc@5 81.250 (83.971)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.8565 (1.6834)\tAcc@1 46.875 (54.713)\tAcc@5 78.125 (84.032)\n",
            " * Acc@1 54.620 Acc@5 84.080\n",
            "==> training...\n",
            "Epoch: [12][0/782]\tTime 0.246 (0.246)\tData 0.208 (0.208)\tLoss 1.2512 (1.2512)\tAcc@1 60.938 (60.938)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [12][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.2076 (1.2269)\tAcc@1 65.625 (64.310)\tAcc@5 93.750 (90.919)\n",
            "Epoch: [12][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.8479 (1.2719)\tAcc@1 45.312 (62.966)\tAcc@5 81.250 (90.026)\n",
            "Epoch: [12][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3190 (1.2970)\tAcc@1 65.625 (62.448)\tAcc@5 89.062 (89.545)\n",
            "Epoch: [12][400/782]\tTime 0.046 (0.040)\tData 0.001 (0.002)\tLoss 1.6200 (1.3108)\tAcc@1 54.688 (62.110)\tAcc@5 82.812 (89.421)\n",
            "Epoch: [12][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.4844 (1.3109)\tAcc@1 53.125 (62.151)\tAcc@5 85.938 (89.393)\n",
            "Epoch: [12][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.3490 (1.3193)\tAcc@1 56.250 (61.972)\tAcc@5 90.625 (89.291)\n",
            "Epoch: [12][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.5379 (1.3219)\tAcc@1 56.250 (61.883)\tAcc@5 84.375 (89.254)\n",
            " * Acc@1 61.828 Acc@5 89.208\n",
            "epoch 12, total time 31.19\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.8657 (1.8657)\tAcc@1 56.250 (56.250)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.2141 (1.8142)\tAcc@1 59.375 (52.444)\tAcc@5 93.750 (80.724)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.5312 (1.8120)\tAcc@1 62.500 (52.472)\tAcc@5 84.375 (80.939)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.9166 (1.8195)\tAcc@1 53.125 (52.668)\tAcc@5 81.250 (81.053)\n",
            " * Acc@1 52.650 Acc@5 81.050\n",
            "==> training...\n",
            "Epoch: [13][0/782]\tTime 0.243 (0.243)\tData 0.203 (0.203)\tLoss 1.2737 (1.2737)\tAcc@1 60.938 (60.938)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [13][100/782]\tTime 0.037 (0.041)\tData 0.001 (0.003)\tLoss 1.0609 (1.2433)\tAcc@1 68.750 (64.372)\tAcc@5 93.750 (90.795)\n",
            "Epoch: [13][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0267 (1.2318)\tAcc@1 68.750 (64.490)\tAcc@5 93.750 (90.874)\n",
            "Epoch: [13][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2861 (1.2474)\tAcc@1 54.688 (63.995)\tAcc@5 89.062 (90.500)\n",
            "Epoch: [13][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2995 (1.2614)\tAcc@1 60.938 (63.630)\tAcc@5 89.062 (90.251)\n",
            "Epoch: [13][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3796 (1.2698)\tAcc@1 62.500 (63.429)\tAcc@5 90.625 (90.129)\n",
            "Epoch: [13][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1055 (1.2774)\tAcc@1 64.062 (63.212)\tAcc@5 92.188 (89.985)\n",
            "Epoch: [13][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.4315 (1.2880)\tAcc@1 54.688 (62.928)\tAcc@5 87.500 (89.867)\n",
            " * Acc@1 62.942 Acc@5 89.854\n",
            "epoch 13, total time 30.95\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 1.6492 (1.6492)\tAcc@1 62.500 (62.500)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.8338 (1.6347)\tAcc@1 46.875 (55.755)\tAcc@5 87.500 (84.189)\n",
            "Test: [200/313]\tTime 0.008 (0.008)\tLoss 1.6973 (1.6323)\tAcc@1 53.125 (55.737)\tAcc@5 84.375 (84.593)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.9912 (1.6369)\tAcc@1 50.000 (55.907)\tAcc@5 87.500 (84.458)\n",
            " * Acc@1 55.890 Acc@5 84.500\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [14][0/782]\tTime 0.238 (0.238)\tData 0.200 (0.200)\tLoss 1.2442 (1.2442)\tAcc@1 67.188 (67.188)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [14][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.0291 (1.1833)\tAcc@1 65.625 (65.439)\tAcc@5 95.312 (90.981)\n",
            "Epoch: [14][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.3128 (1.1952)\tAcc@1 64.062 (65.236)\tAcc@5 92.188 (90.998)\n",
            "Epoch: [14][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.8271 (1.2151)\tAcc@1 50.000 (64.893)\tAcc@5 82.812 (90.786)\n",
            "Epoch: [14][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.4541 (1.2252)\tAcc@1 65.625 (64.768)\tAcc@5 81.250 (90.477)\n",
            "Epoch: [14][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2925 (1.2288)\tAcc@1 62.500 (64.658)\tAcc@5 93.750 (90.475)\n",
            "Epoch: [14][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1947 (1.2482)\tAcc@1 65.625 (64.021)\tAcc@5 92.188 (90.227)\n",
            "Epoch: [14][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1838 (1.2536)\tAcc@1 65.625 (63.891)\tAcc@5 93.750 (90.177)\n",
            " * Acc@1 63.836 Acc@5 90.180\n",
            "epoch 14, total time 31.09\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 1.9398 (1.9398)\tAcc@1 65.625 (65.625)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.5051 (1.7000)\tAcc@1 59.375 (54.332)\tAcc@5 87.500 (82.828)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.2869 (1.7137)\tAcc@1 68.750 (53.918)\tAcc@5 87.500 (83.022)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.5014 (1.7162)\tAcc@1 53.125 (54.132)\tAcc@5 84.375 (83.233)\n",
            " * Acc@1 54.090 Acc@5 83.280\n",
            "==> training...\n",
            "Epoch: [15][0/782]\tTime 0.233 (0.233)\tData 0.192 (0.192)\tLoss 1.2446 (1.2446)\tAcc@1 65.625 (65.625)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [15][100/782]\tTime 0.039 (0.042)\tData 0.001 (0.003)\tLoss 1.2729 (1.1973)\tAcc@1 62.500 (64.743)\tAcc@5 90.625 (91.136)\n",
            "Epoch: [15][200/782]\tTime 0.043 (0.040)\tData 0.001 (0.002)\tLoss 1.2438 (1.1941)\tAcc@1 62.500 (65.190)\tAcc@5 92.188 (91.278)\n",
            "Epoch: [15][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9947 (1.2030)\tAcc@1 70.312 (64.961)\tAcc@5 95.312 (91.087)\n",
            "Epoch: [15][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.4822 (1.2142)\tAcc@1 54.688 (64.760)\tAcc@5 85.938 (90.906)\n",
            "Epoch: [15][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2954 (1.2188)\tAcc@1 62.500 (64.736)\tAcc@5 85.938 (90.793)\n",
            "Epoch: [15][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0731 (1.2249)\tAcc@1 71.875 (64.533)\tAcc@5 90.625 (90.615)\n",
            "Epoch: [15][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3544 (1.2289)\tAcc@1 59.375 (64.482)\tAcc@5 90.625 (90.551)\n",
            " * Acc@1 64.464 Acc@5 90.516\n",
            "epoch 15, total time 31.25\n",
            "Test: [0/313]\tTime 0.109 (0.109)\tLoss 1.4770 (1.4770)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.5145 (1.5913)\tAcc@1 50.000 (56.343)\tAcc@5 87.500 (85.675)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.0617 (1.6049)\tAcc@1 65.625 (55.892)\tAcc@5 96.875 (85.292)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 1.7506 (1.6169)\tAcc@1 50.000 (55.959)\tAcc@5 84.375 (85.123)\n",
            " * Acc@1 55.960 Acc@5 85.110\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [16][0/782]\tTime 0.252 (0.252)\tData 0.208 (0.208)\tLoss 0.9359 (0.9359)\tAcc@1 71.875 (71.875)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [16][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.9360 (1.1357)\tAcc@1 73.438 (66.228)\tAcc@5 95.312 (92.095)\n",
            "Epoch: [16][200/782]\tTime 0.039 (0.041)\tData 0.001 (0.002)\tLoss 1.0481 (1.1514)\tAcc@1 75.000 (66.317)\tAcc@5 89.062 (91.643)\n",
            "Epoch: [16][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.3095 (1.1581)\tAcc@1 59.375 (66.154)\tAcc@5 92.188 (91.502)\n",
            "Epoch: [16][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1864 (1.1692)\tAcc@1 65.625 (65.870)\tAcc@5 89.062 (91.389)\n",
            "Epoch: [16][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1983 (1.1775)\tAcc@1 62.500 (65.778)\tAcc@5 92.188 (91.239)\n",
            "Epoch: [16][600/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 1.0936 (1.1867)\tAcc@1 70.312 (65.459)\tAcc@5 90.625 (91.075)\n",
            "Epoch: [16][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2288 (1.1929)\tAcc@1 59.375 (65.297)\tAcc@5 92.188 (91.006)\n",
            " * Acc@1 65.130 Acc@5 90.850\n",
            "epoch 16, total time 31.09\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 1.7153 (1.7153)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.4652 (1.5657)\tAcc@1 59.375 (57.580)\tAcc@5 90.625 (85.520)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.4041 (1.5595)\tAcc@1 56.250 (57.494)\tAcc@5 90.625 (85.650)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.8479 (1.5628)\tAcc@1 50.000 (57.340)\tAcc@5 81.250 (85.621)\n",
            " * Acc@1 57.290 Acc@5 85.620\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [17][0/782]\tTime 0.261 (0.261)\tData 0.224 (0.224)\tLoss 1.1542 (1.1542)\tAcc@1 59.375 (59.375)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [17][100/782]\tTime 0.039 (0.042)\tData 0.001 (0.004)\tLoss 1.0438 (1.1257)\tAcc@1 67.188 (67.605)\tAcc@5 93.750 (91.955)\n",
            "Epoch: [17][200/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.2165 (1.1307)\tAcc@1 64.062 (67.304)\tAcc@5 89.062 (92.016)\n",
            "Epoch: [17][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1683 (1.1467)\tAcc@1 65.625 (66.871)\tAcc@5 87.500 (91.741)\n",
            "Epoch: [17][400/782]\tTime 0.044 (0.040)\tData 0.001 (0.002)\tLoss 1.4355 (1.1523)\tAcc@1 62.500 (66.615)\tAcc@5 89.062 (91.786)\n",
            "Epoch: [17][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0684 (1.1622)\tAcc@1 73.438 (66.108)\tAcc@5 93.750 (91.754)\n",
            "Epoch: [17][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0458 (1.1695)\tAcc@1 76.562 (66.044)\tAcc@5 93.750 (91.530)\n",
            "Epoch: [17][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2340 (1.1690)\tAcc@1 67.188 (65.962)\tAcc@5 92.188 (91.517)\n",
            " * Acc@1 65.750 Acc@5 91.358\n",
            "epoch 17, total time 31.13\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 1.7284 (1.7284)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.008 (0.008)\tLoss 1.4353 (1.5295)\tAcc@1 56.250 (57.116)\tAcc@5 93.750 (86.262)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.0432 (1.5491)\tAcc@1 68.750 (56.903)\tAcc@5 96.875 (85.930)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 1.9118 (1.5560)\tAcc@1 43.750 (56.624)\tAcc@5 81.250 (85.735)\n",
            " * Acc@1 56.720 Acc@5 85.700\n",
            "==> training...\n",
            "Epoch: [18][0/782]\tTime 0.228 (0.228)\tData 0.198 (0.198)\tLoss 1.0708 (1.0708)\tAcc@1 67.188 (67.188)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [18][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.0438 (1.1142)\tAcc@1 62.500 (67.172)\tAcc@5 92.188 (92.420)\n",
            "Epoch: [18][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0936 (1.1144)\tAcc@1 70.312 (67.289)\tAcc@5 92.188 (92.118)\n",
            "Epoch: [18][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0944 (1.1226)\tAcc@1 68.750 (67.172)\tAcc@5 92.188 (91.933)\n",
            "Epoch: [18][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0272 (1.1281)\tAcc@1 76.562 (67.078)\tAcc@5 92.188 (91.860)\n",
            "Epoch: [18][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2052 (1.1402)\tAcc@1 65.625 (66.894)\tAcc@5 89.062 (91.664)\n",
            "Epoch: [18][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2591 (1.1495)\tAcc@1 62.500 (66.597)\tAcc@5 89.062 (91.488)\n",
            "Epoch: [18][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2367 (1.1511)\tAcc@1 65.625 (66.579)\tAcc@5 89.062 (91.421)\n",
            " * Acc@1 66.472 Acc@5 91.380\n",
            "epoch 18, total time 30.94\n",
            "Test: [0/313]\tTime 0.104 (0.104)\tLoss 1.6421 (1.6421)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 2.0913 (1.7286)\tAcc@1 46.875 (55.384)\tAcc@5 81.250 (83.787)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 2.0235 (1.7349)\tAcc@1 53.125 (55.177)\tAcc@5 81.250 (84.375)\n",
            "Test: [300/313]\tTime 0.009 (0.008)\tLoss 2.1464 (1.7394)\tAcc@1 50.000 (54.942)\tAcc@5 81.250 (84.147)\n",
            " * Acc@1 54.960 Acc@5 84.090\n",
            "==> training...\n",
            "Epoch: [19][0/782]\tTime 0.227 (0.227)\tData 0.194 (0.194)\tLoss 0.9446 (0.9446)\tAcc@1 76.562 (76.562)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [19][100/782]\tTime 0.040 (0.041)\tData 0.002 (0.003)\tLoss 1.0344 (1.0696)\tAcc@1 64.062 (68.796)\tAcc@5 95.312 (92.884)\n",
            "Epoch: [19][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3486 (1.0971)\tAcc@1 70.312 (67.957)\tAcc@5 87.500 (92.366)\n",
            "Epoch: [19][300/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 1.0810 (1.1111)\tAcc@1 68.750 (67.473)\tAcc@5 95.312 (92.203)\n",
            "Epoch: [19][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9085 (1.1262)\tAcc@1 70.312 (67.020)\tAcc@5 95.312 (92.036)\n",
            "Epoch: [19][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2854 (1.1304)\tAcc@1 64.062 (67.041)\tAcc@5 87.500 (91.941)\n",
            "Epoch: [19][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2571 (1.1387)\tAcc@1 60.938 (66.878)\tAcc@5 92.188 (91.824)\n",
            "Epoch: [19][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1606 (1.1442)\tAcc@1 60.938 (66.755)\tAcc@5 93.750 (91.711)\n",
            " * Acc@1 66.672 Acc@5 91.648\n",
            "epoch 19, total time 30.96\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 2.2701 (2.2701)\tAcc@1 50.000 (50.000)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.008 (0.009)\tLoss 1.1762 (1.5016)\tAcc@1 71.875 (57.828)\tAcc@5 93.750 (86.974)\n",
            "Test: [200/313]\tTime 0.008 (0.009)\tLoss 1.5653 (1.5298)\tAcc@1 62.500 (57.758)\tAcc@5 84.375 (86.241)\n",
            "Test: [300/313]\tTime 0.012 (0.009)\tLoss 1.9646 (1.5514)\tAcc@1 40.625 (57.392)\tAcc@5 81.250 (85.714)\n",
            " * Acc@1 57.410 Acc@5 85.780\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [20][0/782]\tTime 0.248 (0.248)\tData 0.204 (0.204)\tLoss 1.0260 (1.0260)\tAcc@1 70.312 (70.312)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [20][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.8537 (1.0563)\tAcc@1 71.875 (69.152)\tAcc@5 98.438 (92.899)\n",
            "Epoch: [20][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9712 (1.0741)\tAcc@1 64.062 (68.797)\tAcc@5 93.750 (92.654)\n",
            "Epoch: [20][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.4347 (1.0860)\tAcc@1 56.250 (68.361)\tAcc@5 89.062 (92.468)\n",
            "Epoch: [20][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0384 (1.0905)\tAcc@1 64.062 (68.177)\tAcc@5 92.188 (92.413)\n",
            "Epoch: [20][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3265 (1.1064)\tAcc@1 60.938 (67.755)\tAcc@5 90.625 (92.237)\n",
            "Epoch: [20][600/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 1.1697 (1.1153)\tAcc@1 65.625 (67.575)\tAcc@5 95.312 (92.071)\n",
            "Epoch: [20][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.2147 (1.1219)\tAcc@1 70.312 (67.415)\tAcc@5 85.938 (91.976)\n",
            " * Acc@1 67.290 Acc@5 91.818\n",
            "epoch 20, total time 30.98\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 1.8232 (1.8232)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.6474 (1.5177)\tAcc@1 56.250 (58.849)\tAcc@5 90.625 (86.355)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1107 (1.5221)\tAcc@1 65.625 (58.831)\tAcc@5 93.750 (86.412)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.6204 (1.5383)\tAcc@1 59.375 (58.627)\tAcc@5 84.375 (86.233)\n",
            " * Acc@1 58.820 Acc@5 86.260\n",
            "saving the best model!\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [21][0/782]\tTime 0.252 (0.252)\tData 0.217 (0.217)\tLoss 0.8597 (0.8597)\tAcc@1 71.875 (71.875)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [21][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.004)\tLoss 0.9909 (1.0118)\tAcc@1 65.625 (70.235)\tAcc@5 93.750 (93.611)\n",
            "Epoch: [21][200/782]\tTime 0.040 (0.040)\tData 0.002 (0.003)\tLoss 0.9785 (1.0559)\tAcc@1 73.438 (69.038)\tAcc@5 95.312 (92.918)\n",
            "Epoch: [21][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2305 (1.0863)\tAcc@1 60.938 (68.143)\tAcc@5 95.312 (92.546)\n",
            "Epoch: [21][400/782]\tTime 0.039 (0.040)\tData 0.002 (0.002)\tLoss 1.3331 (1.0908)\tAcc@1 60.938 (67.936)\tAcc@5 89.062 (92.526)\n",
            "Epoch: [21][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6782 (1.1004)\tAcc@1 82.812 (67.802)\tAcc@5 95.312 (92.318)\n",
            "Epoch: [21][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9230 (1.1086)\tAcc@1 73.438 (67.637)\tAcc@5 93.750 (92.242)\n",
            "Epoch: [21][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.5900 (1.1166)\tAcc@1 57.812 (67.413)\tAcc@5 81.250 (92.101)\n",
            " * Acc@1 67.482 Acc@5 92.054\n",
            "epoch 21, total time 31.07\n",
            "Test: [0/313]\tTime 0.102 (0.102)\tLoss 1.4763 (1.4763)\tAcc@1 62.500 (62.500)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.5319 (1.5253)\tAcc@1 59.375 (58.354)\tAcc@5 93.750 (86.881)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.3282 (1.5385)\tAcc@1 53.125 (57.945)\tAcc@5 93.750 (86.940)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.4568 (1.5538)\tAcc@1 68.750 (57.994)\tAcc@5 87.500 (86.316)\n",
            " * Acc@1 58.130 Acc@5 86.420\n",
            "==> training...\n",
            "Epoch: [22][0/782]\tTime 0.242 (0.242)\tData 0.214 (0.214)\tLoss 1.0755 (1.0755)\tAcc@1 70.312 (70.312)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [22][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.004)\tLoss 1.1307 (1.0175)\tAcc@1 64.062 (70.065)\tAcc@5 89.062 (93.239)\n",
            "Epoch: [22][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8313 (1.0381)\tAcc@1 75.000 (69.450)\tAcc@5 95.312 (93.074)\n",
            "Epoch: [22][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0102 (1.0558)\tAcc@1 67.188 (69.113)\tAcc@5 95.312 (92.935)\n",
            "Epoch: [22][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9396 (1.0693)\tAcc@1 71.875 (68.707)\tAcc@5 92.188 (92.690)\n",
            "Epoch: [22][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0361 (1.0764)\tAcc@1 68.750 (68.544)\tAcc@5 95.312 (92.640)\n",
            "Epoch: [22][600/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.8604 (1.0826)\tAcc@1 71.875 (68.378)\tAcc@5 96.875 (92.531)\n",
            "Epoch: [22][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2111 (1.0945)\tAcc@1 62.500 (68.010)\tAcc@5 90.625 (92.377)\n",
            " * Acc@1 67.902 Acc@5 92.310\n",
            "epoch 22, total time 31.09\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.7945 (1.7945)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.7342 (1.6961)\tAcc@1 53.125 (55.910)\tAcc@5 84.375 (83.447)\n",
            "Test: [200/313]\tTime 0.013 (0.008)\tLoss 0.9136 (1.6717)\tAcc@1 75.000 (56.032)\tAcc@5 93.750 (83.738)\n",
            "Test: [300/313]\tTime 0.012 (0.008)\tLoss 2.2191 (1.6734)\tAcc@1 53.125 (55.949)\tAcc@5 78.125 (83.804)\n",
            " * Acc@1 55.940 Acc@5 83.840\n",
            "==> training...\n",
            "Epoch: [23][0/782]\tTime 0.242 (0.242)\tData 0.208 (0.208)\tLoss 1.2900 (1.2900)\tAcc@1 53.125 (53.125)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [23][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.0025 (1.0454)\tAcc@1 67.188 (69.121)\tAcc@5 93.750 (92.976)\n",
            "Epoch: [23][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7147 (1.0357)\tAcc@1 76.562 (69.248)\tAcc@5 96.875 (92.910)\n",
            "Epoch: [23][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3288 (1.0511)\tAcc@1 60.938 (68.968)\tAcc@5 89.062 (92.857)\n",
            "Epoch: [23][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2277 (1.0577)\tAcc@1 64.062 (68.692)\tAcc@5 85.938 (92.842)\n",
            "Epoch: [23][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8713 (1.0632)\tAcc@1 75.000 (68.513)\tAcc@5 96.875 (92.783)\n",
            "Epoch: [23][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.6421 (1.0725)\tAcc@1 57.812 (68.339)\tAcc@5 81.250 (92.637)\n",
            "Epoch: [23][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2589 (1.0836)\tAcc@1 65.625 (68.166)\tAcc@5 90.625 (92.502)\n",
            " * Acc@1 68.154 Acc@5 92.448\n",
            "epoch 23, total time 31.05\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.4487 (1.4487)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.5733 (1.5306)\tAcc@1 43.750 (59.963)\tAcc@5 87.500 (87.283)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.1361 (1.5101)\tAcc@1 65.625 (59.748)\tAcc@5 100.000 (87.438)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 2.2690 (1.5150)\tAcc@1 46.875 (59.624)\tAcc@5 81.250 (87.458)\n",
            " * Acc@1 59.650 Acc@5 87.480\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [24][0/782]\tTime 0.255 (0.255)\tData 0.217 (0.217)\tLoss 1.0918 (1.0918)\tAcc@1 71.875 (71.875)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [24][100/782]\tTime 0.040 (0.042)\tData 0.001 (0.003)\tLoss 1.0669 (1.0582)\tAcc@1 76.562 (69.462)\tAcc@5 90.625 (93.023)\n",
            "Epoch: [24][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9548 (1.0487)\tAcc@1 75.000 (69.543)\tAcc@5 95.312 (93.066)\n",
            "Epoch: [24][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7685 (1.0434)\tAcc@1 76.562 (69.575)\tAcc@5 92.188 (93.148)\n",
            "Epoch: [24][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.2349 (1.0522)\tAcc@1 60.938 (69.221)\tAcc@5 90.625 (93.095)\n",
            "Epoch: [24][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8743 (1.0562)\tAcc@1 78.125 (69.212)\tAcc@5 96.875 (93.073)\n",
            "Epoch: [24][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1485 (1.0635)\tAcc@1 67.188 (69.059)\tAcc@5 90.625 (92.887)\n",
            "Epoch: [24][700/782]\tTime 0.042 (0.040)\tData 0.002 (0.002)\tLoss 1.1288 (1.0724)\tAcc@1 67.188 (68.674)\tAcc@5 87.500 (92.707)\n",
            " * Acc@1 68.566 Acc@5 92.600\n",
            "epoch 24, total time 31.21\n",
            "Test: [0/313]\tTime 0.119 (0.119)\tLoss 1.9458 (1.9458)\tAcc@1 50.000 (50.000)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.013 (0.010)\tLoss 1.9168 (1.4728)\tAcc@1 50.000 (59.561)\tAcc@5 81.250 (87.531)\n",
            "Test: [200/313]\tTime 0.014 (0.009)\tLoss 0.9507 (1.4451)\tAcc@1 75.000 (60.588)\tAcc@5 93.750 (87.547)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.6761 (1.4472)\tAcc@1 53.125 (60.725)\tAcc@5 87.500 (87.448)\n",
            " * Acc@1 60.770 Acc@5 87.430\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [25][0/782]\tTime 0.246 (0.246)\tData 0.207 (0.207)\tLoss 0.7752 (0.7752)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [25][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.1984 (0.9799)\tAcc@1 64.062 (71.504)\tAcc@5 93.750 (93.719)\n",
            "Epoch: [25][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.2590 (1.0072)\tAcc@1 67.188 (70.857)\tAcc@5 87.500 (93.237)\n",
            "Epoch: [25][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.1179 (1.0213)\tAcc@1 70.312 (70.328)\tAcc@5 92.188 (92.971)\n",
            "Epoch: [25][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2711 (1.0396)\tAcc@1 65.625 (69.709)\tAcc@5 92.188 (92.827)\n",
            "Epoch: [25][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9997 (1.0482)\tAcc@1 70.312 (69.368)\tAcc@5 89.062 (92.758)\n",
            "Epoch: [25][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.4329 (1.0593)\tAcc@1 53.125 (69.046)\tAcc@5 92.188 (92.645)\n",
            "Epoch: [25][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.3817 (1.0628)\tAcc@1 60.938 (68.951)\tAcc@5 85.938 (92.627)\n",
            " * Acc@1 68.806 Acc@5 92.582\n",
            "epoch 25, total time 31.34\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.7039 (1.7039)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.013 (0.010)\tLoss 1.0853 (1.4919)\tAcc@1 62.500 (59.901)\tAcc@5 96.875 (87.252)\n",
            "Test: [200/313]\tTime 0.007 (0.010)\tLoss 1.1251 (1.5007)\tAcc@1 56.250 (59.935)\tAcc@5 93.750 (87.220)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.3606 (1.4938)\tAcc@1 56.250 (60.060)\tAcc@5 96.875 (87.251)\n",
            " * Acc@1 60.130 Acc@5 87.270\n",
            "==> training...\n",
            "Epoch: [26][0/782]\tTime 0.248 (0.248)\tData 0.211 (0.211)\tLoss 0.5329 (0.5329)\tAcc@1 82.812 (82.812)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [26][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.9616 (0.9834)\tAcc@1 73.438 (70.452)\tAcc@5 95.312 (93.765)\n",
            "Epoch: [26][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7405 (1.0006)\tAcc@1 81.250 (70.188)\tAcc@5 95.312 (93.439)\n",
            "Epoch: [26][300/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 1.0990 (1.0136)\tAcc@1 70.312 (69.793)\tAcc@5 93.750 (93.407)\n",
            "Epoch: [26][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3884 (1.0339)\tAcc@1 64.062 (69.358)\tAcc@5 87.500 (93.080)\n",
            "Epoch: [26][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0568 (1.0438)\tAcc@1 70.312 (69.099)\tAcc@5 90.625 (92.980)\n",
            "Epoch: [26][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3012 (1.0510)\tAcc@1 65.625 (68.968)\tAcc@5 89.062 (92.897)\n",
            "Epoch: [26][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9144 (1.0574)\tAcc@1 68.750 (68.783)\tAcc@5 95.312 (92.841)\n",
            " * Acc@1 68.846 Acc@5 92.818\n",
            "epoch 26, total time 30.98\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.5934 (1.5934)\tAcc@1 68.750 (68.750)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.6954 (1.4662)\tAcc@1 43.750 (60.396)\tAcc@5 90.625 (88.057)\n",
            "Test: [200/313]\tTime 0.008 (0.008)\tLoss 1.2071 (1.4545)\tAcc@1 68.750 (61.007)\tAcc@5 90.625 (88.091)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 1.4632 (1.4600)\tAcc@1 68.750 (61.130)\tAcc@5 90.625 (87.905)\n",
            " * Acc@1 61.180 Acc@5 87.920\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [27][0/782]\tTime 0.255 (0.255)\tData 0.210 (0.210)\tLoss 0.9095 (0.9095)\tAcc@1 67.188 (67.188)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [27][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.3591 (0.9792)\tAcc@1 59.375 (71.334)\tAcc@5 85.938 (93.549)\n",
            "Epoch: [27][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7836 (0.9947)\tAcc@1 73.438 (70.872)\tAcc@5 98.438 (93.478)\n",
            "Epoch: [27][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8329 (1.0092)\tAcc@1 79.688 (70.634)\tAcc@5 96.875 (93.221)\n",
            "Epoch: [27][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1579 (1.0286)\tAcc@1 65.625 (70.032)\tAcc@5 89.062 (93.021)\n",
            "Epoch: [27][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8954 (1.0355)\tAcc@1 73.438 (69.776)\tAcc@5 95.312 (92.914)\n",
            "Epoch: [27][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.1871 (1.0393)\tAcc@1 57.812 (69.652)\tAcc@5 96.875 (93.004)\n",
            "Epoch: [27][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8840 (1.0480)\tAcc@1 73.438 (69.439)\tAcc@5 92.188 (92.959)\n",
            " * Acc@1 69.346 Acc@5 92.974\n",
            "epoch 27, total time 30.96\n",
            "Test: [0/313]\tTime 0.117 (0.117)\tLoss 2.2972 (2.2972)\tAcc@1 43.750 (43.750)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.7601 (1.5912)\tAcc@1 46.875 (57.921)\tAcc@5 90.625 (86.634)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.5104 (1.6262)\tAcc@1 56.250 (57.447)\tAcc@5 87.500 (86.101)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.4277 (1.6201)\tAcc@1 62.500 (57.870)\tAcc@5 87.500 (85.735)\n",
            " * Acc@1 58.020 Acc@5 85.760\n",
            "==> training...\n",
            "Epoch: [28][0/782]\tTime 0.246 (0.246)\tData 0.202 (0.202)\tLoss 0.9597 (0.9597)\tAcc@1 76.562 (76.562)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [28][100/782]\tTime 0.040 (0.041)\tData 0.002 (0.003)\tLoss 1.0128 (0.9485)\tAcc@1 68.750 (72.432)\tAcc@5 93.750 (94.044)\n",
            "Epoch: [28][200/782]\tTime 0.044 (0.040)\tData 0.001 (0.002)\tLoss 1.0282 (0.9765)\tAcc@1 76.562 (71.875)\tAcc@5 92.188 (93.556)\n",
            "Epoch: [28][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8558 (1.0028)\tAcc@1 71.875 (71.029)\tAcc@5 95.312 (93.278)\n",
            "Epoch: [28][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0524 (1.0192)\tAcc@1 73.438 (70.425)\tAcc@5 90.625 (93.115)\n",
            "Epoch: [28][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0709 (1.0289)\tAcc@1 67.188 (70.097)\tAcc@5 96.875 (93.092)\n",
            "Epoch: [28][600/782]\tTime 0.043 (0.040)\tData 0.001 (0.002)\tLoss 0.9116 (1.0343)\tAcc@1 73.438 (69.988)\tAcc@5 95.312 (93.022)\n",
            "Epoch: [28][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0798 (1.0402)\tAcc@1 65.625 (69.798)\tAcc@5 92.188 (92.885)\n",
            " * Acc@1 69.678 Acc@5 92.876\n",
            "epoch 28, total time 31.12\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.9225 (1.9225)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.7298 (1.5115)\tAcc@1 50.000 (59.932)\tAcc@5 87.500 (85.922)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.2402 (1.5027)\tAcc@1 65.625 (59.562)\tAcc@5 90.625 (86.007)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.1565 (1.5113)\tAcc@1 65.625 (59.427)\tAcc@5 93.750 (86.026)\n",
            " * Acc@1 59.500 Acc@5 86.120\n",
            "==> training...\n",
            "Epoch: [29][0/782]\tTime 0.254 (0.254)\tData 0.220 (0.220)\tLoss 1.1035 (1.1035)\tAcc@1 70.312 (70.312)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [29][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.004)\tLoss 1.0510 (0.9498)\tAcc@1 64.062 (71.689)\tAcc@5 96.875 (94.075)\n",
            "Epoch: [29][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.003)\tLoss 0.9094 (0.9783)\tAcc@1 67.188 (71.144)\tAcc@5 96.875 (93.789)\n",
            "Epoch: [29][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1343 (0.9944)\tAcc@1 75.000 (70.785)\tAcc@5 95.312 (93.677)\n",
            "Epoch: [29][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.2120 (1.0078)\tAcc@1 65.625 (70.429)\tAcc@5 92.188 (93.473)\n",
            "Epoch: [29][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7342 (1.0185)\tAcc@1 81.250 (70.104)\tAcc@5 100.000 (93.370)\n",
            "Epoch: [29][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0355 (1.0250)\tAcc@1 71.875 (69.993)\tAcc@5 89.062 (93.243)\n",
            "Epoch: [29][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9290 (1.0332)\tAcc@1 73.438 (69.724)\tAcc@5 90.625 (93.092)\n",
            " * Acc@1 69.598 Acc@5 93.052\n",
            "epoch 29, total time 31.02\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 1.7957 (1.7957)\tAcc@1 56.250 (56.250)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.008 (0.008)\tLoss 1.4410 (1.5470)\tAcc@1 65.625 (59.127)\tAcc@5 84.375 (86.850)\n",
            "Test: [200/313]\tTime 0.012 (0.008)\tLoss 1.5410 (1.5582)\tAcc@1 62.500 (58.738)\tAcc@5 93.750 (86.676)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.8357 (1.5592)\tAcc@1 43.750 (58.991)\tAcc@5 81.250 (86.690)\n",
            " * Acc@1 58.890 Acc@5 86.730\n",
            "==> training...\n",
            "Epoch: [30][0/782]\tTime 0.249 (0.249)\tData 0.206 (0.206)\tLoss 1.0512 (1.0512)\tAcc@1 68.750 (68.750)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [30][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.0414 (0.9684)\tAcc@1 73.438 (71.163)\tAcc@5 92.188 (93.827)\n",
            "Epoch: [30][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.5890 (0.9584)\tAcc@1 81.250 (71.541)\tAcc@5 98.438 (93.952)\n",
            "Epoch: [30][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0521 (0.9836)\tAcc@1 68.750 (70.899)\tAcc@5 93.750 (93.584)\n",
            "Epoch: [30][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9541 (1.0024)\tAcc@1 73.438 (70.445)\tAcc@5 92.188 (93.337)\n",
            "Epoch: [30][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1316 (1.0090)\tAcc@1 60.938 (70.213)\tAcc@5 95.312 (93.288)\n",
            "Epoch: [30][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9170 (1.0172)\tAcc@1 76.562 (69.941)\tAcc@5 95.312 (93.204)\n",
            "Epoch: [30][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2334 (1.0211)\tAcc@1 65.625 (69.869)\tAcc@5 89.062 (93.117)\n",
            " * Acc@1 69.664 Acc@5 92.970\n",
            "epoch 30, total time 31.03\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.6995 (1.6995)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.7215 (1.5424)\tAcc@1 50.000 (59.592)\tAcc@5 84.375 (86.200)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.4103 (1.4990)\tAcc@1 65.625 (60.012)\tAcc@5 93.750 (86.723)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.7567 (1.4980)\tAcc@1 46.875 (60.216)\tAcc@5 87.500 (86.887)\n",
            " * Acc@1 60.260 Acc@5 86.920\n",
            "==> training...\n",
            "Epoch: [31][0/782]\tTime 0.266 (0.266)\tData 0.222 (0.222)\tLoss 0.9179 (0.9179)\tAcc@1 68.750 (68.750)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [31][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.004)\tLoss 0.7279 (0.9510)\tAcc@1 75.000 (72.092)\tAcc@5 96.875 (94.230)\n",
            "Epoch: [31][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.6506 (0.9743)\tAcc@1 85.938 (71.245)\tAcc@5 95.312 (94.038)\n",
            "Epoch: [31][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.2026 (0.9854)\tAcc@1 68.750 (71.055)\tAcc@5 84.375 (93.833)\n",
            "Epoch: [31][400/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.8016 (0.9933)\tAcc@1 73.438 (70.831)\tAcc@5 95.312 (93.695)\n",
            "Epoch: [31][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1271 (1.0026)\tAcc@1 65.625 (70.500)\tAcc@5 92.188 (93.519)\n",
            "Epoch: [31][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1182 (1.0104)\tAcc@1 64.062 (70.289)\tAcc@5 95.312 (93.376)\n",
            "Epoch: [31][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9662 (1.0191)\tAcc@1 67.188 (70.007)\tAcc@5 95.312 (93.275)\n",
            " * Acc@1 69.896 Acc@5 93.232\n",
            "epoch 31, total time 31.08\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.8564 (1.8564)\tAcc@1 65.625 (65.625)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.013 (0.010)\tLoss 1.7566 (1.6295)\tAcc@1 46.875 (56.590)\tAcc@5 90.625 (86.386)\n",
            "Test: [200/313]\tTime 0.012 (0.009)\tLoss 1.1816 (1.5966)\tAcc@1 68.750 (57.121)\tAcc@5 96.875 (86.287)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 2.0283 (1.5940)\tAcc@1 50.000 (57.361)\tAcc@5 84.375 (86.005)\n",
            " * Acc@1 57.370 Acc@5 85.970\n",
            "==> training...\n",
            "Epoch: [32][0/782]\tTime 0.253 (0.253)\tData 0.206 (0.206)\tLoss 0.9567 (0.9567)\tAcc@1 73.438 (73.438)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [32][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.0987 (0.9637)\tAcc@1 70.312 (72.494)\tAcc@5 92.188 (93.348)\n",
            "Epoch: [32][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8591 (0.9653)\tAcc@1 78.125 (72.163)\tAcc@5 95.312 (93.493)\n",
            "Epoch: [32][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9323 (0.9743)\tAcc@1 71.875 (71.818)\tAcc@5 93.750 (93.589)\n",
            "Epoch: [32][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9841 (0.9789)\tAcc@1 71.875 (71.594)\tAcc@5 92.188 (93.586)\n",
            "Epoch: [32][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1181 (1.0019)\tAcc@1 70.312 (70.805)\tAcc@5 93.750 (93.404)\n",
            "Epoch: [32][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1343 (1.0082)\tAcc@1 65.625 (70.606)\tAcc@5 92.188 (93.318)\n",
            "Epoch: [32][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0690 (1.0158)\tAcc@1 65.625 (70.370)\tAcc@5 95.312 (93.280)\n",
            " * Acc@1 70.170 Acc@5 93.216\n",
            "epoch 32, total time 31.00\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 1.5344 (1.5344)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.4282 (1.3924)\tAcc@1 62.500 (63.119)\tAcc@5 96.875 (88.428)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.3608 (1.3718)\tAcc@1 53.125 (63.075)\tAcc@5 93.750 (88.464)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.7360 (1.3810)\tAcc@1 59.375 (62.811)\tAcc@5 81.250 (88.061)\n",
            " * Acc@1 62.760 Acc@5 88.020\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [33][0/782]\tTime 0.235 (0.235)\tData 0.205 (0.205)\tLoss 0.9912 (0.9912)\tAcc@1 71.875 (71.875)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [33][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.8890 (0.9407)\tAcc@1 73.438 (72.401)\tAcc@5 96.875 (93.936)\n",
            "Epoch: [33][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8993 (0.9404)\tAcc@1 73.438 (72.264)\tAcc@5 98.438 (94.076)\n",
            "Epoch: [33][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0008 (0.9592)\tAcc@1 71.875 (71.833)\tAcc@5 92.188 (94.004)\n",
            "Epoch: [33][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.1495 (0.9786)\tAcc@1 75.000 (71.368)\tAcc@5 89.062 (93.719)\n",
            "Epoch: [33][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9955 (0.9845)\tAcc@1 67.188 (71.092)\tAcc@5 93.750 (93.728)\n",
            "Epoch: [33][600/782]\tTime 0.040 (0.040)\tData 0.002 (0.002)\tLoss 0.9098 (0.9921)\tAcc@1 71.875 (70.908)\tAcc@5 90.625 (93.565)\n",
            "Epoch: [33][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8409 (0.9974)\tAcc@1 70.312 (70.711)\tAcc@5 98.438 (93.456)\n",
            " * Acc@1 70.558 Acc@5 93.434\n",
            "epoch 33, total time 31.12\n",
            "Test: [0/313]\tTime 0.103 (0.103)\tLoss 1.6270 (1.6270)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.4458 (1.6209)\tAcc@1 50.000 (59.406)\tAcc@5 87.500 (84.468)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.5996 (1.6391)\tAcc@1 59.375 (58.085)\tAcc@5 87.500 (84.577)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.0098 (1.6533)\tAcc@1 53.125 (57.454)\tAcc@5 84.375 (84.853)\n",
            " * Acc@1 57.440 Acc@5 84.840\n",
            "==> training...\n",
            "Epoch: [34][0/782]\tTime 0.246 (0.246)\tData 0.205 (0.205)\tLoss 0.8087 (0.8087)\tAcc@1 78.125 (78.125)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [34][100/782]\tTime 0.038 (0.041)\tData 0.001 (0.003)\tLoss 0.8881 (0.8963)\tAcc@1 68.750 (73.205)\tAcc@5 93.750 (94.848)\n",
            "Epoch: [34][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7707 (0.9236)\tAcc@1 81.250 (72.707)\tAcc@5 95.312 (94.232)\n",
            "Epoch: [34][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0280 (0.9410)\tAcc@1 68.750 (72.353)\tAcc@5 90.625 (94.145)\n",
            "Epoch: [34][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9008 (0.9619)\tAcc@1 78.125 (71.672)\tAcc@5 87.500 (93.859)\n",
            "Epoch: [34][500/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 0.7886 (0.9821)\tAcc@1 79.688 (71.098)\tAcc@5 98.438 (93.635)\n",
            "Epoch: [34][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0330 (0.9898)\tAcc@1 65.625 (70.882)\tAcc@5 90.625 (93.578)\n",
            "Epoch: [34][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0899 (1.0020)\tAcc@1 67.188 (70.540)\tAcc@5 93.750 (93.389)\n",
            " * Acc@1 70.378 Acc@5 93.290\n",
            "epoch 34, total time 30.99\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.5840 (1.5840)\tAcc@1 65.625 (65.625)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.4480 (1.5587)\tAcc@1 56.250 (59.684)\tAcc@5 93.750 (86.974)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.4426 (1.5623)\tAcc@1 65.625 (59.080)\tAcc@5 90.625 (87.065)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.6746 (1.5680)\tAcc@1 53.125 (59.271)\tAcc@5 81.250 (86.752)\n",
            " * Acc@1 59.270 Acc@5 86.700\n",
            "==> training...\n",
            "Epoch: [35][0/782]\tTime 0.229 (0.229)\tData 0.187 (0.187)\tLoss 0.9273 (0.9273)\tAcc@1 75.000 (75.000)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [35][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.0671 (0.9329)\tAcc@1 65.625 (72.649)\tAcc@5 93.750 (94.261)\n",
            "Epoch: [35][200/782]\tTime 0.040 (0.041)\tData 0.001 (0.002)\tLoss 1.1306 (0.9458)\tAcc@1 70.312 (72.505)\tAcc@5 85.938 (94.038)\n",
            "Epoch: [35][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.2249 (0.9532)\tAcc@1 62.500 (72.233)\tAcc@5 92.188 (93.958)\n",
            "Epoch: [35][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9210 (0.9681)\tAcc@1 75.000 (71.937)\tAcc@5 96.875 (93.719)\n",
            "Epoch: [35][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2184 (0.9751)\tAcc@1 65.625 (71.563)\tAcc@5 87.500 (93.641)\n",
            "Epoch: [35][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8336 (0.9786)\tAcc@1 73.438 (71.425)\tAcc@5 95.312 (93.701)\n",
            "Epoch: [35][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9692 (0.9909)\tAcc@1 73.438 (71.180)\tAcc@5 98.438 (93.545)\n",
            " * Acc@1 71.024 Acc@5 93.444\n",
            "epoch 35, total time 31.24\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.9519 (1.9519)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.7798 (1.7250)\tAcc@1 53.125 (54.858)\tAcc@5 87.500 (84.344)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.7048 (1.7484)\tAcc@1 62.500 (54.524)\tAcc@5 90.625 (83.862)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.0619 (1.7483)\tAcc@1 43.750 (54.558)\tAcc@5 78.125 (83.762)\n",
            " * Acc@1 54.610 Acc@5 83.840\n",
            "==> training...\n",
            "Epoch: [36][0/782]\tTime 0.250 (0.250)\tData 0.213 (0.213)\tLoss 0.9747 (0.9747)\tAcc@1 75.000 (75.000)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [36][100/782]\tTime 0.044 (0.041)\tData 0.001 (0.004)\tLoss 0.8527 (0.8709)\tAcc@1 78.125 (74.752)\tAcc@5 98.438 (94.879)\n",
            "Epoch: [36][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.003)\tLoss 1.1053 (0.9086)\tAcc@1 70.312 (73.336)\tAcc@5 93.750 (94.582)\n",
            "Epoch: [36][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1139 (0.9336)\tAcc@1 70.312 (72.643)\tAcc@5 90.625 (94.352)\n",
            "Epoch: [36][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0842 (0.9557)\tAcc@1 70.312 (72.117)\tAcc@5 90.625 (94.019)\n",
            "Epoch: [36][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9891 (0.9635)\tAcc@1 71.875 (71.903)\tAcc@5 93.750 (93.978)\n",
            "Epoch: [36][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1235 (0.9783)\tAcc@1 67.188 (71.550)\tAcc@5 89.062 (93.755)\n",
            "Epoch: [36][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0287 (0.9851)\tAcc@1 65.625 (71.380)\tAcc@5 93.750 (93.681)\n",
            " * Acc@1 71.176 Acc@5 93.580\n",
            "epoch 36, total time 31.04\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.8054 (1.8054)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.4506 (1.4491)\tAcc@1 53.125 (60.582)\tAcc@5 87.500 (87.624)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 0.8191 (1.4330)\tAcc@1 65.625 (61.070)\tAcc@5 100.000 (87.764)\n",
            "Test: [300/313]\tTime 0.013 (0.008)\tLoss 1.3143 (1.4345)\tAcc@1 59.375 (61.140)\tAcc@5 87.500 (87.593)\n",
            " * Acc@1 61.190 Acc@5 87.620\n",
            "==> training...\n",
            "Epoch: [37][0/782]\tTime 0.234 (0.234)\tData 0.200 (0.200)\tLoss 0.7495 (0.7495)\tAcc@1 78.125 (78.125)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [37][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.8662 (0.9254)\tAcc@1 73.438 (72.958)\tAcc@5 96.875 (94.415)\n",
            "Epoch: [37][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3441 (0.9216)\tAcc@1 67.188 (72.847)\tAcc@5 87.500 (94.395)\n",
            "Epoch: [37][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1994 (0.9334)\tAcc@1 60.938 (72.545)\tAcc@5 92.188 (94.383)\n",
            "Epoch: [37][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1289 (0.9495)\tAcc@1 70.312 (72.128)\tAcc@5 92.188 (94.140)\n",
            "Epoch: [37][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7363 (0.9650)\tAcc@1 82.812 (71.710)\tAcc@5 95.312 (93.959)\n",
            "Epoch: [37][600/782]\tTime 0.040 (0.039)\tData 0.001 (0.002)\tLoss 0.8410 (0.9703)\tAcc@1 75.000 (71.599)\tAcc@5 93.750 (93.872)\n",
            "Epoch: [37][700/782]\tTime 0.039 (0.039)\tData 0.001 (0.002)\tLoss 1.1516 (0.9781)\tAcc@1 70.312 (71.304)\tAcc@5 89.062 (93.746)\n",
            " * Acc@1 71.110 Acc@5 93.698\n",
            "epoch 37, total time 30.88\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.7796 (1.7796)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.3819 (1.4285)\tAcc@1 53.125 (61.417)\tAcc@5 87.500 (87.902)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.2645 (1.4080)\tAcc@1 65.625 (61.583)\tAcc@5 90.625 (87.889)\n",
            "Test: [300/313]\tTime 0.013 (0.008)\tLoss 1.6698 (1.4181)\tAcc@1 56.250 (61.680)\tAcc@5 87.500 (87.728)\n",
            " * Acc@1 61.630 Acc@5 87.730\n",
            "==> training...\n",
            "Epoch: [38][0/782]\tTime 0.261 (0.261)\tData 0.226 (0.226)\tLoss 1.0942 (1.0942)\tAcc@1 71.875 (71.875)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [38][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.004)\tLoss 0.9555 (0.9304)\tAcc@1 68.750 (72.200)\tAcc@5 95.312 (94.028)\n",
            "Epoch: [38][200/782]\tTime 0.044 (0.040)\tData 0.001 (0.003)\tLoss 0.9437 (0.9436)\tAcc@1 68.750 (72.170)\tAcc@5 90.625 (94.108)\n",
            "Epoch: [38][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9020 (0.9511)\tAcc@1 70.312 (71.911)\tAcc@5 93.750 (94.119)\n",
            "Epoch: [38][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2020 (0.9557)\tAcc@1 70.312 (71.809)\tAcc@5 95.312 (94.062)\n",
            "Epoch: [38][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7727 (0.9736)\tAcc@1 76.562 (71.376)\tAcc@5 98.438 (93.900)\n",
            "Epoch: [38][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9308 (0.9834)\tAcc@1 71.875 (71.194)\tAcc@5 93.750 (93.703)\n",
            "Epoch: [38][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7878 (0.9845)\tAcc@1 79.688 (71.084)\tAcc@5 98.438 (93.719)\n",
            " * Acc@1 70.956 Acc@5 93.630\n",
            "epoch 38, total time 31.13\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 1.3504 (1.3504)\tAcc@1 71.875 (71.875)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.008 (0.009)\tLoss 1.6855 (1.4526)\tAcc@1 50.000 (61.417)\tAcc@5 84.375 (87.191)\n",
            "Test: [200/313]\tTime 0.008 (0.009)\tLoss 1.4242 (1.4289)\tAcc@1 65.625 (61.660)\tAcc@5 93.750 (87.687)\n",
            "Test: [300/313]\tTime 0.008 (0.009)\tLoss 1.7431 (1.4342)\tAcc@1 56.250 (62.189)\tAcc@5 81.250 (87.531)\n",
            " * Acc@1 62.090 Acc@5 87.500\n",
            "==> training...\n",
            "Epoch: [39][0/782]\tTime 0.252 (0.252)\tData 0.215 (0.215)\tLoss 0.8393 (0.8393)\tAcc@1 79.688 (79.688)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [39][100/782]\tTime 0.039 (0.041)\tData 0.002 (0.004)\tLoss 1.1122 (0.9166)\tAcc@1 59.375 (73.252)\tAcc@5 92.188 (94.539)\n",
            "Epoch: [39][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.003)\tLoss 0.7516 (0.9054)\tAcc@1 75.000 (73.305)\tAcc@5 93.750 (94.558)\n",
            "Epoch: [39][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9330 (0.9344)\tAcc@1 68.750 (72.571)\tAcc@5 96.875 (94.207)\n",
            "Epoch: [39][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9547 (0.9499)\tAcc@1 75.000 (72.233)\tAcc@5 92.188 (94.011)\n",
            "Epoch: [39][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9281 (0.9550)\tAcc@1 65.625 (72.218)\tAcc@5 96.875 (93.915)\n",
            "Epoch: [39][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3640 (0.9654)\tAcc@1 60.938 (71.880)\tAcc@5 90.625 (93.815)\n",
            "Epoch: [39][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7940 (0.9764)\tAcc@1 75.000 (71.625)\tAcc@5 96.875 (93.672)\n",
            " * Acc@1 71.484 Acc@5 93.658\n",
            "epoch 39, total time 31.15\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 2.0781 (2.0781)\tAcc@1 53.125 (53.125)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.5455 (1.8202)\tAcc@1 56.250 (52.197)\tAcc@5 84.375 (82.921)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.5007 (1.8545)\tAcc@1 59.375 (52.254)\tAcc@5 96.875 (82.867)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.9746 (1.8420)\tAcc@1 46.875 (52.845)\tAcc@5 84.375 (82.838)\n",
            " * Acc@1 52.920 Acc@5 82.930\n",
            "==> training...\n",
            "Epoch: [40][0/782]\tTime 0.229 (0.229)\tData 0.193 (0.193)\tLoss 0.9203 (0.9203)\tAcc@1 75.000 (75.000)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [40][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.1658 (0.9260)\tAcc@1 68.750 (73.097)\tAcc@5 93.750 (94.214)\n",
            "Epoch: [40][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8896 (0.9219)\tAcc@1 76.562 (73.018)\tAcc@5 93.750 (94.279)\n",
            "Epoch: [40][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8378 (0.9375)\tAcc@1 73.438 (72.404)\tAcc@5 95.312 (93.999)\n",
            "Epoch: [40][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8741 (0.9471)\tAcc@1 68.750 (72.249)\tAcc@5 96.875 (93.910)\n",
            "Epoch: [40][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8344 (0.9602)\tAcc@1 78.125 (71.863)\tAcc@5 92.188 (93.834)\n",
            "Epoch: [40][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9173 (0.9655)\tAcc@1 75.000 (71.685)\tAcc@5 90.625 (93.792)\n",
            "Epoch: [40][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1582 (0.9718)\tAcc@1 67.188 (71.603)\tAcc@5 92.188 (93.717)\n",
            " * Acc@1 71.370 Acc@5 93.632\n",
            "epoch 40, total time 30.96\n",
            "Test: [0/313]\tTime 0.125 (0.125)\tLoss 1.6355 (1.6355)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.7900 (1.5084)\tAcc@1 53.125 (59.066)\tAcc@5 84.375 (87.407)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1314 (1.4847)\tAcc@1 68.750 (59.810)\tAcc@5 93.750 (87.391)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.0142 (1.4864)\tAcc@1 37.500 (59.853)\tAcc@5 81.250 (87.500)\n",
            " * Acc@1 59.820 Acc@5 87.550\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [41][0/782]\tTime 0.244 (0.244)\tData 0.206 (0.206)\tLoss 1.0039 (1.0039)\tAcc@1 73.438 (73.438)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [41][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.7930 (0.9119)\tAcc@1 68.750 (73.113)\tAcc@5 98.438 (94.926)\n",
            "Epoch: [41][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8660 (0.9276)\tAcc@1 71.875 (72.676)\tAcc@5 93.750 (94.582)\n",
            "Epoch: [41][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0412 (0.9352)\tAcc@1 70.312 (72.477)\tAcc@5 93.750 (94.363)\n",
            "Epoch: [41][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0949 (0.9413)\tAcc@1 70.312 (72.241)\tAcc@5 92.188 (94.284)\n",
            "Epoch: [41][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7962 (0.9521)\tAcc@1 81.250 (72.003)\tAcc@5 93.750 (94.127)\n",
            "Epoch: [41][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0876 (0.9634)\tAcc@1 75.000 (71.716)\tAcc@5 89.062 (93.971)\n",
            "Epoch: [41][700/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 0.9362 (0.9699)\tAcc@1 71.875 (71.465)\tAcc@5 90.625 (93.913)\n",
            " * Acc@1 71.178 Acc@5 93.772\n",
            "epoch 41, total time 31.10\n",
            "Test: [0/313]\tTime 0.109 (0.109)\tLoss 1.9844 (1.9844)\tAcc@1 59.375 (59.375)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.6730 (1.7622)\tAcc@1 59.375 (55.786)\tAcc@5 87.500 (83.230)\n",
            "Test: [200/313]\tTime 0.013 (0.008)\tLoss 0.9494 (1.7505)\tAcc@1 75.000 (55.861)\tAcc@5 93.750 (84.017)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.2598 (1.7682)\tAcc@1 43.750 (55.523)\tAcc@5 75.000 (83.949)\n",
            " * Acc@1 55.650 Acc@5 84.010\n",
            "==> training...\n",
            "Epoch: [42][0/782]\tTime 0.257 (0.257)\tData 0.215 (0.215)\tLoss 0.7889 (0.7889)\tAcc@1 75.000 (75.000)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [42][100/782]\tTime 0.041 (0.041)\tData 0.001 (0.003)\tLoss 0.8410 (0.9266)\tAcc@1 73.438 (72.308)\tAcc@5 98.438 (94.369)\n",
            "Epoch: [42][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7694 (0.9112)\tAcc@1 81.250 (73.127)\tAcc@5 93.750 (94.504)\n",
            "Epoch: [42][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2213 (0.9405)\tAcc@1 64.062 (72.238)\tAcc@5 93.750 (94.145)\n",
            "Epoch: [42][400/782]\tTime 0.036 (0.040)\tData 0.001 (0.002)\tLoss 1.1076 (0.9551)\tAcc@1 68.750 (71.828)\tAcc@5 95.312 (94.054)\n",
            "Epoch: [42][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2122 (0.9611)\tAcc@1 71.875 (71.625)\tAcc@5 90.625 (93.922)\n",
            "Epoch: [42][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7447 (0.9688)\tAcc@1 79.688 (71.347)\tAcc@5 98.438 (93.802)\n",
            "Epoch: [42][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7214 (0.9717)\tAcc@1 79.688 (71.275)\tAcc@5 96.875 (93.752)\n",
            " * Acc@1 71.206 Acc@5 93.642\n",
            "epoch 42, total time 31.01\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.5952 (1.5952)\tAcc@1 65.625 (65.625)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.5068 (1.3937)\tAcc@1 53.125 (62.407)\tAcc@5 93.750 (89.140)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.0287 (1.3972)\tAcc@1 68.750 (62.811)\tAcc@5 100.000 (88.542)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.2001 (1.4052)\tAcc@1 65.625 (62.635)\tAcc@5 96.875 (88.466)\n",
            " * Acc@1 62.690 Acc@5 88.470\n",
            "==> training...\n",
            "Epoch: [43][0/782]\tTime 0.264 (0.264)\tData 0.223 (0.223)\tLoss 0.8763 (0.8763)\tAcc@1 70.312 (70.312)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [43][100/782]\tTime 0.037 (0.041)\tData 0.001 (0.004)\tLoss 0.8693 (0.9053)\tAcc@1 68.750 (73.546)\tAcc@5 96.875 (94.817)\n",
            "Epoch: [43][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.003)\tLoss 0.9048 (0.9186)\tAcc@1 73.438 (72.862)\tAcc@5 92.188 (94.613)\n",
            "Epoch: [43][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9644 (0.9352)\tAcc@1 71.875 (72.529)\tAcc@5 90.625 (94.321)\n",
            "Epoch: [43][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7794 (0.9444)\tAcc@1 82.812 (72.288)\tAcc@5 95.312 (94.171)\n",
            "Epoch: [43][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0968 (0.9529)\tAcc@1 68.750 (72.031)\tAcc@5 90.625 (94.034)\n",
            "Epoch: [43][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0209 (0.9634)\tAcc@1 65.625 (71.693)\tAcc@5 92.188 (93.924)\n",
            "Epoch: [43][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7733 (0.9723)\tAcc@1 75.000 (71.565)\tAcc@5 95.312 (93.846)\n",
            " * Acc@1 71.434 Acc@5 93.796\n",
            "epoch 43, total time 30.96\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 1.6391 (1.6391)\tAcc@1 68.750 (68.750)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 2.0707 (1.5495)\tAcc@1 50.000 (59.468)\tAcc@5 81.250 (85.489)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.3108 (1.5288)\tAcc@1 68.750 (59.935)\tAcc@5 90.625 (86.365)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.9205 (1.5294)\tAcc@1 53.125 (59.894)\tAcc@5 84.375 (86.337)\n",
            " * Acc@1 59.900 Acc@5 86.310\n",
            "==> training...\n",
            "Epoch: [44][0/782]\tTime 0.232 (0.232)\tData 0.204 (0.204)\tLoss 0.6463 (0.6463)\tAcc@1 81.250 (81.250)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [44][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.004)\tLoss 0.8925 (0.9025)\tAcc@1 76.562 (73.205)\tAcc@5 92.188 (94.817)\n",
            "Epoch: [44][200/782]\tTime 0.040 (0.041)\tData 0.002 (0.003)\tLoss 0.8299 (0.9155)\tAcc@1 78.125 (72.769)\tAcc@5 96.875 (94.426)\n",
            "Epoch: [44][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7843 (0.9176)\tAcc@1 75.000 (72.851)\tAcc@5 92.188 (94.420)\n",
            "Epoch: [44][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7820 (0.9430)\tAcc@1 78.125 (72.179)\tAcc@5 95.312 (94.175)\n",
            "Epoch: [44][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9946 (0.9470)\tAcc@1 70.312 (72.106)\tAcc@5 92.188 (94.121)\n",
            "Epoch: [44][600/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.9580 (0.9551)\tAcc@1 67.188 (71.857)\tAcc@5 96.875 (94.059)\n",
            "Epoch: [44][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8764 (0.9647)\tAcc@1 71.875 (71.670)\tAcc@5 96.875 (93.935)\n",
            " * Acc@1 71.418 Acc@5 93.818\n",
            "epoch 44, total time 31.08\n",
            "Test: [0/313]\tTime 0.104 (0.104)\tLoss 1.5327 (1.5327)\tAcc@1 62.500 (62.500)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.2811 (1.5304)\tAcc@1 65.625 (58.849)\tAcc@5 90.625 (86.757)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1272 (1.5216)\tAcc@1 56.250 (58.489)\tAcc@5 96.875 (86.971)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.7007 (1.5190)\tAcc@1 50.000 (58.835)\tAcc@5 87.500 (86.856)\n",
            " * Acc@1 58.880 Acc@5 86.900\n",
            "==> training...\n",
            "Epoch: [45][0/782]\tTime 0.237 (0.237)\tData 0.204 (0.204)\tLoss 0.9274 (0.9274)\tAcc@1 71.875 (71.875)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [45][100/782]\tTime 0.038 (0.041)\tData 0.001 (0.003)\tLoss 1.0304 (0.8981)\tAcc@1 67.188 (73.298)\tAcc@5 92.188 (94.539)\n",
            "Epoch: [45][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9181 (0.8902)\tAcc@1 68.750 (73.686)\tAcc@5 95.312 (94.551)\n",
            "Epoch: [45][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8775 (0.9133)\tAcc@1 73.438 (72.965)\tAcc@5 92.188 (94.420)\n",
            "Epoch: [45][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9507 (0.9255)\tAcc@1 68.750 (72.678)\tAcc@5 93.750 (94.292)\n",
            "Epoch: [45][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7973 (0.9383)\tAcc@1 76.562 (72.405)\tAcc@5 96.875 (94.102)\n",
            "Epoch: [45][600/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.7890 (0.9516)\tAcc@1 79.688 (71.995)\tAcc@5 95.312 (94.002)\n",
            "Epoch: [45][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0909 (0.9598)\tAcc@1 70.312 (71.815)\tAcc@5 93.750 (93.913)\n",
            " * Acc@1 71.570 Acc@5 93.820\n",
            "epoch 45, total time 30.91\n",
            "Test: [0/313]\tTime 0.112 (0.112)\tLoss 1.5800 (1.5800)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.4674 (1.4522)\tAcc@1 62.500 (60.458)\tAcc@5 90.625 (87.748)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.4248 (1.4496)\tAcc@1 56.250 (60.432)\tAcc@5 90.625 (87.516)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.4319 (1.4522)\tAcc@1 46.875 (60.777)\tAcc@5 100.000 (87.386)\n",
            " * Acc@1 60.960 Acc@5 87.440\n",
            "==> training...\n",
            "Epoch: [46][0/782]\tTime 0.231 (0.231)\tData 0.193 (0.193)\tLoss 0.8048 (0.8048)\tAcc@1 78.125 (78.125)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [46][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.9709 (0.8607)\tAcc@1 71.875 (74.381)\tAcc@5 95.312 (95.328)\n",
            "Epoch: [46][200/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 1.0079 (0.8903)\tAcc@1 73.438 (73.546)\tAcc@5 93.750 (94.893)\n",
            "Epoch: [46][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0074 (0.9058)\tAcc@1 75.000 (72.866)\tAcc@5 90.625 (94.778)\n",
            "Epoch: [46][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0815 (0.9323)\tAcc@1 64.062 (72.339)\tAcc@5 93.750 (94.455)\n",
            "Epoch: [46][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2509 (0.9442)\tAcc@1 67.188 (72.040)\tAcc@5 92.188 (94.311)\n",
            "Epoch: [46][600/782]\tTime 0.039 (0.040)\tData 0.002 (0.002)\tLoss 1.0900 (0.9525)\tAcc@1 64.062 (71.849)\tAcc@5 92.188 (94.130)\n",
            "Epoch: [46][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9271 (0.9609)\tAcc@1 70.312 (71.710)\tAcc@5 98.438 (94.020)\n",
            " * Acc@1 71.668 Acc@5 93.962\n",
            "epoch 46, total time 30.96\n",
            "Test: [0/313]\tTime 0.112 (0.112)\tLoss 1.6894 (1.6894)\tAcc@1 62.500 (62.500)\tAcc@5 75.000 (75.000)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.7783 (1.7582)\tAcc@1 53.125 (56.590)\tAcc@5 87.500 (84.097)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.3403 (1.6992)\tAcc@1 65.625 (57.276)\tAcc@5 96.875 (85.152)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.0320 (1.7091)\tAcc@1 50.000 (57.350)\tAcc@5 87.500 (84.998)\n",
            " * Acc@1 57.260 Acc@5 84.990\n",
            "==> training...\n",
            "Epoch: [47][0/782]\tTime 0.264 (0.264)\tData 0.220 (0.220)\tLoss 0.8872 (0.8872)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [47][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.9958 (0.9059)\tAcc@1 73.438 (73.236)\tAcc@5 95.312 (94.477)\n",
            "Epoch: [47][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6721 (0.9209)\tAcc@1 73.438 (72.761)\tAcc@5 100.000 (94.504)\n",
            "Epoch: [47][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8866 (0.9227)\tAcc@1 75.000 (72.591)\tAcc@5 93.750 (94.503)\n",
            "Epoch: [47][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0678 (0.9318)\tAcc@1 70.312 (72.249)\tAcc@5 89.062 (94.315)\n",
            "Epoch: [47][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9622 (0.9432)\tAcc@1 70.312 (71.975)\tAcc@5 98.438 (94.168)\n",
            "Epoch: [47][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0854 (0.9474)\tAcc@1 67.188 (71.872)\tAcc@5 95.312 (94.088)\n",
            "Epoch: [47][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6569 (0.9572)\tAcc@1 84.375 (71.710)\tAcc@5 95.312 (93.993)\n",
            " * Acc@1 71.602 Acc@5 93.928\n",
            "epoch 47, total time 30.94\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.5771 (1.5771)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.008 (0.009)\tLoss 1.3138 (1.3477)\tAcc@1 68.750 (63.490)\tAcc@5 93.750 (88.738)\n",
            "Test: [200/313]\tTime 0.008 (0.008)\tLoss 1.1699 (1.3457)\tAcc@1 68.750 (63.231)\tAcc@5 90.625 (88.682)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.6898 (1.3528)\tAcc@1 59.375 (62.998)\tAcc@5 81.250 (88.569)\n",
            " * Acc@1 63.150 Acc@5 88.590\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [48][0/782]\tTime 0.265 (0.265)\tData 0.231 (0.231)\tLoss 1.2843 (1.2843)\tAcc@1 65.625 (65.625)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [48][100/782]\tTime 0.041 (0.042)\tData 0.001 (0.004)\tLoss 1.2208 (0.8983)\tAcc@1 62.500 (74.041)\tAcc@5 89.062 (94.957)\n",
            "Epoch: [48][200/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.9870 (0.8966)\tAcc@1 65.625 (73.702)\tAcc@5 95.312 (94.831)\n",
            "Epoch: [48][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8322 (0.9147)\tAcc@1 73.438 (73.012)\tAcc@5 98.438 (94.612)\n",
            "Epoch: [48][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8628 (0.9147)\tAcc@1 73.438 (73.013)\tAcc@5 95.312 (94.592)\n",
            "Epoch: [48][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0249 (0.9278)\tAcc@1 67.188 (72.686)\tAcc@5 93.750 (94.449)\n",
            "Epoch: [48][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9353 (0.9337)\tAcc@1 73.438 (72.582)\tAcc@5 92.188 (94.306)\n",
            "Epoch: [48][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1748 (0.9489)\tAcc@1 70.312 (72.176)\tAcc@5 92.188 (94.122)\n",
            " * Acc@1 72.030 Acc@5 94.042\n",
            "epoch 48, total time 31.22\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.6486 (1.6486)\tAcc@1 65.625 (65.625)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.3293 (1.3620)\tAcc@1 59.375 (61.912)\tAcc@5 96.875 (89.573)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.0455 (1.3806)\tAcc@1 78.125 (61.676)\tAcc@5 90.625 (89.397)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.5783 (1.3943)\tAcc@1 56.250 (61.669)\tAcc@5 90.625 (88.704)\n",
            " * Acc@1 61.740 Acc@5 88.720\n",
            "==> training...\n",
            "Epoch: [49][0/782]\tTime 0.242 (0.242)\tData 0.205 (0.205)\tLoss 0.6765 (0.6765)\tAcc@1 78.125 (78.125)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [49][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.0071 (0.8302)\tAcc@1 67.188 (75.789)\tAcc@5 93.750 (95.235)\n",
            "Epoch: [49][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8426 (0.8777)\tAcc@1 79.688 (74.199)\tAcc@5 96.875 (94.761)\n",
            "Epoch: [49][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8525 (0.8986)\tAcc@1 71.875 (73.557)\tAcc@5 90.625 (94.518)\n",
            "Epoch: [49][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9994 (0.9171)\tAcc@1 71.875 (73.021)\tAcc@5 90.625 (94.346)\n",
            "Epoch: [49][500/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9734 (0.9213)\tAcc@1 71.875 (72.861)\tAcc@5 93.750 (94.261)\n",
            "Epoch: [49][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1578 (0.9312)\tAcc@1 68.750 (72.598)\tAcc@5 90.625 (94.171)\n",
            "Epoch: [49][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7947 (0.9390)\tAcc@1 78.125 (72.303)\tAcc@5 96.875 (94.084)\n",
            " * Acc@1 72.070 Acc@5 94.042\n",
            "epoch 49, total time 30.99\n",
            "Test: [0/313]\tTime 0.109 (0.109)\tLoss 1.7828 (1.7828)\tAcc@1 62.500 (62.500)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.7946 (1.6034)\tAcc@1 50.000 (59.561)\tAcc@5 84.375 (85.118)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.6012 (1.5657)\tAcc@1 50.000 (59.608)\tAcc@5 90.625 (86.287)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.5496 (1.5507)\tAcc@1 46.875 (59.842)\tAcc@5 71.875 (86.451)\n",
            " * Acc@1 59.920 Acc@5 86.460\n",
            "==> training...\n",
            "Epoch: [50][0/782]\tTime 0.244 (0.244)\tData 0.207 (0.207)\tLoss 0.7744 (0.7744)\tAcc@1 75.000 (75.000)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [50][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.1038 (0.8606)\tAcc@1 73.438 (74.861)\tAcc@5 92.188 (95.019)\n",
            "Epoch: [50][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0895 (0.8967)\tAcc@1 70.312 (73.888)\tAcc@5 95.312 (94.846)\n",
            "Epoch: [50][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9742 (0.9146)\tAcc@1 73.438 (73.204)\tAcc@5 90.625 (94.591)\n",
            "Epoch: [50][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0337 (0.9211)\tAcc@1 60.938 (73.056)\tAcc@5 96.875 (94.451)\n",
            "Epoch: [50][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0795 (0.9322)\tAcc@1 64.062 (72.633)\tAcc@5 92.188 (94.311)\n",
            "Epoch: [50][600/782]\tTime 0.043 (0.040)\tData 0.001 (0.002)\tLoss 1.1054 (0.9478)\tAcc@1 64.062 (72.242)\tAcc@5 89.062 (94.171)\n",
            "Epoch: [50][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2684 (0.9529)\tAcc@1 62.500 (72.067)\tAcc@5 93.750 (94.042)\n",
            " * Acc@1 72.048 Acc@5 93.952\n",
            "epoch 50, total time 31.05\n",
            "Test: [0/313]\tTime 0.105 (0.105)\tLoss 1.4649 (1.4649)\tAcc@1 56.250 (56.250)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.012 (0.009)\tLoss 1.7339 (1.5720)\tAcc@1 53.125 (59.251)\tAcc@5 87.500 (86.943)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1298 (1.5633)\tAcc@1 62.500 (59.282)\tAcc@5 93.750 (87.142)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.1674 (1.5683)\tAcc@1 40.625 (59.500)\tAcc@5 71.875 (86.649)\n",
            " * Acc@1 59.380 Acc@5 86.640\n",
            "==> training...\n",
            "Epoch: [51][0/782]\tTime 0.238 (0.238)\tData 0.210 (0.210)\tLoss 0.5677 (0.5677)\tAcc@1 84.375 (84.375)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [51][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.0635 (0.8888)\tAcc@1 67.188 (73.391)\tAcc@5 93.750 (94.817)\n",
            "Epoch: [51][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9393 (0.8882)\tAcc@1 68.750 (73.321)\tAcc@5 98.438 (94.815)\n",
            "Epoch: [51][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8817 (0.8916)\tAcc@1 81.250 (73.484)\tAcc@5 90.625 (94.747)\n",
            "Epoch: [51][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0300 (0.9085)\tAcc@1 81.250 (73.079)\tAcc@5 95.312 (94.549)\n",
            "Epoch: [51][500/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.2900 (0.9184)\tAcc@1 67.188 (72.948)\tAcc@5 89.062 (94.408)\n",
            "Epoch: [51][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9799 (0.9290)\tAcc@1 73.438 (72.590)\tAcc@5 96.875 (94.348)\n",
            "Epoch: [51][700/782]\tTime 0.040 (0.039)\tData 0.001 (0.002)\tLoss 0.6638 (0.9422)\tAcc@1 79.688 (72.267)\tAcc@5 98.438 (94.182)\n",
            " * Acc@1 71.976 Acc@5 94.034\n",
            "epoch 51, total time 30.91\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.5352 (1.5352)\tAcc@1 65.625 (65.625)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.008 (0.008)\tLoss 2.0414 (1.4666)\tAcc@1 43.750 (61.788)\tAcc@5 90.625 (88.645)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.1786 (1.4468)\tAcc@1 62.500 (62.065)\tAcc@5 96.875 (88.029)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.4989 (1.4665)\tAcc@1 65.625 (61.514)\tAcc@5 93.750 (87.946)\n",
            " * Acc@1 61.510 Acc@5 87.980\n",
            "==> training...\n",
            "Epoch: [52][0/782]\tTime 0.259 (0.259)\tData 0.222 (0.222)\tLoss 1.2510 (1.2510)\tAcc@1 64.062 (64.062)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [52][100/782]\tTime 0.041 (0.041)\tData 0.001 (0.004)\tLoss 1.1095 (0.9234)\tAcc@1 65.625 (73.283)\tAcc@5 92.188 (94.384)\n",
            "Epoch: [52][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.003)\tLoss 0.4934 (0.9190)\tAcc@1 87.500 (73.095)\tAcc@5 95.312 (94.403)\n",
            "Epoch: [52][300/782]\tTime 0.045 (0.040)\tData 0.001 (0.002)\tLoss 0.9528 (0.9215)\tAcc@1 75.000 (73.027)\tAcc@5 95.312 (94.461)\n",
            "Epoch: [52][400/782]\tTime 0.039 (0.040)\tData 0.002 (0.002)\tLoss 0.9973 (0.9253)\tAcc@1 76.562 (72.869)\tAcc@5 89.062 (94.331)\n",
            "Epoch: [52][500/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 0.9425 (0.9374)\tAcc@1 71.875 (72.446)\tAcc@5 95.312 (94.180)\n",
            "Epoch: [52][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7418 (0.9406)\tAcc@1 75.000 (72.353)\tAcc@5 96.875 (94.148)\n",
            "Epoch: [52][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1418 (0.9474)\tAcc@1 73.438 (72.156)\tAcc@5 90.625 (94.049)\n",
            " * Acc@1 71.910 Acc@5 93.944\n",
            "epoch 52, total time 30.99\n",
            "Test: [0/313]\tTime 0.104 (0.104)\tLoss 1.7550 (1.7550)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 2.0925 (1.7638)\tAcc@1 50.000 (56.528)\tAcc@5 84.375 (84.035)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.6616 (1.7354)\tAcc@1 65.625 (56.530)\tAcc@5 87.500 (84.608)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.6293 (1.7431)\tAcc@1 43.750 (56.769)\tAcc@5 90.625 (84.603)\n",
            " * Acc@1 56.890 Acc@5 84.580\n",
            "==> training...\n",
            "Epoch: [53][0/782]\tTime 0.220 (0.220)\tData 0.190 (0.190)\tLoss 1.0834 (1.0834)\tAcc@1 68.750 (68.750)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [53][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.9949 (0.8648)\tAcc@1 68.750 (74.350)\tAcc@5 93.750 (94.848)\n",
            "Epoch: [53][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.6406 (0.8861)\tAcc@1 79.688 (73.375)\tAcc@5 98.438 (94.714)\n",
            "Epoch: [53][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7535 (0.9049)\tAcc@1 73.438 (73.194)\tAcc@5 96.875 (94.570)\n",
            "Epoch: [53][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0505 (0.9091)\tAcc@1 68.750 (73.258)\tAcc@5 87.500 (94.522)\n",
            "Epoch: [53][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1540 (0.9141)\tAcc@1 71.875 (73.066)\tAcc@5 87.500 (94.486)\n",
            "Epoch: [53][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2020 (0.9293)\tAcc@1 60.938 (72.593)\tAcc@5 92.188 (94.322)\n",
            "Epoch: [53][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9585 (0.9383)\tAcc@1 67.188 (72.299)\tAcc@5 90.625 (94.245)\n",
            " * Acc@1 72.262 Acc@5 94.174\n",
            "epoch 53, total time 31.00\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.2979 (1.2979)\tAcc@1 65.625 (65.625)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.6861 (1.3251)\tAcc@1 62.500 (63.552)\tAcc@5 84.375 (88.490)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 0.7860 (1.3408)\tAcc@1 84.375 (62.609)\tAcc@5 93.750 (88.511)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.3900 (1.3477)\tAcc@1 62.500 (62.884)\tAcc@5 87.500 (88.455)\n",
            " * Acc@1 63.120 Acc@5 88.570\n",
            "==> training...\n",
            "Epoch: [54][0/782]\tTime 0.232 (0.232)\tData 0.200 (0.200)\tLoss 0.7792 (0.7792)\tAcc@1 71.875 (71.875)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [54][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.8515 (0.8666)\tAcc@1 76.562 (74.196)\tAcc@5 93.750 (95.019)\n",
            "Epoch: [54][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8368 (0.8706)\tAcc@1 75.000 (74.098)\tAcc@5 98.438 (95.025)\n",
            "Epoch: [54][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2435 (0.8881)\tAcc@1 56.250 (73.661)\tAcc@5 90.625 (94.767)\n",
            "Epoch: [54][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2177 (0.9117)\tAcc@1 59.375 (73.114)\tAcc@5 92.188 (94.514)\n",
            "Epoch: [54][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8756 (0.9283)\tAcc@1 71.875 (72.689)\tAcc@5 93.750 (94.280)\n",
            "Epoch: [54][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8300 (0.9368)\tAcc@1 75.000 (72.457)\tAcc@5 96.875 (94.205)\n",
            "Epoch: [54][700/782]\tTime 0.044 (0.040)\tData 0.001 (0.002)\tLoss 1.0763 (0.9430)\tAcc@1 70.312 (72.267)\tAcc@5 90.625 (94.151)\n",
            " * Acc@1 72.132 Acc@5 94.074\n",
            "epoch 54, total time 30.95\n",
            "Test: [0/313]\tTime 0.104 (0.104)\tLoss 1.5566 (1.5566)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.8468 (1.5257)\tAcc@1 53.125 (60.149)\tAcc@5 78.125 (86.696)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1413 (1.5055)\tAcc@1 68.750 (60.759)\tAcc@5 96.875 (87.018)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.6506 (1.5091)\tAcc@1 56.250 (60.735)\tAcc@5 87.500 (87.105)\n",
            " * Acc@1 60.720 Acc@5 87.170\n",
            "==> training...\n",
            "Epoch: [55][0/782]\tTime 0.251 (0.251)\tData 0.215 (0.215)\tLoss 0.9573 (0.9573)\tAcc@1 67.188 (67.188)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [55][100/782]\tTime 0.040 (0.041)\tData 0.002 (0.003)\tLoss 0.6065 (0.8780)\tAcc@1 81.250 (73.809)\tAcc@5 98.438 (94.910)\n",
            "Epoch: [55][200/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 1.0118 (0.8802)\tAcc@1 76.562 (73.919)\tAcc@5 90.625 (94.698)\n",
            "Epoch: [55][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9757 (0.8966)\tAcc@1 68.750 (73.412)\tAcc@5 96.875 (94.560)\n",
            "Epoch: [55][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8545 (0.9090)\tAcc@1 78.125 (73.126)\tAcc@5 96.875 (94.370)\n",
            "Epoch: [55][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8614 (0.9205)\tAcc@1 73.438 (72.960)\tAcc@5 98.438 (94.249)\n",
            "Epoch: [55][600/782]\tTime 0.041 (0.040)\tData 0.002 (0.002)\tLoss 0.8202 (0.9276)\tAcc@1 71.875 (72.710)\tAcc@5 95.312 (94.189)\n",
            "Epoch: [55][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9426 (0.9341)\tAcc@1 75.000 (72.550)\tAcc@5 90.625 (94.100)\n",
            " * Acc@1 72.326 Acc@5 94.006\n",
            "epoch 55, total time 31.28\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.4265 (1.4265)\tAcc@1 71.875 (71.875)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.6604 (1.4325)\tAcc@1 56.250 (62.314)\tAcc@5 84.375 (87.438)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.2771 (1.4532)\tAcc@1 59.375 (61.707)\tAcc@5 90.625 (86.971)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 2.1561 (1.4624)\tAcc@1 56.250 (61.534)\tAcc@5 78.125 (86.586)\n",
            " * Acc@1 61.500 Acc@5 86.680\n",
            "==> training...\n",
            "Epoch: [56][0/782]\tTime 0.256 (0.256)\tData 0.218 (0.218)\tLoss 0.7405 (0.7405)\tAcc@1 79.688 (79.688)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [56][100/782]\tTime 0.044 (0.042)\tData 0.001 (0.003)\tLoss 0.8540 (0.8890)\tAcc@1 71.875 (73.082)\tAcc@5 96.875 (94.988)\n",
            "Epoch: [56][200/782]\tTime 0.039 (0.041)\tData 0.001 (0.002)\tLoss 0.8302 (0.8859)\tAcc@1 79.688 (73.663)\tAcc@5 93.750 (95.110)\n",
            "Epoch: [56][300/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 0.7587 (0.9053)\tAcc@1 79.688 (73.240)\tAcc@5 95.312 (94.856)\n",
            "Epoch: [56][400/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 1.1176 (0.9157)\tAcc@1 67.188 (73.149)\tAcc@5 90.625 (94.631)\n",
            "Epoch: [56][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0902 (0.9229)\tAcc@1 68.750 (72.907)\tAcc@5 92.188 (94.489)\n",
            "Epoch: [56][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0571 (0.9279)\tAcc@1 67.188 (72.730)\tAcc@5 95.312 (94.387)\n",
            "Epoch: [56][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7639 (0.9382)\tAcc@1 76.562 (72.459)\tAcc@5 95.312 (94.287)\n",
            " * Acc@1 72.254 Acc@5 94.154\n",
            "epoch 56, total time 31.28\n",
            "Test: [0/313]\tTime 0.112 (0.112)\tLoss 1.3026 (1.3026)\tAcc@1 68.750 (68.750)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.9137 (1.4990)\tAcc@1 50.000 (61.170)\tAcc@5 84.375 (86.417)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.2713 (1.4705)\tAcc@1 68.750 (61.365)\tAcc@5 96.875 (87.189)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.5319 (1.4687)\tAcc@1 56.250 (61.618)\tAcc@5 87.500 (87.116)\n",
            " * Acc@1 61.630 Acc@5 87.070\n",
            "==> training...\n",
            "Epoch: [57][0/782]\tTime 0.249 (0.249)\tData 0.211 (0.211)\tLoss 0.5428 (0.5428)\tAcc@1 87.500 (87.500)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [57][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.9144 (0.8642)\tAcc@1 78.125 (74.288)\tAcc@5 95.312 (94.926)\n",
            "Epoch: [57][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9927 (0.8630)\tAcc@1 75.000 (74.355)\tAcc@5 93.750 (94.994)\n",
            "Epoch: [57][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1039 (0.8783)\tAcc@1 68.750 (74.097)\tAcc@5 95.312 (94.840)\n",
            "Epoch: [57][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2140 (0.9096)\tAcc@1 59.375 (73.122)\tAcc@5 87.500 (94.545)\n",
            "Epoch: [57][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8653 (0.9173)\tAcc@1 78.125 (72.895)\tAcc@5 95.312 (94.483)\n",
            "Epoch: [57][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9336 (0.9252)\tAcc@1 70.312 (72.642)\tAcc@5 95.312 (94.374)\n",
            "Epoch: [57][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1169 (0.9312)\tAcc@1 68.750 (72.555)\tAcc@5 92.188 (94.312)\n",
            " * Acc@1 72.516 Acc@5 94.284\n",
            "epoch 57, total time 31.10\n",
            "Test: [0/313]\tTime 0.108 (0.108)\tLoss 1.6984 (1.6984)\tAcc@1 56.250 (56.250)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.5254 (1.5585)\tAcc@1 59.375 (59.623)\tAcc@5 84.375 (86.046)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.4336 (1.5752)\tAcc@1 65.625 (59.157)\tAcc@5 84.375 (85.712)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 1.7870 (1.5872)\tAcc@1 56.250 (59.240)\tAcc@5 84.375 (85.299)\n",
            " * Acc@1 59.220 Acc@5 85.270\n",
            "==> training...\n",
            "Epoch: [58][0/782]\tTime 0.241 (0.241)\tData 0.205 (0.205)\tLoss 0.6257 (0.6257)\tAcc@1 82.812 (82.812)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [58][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.8529 (0.8832)\tAcc@1 73.438 (73.608)\tAcc@5 96.875 (94.848)\n",
            "Epoch: [58][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8158 (0.8941)\tAcc@1 78.125 (73.476)\tAcc@5 98.438 (94.745)\n",
            "Epoch: [58][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0609 (0.8954)\tAcc@1 70.312 (73.292)\tAcc@5 95.312 (94.762)\n",
            "Epoch: [58][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8286 (0.9035)\tAcc@1 78.125 (73.083)\tAcc@5 98.438 (94.615)\n",
            "Epoch: [58][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8977 (0.9173)\tAcc@1 75.000 (72.776)\tAcc@5 95.312 (94.374)\n",
            "Epoch: [58][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0538 (0.9292)\tAcc@1 73.438 (72.489)\tAcc@5 90.625 (94.273)\n",
            "Epoch: [58][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7698 (0.9357)\tAcc@1 76.562 (72.350)\tAcc@5 96.875 (94.209)\n",
            " * Acc@1 72.290 Acc@5 94.148\n",
            "epoch 58, total time 31.08\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 1.4693 (1.4693)\tAcc@1 59.375 (59.375)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.4053 (1.3404)\tAcc@1 59.375 (63.119)\tAcc@5 87.500 (89.387)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.0270 (1.3429)\tAcc@1 65.625 (63.075)\tAcc@5 93.750 (89.039)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.8537 (1.3676)\tAcc@1 50.000 (62.936)\tAcc@5 87.500 (88.611)\n",
            " * Acc@1 62.930 Acc@5 88.580\n",
            "==> training...\n",
            "Epoch: [59][0/782]\tTime 0.239 (0.239)\tData 0.198 (0.198)\tLoss 0.8319 (0.8319)\tAcc@1 79.688 (79.688)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [59][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.0410 (0.8873)\tAcc@1 65.625 (73.623)\tAcc@5 93.750 (94.431)\n",
            "Epoch: [59][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.5509 (0.8814)\tAcc@1 82.812 (73.904)\tAcc@5 98.438 (94.706)\n",
            "Epoch: [59][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9128 (0.8881)\tAcc@1 73.438 (73.905)\tAcc@5 96.875 (94.632)\n",
            "Epoch: [59][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1793 (0.8973)\tAcc@1 64.062 (73.671)\tAcc@5 92.188 (94.498)\n",
            "Epoch: [59][500/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.1048 (0.9096)\tAcc@1 70.312 (73.216)\tAcc@5 89.062 (94.417)\n",
            "Epoch: [59][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8032 (0.9228)\tAcc@1 71.875 (72.824)\tAcc@5 96.875 (94.239)\n",
            "Epoch: [59][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6534 (0.9339)\tAcc@1 78.125 (72.577)\tAcc@5 96.875 (94.136)\n",
            " * Acc@1 72.430 Acc@5 94.128\n",
            "epoch 59, total time 31.04\n",
            "Test: [0/313]\tTime 0.108 (0.108)\tLoss 1.7936 (1.7936)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.3472 (1.6420)\tAcc@1 56.250 (58.323)\tAcc@5 93.750 (85.551)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.4342 (1.6308)\tAcc@1 62.500 (58.629)\tAcc@5 87.500 (85.774)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.8319 (1.6182)\tAcc@1 53.125 (59.261)\tAcc@5 81.250 (85.777)\n",
            " * Acc@1 59.260 Acc@5 85.790\n",
            "==> training...\n",
            "Epoch: [60][0/782]\tTime 0.236 (0.236)\tData 0.208 (0.208)\tLoss 0.6117 (0.6117)\tAcc@1 85.938 (85.938)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [60][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.0444 (0.8767)\tAcc@1 70.312 (73.963)\tAcc@5 96.875 (95.003)\n",
            "Epoch: [60][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9417 (0.8779)\tAcc@1 70.312 (74.122)\tAcc@5 96.875 (94.854)\n",
            "Epoch: [60][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9646 (0.8761)\tAcc@1 71.875 (74.133)\tAcc@5 92.188 (94.835)\n",
            "Epoch: [60][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.4498 (0.8890)\tAcc@1 60.938 (73.839)\tAcc@5 89.062 (94.732)\n",
            "Epoch: [60][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7405 (0.9042)\tAcc@1 78.125 (73.406)\tAcc@5 95.312 (94.555)\n",
            "Epoch: [60][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7774 (0.9131)\tAcc@1 78.125 (73.237)\tAcc@5 98.438 (94.501)\n",
            "Epoch: [60][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.8125 (0.9256)\tAcc@1 78.125 (72.969)\tAcc@5 93.750 (94.336)\n",
            " * Acc@1 72.712 Acc@5 94.252\n",
            "epoch 60, total time 31.06\n",
            "Test: [0/313]\tTime 0.105 (0.105)\tLoss 2.0225 (2.0225)\tAcc@1 50.000 (50.000)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.9055 (1.5447)\tAcc@1 46.875 (59.870)\tAcc@5 81.250 (86.634)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.2172 (1.5435)\tAcc@1 65.625 (59.904)\tAcc@5 90.625 (86.738)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 2.0524 (1.5445)\tAcc@1 43.750 (59.790)\tAcc@5 78.125 (86.607)\n",
            " * Acc@1 59.900 Acc@5 86.610\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [61][0/782]\tTime 0.254 (0.254)\tData 0.217 (0.217)\tLoss 0.7601 (0.7601)\tAcc@1 79.688 (79.688)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [61][100/782]\tTime 0.040 (0.042)\tData 0.001 (0.004)\tLoss 0.6565 (0.8652)\tAcc@1 78.125 (74.644)\tAcc@5 100.000 (94.957)\n",
            "Epoch: [61][200/782]\tTime 0.044 (0.041)\tData 0.001 (0.003)\tLoss 0.9502 (0.8873)\tAcc@1 76.562 (73.997)\tAcc@5 96.875 (94.729)\n",
            "Epoch: [61][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8833 (0.8911)\tAcc@1 73.438 (73.785)\tAcc@5 93.750 (94.773)\n",
            "Epoch: [61][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.8432 (0.9020)\tAcc@1 79.688 (73.589)\tAcc@5 96.875 (94.654)\n",
            "Epoch: [61][500/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.1650 (0.9075)\tAcc@1 68.750 (73.372)\tAcc@5 87.500 (94.645)\n",
            "Epoch: [61][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0202 (0.9190)\tAcc@1 71.875 (73.040)\tAcc@5 93.750 (94.465)\n",
            "Epoch: [61][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.3841 (0.9238)\tAcc@1 59.375 (72.949)\tAcc@5 89.062 (94.414)\n",
            " * Acc@1 72.740 Acc@5 94.388\n",
            "epoch 61, total time 31.27\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.9144 (1.9144)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.008 (0.010)\tLoss 1.8366 (1.6547)\tAcc@1 56.250 (57.271)\tAcc@5 81.250 (85.922)\n",
            "Test: [200/313]\tTime 0.008 (0.009)\tLoss 1.6694 (1.6542)\tAcc@1 50.000 (57.105)\tAcc@5 90.625 (85.852)\n",
            "Test: [300/313]\tTime 0.008 (0.009)\tLoss 2.1410 (1.6467)\tAcc@1 59.375 (57.569)\tAcc@5 75.000 (85.662)\n",
            " * Acc@1 57.690 Acc@5 85.730\n",
            "==> training...\n",
            "Epoch: [62][0/782]\tTime 0.270 (0.270)\tData 0.229 (0.229)\tLoss 0.7420 (0.7420)\tAcc@1 81.250 (81.250)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [62][100/782]\tTime 0.040 (0.042)\tData 0.001 (0.004)\tLoss 0.8175 (0.8903)\tAcc@1 79.688 (73.871)\tAcc@5 95.312 (94.616)\n",
            "Epoch: [62][200/782]\tTime 0.041 (0.041)\tData 0.001 (0.003)\tLoss 1.0716 (0.8890)\tAcc@1 70.312 (73.966)\tAcc@5 92.188 (94.799)\n",
            "Epoch: [62][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0701 (0.9022)\tAcc@1 68.750 (73.552)\tAcc@5 92.188 (94.664)\n",
            "Epoch: [62][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9797 (0.9097)\tAcc@1 67.188 (73.067)\tAcc@5 90.625 (94.592)\n",
            "Epoch: [62][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0937 (0.9212)\tAcc@1 65.625 (72.717)\tAcc@5 92.188 (94.414)\n",
            "Epoch: [62][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1344 (0.9262)\tAcc@1 67.188 (72.502)\tAcc@5 89.062 (94.353)\n",
            "Epoch: [62][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1515 (0.9333)\tAcc@1 68.750 (72.368)\tAcc@5 90.625 (94.267)\n",
            " * Acc@1 72.258 Acc@5 94.220\n",
            "epoch 62, total time 31.08\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 1.5964 (1.5964)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.1985 (1.4789)\tAcc@1 59.375 (61.788)\tAcc@5 93.750 (86.231)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1896 (1.4701)\tAcc@1 62.500 (61.723)\tAcc@5 93.750 (86.443)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.8576 (1.4870)\tAcc@1 50.000 (61.389)\tAcc@5 87.500 (86.420)\n",
            " * Acc@1 61.440 Acc@5 86.520\n",
            "==> training...\n",
            "Epoch: [63][0/782]\tTime 0.240 (0.240)\tData 0.202 (0.202)\tLoss 0.9630 (0.9630)\tAcc@1 70.312 (70.312)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [63][100/782]\tTime 0.044 (0.041)\tData 0.001 (0.003)\tLoss 0.6678 (0.8636)\tAcc@1 79.688 (74.691)\tAcc@5 96.875 (95.111)\n",
            "Epoch: [63][200/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.9172 (0.8852)\tAcc@1 68.750 (73.609)\tAcc@5 93.750 (94.939)\n",
            "Epoch: [63][300/782]\tTime 0.044 (0.040)\tData 0.001 (0.002)\tLoss 0.9602 (0.8926)\tAcc@1 68.750 (73.277)\tAcc@5 92.188 (94.809)\n",
            "Epoch: [63][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0918 (0.9047)\tAcc@1 65.625 (73.212)\tAcc@5 93.750 (94.631)\n",
            "Epoch: [63][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0343 (0.9138)\tAcc@1 68.750 (72.976)\tAcc@5 95.312 (94.558)\n",
            "Epoch: [63][600/782]\tTime 0.044 (0.040)\tData 0.001 (0.002)\tLoss 1.0067 (0.9215)\tAcc@1 73.438 (72.785)\tAcc@5 92.188 (94.465)\n",
            "Epoch: [63][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3723 (0.9248)\tAcc@1 59.375 (72.718)\tAcc@5 92.188 (94.441)\n",
            " * Acc@1 72.628 Acc@5 94.378\n",
            "epoch 63, total time 31.19\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.7974 (1.7974)\tAcc@1 56.250 (56.250)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.4881 (1.3921)\tAcc@1 53.125 (62.593)\tAcc@5 93.750 (88.614)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.0526 (1.4027)\tAcc@1 65.625 (62.158)\tAcc@5 96.875 (88.650)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.7544 (1.4241)\tAcc@1 56.250 (61.815)\tAcc@5 84.375 (88.196)\n",
            " * Acc@1 61.960 Acc@5 88.200\n",
            "==> training...\n",
            "Epoch: [64][0/782]\tTime 0.243 (0.243)\tData 0.198 (0.198)\tLoss 0.8833 (0.8833)\tAcc@1 76.562 (76.562)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [64][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.7861 (0.8607)\tAcc@1 81.250 (74.505)\tAcc@5 92.188 (95.003)\n",
            "Epoch: [64][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0671 (0.8692)\tAcc@1 68.750 (74.324)\tAcc@5 93.750 (94.807)\n",
            "Epoch: [64][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0771 (0.8766)\tAcc@1 67.188 (74.289)\tAcc@5 95.312 (94.856)\n",
            "Epoch: [64][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7405 (0.8880)\tAcc@1 76.562 (74.034)\tAcc@5 98.438 (94.607)\n",
            "Epoch: [64][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8806 (0.9030)\tAcc@1 71.875 (73.462)\tAcc@5 93.750 (94.539)\n",
            "Epoch: [64][600/782]\tTime 0.043 (0.040)\tData 0.001 (0.002)\tLoss 0.7808 (0.9199)\tAcc@1 71.875 (73.035)\tAcc@5 98.438 (94.395)\n",
            "Epoch: [64][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1855 (0.9297)\tAcc@1 60.938 (72.767)\tAcc@5 90.625 (94.338)\n",
            " * Acc@1 72.724 Acc@5 94.316\n",
            "epoch 64, total time 31.17\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.8345 (1.8345)\tAcc@1 68.750 (68.750)\tAcc@5 71.875 (71.875)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.9874 (1.6217)\tAcc@1 50.000 (59.220)\tAcc@5 87.500 (85.891)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1055 (1.5736)\tAcc@1 68.750 (59.624)\tAcc@5 90.625 (86.303)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 1.6066 (1.5710)\tAcc@1 56.250 (59.676)\tAcc@5 87.500 (86.337)\n",
            " * Acc@1 59.570 Acc@5 86.330\n",
            "==> training...\n",
            "Epoch: [65][0/782]\tTime 0.251 (0.251)\tData 0.213 (0.213)\tLoss 1.0600 (1.0600)\tAcc@1 65.625 (65.625)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [65][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.004)\tLoss 0.7635 (0.8805)\tAcc@1 78.125 (74.180)\tAcc@5 93.750 (94.787)\n",
            "Epoch: [65][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8221 (0.8940)\tAcc@1 78.125 (73.577)\tAcc@5 95.312 (94.761)\n",
            "Epoch: [65][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9271 (0.8966)\tAcc@1 78.125 (73.598)\tAcc@5 96.875 (94.669)\n",
            "Epoch: [65][400/782]\tTime 0.043 (0.040)\tData 0.001 (0.002)\tLoss 0.7117 (0.9007)\tAcc@1 76.562 (73.465)\tAcc@5 96.875 (94.599)\n",
            "Epoch: [65][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9828 (0.9069)\tAcc@1 68.750 (73.331)\tAcc@5 95.312 (94.530)\n",
            "Epoch: [65][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1718 (0.9167)\tAcc@1 67.188 (72.949)\tAcc@5 92.188 (94.457)\n",
            "Epoch: [65][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9472 (0.9208)\tAcc@1 67.188 (72.840)\tAcc@5 95.312 (94.379)\n",
            " * Acc@1 72.612 Acc@5 94.304\n",
            "epoch 65, total time 31.01\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.7811 (1.7811)\tAcc@1 62.500 (62.500)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.2867 (1.4114)\tAcc@1 65.625 (62.160)\tAcc@5 93.750 (88.583)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.4201 (1.4037)\tAcc@1 59.375 (62.111)\tAcc@5 84.375 (88.293)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.7795 (1.4195)\tAcc@1 65.625 (61.919)\tAcc@5 84.375 (87.822)\n",
            " * Acc@1 61.880 Acc@5 87.790\n",
            "==> training...\n",
            "Epoch: [66][0/782]\tTime 0.227 (0.227)\tData 0.190 (0.190)\tLoss 0.8562 (0.8562)\tAcc@1 75.000 (75.000)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [66][100/782]\tTime 0.044 (0.041)\tData 0.001 (0.003)\tLoss 0.7504 (0.8742)\tAcc@1 75.000 (74.459)\tAcc@5 95.312 (94.833)\n",
            "Epoch: [66][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8909 (0.8719)\tAcc@1 71.875 (74.347)\tAcc@5 92.188 (94.970)\n",
            "Epoch: [66][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1971 (0.8813)\tAcc@1 68.750 (74.009)\tAcc@5 95.312 (94.850)\n",
            "Epoch: [66][400/782]\tTime 0.038 (0.040)\tData 0.002 (0.002)\tLoss 0.9352 (0.8870)\tAcc@1 75.000 (73.952)\tAcc@5 95.312 (94.818)\n",
            "Epoch: [66][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9398 (0.8922)\tAcc@1 70.312 (73.781)\tAcc@5 96.875 (94.789)\n",
            "Epoch: [66][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9717 (0.9012)\tAcc@1 73.438 (73.495)\tAcc@5 89.062 (94.676)\n",
            "Epoch: [66][700/782]\tTime 0.038 (0.040)\tData 0.002 (0.002)\tLoss 0.7048 (0.9113)\tAcc@1 79.688 (73.101)\tAcc@5 96.875 (94.570)\n",
            " * Acc@1 72.906 Acc@5 94.482\n",
            "epoch 66, total time 31.09\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 1.8555 (1.8555)\tAcc@1 68.750 (68.750)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.012 (0.010)\tLoss 2.0666 (1.6139)\tAcc@1 50.000 (59.313)\tAcc@5 84.375 (85.984)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.6607 (1.6284)\tAcc@1 50.000 (58.364)\tAcc@5 87.500 (85.681)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 2.1549 (1.6267)\tAcc@1 56.250 (58.544)\tAcc@5 71.875 (85.600)\n",
            " * Acc@1 58.600 Acc@5 85.700\n",
            "==> training...\n",
            "Epoch: [67][0/782]\tTime 0.229 (0.229)\tData 0.191 (0.191)\tLoss 0.7287 (0.7287)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [67][100/782]\tTime 0.037 (0.041)\tData 0.001 (0.003)\tLoss 0.7986 (0.8534)\tAcc@1 76.562 (74.752)\tAcc@5 95.312 (95.204)\n",
            "Epoch: [67][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0905 (0.8717)\tAcc@1 67.188 (74.471)\tAcc@5 90.625 (95.048)\n",
            "Epoch: [67][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2792 (0.8831)\tAcc@1 65.625 (74.372)\tAcc@5 89.062 (94.835)\n",
            "Epoch: [67][400/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 0.7200 (0.9008)\tAcc@1 81.250 (73.897)\tAcc@5 95.312 (94.576)\n",
            "Epoch: [67][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0281 (0.9166)\tAcc@1 68.750 (73.307)\tAcc@5 95.312 (94.408)\n",
            "Epoch: [67][600/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.9225 (0.9168)\tAcc@1 71.875 (73.284)\tAcc@5 92.188 (94.377)\n",
            "Epoch: [67][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3416 (0.9253)\tAcc@1 65.625 (72.978)\tAcc@5 89.062 (94.283)\n",
            " * Acc@1 72.818 Acc@5 94.218\n",
            "epoch 67, total time 30.97\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.4441 (1.4441)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.5924 (1.5344)\tAcc@1 56.250 (59.313)\tAcc@5 90.625 (86.170)\n",
            "Test: [200/313]\tTime 0.013 (0.009)\tLoss 1.4538 (1.5238)\tAcc@1 53.125 (59.935)\tAcc@5 90.625 (86.769)\n",
            "Test: [300/313]\tTime 0.012 (0.009)\tLoss 1.8676 (1.5221)\tAcc@1 53.125 (60.143)\tAcc@5 78.125 (86.659)\n",
            " * Acc@1 60.170 Acc@5 86.700\n",
            "==> training...\n",
            "Epoch: [68][0/782]\tTime 0.247 (0.247)\tData 0.211 (0.211)\tLoss 0.7227 (0.7227)\tAcc@1 76.562 (76.562)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [68][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.8331 (0.8196)\tAcc@1 75.000 (76.284)\tAcc@5 95.312 (95.854)\n",
            "Epoch: [68][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9370 (0.8505)\tAcc@1 70.312 (75.124)\tAcc@5 93.750 (95.445)\n",
            "Epoch: [68][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6540 (0.8699)\tAcc@1 82.812 (74.237)\tAcc@5 96.875 (95.084)\n",
            "Epoch: [68][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1276 (0.8901)\tAcc@1 70.312 (73.683)\tAcc@5 93.750 (94.779)\n",
            "Epoch: [68][500/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.9676 (0.9050)\tAcc@1 67.188 (73.229)\tAcc@5 96.875 (94.611)\n",
            "Epoch: [68][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9824 (0.9150)\tAcc@1 68.750 (72.944)\tAcc@5 95.312 (94.499)\n",
            "Epoch: [68][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1197 (0.9203)\tAcc@1 67.188 (72.796)\tAcc@5 90.625 (94.441)\n",
            " * Acc@1 72.470 Acc@5 94.302\n",
            "epoch 68, total time 31.06\n",
            "Test: [0/313]\tTime 0.109 (0.109)\tLoss 1.4953 (1.4953)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.008 (0.010)\tLoss 1.5199 (1.3718)\tAcc@1 65.625 (62.902)\tAcc@5 90.625 (88.088)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.2364 (1.3608)\tAcc@1 59.375 (62.702)\tAcc@5 93.750 (88.557)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.4778 (1.3567)\tAcc@1 53.125 (62.666)\tAcc@5 87.500 (88.600)\n",
            " * Acc@1 62.770 Acc@5 88.600\n",
            "==> training...\n",
            "Epoch: [69][0/782]\tTime 0.238 (0.238)\tData 0.210 (0.210)\tLoss 0.8495 (0.8495)\tAcc@1 73.438 (73.438)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [69][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.6362 (0.8393)\tAcc@1 84.375 (74.768)\tAcc@5 98.438 (95.297)\n",
            "Epoch: [69][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.6416 (0.8274)\tAcc@1 78.125 (75.513)\tAcc@5 98.438 (95.382)\n",
            "Epoch: [69][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0870 (0.8611)\tAcc@1 73.438 (74.408)\tAcc@5 89.062 (95.084)\n",
            "Epoch: [69][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.2210 (0.8826)\tAcc@1 60.938 (73.975)\tAcc@5 90.625 (94.786)\n",
            "Epoch: [69][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9320 (0.9023)\tAcc@1 75.000 (73.384)\tAcc@5 93.750 (94.539)\n",
            "Epoch: [69][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0406 (0.9074)\tAcc@1 75.000 (73.250)\tAcc@5 93.750 (94.483)\n",
            "Epoch: [69][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0249 (0.9137)\tAcc@1 75.000 (73.050)\tAcc@5 90.625 (94.494)\n",
            " * Acc@1 72.814 Acc@5 94.400\n",
            "epoch 69, total time 31.07\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.5610 (1.5610)\tAcc@1 71.875 (71.875)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.5127 (1.3560)\tAcc@1 65.625 (63.552)\tAcc@5 87.500 (88.274)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.3764 (1.3350)\tAcc@1 56.250 (63.386)\tAcc@5 90.625 (88.961)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.4663 (1.3525)\tAcc@1 59.375 (63.299)\tAcc@5 90.625 (88.611)\n",
            " * Acc@1 63.370 Acc@5 88.680\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [70][0/782]\tTime 0.247 (0.247)\tData 0.212 (0.212)\tLoss 0.8857 (0.8857)\tAcc@1 76.562 (76.562)\tAcc@5 90.625 (90.625)\n",
            "Epoch: [70][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.5092 (0.8381)\tAcc@1 87.500 (75.433)\tAcc@5 95.312 (95.328)\n",
            "Epoch: [70][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9689 (0.8583)\tAcc@1 76.562 (74.705)\tAcc@5 92.188 (95.025)\n",
            "Epoch: [70][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0132 (0.8733)\tAcc@1 64.062 (74.092)\tAcc@5 96.875 (94.814)\n",
            "Epoch: [70][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9443 (0.8839)\tAcc@1 70.312 (73.699)\tAcc@5 95.312 (94.763)\n",
            "Epoch: [70][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2029 (0.8984)\tAcc@1 67.188 (73.406)\tAcc@5 89.062 (94.623)\n",
            "Epoch: [70][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.8903 (0.9145)\tAcc@1 71.875 (72.811)\tAcc@5 95.312 (94.538)\n",
            "Epoch: [70][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7642 (0.9222)\tAcc@1 78.125 (72.689)\tAcc@5 98.438 (94.465)\n",
            " * Acc@1 72.556 Acc@5 94.358\n",
            "epoch 70, total time 31.07\n",
            "Test: [0/313]\tTime 0.112 (0.112)\tLoss 0.9827 (0.9827)\tAcc@1 78.125 (78.125)\tAcc@5 90.625 (90.625)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.8693 (1.5616)\tAcc@1 53.125 (59.406)\tAcc@5 81.250 (87.098)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 0.8190 (1.5432)\tAcc@1 71.875 (60.012)\tAcc@5 100.000 (87.236)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.8866 (1.5466)\tAcc@1 50.000 (59.832)\tAcc@5 75.000 (87.054)\n",
            " * Acc@1 59.980 Acc@5 87.170\n",
            "==> training...\n",
            "Epoch: [71][0/782]\tTime 0.229 (0.229)\tData 0.193 (0.193)\tLoss 1.2118 (1.2118)\tAcc@1 65.625 (65.625)\tAcc@5 85.938 (85.938)\n",
            "Epoch: [71][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.9409 (0.8197)\tAcc@1 71.875 (75.959)\tAcc@5 90.625 (95.730)\n",
            "Epoch: [71][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.6804 (0.8487)\tAcc@1 81.250 (75.016)\tAcc@5 96.875 (95.258)\n",
            "Epoch: [71][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0044 (0.8720)\tAcc@1 73.438 (74.341)\tAcc@5 93.750 (94.970)\n",
            "Epoch: [71][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0482 (0.8855)\tAcc@1 68.750 (74.010)\tAcc@5 93.750 (94.841)\n",
            "Epoch: [71][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1709 (0.9009)\tAcc@1 60.938 (73.587)\tAcc@5 93.750 (94.726)\n",
            "Epoch: [71][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1113 (0.9126)\tAcc@1 67.188 (73.206)\tAcc@5 92.188 (94.559)\n",
            "Epoch: [71][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9105 (0.9163)\tAcc@1 78.125 (73.061)\tAcc@5 92.188 (94.483)\n",
            " * Acc@1 72.940 Acc@5 94.416\n",
            "epoch 71, total time 30.93\n",
            "Test: [0/313]\tTime 0.114 (0.114)\tLoss 1.5622 (1.5622)\tAcc@1 68.750 (68.750)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 2.0032 (1.4567)\tAcc@1 50.000 (61.355)\tAcc@5 84.375 (87.376)\n",
            "Test: [200/313]\tTime 0.013 (0.008)\tLoss 1.0356 (1.4275)\tAcc@1 75.000 (62.174)\tAcc@5 87.500 (87.733)\n",
            "Test: [300/313]\tTime 0.013 (0.009)\tLoss 1.4605 (1.4319)\tAcc@1 59.375 (62.438)\tAcc@5 93.750 (87.510)\n",
            " * Acc@1 62.440 Acc@5 87.540\n",
            "==> training...\n",
            "Epoch: [72][0/782]\tTime 0.243 (0.243)\tData 0.209 (0.209)\tLoss 0.9626 (0.9626)\tAcc@1 68.750 (68.750)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [72][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.7368 (0.8422)\tAcc@1 81.250 (75.201)\tAcc@5 96.875 (95.514)\n",
            "Epoch: [72][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7389 (0.8497)\tAcc@1 79.688 (75.194)\tAcc@5 92.188 (95.126)\n",
            "Epoch: [72][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0464 (0.8629)\tAcc@1 68.750 (74.818)\tAcc@5 93.750 (94.918)\n",
            "Epoch: [72][400/782]\tTime 0.043 (0.040)\tData 0.001 (0.002)\tLoss 0.8493 (0.8750)\tAcc@1 76.562 (74.147)\tAcc@5 100.000 (94.810)\n",
            "Epoch: [72][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.3407 (0.8910)\tAcc@1 67.188 (73.609)\tAcc@5 89.062 (94.679)\n",
            "Epoch: [72][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0878 (0.9004)\tAcc@1 64.062 (73.318)\tAcc@5 92.188 (94.548)\n",
            "Epoch: [72][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7682 (0.9127)\tAcc@1 81.250 (73.005)\tAcc@5 96.875 (94.394)\n",
            " * Acc@1 72.966 Acc@5 94.348\n",
            "epoch 72, total time 31.07\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.5172 (1.5172)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.008 (0.010)\tLoss 1.4768 (1.4358)\tAcc@1 59.375 (62.098)\tAcc@5 84.375 (87.500)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.1439 (1.4435)\tAcc@1 62.500 (61.396)\tAcc@5 93.750 (87.251)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.9040 (1.4468)\tAcc@1 46.875 (61.503)\tAcc@5 81.250 (87.438)\n",
            " * Acc@1 61.510 Acc@5 87.370\n",
            "==> training...\n",
            "Epoch: [73][0/782]\tTime 0.248 (0.248)\tData 0.212 (0.212)\tLoss 1.1140 (1.1140)\tAcc@1 71.875 (71.875)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [73][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.6601 (0.8279)\tAcc@1 85.938 (75.851)\tAcc@5 95.312 (95.452)\n",
            "Epoch: [73][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9505 (0.8448)\tAcc@1 73.438 (75.451)\tAcc@5 92.188 (95.165)\n",
            "Epoch: [73][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7737 (0.8635)\tAcc@1 81.250 (74.907)\tAcc@5 96.875 (94.918)\n",
            "Epoch: [73][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1692 (0.8818)\tAcc@1 64.062 (74.283)\tAcc@5 85.938 (94.716)\n",
            "Epoch: [73][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9380 (0.8972)\tAcc@1 76.562 (73.687)\tAcc@5 92.188 (94.527)\n",
            "Epoch: [73][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0608 (0.9058)\tAcc@1 70.312 (73.427)\tAcc@5 90.625 (94.447)\n",
            "Epoch: [73][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7610 (0.9135)\tAcc@1 78.125 (73.190)\tAcc@5 96.875 (94.374)\n",
            " * Acc@1 72.976 Acc@5 94.254\n",
            "epoch 73, total time 30.99\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.4584 (1.4584)\tAcc@1 71.875 (71.875)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.4520 (1.3933)\tAcc@1 62.500 (62.222)\tAcc@5 93.750 (88.212)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 0.9967 (1.3597)\tAcc@1 71.875 (63.013)\tAcc@5 93.750 (88.744)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.8447 (1.3735)\tAcc@1 56.250 (62.645)\tAcc@5 90.625 (88.652)\n",
            " * Acc@1 62.670 Acc@5 88.690\n",
            "==> training...\n",
            "Epoch: [74][0/782]\tTime 0.254 (0.254)\tData 0.212 (0.212)\tLoss 0.7814 (0.7814)\tAcc@1 79.688 (79.688)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [74][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.6341 (0.8156)\tAcc@1 78.125 (75.557)\tAcc@5 98.438 (95.761)\n",
            "Epoch: [74][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6570 (0.8383)\tAcc@1 78.125 (75.233)\tAcc@5 98.438 (95.297)\n",
            "Epoch: [74][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9549 (0.8592)\tAcc@1 68.750 (74.533)\tAcc@5 95.312 (95.136)\n",
            "Epoch: [74][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.6587 (0.8769)\tAcc@1 85.938 (74.166)\tAcc@5 95.312 (94.880)\n",
            "Epoch: [74][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0068 (0.8956)\tAcc@1 73.438 (73.537)\tAcc@5 92.188 (94.667)\n",
            "Epoch: [74][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9656 (0.8996)\tAcc@1 75.000 (73.419)\tAcc@5 89.062 (94.585)\n",
            "Epoch: [74][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.4626 (0.9109)\tAcc@1 64.062 (73.190)\tAcc@5 87.500 (94.414)\n",
            " * Acc@1 72.992 Acc@5 94.330\n",
            "epoch 74, total time 30.93\n",
            "Test: [0/313]\tTime 0.106 (0.106)\tLoss 1.5001 (1.5001)\tAcc@1 68.750 (68.750)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.8501 (1.3875)\tAcc@1 62.500 (63.552)\tAcc@5 93.750 (87.995)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1779 (1.3690)\tAcc@1 59.375 (63.744)\tAcc@5 93.750 (88.355)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 1.5919 (1.3656)\tAcc@1 62.500 (63.735)\tAcc@5 90.625 (88.476)\n",
            " * Acc@1 63.790 Acc@5 88.550\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [75][0/782]\tTime 0.252 (0.252)\tData 0.217 (0.217)\tLoss 0.7756 (0.7756)\tAcc@1 79.688 (79.688)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [75][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.0679 (0.8149)\tAcc@1 65.625 (76.160)\tAcc@5 93.750 (95.452)\n",
            "Epoch: [75][200/782]\tTime 0.035 (0.040)\tData 0.001 (0.002)\tLoss 0.9164 (0.8305)\tAcc@1 70.312 (75.428)\tAcc@5 96.875 (95.414)\n",
            "Epoch: [75][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0259 (0.8574)\tAcc@1 68.750 (74.652)\tAcc@5 89.062 (95.084)\n",
            "Epoch: [75][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.5843 (0.8701)\tAcc@1 87.500 (74.380)\tAcc@5 96.875 (94.977)\n",
            "Epoch: [75][500/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.7418 (0.8842)\tAcc@1 82.812 (74.008)\tAcc@5 96.875 (94.870)\n",
            "Epoch: [75][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9052 (0.8970)\tAcc@1 70.312 (73.674)\tAcc@5 95.312 (94.741)\n",
            "Epoch: [75][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9099 (0.9053)\tAcc@1 71.875 (73.455)\tAcc@5 95.312 (94.648)\n",
            " * Acc@1 73.256 Acc@5 94.546\n",
            "epoch 75, total time 30.98\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.2995 (1.2995)\tAcc@1 65.625 (65.625)\tAcc@5 93.750 (93.750)\n",
            "Test: [100/313]\tTime 0.012 (0.010)\tLoss 1.3488 (1.4055)\tAcc@1 65.625 (62.500)\tAcc@5 90.625 (87.748)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 0.7162 (1.3949)\tAcc@1 71.875 (62.267)\tAcc@5 100.000 (88.029)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.8601 (1.3926)\tAcc@1 59.375 (62.510)\tAcc@5 81.250 (87.811)\n",
            " * Acc@1 62.480 Acc@5 87.760\n",
            "==> training...\n",
            "Epoch: [76][0/782]\tTime 0.239 (0.239)\tData 0.204 (0.204)\tLoss 0.6168 (0.6168)\tAcc@1 81.250 (81.250)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [76][100/782]\tTime 0.038 (0.041)\tData 0.001 (0.003)\tLoss 1.2397 (0.8785)\tAcc@1 59.375 (73.809)\tAcc@5 92.188 (94.601)\n",
            "Epoch: [76][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9121 (0.8860)\tAcc@1 71.875 (73.710)\tAcc@5 96.875 (94.714)\n",
            "Epoch: [76][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7550 (0.8886)\tAcc@1 76.562 (73.412)\tAcc@5 93.750 (94.669)\n",
            "Epoch: [76][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.8396 (0.8878)\tAcc@1 68.750 (73.395)\tAcc@5 95.312 (94.709)\n",
            "Epoch: [76][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6349 (0.8927)\tAcc@1 76.562 (73.419)\tAcc@5 98.438 (94.642)\n",
            "Epoch: [76][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9672 (0.9042)\tAcc@1 67.188 (73.206)\tAcc@5 92.188 (94.486)\n",
            "Epoch: [76][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9870 (0.9110)\tAcc@1 70.312 (73.025)\tAcc@5 93.750 (94.394)\n",
            " * Acc@1 73.006 Acc@5 94.360\n",
            "epoch 76, total time 31.02\n",
            "Test: [0/313]\tTime 0.104 (0.104)\tLoss 1.8434 (1.8434)\tAcc@1 56.250 (56.250)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.6126 (1.3461)\tAcc@1 56.250 (63.645)\tAcc@5 93.750 (88.861)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.3473 (1.3290)\tAcc@1 65.625 (63.806)\tAcc@5 87.500 (89.132)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.9932 (1.3388)\tAcc@1 53.125 (63.673)\tAcc@5 78.125 (88.808)\n",
            " * Acc@1 63.780 Acc@5 88.840\n",
            "==> training...\n",
            "Epoch: [77][0/782]\tTime 0.241 (0.241)\tData 0.204 (0.204)\tLoss 0.7837 (0.7837)\tAcc@1 78.125 (78.125)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [77][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.7220 (0.8798)\tAcc@1 78.125 (74.196)\tAcc@5 93.750 (95.127)\n",
            "Epoch: [77][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8965 (0.8624)\tAcc@1 76.562 (74.868)\tAcc@5 95.312 (95.072)\n",
            "Epoch: [77][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.5811 (0.8802)\tAcc@1 81.250 (74.247)\tAcc@5 96.875 (94.866)\n",
            "Epoch: [77][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1418 (0.8954)\tAcc@1 62.500 (73.691)\tAcc@5 90.625 (94.646)\n",
            "Epoch: [77][500/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9110 (0.9001)\tAcc@1 71.875 (73.581)\tAcc@5 87.500 (94.567)\n",
            "Epoch: [77][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9161 (0.9040)\tAcc@1 68.750 (73.453)\tAcc@5 95.312 (94.561)\n",
            "Epoch: [77][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2057 (0.9132)\tAcc@1 68.750 (73.137)\tAcc@5 89.062 (94.474)\n",
            " * Acc@1 73.048 Acc@5 94.428\n",
            "epoch 77, total time 30.92\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.7337 (1.7337)\tAcc@1 65.625 (65.625)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.008 (0.010)\tLoss 1.3419 (1.4288)\tAcc@1 59.375 (61.324)\tAcc@5 96.875 (87.840)\n",
            "Test: [200/313]\tTime 0.008 (0.009)\tLoss 1.3032 (1.4263)\tAcc@1 65.625 (61.474)\tAcc@5 90.625 (87.982)\n",
            "Test: [300/313]\tTime 0.008 (0.009)\tLoss 1.9466 (1.4355)\tAcc@1 56.250 (61.306)\tAcc@5 84.375 (87.832)\n",
            " * Acc@1 61.430 Acc@5 87.840\n",
            "==> training...\n",
            "Epoch: [78][0/782]\tTime 0.229 (0.229)\tData 0.193 (0.193)\tLoss 1.0091 (1.0091)\tAcc@1 70.312 (70.312)\tAcc@5 89.062 (89.062)\n",
            "Epoch: [78][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.8765 (0.7973)\tAcc@1 65.625 (76.423)\tAcc@5 98.438 (95.854)\n",
            "Epoch: [78][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9111 (0.8207)\tAcc@1 70.312 (75.941)\tAcc@5 95.312 (95.491)\n",
            "Epoch: [78][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7459 (0.8452)\tAcc@1 71.875 (75.104)\tAcc@5 98.438 (95.261)\n",
            "Epoch: [78][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0091 (0.8605)\tAcc@1 71.875 (74.595)\tAcc@5 93.750 (95.125)\n",
            "Epoch: [78][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7568 (0.8664)\tAcc@1 76.562 (74.436)\tAcc@5 95.312 (94.988)\n",
            "Epoch: [78][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0419 (0.8818)\tAcc@1 73.438 (73.913)\tAcc@5 95.312 (94.902)\n",
            "Epoch: [78][700/782]\tTime 0.037 (0.040)\tData 0.001 (0.002)\tLoss 0.8813 (0.8977)\tAcc@1 71.875 (73.482)\tAcc@5 96.875 (94.720)\n",
            " * Acc@1 73.106 Acc@5 94.524\n",
            "epoch 78, total time 30.99\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 1.2823 (1.2823)\tAcc@1 65.625 (65.625)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.008 (0.010)\tLoss 1.8932 (1.4211)\tAcc@1 43.750 (62.191)\tAcc@5 87.500 (88.428)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.3718 (1.3869)\tAcc@1 65.625 (62.718)\tAcc@5 90.625 (88.946)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.4535 (1.3916)\tAcc@1 59.375 (62.562)\tAcc@5 90.625 (88.829)\n",
            " * Acc@1 62.650 Acc@5 88.830\n",
            "==> training...\n",
            "Epoch: [79][0/782]\tTime 0.253 (0.253)\tData 0.217 (0.217)\tLoss 0.7829 (0.7829)\tAcc@1 71.875 (71.875)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [79][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.004)\tLoss 0.8042 (0.8168)\tAcc@1 73.438 (75.913)\tAcc@5 98.438 (95.591)\n",
            "Epoch: [79][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8131 (0.8192)\tAcc@1 78.125 (75.808)\tAcc@5 95.312 (95.468)\n",
            "Epoch: [79][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9968 (0.8572)\tAcc@1 68.750 (74.683)\tAcc@5 92.188 (95.058)\n",
            "Epoch: [79][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2013 (0.8695)\tAcc@1 70.312 (74.419)\tAcc@5 90.625 (94.899)\n",
            "Epoch: [79][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0576 (0.8847)\tAcc@1 75.000 (74.092)\tAcc@5 90.625 (94.739)\n",
            "Epoch: [79][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7579 (0.8902)\tAcc@1 78.125 (73.853)\tAcc@5 98.438 (94.707)\n",
            "Epoch: [79][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9350 (0.9081)\tAcc@1 70.312 (73.397)\tAcc@5 93.750 (94.521)\n",
            " * Acc@1 73.252 Acc@5 94.408\n",
            "epoch 79, total time 31.09\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.5408 (1.5408)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.5989 (1.4643)\tAcc@1 56.250 (61.572)\tAcc@5 90.625 (87.345)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.7223 (1.4482)\tAcc@1 59.375 (61.412)\tAcc@5 96.875 (87.764)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.9409 (1.4359)\tAcc@1 50.000 (61.825)\tAcc@5 84.375 (87.801)\n",
            " * Acc@1 61.840 Acc@5 87.810\n",
            "==> training...\n",
            "Epoch: [80][0/782]\tTime 0.243 (0.243)\tData 0.208 (0.208)\tLoss 0.8261 (0.8261)\tAcc@1 76.562 (76.562)\tAcc@5 100.000 (100.000)\n",
            "Epoch: [80][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.1820 (0.8366)\tAcc@1 67.188 (75.093)\tAcc@5 90.625 (95.575)\n",
            "Epoch: [80][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7267 (0.8479)\tAcc@1 75.000 (74.961)\tAcc@5 98.438 (95.274)\n",
            "Epoch: [80][300/782]\tTime 0.043 (0.040)\tData 0.001 (0.002)\tLoss 1.1627 (0.8664)\tAcc@1 70.312 (74.476)\tAcc@5 89.062 (94.996)\n",
            "Epoch: [80][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.4051 (0.8755)\tAcc@1 89.062 (74.221)\tAcc@5 98.438 (94.888)\n",
            "Epoch: [80][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0069 (0.8825)\tAcc@1 70.312 (74.096)\tAcc@5 92.188 (94.779)\n",
            "Epoch: [80][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7862 (0.8906)\tAcc@1 75.000 (73.934)\tAcc@5 98.438 (94.730)\n",
            "Epoch: [80][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.6800 (0.8992)\tAcc@1 78.125 (73.649)\tAcc@5 96.875 (94.644)\n",
            " * Acc@1 73.286 Acc@5 94.544\n",
            "epoch 80, total time 31.08\n",
            "Test: [0/313]\tTime 0.108 (0.108)\tLoss 1.5994 (1.5994)\tAcc@1 56.250 (56.250)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.6205 (1.5401)\tAcc@1 50.000 (60.118)\tAcc@5 87.500 (87.748)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.4306 (1.5351)\tAcc@1 59.375 (60.044)\tAcc@5 84.375 (87.655)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 2.4521 (1.5370)\tAcc@1 50.000 (60.424)\tAcc@5 78.125 (87.458)\n",
            " * Acc@1 60.290 Acc@5 87.380\n",
            "==> Saving...\n",
            "==> training...\n",
            "Epoch: [81][0/782]\tTime 0.261 (0.261)\tData 0.219 (0.219)\tLoss 0.8426 (0.8426)\tAcc@1 75.000 (75.000)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [81][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.0528 (0.8554)\tAcc@1 71.875 (75.278)\tAcc@5 93.750 (95.359)\n",
            "Epoch: [81][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9288 (0.8643)\tAcc@1 71.875 (74.852)\tAcc@5 96.875 (95.165)\n",
            "Epoch: [81][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8821 (0.8680)\tAcc@1 73.438 (74.637)\tAcc@5 95.312 (94.918)\n",
            "Epoch: [81][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8265 (0.8859)\tAcc@1 75.000 (73.979)\tAcc@5 92.188 (94.677)\n",
            "Epoch: [81][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.5805 (0.8871)\tAcc@1 84.375 (73.952)\tAcc@5 96.875 (94.664)\n",
            "Epoch: [81][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8848 (0.9012)\tAcc@1 75.000 (73.554)\tAcc@5 93.750 (94.564)\n",
            "Epoch: [81][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0777 (0.9090)\tAcc@1 68.750 (73.308)\tAcc@5 93.750 (94.465)\n",
            " * Acc@1 73.028 Acc@5 94.376\n",
            "epoch 81, total time 30.97\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.7918 (1.7918)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.8361 (1.5705)\tAcc@1 56.250 (58.694)\tAcc@5 90.625 (86.912)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.1085 (1.5477)\tAcc@1 68.750 (58.893)\tAcc@5 96.875 (87.158)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.7068 (1.5477)\tAcc@1 56.250 (59.199)\tAcc@5 90.625 (86.836)\n",
            " * Acc@1 59.330 Acc@5 86.800\n",
            "==> training...\n",
            "Epoch: [82][0/782]\tTime 0.233 (0.233)\tData 0.193 (0.193)\tLoss 0.8427 (0.8427)\tAcc@1 79.688 (79.688)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [82][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.7333 (0.8501)\tAcc@1 79.688 (75.015)\tAcc@5 96.875 (95.251)\n",
            "Epoch: [82][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1112 (0.8423)\tAcc@1 65.625 (75.202)\tAcc@5 92.188 (95.414)\n",
            "Epoch: [82][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.8634 (0.8605)\tAcc@1 73.438 (74.616)\tAcc@5 92.188 (95.110)\n",
            "Epoch: [82][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1481 (0.8658)\tAcc@1 62.500 (74.454)\tAcc@5 90.625 (94.942)\n",
            "Epoch: [82][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8449 (0.8741)\tAcc@1 76.562 (74.220)\tAcc@5 96.875 (94.832)\n",
            "Epoch: [82][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7944 (0.8825)\tAcc@1 71.875 (74.017)\tAcc@5 98.438 (94.730)\n",
            "Epoch: [82][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9449 (0.8935)\tAcc@1 70.312 (73.694)\tAcc@5 92.188 (94.664)\n",
            " * Acc@1 73.446 Acc@5 94.576\n",
            "epoch 82, total time 30.94\n",
            "Test: [0/313]\tTime 0.110 (0.110)\tLoss 1.5146 (1.5146)\tAcc@1 65.625 (65.625)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.012 (0.009)\tLoss 1.9319 (1.6217)\tAcc@1 40.625 (58.787)\tAcc@5 81.250 (85.736)\n",
            "Test: [200/313]\tTime 0.012 (0.009)\tLoss 0.9335 (1.5798)\tAcc@1 68.750 (58.831)\tAcc@5 90.625 (86.552)\n",
            "Test: [300/313]\tTime 0.007 (0.009)\tLoss 1.8217 (1.6059)\tAcc@1 46.875 (58.856)\tAcc@5 87.500 (86.026)\n",
            " * Acc@1 58.840 Acc@5 86.080\n",
            "==> training...\n",
            "Epoch: [83][0/782]\tTime 0.233 (0.233)\tData 0.189 (0.189)\tLoss 0.7884 (0.7884)\tAcc@1 73.438 (73.438)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [83][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.7178 (0.8302)\tAcc@1 78.125 (75.975)\tAcc@5 95.312 (95.405)\n",
            "Epoch: [83][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6638 (0.8465)\tAcc@1 82.812 (75.249)\tAcc@5 100.000 (95.250)\n",
            "Epoch: [83][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8524 (0.8480)\tAcc@1 76.562 (75.114)\tAcc@5 93.750 (95.276)\n",
            "Epoch: [83][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9082 (0.8687)\tAcc@1 76.562 (74.396)\tAcc@5 93.750 (94.927)\n",
            "Epoch: [83][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0694 (0.8801)\tAcc@1 67.188 (74.049)\tAcc@5 96.875 (94.898)\n",
            "Epoch: [83][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8950 (0.8918)\tAcc@1 76.562 (73.744)\tAcc@5 96.875 (94.798)\n",
            "Epoch: [83][700/782]\tTime 0.039 (0.039)\tData 0.001 (0.002)\tLoss 0.9083 (0.8988)\tAcc@1 76.562 (73.475)\tAcc@5 92.188 (94.731)\n",
            " * Acc@1 73.254 Acc@5 94.672\n",
            "epoch 83, total time 30.90\n",
            "Test: [0/313]\tTime 0.104 (0.104)\tLoss 1.6496 (1.6496)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.3517 (1.4190)\tAcc@1 56.250 (62.500)\tAcc@5 100.000 (88.490)\n",
            "Test: [200/313]\tTime 0.008 (0.008)\tLoss 0.8086 (1.4052)\tAcc@1 68.750 (62.562)\tAcc@5 93.750 (88.293)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.6027 (1.4166)\tAcc@1 50.000 (62.240)\tAcc@5 84.375 (87.895)\n",
            " * Acc@1 62.300 Acc@5 87.910\n",
            "==> training...\n",
            "Epoch: [84][0/782]\tTime 0.227 (0.227)\tData 0.191 (0.191)\tLoss 0.7249 (0.7249)\tAcc@1 78.125 (78.125)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [84][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.9931 (0.8344)\tAcc@1 68.750 (75.170)\tAcc@5 95.312 (95.405)\n",
            "Epoch: [84][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.6887 (0.8437)\tAcc@1 82.812 (74.767)\tAcc@5 95.312 (95.173)\n",
            "Epoch: [84][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7426 (0.8594)\tAcc@1 79.688 (74.574)\tAcc@5 96.875 (95.017)\n",
            "Epoch: [84][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7528 (0.8805)\tAcc@1 79.688 (73.925)\tAcc@5 98.438 (94.896)\n",
            "Epoch: [84][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7193 (0.8916)\tAcc@1 82.812 (73.640)\tAcc@5 93.750 (94.757)\n",
            "Epoch: [84][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9790 (0.8968)\tAcc@1 65.625 (73.666)\tAcc@5 95.312 (94.639)\n",
            "Epoch: [84][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8468 (0.9056)\tAcc@1 78.125 (73.393)\tAcc@5 95.312 (94.546)\n",
            " * Acc@1 73.188 Acc@5 94.448\n",
            "epoch 84, total time 31.05\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.6545 (1.6545)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.5328 (1.5666)\tAcc@1 65.625 (58.942)\tAcc@5 93.750 (85.891)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1018 (1.5606)\tAcc@1 71.875 (58.909)\tAcc@5 90.625 (86.318)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.6844 (1.5757)\tAcc@1 59.375 (58.441)\tAcc@5 84.375 (86.109)\n",
            " * Acc@1 58.450 Acc@5 86.040\n",
            "==> training...\n",
            "Epoch: [85][0/782]\tTime 0.256 (0.256)\tData 0.218 (0.218)\tLoss 0.9356 (0.9356)\tAcc@1 68.750 (68.750)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [85][100/782]\tTime 0.042 (0.041)\tData 0.001 (0.004)\tLoss 0.8663 (0.8253)\tAcc@1 76.562 (76.006)\tAcc@5 96.875 (95.220)\n",
            "Epoch: [85][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.6771 (0.8468)\tAcc@1 79.688 (75.404)\tAcc@5 98.438 (95.017)\n",
            "Epoch: [85][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.1330 (0.8680)\tAcc@1 67.188 (74.668)\tAcc@5 96.875 (94.861)\n",
            "Epoch: [85][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0693 (0.8735)\tAcc@1 75.000 (74.529)\tAcc@5 90.625 (94.896)\n",
            "Epoch: [85][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0464 (0.8806)\tAcc@1 73.438 (74.242)\tAcc@5 90.625 (94.829)\n",
            "Epoch: [85][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8742 (0.8905)\tAcc@1 67.188 (73.978)\tAcc@5 90.625 (94.702)\n",
            "Epoch: [85][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8425 (0.8971)\tAcc@1 76.562 (73.787)\tAcc@5 95.312 (94.606)\n",
            " * Acc@1 73.588 Acc@5 94.520\n",
            "epoch 85, total time 31.01\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.4700 (1.4700)\tAcc@1 75.000 (75.000)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.008 (0.009)\tLoss 1.4451 (1.4689)\tAcc@1 65.625 (61.262)\tAcc@5 87.500 (87.345)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.2218 (1.4643)\tAcc@1 62.500 (61.256)\tAcc@5 93.750 (87.764)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.4857 (1.4681)\tAcc@1 62.500 (61.794)\tAcc@5 87.500 (87.645)\n",
            " * Acc@1 61.770 Acc@5 87.650\n",
            "==> training...\n",
            "Epoch: [86][0/782]\tTime 0.242 (0.242)\tData 0.210 (0.210)\tLoss 1.0062 (1.0062)\tAcc@1 65.625 (65.625)\tAcc@5 93.750 (93.750)\n",
            "Epoch: [86][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.7097 (0.8189)\tAcc@1 84.375 (75.835)\tAcc@5 98.438 (95.359)\n",
            "Epoch: [86][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.6743 (0.8248)\tAcc@1 79.688 (75.754)\tAcc@5 93.750 (95.297)\n",
            "Epoch: [86][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.5765 (0.8470)\tAcc@1 78.125 (74.995)\tAcc@5 98.438 (95.037)\n",
            "Epoch: [86][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6157 (0.8674)\tAcc@1 81.250 (74.451)\tAcc@5 98.438 (94.853)\n",
            "Epoch: [86][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8828 (0.8873)\tAcc@1 71.875 (73.902)\tAcc@5 98.438 (94.642)\n",
            "Epoch: [86][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2528 (0.8983)\tAcc@1 60.938 (73.560)\tAcc@5 90.625 (94.520)\n",
            "Epoch: [86][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.1680 (0.9057)\tAcc@1 62.500 (73.382)\tAcc@5 93.750 (94.448)\n",
            " * Acc@1 73.298 Acc@5 94.348\n",
            "epoch 86, total time 30.93\n",
            "Test: [0/313]\tTime 0.112 (0.112)\tLoss 1.7211 (1.7211)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.3802 (1.4190)\tAcc@1 59.375 (62.407)\tAcc@5 90.625 (87.964)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 0.7113 (1.4372)\tAcc@1 81.250 (62.018)\tAcc@5 96.875 (87.873)\n",
            "Test: [300/313]\tTime 0.008 (0.009)\tLoss 1.5157 (1.4503)\tAcc@1 53.125 (61.669)\tAcc@5 93.750 (87.708)\n",
            " * Acc@1 61.760 Acc@5 87.690\n",
            "==> training...\n",
            "Epoch: [87][0/782]\tTime 0.232 (0.232)\tData 0.197 (0.197)\tLoss 0.7362 (0.7362)\tAcc@1 81.250 (81.250)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [87][100/782]\tTime 0.038 (0.041)\tData 0.001 (0.003)\tLoss 0.9449 (0.7978)\tAcc@1 75.000 (75.959)\tAcc@5 93.750 (95.761)\n",
            "Epoch: [87][200/782]\tTime 0.040 (0.040)\tData 0.002 (0.002)\tLoss 0.7447 (0.8218)\tAcc@1 78.125 (75.933)\tAcc@5 95.312 (95.616)\n",
            "Epoch: [87][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8138 (0.8443)\tAcc@1 78.125 (75.067)\tAcc@5 96.875 (95.432)\n",
            "Epoch: [87][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.8642 (0.8693)\tAcc@1 75.000 (74.353)\tAcc@5 95.312 (95.137)\n",
            "Epoch: [87][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8210 (0.8791)\tAcc@1 76.562 (74.092)\tAcc@5 96.875 (94.969)\n",
            "Epoch: [87][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0427 (0.8832)\tAcc@1 68.750 (74.059)\tAcc@5 89.062 (94.899)\n",
            "Epoch: [87][700/782]\tTime 0.039 (0.039)\tData 0.001 (0.002)\tLoss 0.9902 (0.8950)\tAcc@1 68.750 (73.634)\tAcc@5 96.875 (94.795)\n",
            " * Acc@1 73.484 Acc@5 94.638\n",
            "epoch 87, total time 30.91\n",
            "Test: [0/313]\tTime 0.104 (0.104)\tLoss 1.2199 (1.2199)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.5428 (1.4338)\tAcc@1 59.375 (62.345)\tAcc@5 90.625 (87.840)\n",
            "Test: [200/313]\tTime 0.008 (0.008)\tLoss 1.2438 (1.4289)\tAcc@1 71.875 (62.298)\tAcc@5 93.750 (88.013)\n",
            "Test: [300/313]\tTime 0.008 (0.008)\tLoss 1.5962 (1.4272)\tAcc@1 62.500 (62.635)\tAcc@5 93.750 (87.822)\n",
            " * Acc@1 62.670 Acc@5 87.860\n",
            "==> training...\n",
            "Epoch: [88][0/782]\tTime 0.232 (0.232)\tData 0.188 (0.188)\tLoss 1.0152 (1.0152)\tAcc@1 71.875 (71.875)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [88][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.8133 (0.8286)\tAcc@1 68.750 (75.325)\tAcc@5 98.438 (95.436)\n",
            "Epoch: [88][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9151 (0.8384)\tAcc@1 73.438 (75.016)\tAcc@5 90.625 (95.328)\n",
            "Epoch: [88][300/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7024 (0.8570)\tAcc@1 78.125 (74.434)\tAcc@5 95.312 (95.115)\n",
            "Epoch: [88][400/782]\tTime 0.044 (0.040)\tData 0.001 (0.002)\tLoss 0.9181 (0.8729)\tAcc@1 76.562 (74.158)\tAcc@5 96.875 (94.845)\n",
            "Epoch: [88][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0563 (0.8870)\tAcc@1 68.750 (73.724)\tAcc@5 95.312 (94.686)\n",
            "Epoch: [88][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1579 (0.8966)\tAcc@1 67.188 (73.393)\tAcc@5 93.750 (94.579)\n",
            "Epoch: [88][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9147 (0.9101)\tAcc@1 75.000 (73.125)\tAcc@5 93.750 (94.401)\n",
            " * Acc@1 72.938 Acc@5 94.328\n",
            "epoch 88, total time 30.98\n",
            "Test: [0/313]\tTime 0.113 (0.113)\tLoss 1.4247 (1.4247)\tAcc@1 65.625 (65.625)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.5486 (1.3906)\tAcc@1 56.250 (61.510)\tAcc@5 84.375 (88.026)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 0.9861 (1.4024)\tAcc@1 75.000 (61.723)\tAcc@5 93.750 (88.340)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.8087 (1.4008)\tAcc@1 50.000 (61.898)\tAcc@5 87.500 (88.081)\n",
            " * Acc@1 62.060 Acc@5 88.270\n",
            "==> training...\n",
            "Epoch: [89][0/782]\tTime 0.234 (0.234)\tData 0.191 (0.191)\tLoss 0.7287 (0.7287)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [89][100/782]\tTime 0.041 (0.041)\tData 0.001 (0.003)\tLoss 0.7851 (0.8137)\tAcc@1 75.000 (75.603)\tAcc@5 98.438 (95.854)\n",
            "Epoch: [89][200/782]\tTime 0.044 (0.040)\tData 0.001 (0.002)\tLoss 0.8385 (0.8162)\tAcc@1 76.562 (75.731)\tAcc@5 96.875 (95.686)\n",
            "Epoch: [89][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1745 (0.8421)\tAcc@1 59.375 (74.984)\tAcc@5 89.062 (95.396)\n",
            "Epoch: [89][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9164 (0.8589)\tAcc@1 70.312 (74.610)\tAcc@5 95.312 (95.114)\n",
            "Epoch: [89][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7719 (0.8753)\tAcc@1 76.562 (74.092)\tAcc@5 95.312 (95.060)\n",
            "Epoch: [89][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9112 (0.8868)\tAcc@1 75.000 (73.903)\tAcc@5 92.188 (94.878)\n",
            "Epoch: [89][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8430 (0.8931)\tAcc@1 78.125 (73.774)\tAcc@5 95.312 (94.804)\n",
            " * Acc@1 73.516 Acc@5 94.784\n",
            "epoch 89, total time 30.95\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.7919 (1.7919)\tAcc@1 53.125 (53.125)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.6869 (1.4327)\tAcc@1 50.000 (62.036)\tAcc@5 87.500 (87.469)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.7843 (1.4471)\tAcc@1 59.375 (61.971)\tAcc@5 84.375 (87.749)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.3836 (1.4515)\tAcc@1 65.625 (62.126)\tAcc@5 84.375 (87.521)\n",
            " * Acc@1 62.290 Acc@5 87.610\n",
            "==> training...\n",
            "Epoch: [90][0/782]\tTime 0.232 (0.232)\tData 0.195 (0.195)\tLoss 0.6528 (0.6528)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [90][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 1.0853 (0.8536)\tAcc@1 67.188 (75.325)\tAcc@5 96.875 (94.926)\n",
            "Epoch: [90][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2512 (0.8531)\tAcc@1 62.500 (74.712)\tAcc@5 87.500 (95.048)\n",
            "Epoch: [90][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8342 (0.8673)\tAcc@1 79.688 (74.268)\tAcc@5 93.750 (94.892)\n",
            "Epoch: [90][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0555 (0.8773)\tAcc@1 71.875 (73.928)\tAcc@5 92.188 (94.794)\n",
            "Epoch: [90][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0469 (0.8876)\tAcc@1 65.625 (73.650)\tAcc@5 92.188 (94.782)\n",
            "Epoch: [90][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7153 (0.8896)\tAcc@1 76.562 (73.484)\tAcc@5 96.875 (94.704)\n",
            "Epoch: [90][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3269 (0.8980)\tAcc@1 62.500 (73.279)\tAcc@5 89.062 (94.624)\n",
            " * Acc@1 73.178 Acc@5 94.526\n",
            "epoch 90, total time 31.02\n",
            "Test: [0/313]\tTime 0.112 (0.112)\tLoss 1.5303 (1.5303)\tAcc@1 62.500 (62.500)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.013 (0.010)\tLoss 1.5514 (1.6569)\tAcc@1 50.000 (57.580)\tAcc@5 90.625 (85.675)\n",
            "Test: [200/313]\tTime 0.007 (0.009)\tLoss 1.3255 (1.6254)\tAcc@1 62.500 (58.582)\tAcc@5 96.875 (86.054)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.5851 (1.6318)\tAcc@1 50.000 (58.814)\tAcc@5 96.875 (85.860)\n",
            " * Acc@1 58.810 Acc@5 85.890\n",
            "==> training...\n",
            "Epoch: [91][0/782]\tTime 0.241 (0.241)\tData 0.213 (0.213)\tLoss 0.7258 (0.7258)\tAcc@1 75.000 (75.000)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [91][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.8866 (0.8486)\tAcc@1 76.562 (74.969)\tAcc@5 92.188 (95.251)\n",
            "Epoch: [91][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8576 (0.8598)\tAcc@1 76.562 (74.705)\tAcc@5 95.312 (95.196)\n",
            "Epoch: [91][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8963 (0.8696)\tAcc@1 75.000 (74.367)\tAcc@5 95.312 (95.089)\n",
            "Epoch: [91][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9521 (0.8789)\tAcc@1 73.438 (74.190)\tAcc@5 93.750 (94.806)\n",
            "Epoch: [91][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9737 (0.8872)\tAcc@1 71.875 (73.971)\tAcc@5 96.875 (94.748)\n",
            "Epoch: [91][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0814 (0.8940)\tAcc@1 62.500 (73.814)\tAcc@5 92.188 (94.626)\n",
            "Epoch: [91][700/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0736 (0.9050)\tAcc@1 62.500 (73.553)\tAcc@5 95.312 (94.499)\n",
            " * Acc@1 73.594 Acc@5 94.474\n",
            "epoch 91, total time 30.94\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.5268 (1.5268)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.5958 (1.5211)\tAcc@1 53.125 (60.767)\tAcc@5 87.500 (86.541)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1331 (1.5261)\tAcc@1 65.625 (60.728)\tAcc@5 96.875 (86.521)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.5622 (1.5335)\tAcc@1 62.500 (60.714)\tAcc@5 87.500 (86.566)\n",
            " * Acc@1 60.670 Acc@5 86.540\n",
            "==> training...\n",
            "Epoch: [92][0/782]\tTime 0.243 (0.243)\tData 0.205 (0.205)\tLoss 0.6271 (0.6271)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [92][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.5774 (0.8265)\tAcc@1 85.938 (75.511)\tAcc@5 95.312 (95.823)\n",
            "Epoch: [92][200/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7482 (0.8348)\tAcc@1 78.125 (75.093)\tAcc@5 95.312 (95.421)\n",
            "Epoch: [92][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.2300 (0.8402)\tAcc@1 56.250 (74.875)\tAcc@5 90.625 (95.318)\n",
            "Epoch: [92][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 1.0684 (0.8616)\tAcc@1 70.312 (74.408)\tAcc@5 92.188 (95.020)\n",
            "Epoch: [92][500/782]\tTime 0.039 (0.040)\tData 0.002 (0.002)\tLoss 0.9372 (0.8774)\tAcc@1 76.562 (74.024)\tAcc@5 95.312 (94.873)\n",
            "Epoch: [92][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2182 (0.8860)\tAcc@1 60.938 (73.799)\tAcc@5 93.750 (94.733)\n",
            "Epoch: [92][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6466 (0.8925)\tAcc@1 78.125 (73.672)\tAcc@5 96.875 (94.666)\n",
            " * Acc@1 73.344 Acc@5 94.534\n",
            "epoch 92, total time 30.92\n",
            "Test: [0/313]\tTime 0.112 (0.112)\tLoss 1.6685 (1.6685)\tAcc@1 65.625 (65.625)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.3510 (1.4487)\tAcc@1 71.875 (61.881)\tAcc@5 93.750 (88.026)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 0.9373 (1.4774)\tAcc@1 71.875 (60.836)\tAcc@5 93.750 (87.811)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.6413 (1.4792)\tAcc@1 53.125 (61.410)\tAcc@5 81.250 (87.749)\n",
            " * Acc@1 61.500 Acc@5 87.850\n",
            "==> training...\n",
            "Epoch: [93][0/782]\tTime 0.241 (0.241)\tData 0.213 (0.213)\tLoss 1.0234 (1.0234)\tAcc@1 67.188 (67.188)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [93][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.7955 (0.8463)\tAcc@1 73.438 (74.799)\tAcc@5 95.312 (95.374)\n",
            "Epoch: [93][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7301 (0.8485)\tAcc@1 78.125 (75.000)\tAcc@5 93.750 (95.414)\n",
            "Epoch: [93][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.5979 (0.8458)\tAcc@1 81.250 (74.813)\tAcc@5 96.875 (95.515)\n",
            "Epoch: [93][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7084 (0.8612)\tAcc@1 73.438 (74.299)\tAcc@5 98.438 (95.254)\n",
            "Epoch: [93][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2780 (0.8717)\tAcc@1 68.750 (74.024)\tAcc@5 87.500 (95.113)\n",
            "Epoch: [93][600/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9022 (0.8839)\tAcc@1 68.750 (73.705)\tAcc@5 95.312 (94.907)\n",
            "Epoch: [93][700/782]\tTime 0.038 (0.039)\tData 0.001 (0.002)\tLoss 0.7404 (0.8909)\tAcc@1 78.125 (73.482)\tAcc@5 98.438 (94.860)\n",
            " * Acc@1 73.174 Acc@5 94.714\n",
            "epoch 93, total time 30.92\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.7781 (1.7781)\tAcc@1 59.375 (59.375)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 2.0409 (1.6232)\tAcc@1 53.125 (58.478)\tAcc@5 84.375 (86.231)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.0437 (1.6124)\tAcc@1 75.000 (58.660)\tAcc@5 96.875 (86.350)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.9766 (1.6243)\tAcc@1 43.750 (58.607)\tAcc@5 81.250 (86.181)\n",
            " * Acc@1 58.660 Acc@5 86.150\n",
            "==> training...\n",
            "Epoch: [94][0/782]\tTime 0.239 (0.239)\tData 0.204 (0.204)\tLoss 0.9704 (0.9704)\tAcc@1 75.000 (75.000)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [94][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.9359 (0.8422)\tAcc@1 73.438 (75.464)\tAcc@5 93.750 (95.343)\n",
            "Epoch: [94][200/782]\tTime 0.041 (0.040)\tData 0.001 (0.002)\tLoss 0.6683 (0.8416)\tAcc@1 78.125 (75.148)\tAcc@5 100.000 (95.297)\n",
            "Epoch: [94][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.9368 (0.8423)\tAcc@1 71.875 (75.026)\tAcc@5 93.750 (95.307)\n",
            "Epoch: [94][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7130 (0.8562)\tAcc@1 75.000 (74.591)\tAcc@5 95.312 (95.106)\n",
            "Epoch: [94][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0184 (0.8722)\tAcc@1 65.625 (74.158)\tAcc@5 95.312 (94.929)\n",
            "Epoch: [94][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.5842 (0.8868)\tAcc@1 57.812 (73.791)\tAcc@5 87.500 (94.761)\n",
            "Epoch: [94][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7850 (0.9014)\tAcc@1 76.562 (73.402)\tAcc@5 96.875 (94.657)\n",
            " * Acc@1 73.180 Acc@5 94.598\n",
            "epoch 94, total time 31.05\n",
            "Test: [0/313]\tTime 0.116 (0.116)\tLoss 1.9378 (1.9378)\tAcc@1 53.125 (53.125)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.010)\tLoss 1.3823 (1.6440)\tAcc@1 56.250 (58.045)\tAcc@5 93.750 (85.458)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.4748 (1.6755)\tAcc@1 59.375 (57.758)\tAcc@5 90.625 (85.121)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.4048 (1.6839)\tAcc@1 62.500 (57.787)\tAcc@5 87.500 (85.164)\n",
            " * Acc@1 57.790 Acc@5 85.120\n",
            "==> training...\n",
            "Epoch: [95][0/782]\tTime 0.264 (0.264)\tData 0.221 (0.221)\tLoss 0.6860 (0.6860)\tAcc@1 76.562 (76.562)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [95][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.004)\tLoss 0.7461 (0.7891)\tAcc@1 78.125 (76.593)\tAcc@5 93.750 (95.962)\n",
            "Epoch: [95][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6926 (0.8052)\tAcc@1 81.250 (76.073)\tAcc@5 90.625 (95.561)\n",
            "Epoch: [95][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6483 (0.8394)\tAcc@1 81.250 (75.057)\tAcc@5 100.000 (95.292)\n",
            "Epoch: [95][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8859 (0.8536)\tAcc@1 73.438 (74.719)\tAcc@5 95.312 (95.141)\n",
            "Epoch: [95][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.3247 (0.8696)\tAcc@1 62.500 (74.420)\tAcc@5 84.375 (94.944)\n",
            "Epoch: [95][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8708 (0.8779)\tAcc@1 78.125 (74.251)\tAcc@5 93.750 (94.842)\n",
            "Epoch: [95][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7442 (0.8863)\tAcc@1 76.562 (73.975)\tAcc@5 98.438 (94.755)\n",
            " * Acc@1 73.832 Acc@5 94.678\n",
            "epoch 95, total time 31.04\n",
            "Test: [0/313]\tTime 0.104 (0.104)\tLoss 1.5259 (1.5259)\tAcc@1 65.625 (65.625)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 2.1136 (1.7677)\tAcc@1 50.000 (56.250)\tAcc@5 78.125 (84.499)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.1989 (1.7243)\tAcc@1 59.375 (57.400)\tAcc@5 90.625 (84.764)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.6743 (1.7392)\tAcc@1 43.750 (57.257)\tAcc@5 78.125 (84.427)\n",
            " * Acc@1 57.350 Acc@5 84.520\n",
            "==> training...\n",
            "Epoch: [96][0/782]\tTime 0.260 (0.260)\tData 0.223 (0.223)\tLoss 0.9687 (0.9687)\tAcc@1 68.750 (68.750)\tAcc@5 92.188 (92.188)\n",
            "Epoch: [96][100/782]\tTime 0.040 (0.042)\tData 0.001 (0.004)\tLoss 0.5893 (0.8528)\tAcc@1 81.250 (75.093)\tAcc@5 96.875 (95.374)\n",
            "Epoch: [96][200/782]\tTime 0.040 (0.040)\tData 0.002 (0.003)\tLoss 0.7567 (0.8443)\tAcc@1 78.125 (75.054)\tAcc@5 96.875 (95.406)\n",
            "Epoch: [96][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8639 (0.8620)\tAcc@1 71.875 (74.512)\tAcc@5 96.875 (95.302)\n",
            "Epoch: [96][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7577 (0.8812)\tAcc@1 79.688 (73.878)\tAcc@5 92.188 (95.040)\n",
            "Epoch: [96][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7842 (0.8890)\tAcc@1 75.000 (73.724)\tAcc@5 92.188 (94.982)\n",
            "Epoch: [96][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.5689 (0.8950)\tAcc@1 84.375 (73.617)\tAcc@5 98.438 (94.876)\n",
            "Epoch: [96][700/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.9859 (0.8985)\tAcc@1 65.625 (73.549)\tAcc@5 92.188 (94.804)\n",
            " * Acc@1 73.388 Acc@5 94.746\n",
            "epoch 96, total time 31.04\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.7819 (1.7819)\tAcc@1 59.375 (59.375)\tAcc@5 81.250 (81.250)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.2990 (1.3889)\tAcc@1 62.500 (63.397)\tAcc@5 90.625 (88.304)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.3758 (1.3926)\tAcc@1 62.500 (62.982)\tAcc@5 93.750 (88.573)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.7010 (1.3950)\tAcc@1 62.500 (62.884)\tAcc@5 87.500 (88.538)\n",
            " * Acc@1 62.970 Acc@5 88.520\n",
            "==> training...\n",
            "Epoch: [97][0/782]\tTime 0.228 (0.228)\tData 0.190 (0.190)\tLoss 0.7299 (0.7299)\tAcc@1 78.125 (78.125)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [97][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.7993 (0.8042)\tAcc@1 78.125 (75.743)\tAcc@5 93.750 (96.272)\n",
            "Epoch: [97][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1337 (0.8288)\tAcc@1 68.750 (75.435)\tAcc@5 89.062 (95.833)\n",
            "Epoch: [97][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8076 (0.8414)\tAcc@1 78.125 (74.990)\tAcc@5 92.188 (95.640)\n",
            "Epoch: [97][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9901 (0.8645)\tAcc@1 73.438 (74.349)\tAcc@5 96.875 (95.227)\n",
            "Epoch: [97][500/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.7553 (0.8696)\tAcc@1 75.000 (74.320)\tAcc@5 95.312 (95.113)\n",
            "Epoch: [97][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.7804 (0.8785)\tAcc@1 75.000 (74.009)\tAcc@5 95.312 (95.047)\n",
            "Epoch: [97][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.0610 (0.8953)\tAcc@1 71.875 (73.589)\tAcc@5 93.750 (94.853)\n",
            " * Acc@1 73.526 Acc@5 94.736\n",
            "epoch 97, total time 30.98\n",
            "Test: [0/313]\tTime 0.105 (0.105)\tLoss 1.2015 (1.2015)\tAcc@1 71.875 (71.875)\tAcc@5 87.500 (87.500)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.4763 (1.4113)\tAcc@1 62.500 (62.840)\tAcc@5 84.375 (87.469)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.2066 (1.4104)\tAcc@1 68.750 (62.951)\tAcc@5 96.875 (87.795)\n",
            "Test: [300/313]\tTime 0.007 (0.007)\tLoss 1.7058 (1.3977)\tAcc@1 62.500 (63.164)\tAcc@5 81.250 (88.092)\n",
            " * Acc@1 63.190 Acc@5 88.230\n",
            "==> training...\n",
            "Epoch: [98][0/782]\tTime 0.222 (0.222)\tData 0.188 (0.188)\tLoss 0.7667 (0.7667)\tAcc@1 73.438 (73.438)\tAcc@5 95.312 (95.312)\n",
            "Epoch: [98][100/782]\tTime 0.039 (0.041)\tData 0.001 (0.003)\tLoss 0.8296 (0.8285)\tAcc@1 76.562 (75.449)\tAcc@5 98.438 (95.653)\n",
            "Epoch: [98][200/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 1.0677 (0.8246)\tAcc@1 64.062 (75.707)\tAcc@5 93.750 (95.569)\n",
            "Epoch: [98][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8897 (0.8301)\tAcc@1 71.875 (75.363)\tAcc@5 96.875 (95.582)\n",
            "Epoch: [98][400/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8751 (0.8470)\tAcc@1 76.562 (75.023)\tAcc@5 95.312 (95.211)\n",
            "Epoch: [98][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1112 (0.8634)\tAcc@1 64.062 (74.591)\tAcc@5 90.625 (94.979)\n",
            "Epoch: [98][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8522 (0.8720)\tAcc@1 73.438 (74.425)\tAcc@5 95.312 (94.930)\n",
            "Epoch: [98][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8073 (0.8811)\tAcc@1 71.875 (74.111)\tAcc@5 93.750 (94.833)\n",
            " * Acc@1 73.930 Acc@5 94.744\n",
            "epoch 98, total time 31.00\n",
            "Test: [0/313]\tTime 0.111 (0.111)\tLoss 1.7702 (1.7702)\tAcc@1 59.375 (59.375)\tAcc@5 78.125 (78.125)\n",
            "Test: [100/313]\tTime 0.007 (0.009)\tLoss 1.5304 (1.4664)\tAcc@1 50.000 (60.860)\tAcc@5 87.500 (86.819)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 0.9251 (1.4692)\tAcc@1 62.500 (61.365)\tAcc@5 93.750 (87.080)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.7612 (1.4651)\tAcc@1 59.375 (61.327)\tAcc@5 90.625 (87.189)\n",
            " * Acc@1 61.400 Acc@5 87.210\n",
            "==> training...\n",
            "Epoch: [99][0/782]\tTime 0.251 (0.251)\tData 0.210 (0.210)\tLoss 0.5480 (0.5480)\tAcc@1 84.375 (84.375)\tAcc@5 98.438 (98.438)\n",
            "Epoch: [99][100/782]\tTime 0.040 (0.041)\tData 0.001 (0.003)\tLoss 0.7186 (0.7963)\tAcc@1 76.562 (75.681)\tAcc@5 100.000 (95.761)\n",
            "Epoch: [99][200/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9076 (0.8288)\tAcc@1 71.875 (75.062)\tAcc@5 95.312 (95.359)\n",
            "Epoch: [99][300/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.8380 (0.8494)\tAcc@1 73.438 (74.855)\tAcc@5 93.750 (95.037)\n",
            "Epoch: [99][400/782]\tTime 0.038 (0.040)\tData 0.001 (0.002)\tLoss 0.8728 (0.8645)\tAcc@1 73.438 (74.369)\tAcc@5 98.438 (94.923)\n",
            "Epoch: [99][500/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.1054 (0.8721)\tAcc@1 71.875 (74.267)\tAcc@5 92.188 (94.773)\n",
            "Epoch: [99][600/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7181 (0.8796)\tAcc@1 76.562 (74.059)\tAcc@5 96.875 (94.725)\n",
            "Epoch: [99][700/782]\tTime 0.040 (0.039)\tData 0.001 (0.002)\tLoss 1.0802 (0.8955)\tAcc@1 70.312 (73.667)\tAcc@5 92.188 (94.454)\n",
            " * Acc@1 73.528 Acc@5 94.430\n",
            "epoch 99, total time 30.93\n",
            "Test: [0/313]\tTime 0.107 (0.107)\tLoss 1.5571 (1.5571)\tAcc@1 62.500 (62.500)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.4312 (1.5408)\tAcc@1 53.125 (60.118)\tAcc@5 93.750 (86.139)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 1.4664 (1.4934)\tAcc@1 56.250 (60.479)\tAcc@5 93.750 (86.614)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 2.0392 (1.5010)\tAcc@1 53.125 (60.880)\tAcc@5 84.375 (86.514)\n",
            " * Acc@1 60.900 Acc@5 86.520\n",
            "==> training...\n",
            "Epoch: [100][0/782]\tTime 0.238 (0.238)\tData 0.205 (0.205)\tLoss 0.7739 (0.7739)\tAcc@1 70.312 (70.312)\tAcc@5 96.875 (96.875)\n",
            "Epoch: [100][100/782]\tTime 0.040 (0.042)\tData 0.001 (0.003)\tLoss 0.7979 (0.8798)\tAcc@1 75.000 (73.453)\tAcc@5 93.750 (95.545)\n",
            "Epoch: [100][200/782]\tTime 0.039 (0.041)\tData 0.001 (0.002)\tLoss 0.8570 (0.8563)\tAcc@1 73.438 (74.534)\tAcc@5 96.875 (95.623)\n",
            "Epoch: [100][300/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.7385 (0.8656)\tAcc@1 75.000 (74.424)\tAcc@5 93.750 (95.396)\n",
            "Epoch: [100][400/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.6489 (0.8768)\tAcc@1 76.562 (74.041)\tAcc@5 98.438 (95.090)\n",
            "Epoch: [100][500/782]\tTime 0.040 (0.040)\tData 0.001 (0.002)\tLoss 0.8123 (0.8829)\tAcc@1 75.000 (74.008)\tAcc@5 96.875 (94.951)\n",
            "Epoch: [100][600/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 1.2674 (0.8900)\tAcc@1 65.625 (73.825)\tAcc@5 92.188 (94.850)\n",
            "Epoch: [100][700/782]\tTime 0.039 (0.040)\tData 0.001 (0.002)\tLoss 0.9144 (0.8994)\tAcc@1 73.438 (73.536)\tAcc@5 95.312 (94.789)\n",
            " * Acc@1 73.326 Acc@5 94.700\n",
            "epoch 100, total time 31.02\n",
            "Test: [0/313]\tTime 0.105 (0.105)\tLoss 1.2058 (1.2058)\tAcc@1 78.125 (78.125)\tAcc@5 84.375 (84.375)\n",
            "Test: [100/313]\tTime 0.007 (0.008)\tLoss 1.7649 (1.4187)\tAcc@1 50.000 (61.572)\tAcc@5 90.625 (87.995)\n",
            "Test: [200/313]\tTime 0.007 (0.008)\tLoss 0.8815 (1.3990)\tAcc@1 71.875 (62.298)\tAcc@5 96.875 (88.433)\n",
            "Test: [300/313]\tTime 0.007 (0.008)\tLoss 1.9849 (1.4114)\tAcc@1 56.250 (62.189)\tAcc@5 78.125 (87.978)\n",
            " * Acc@1 62.240 Acc@5 88.000\n",
            "==> Saving...\n",
            "best accuracy: tensor(63.7900, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/ICKD-DCKD -name \"*resnet32x4_best.pth\"\n"
      ],
      "metadata": {
        "id": "TcLUPRQDnxK_"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_student.py \\\n",
        "    --path_t ./save/models/resnet32x4_cifar100_lr_0.05_decay_0.0005_trial_0/resnet32x4_best.pth \\\n",
        "    --distill dckd \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --model_t resnet32x4 \\\n",
        "    -a 0.5 -b 0.5 --trial 1"
      ],
      "metadata": {
        "id": "AmNKayf09TbD"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ICKD-DCKD/Cifar100\n",
        "\n",
        "!python train_student.py \\\n",
        "    --path_t ./save/models/resnet32x4_cifar100_lr_0.05_decay_0.0005_trial_0/resnet32x4_best.pth \\\n",
        "    --distill dckd \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --model_t resnet32x4 \\\n",
        "    -a 0.5 -b 0.5 --trial 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orro3FPpnitu",
        "outputId": "cd6636ba-aada-4233-b012-95ab6bc57e4e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/ICKD-DCKD/Cifar100/train_student.py\"\n",
        "\n",
        "inside_block = False\n",
        "with open(file_path, \"r\") as f:\n",
        "    for line in f:\n",
        "        if 'elif opt.distill == \\'dckd\\'' in line:\n",
        "            inside_block = True\n",
        "            print(\"🚩 Bloc 'dckd' trouvé :\")\n",
        "        if inside_block:\n",
        "            print(line.rstrip())\n",
        "            if line.strip() == '' or line.startswith(\"elif\"):\n",
        "                break\n"
      ],
      "metadata": {
        "id": "OQ-6nQUMrFG_"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_lines = []\n",
        "start_fix = False\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    for line in f:\n",
        "        if \"elif opt.distill == 'dckd':\" in line:\n",
        "            start_fix = True\n",
        "            fixed_lines.append(line)\n",
        "            fixed_lines.append(\"    opt.s_dim = feat_s[-2].shape[1]\\n\")\n",
        "            fixed_lines.append(\"    opt.t_dim = feat_t[-2].shape[1]\\n\")\n",
        "            fixed_lines.append(\"    opt.feat_dim = opt.t_dim\\n\")\n",
        "            fixed_lines.append(\"    criterion_kd = DCKDLoss(opt)\\n\")\n",
        "            fixed_lines.append(\"    module_list.append(criterion_kd)\\n\")\n",
        "            fixed_lines.append(\"    trainable_list.append(criterion_kd)\\n\")\n",
        "        elif start_fix and line.strip().startswith(\"module_list.append\") or line.strip().startswith(\"trainable_list.append\"):\n",
        "            continue  # skip old incorrect lines\n",
        "        elif start_fix and line.strip() == \"\":\n",
        "            start_fix = False  # fin du bloc\n",
        "            fixed_lines.append(line)\n",
        "        else:\n",
        "            fixed_lines.append(line)\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    f.writelines(fixed_lines)\n",
        "\n",
        "print(\"✅ Bloc 'dckd' corrigé dans train_student.py.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOAyJ1N3rLz4",
        "outputId": "7046ea10-b8d4-44ba-c370-2fa74c333b24"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Bloc 'dckd' corrigé dans train_student.py.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/ICKD-DCKD -type f -name \"*.pth\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rHNLsp6Y6xi",
        "outputId": "19c3188a-8a71-44a5-dd07-4f9d6ee99e19"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100/save/models/resnet110_cifar100_lr_0.05_decay_0.0005_trial_0/ckpt_epoch_80.pth\n",
            "/content/ICKD-DCKD/Cifar100/save/models/resnet110_cifar100_lr_0.05_decay_0.0005_trial_0/ckpt_epoch_240.pth\n",
            "/content/ICKD-DCKD/Cifar100/save/models/resnet110_cifar100_lr_0.05_decay_0.0005_trial_0/ckpt_epoch_200.pth\n",
            "/content/ICKD-DCKD/Cifar100/save/models/resnet110_cifar100_lr_0.05_decay_0.0005_trial_0/resnet110_best.pth\n",
            "/content/ICKD-DCKD/Cifar100/save/models/resnet110_cifar100_lr_0.05_decay_0.0005_trial_0/ckpt_epoch_120.pth\n",
            "/content/ICKD-DCKD/Cifar100/save/models/resnet110_cifar100_lr_0.05_decay_0.0005_trial_0/resnet110_last.pth\n",
            "/content/ICKD-DCKD/Cifar100/save/models/resnet110_cifar100_lr_0.05_decay_0.0005_trial_0/ckpt_epoch_40.pth\n",
            "/content/ICKD-DCKD/Cifar100/save/models/resnet110_cifar100_lr_0.05_decay_0.0005_trial_0/ckpt_epoch_160.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard_logger pudb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tyBa80Yn7IO",
        "outputId": "411ede74-aaaf-44ef-9083-18461b003e3a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboard_logger in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: pudb in /usr/local/lib/python3.11/dist-packages (2025.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (1.15.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (11.2.1)\n",
            "Requirement already satisfied: jedi<1,>=0.18 in /usr/local/lib/python3.11/dist-packages (from pudb) (0.19.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pudb) (24.2)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from pudb) (2.19.1)\n",
            "Requirement already satisfied: urwid-readline in /usr/local/lib/python3.11/dist-packages (from pudb) (0.15.1)\n",
            "Requirement already satisfied: urwid in /usr/local/lib/python3.11/dist-packages (from pudb) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi<1,>=0.18->pudb) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from urwid->pudb) (0.2.13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ICKD/ICKD-DCKD/Cifar100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjL1eOAOt2_e",
        "outputId": "16bc95ee-e5c9-4a48-960f-6e7b63546306"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/ICKD/ICKD-DCKD/Cifar100': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_teacher_name(model_path):\n",
        "    # Nouveau parsing robuste\n",
        "    filename = os.path.basename(model_path)\n",
        "    if filename.startswith(\"wrn\"):\n",
        "        # ex: wrn_40_2_best.pth\n",
        "        return \"_\".join(filename.split('_')[:3])\n",
        "    elif filename.startswith(\"resnet\") and 'x4' in filename:\n",
        "        # ex: resnet32x4_best.pth\n",
        "        return filename.split('_')[0]\n",
        "    else:\n",
        "        # ex: resnet32_best.pth\n",
        "        return filename.split('_')[0]\n"
      ],
      "metadata": {
        "id": "0a43xzCgweuH"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AqCBI9Ptivm",
        "outputId": "2b1b054a-159a-4492-b85b-0514c96a6121"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lrezqi/ICKD-DCKD.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CMI9-wLtbNl",
        "outputId": "1f561826-f912-4862-9f98-c5d7b95e9d31"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'ICKD-DCKD' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ICKD-DCKD/Cifar100\n",
        "!python train_student.py \\\n",
        "    --path_t ./save/models/resnet32x4_cifar100_lr_0.05_decay_0.0005_trial_0/resnet32x4_best.pth \\\n",
        "    --distill dckd \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --model_t resnet32x4 \\\n",
        "    -a 0.5 -b 0.5 --trial 1\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szxlmt1KrkFC",
        "outputId": "e69f83ab-d959-42f2-aa97-bd04c78b6bd8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load /content/ICKD-DCKD/Cifar100/train_student.py\n",
        "    elif opt.distill == 'fsp':\n",
        "        s_shapes = [s.shape for s in feat_s[:-1]]\n",
        "        t_shapes = [t.shape for t in feat_t[:-1]]\n",
        "        criterion_kd = FSP(s_shapes, t_shapes)\n",
        "        # init stage training\n",
        "        init_trainable_list = nn.ModuleList([])\n",
        "        init_trainable_list.append(model_s.get_feat_modules())\n",
        "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
        "        # classification training\n",
        "        pass\n",
        "    elif opt.distill == 'dckd':\n",
        "        opt.s_dim = feat_s[-2].shape[1]\n",
        "        opt.t_dim = feat_t[-2].shape[1]\n",
        "        opt.feat_dim = opt.t_dim\n",
        "        criterion_kd = DCKDLoss(opt)\n",
        "        # S'il n'y a pas d'attribut embed_s/embed_t dans DCKDLoss, ne pas les ajouter\n",
        "        # Sinon, décommente les lignes suivantes si ces attributs existent :\n",
        "        # module_list.append(criterion_kd.embed_s)\n",
        "        # module_list.append(criterion_kd.embed_t)\n",
        "        # trainable_list.append(criterion_kd.embed_s)\n",
        "        # trainable_list.append(criterion_kd.embed_t)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(opt.distill)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m041Bykg8u2g"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " %load /content/ICKD-DCKD/Cifar100/train_student.py\n",
        "    elif opt.distill == 'fsp':\n",
        "        s_shapes = [s.shape for s in feat_s[:-1]]\n",
        "        t_shapes = [t.shape for t in feat_t[:-1]]\n",
        "        criterion_kd = FSP(s_shapes, t_shapes)\n",
        "        # init stage training\n",
        "        init_trainable_list = nn.ModuleList([])\n",
        "        init_trainable_list.append(model_s.get_feat_modules())\n",
        "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
        "        # classification training\n",
        "        pass\n",
        "    elif opt.distill == 'dckd':\n",
        "        opt.s_dim = feat_s[-2].shape[1]\n",
        "        opt.t_dim = feat_t[-2].shape[1]\n",
        "        opt.feat_dim = opt.t_dim\n",
        "        criterion_kd = DCKDLoss(opt)\n",
        "        # S'il n'y a pas d'attribut embed_s/embed_t dans DCKDLoss, ne pas les ajouter\n",
        "        # Sinon, décommente les lignes suivantes si ces attributs existent :\n",
        "        # module_list.append(criterion_kd.embed_s)\n",
        "        # module_list.append(criterion_kd.embed_t)\n",
        "        # trainable_list.append(criterion_kd.embed_s)\n",
        "        # trainable_list.append(criterion_kd.embed_t)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(opt.distill)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_lKwNI1R8pyQ"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " %load /content/ICKD-DCKD/Cifar100/train_student.py\n",
        "    elif opt.distill == 'fsp':\n",
        "        s_shapes = [s.shape for s in feat_s[:-1]]\n",
        "        t_shapes = [t.shape for t in feat_t[:-1]]\n",
        "        criterion_kd = FSP(s_shapes, t_shapes)\n",
        "        # init stage training\n",
        "        init_trainable_list = nn.ModuleList([])\n",
        "        init_trainable_list.append(model_s.get_feat_modules())\n",
        "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
        "        # classification training\n",
        "        pass\n",
        "    elif opt.distill == 'dckd':\n",
        "        opt.s_dim = feat_s[-2].shape[1]\n",
        "        opt.t_dim = feat_t[-2].shape[1]\n",
        "        opt.feat_dim = opt.t_dim\n",
        "        criterion_kd = DCKDLoss(opt)\n",
        "        # S'il n'y a pas d'attribut embed_s/embed_t dans DCKDLoss, ne pas les ajouter\n",
        "        # Sinon, décommente les lignes suivantes si ces attributs existent :\n",
        "        # module_list.append(criterion_kd.embed_s)\n",
        "        # module_list.append(criterion_kd.embed_t)\n",
        "        # trainable_list.append(criterion_kd.embed_s)\n",
        "        # trainable_list.append(criterion_kd.embed_t)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(opt.distill)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "3_otBdJg44At",
        "outputId": "822dc619-cf50-4ac9-9622-a5b94cf34131"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (ipython-input-88-3458621641.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-88-3458621641.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    elif opt.distill == 'fsp':\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load /content/ICKD-DCKD/Cifar100/train_student.py\n",
        "\"\"\"\n",
        "the general training framework\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import socket\n",
        "import time\n",
        "\n",
        "import tensorboard_logger as tb_logger\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "from models import model_dict, LAYER\n",
        "from models.util import Embed, ConvReg, LinearEmbed\n",
        "from models.util import Connector, Translator, Paraphraser\n",
        "\n",
        "from dataset.cifar100 import get_cifar100_dataloaders, get_cifar100_dataloaders_sample\n",
        "\n",
        "from helper.util import adjust_learning_rate\n",
        "\n",
        "from distiller_zoo import DistillKL, HintLoss, Attention, Similarity, Correlation, VIDLoss, RKDLoss\n",
        "from distiller_zoo import PKT, ABLoss, FactorTransfer, KDSVD, FSP, NSTLoss, ICKDLoss, AFD\n",
        "from crd.criterion import CRDLoss\n",
        "from distiller_zoo.DCKD import DCKDLoss\n",
        "\n",
        "\n",
        "from helper.loops import train_distill as train, validate\n",
        "from helper.pretrain import init\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def unique_shape(s_shapes):\n",
        "    n_s = []\n",
        "    unique_shapes = []\n",
        "    n = -1\n",
        "    for s_shape in s_shapes:\n",
        "        if s_shape not in unique_shapes:\n",
        "            unique_shapes.append(s_shape)\n",
        "            n += 1\n",
        "        n_s.append(n)\n",
        "    return n_s, unique_shapes\n",
        "\n",
        "def parse_option():\n",
        "\n",
        "    hostname = socket.gethostname()\n",
        "\n",
        "    parser = argparse.ArgumentParser('argument for training')\n",
        "\n",
        "    parser.add_argument('--print_freq', type=int, default=100, help='print frequency')\n",
        "    parser.add_argument('--tb_freq', type=int, default=500, help='tb frequency')\n",
        "    parser.add_argument('--save_freq', type=int, default=40, help='save frequency')\n",
        "    parser.add_argument('--batch_size', type=int, default=64, help='batch_size')\n",
        "    parser.add_argument('--num_workers', type=int, default=8, help='num of workers to use')\n",
        "    parser.add_argument('--epochs', type=int, default=240, help='number of training epochs')\n",
        "    parser.add_argument('--init_epochs', type=int, default=30, help='init training for two-stage methods')\n",
        "\n",
        "    # optimization\n",
        "    parser.add_argument('--learning_rate', type=float, default=0.05, help='learning rate')\n",
        "    parser.add_argument('--lr_decay_epochs', type=str, default='150,180,210', help='where to decay lr, can be a list')\n",
        "    parser.add_argument('--lr_decay_rate', type=float, default=0.1, help='decay rate for learning rate')\n",
        "    parser.add_argument('--weight_decay', type=float, default=5e-4, help='weight decay')\n",
        "    parser.add_argument('--momentum', type=float, default=0.9, help='momentum')\n",
        "\n",
        "    # dataset\n",
        "    parser.add_argument('--dataset', type=str, default='cifar100', choices=['cifar100'], help='dataset')\n",
        "\n",
        "    # model\n",
        "    parser.add_argument('--model_s', type=str, default='resnet8',\n",
        "                        choices=['resnet8', 'resnet14', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110',\n",
        "                                 'resnet8x4', 'resnet32x4', 'wrn_16_1', 'wrn_16_2', 'wrn_40_1', 'wrn_40_2',\n",
        "                                 'vgg8', 'vgg11', 'vgg13', 'vgg16', 'vgg19', 'ResNet50',\n",
        "                                 'MobileNetV2', 'ShuffleV1', 'ShuffleV2'])\n",
        "    parser.add_argument('--model_t', type=str, required=True, help='teacher model')\n",
        "\n",
        "    parser.add_argument('--path_t', type=str, default=None, help='teacher model snapshot')\n",
        "    parser.add_argument('--path_s', type=str, default=None, help='student model path (optional)')\n",
        "\n",
        "\n",
        "    # distillation\n",
        "    parser.add_argument('--distill', type=str, default='kd', choices=['afd', 'ickd', 'kd', 'hint', 'attention', 'similarity',\n",
        "                                                                      'correlation', 'vid', 'crd', 'kdsvd', 'fsp',\n",
        "                                                                      'rkd', 'pkt', 'abound', 'factor', 'nst','dckd'])\n",
        "\n",
        "    parser.add_argument('--trial', type=str, default='1', help='trial id')\n",
        "\n",
        "    parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
        "\n",
        "    parser.add_argument('-r', '--gamma', type=float, default=1, help='weight for classification')\n",
        "    parser.add_argument('-a', '--alpha', type=float, default=None, help='weight balance for KD')\n",
        "    parser.add_argument('-b', '--beta', type=float, default=None, help='weight balance for other losses')\n",
        "    # KL distillation\n",
        "    parser.add_argument('--kd_T', type=float, default=4, help='temperature for KD distillation')\n",
        "\n",
        "    # NCE distillation\n",
        "    parser.add_argument('--feat_dim', default=128, type=int, help='feature dimension')\n",
        "    parser.add_argument('--mode', default='exact', type=str, choices=['exact', 'relax'])\n",
        "    parser.add_argument('--nce_k', default=16384, type=int, help='number of negative samples for NCE')\n",
        "    parser.add_argument('--nce_t', default=0.07, type=float, help='temperature parameter for softmax')\n",
        "    parser.add_argument('--nce_m', default=0.5, type=float, help='momentum for non-parametric updates')\n",
        "\n",
        "    # hint layer\n",
        "    parser.add_argument('--hint_layer', default=2, type=int, choices=[0, 1, 2, 3, 4])\n",
        "\n",
        "    parser.add_argument('--qk_dim', default=128, type=int)\n",
        "\n",
        "    opt = parser.parse_args()\n",
        "\n",
        "    # set different learning rate from these 4 models\n",
        "    if opt.model_s in ['MobileNetV2', 'ShuffleV1', 'ShuffleV2']:\n",
        "        opt.learning_rate = 0.01\n",
        "\n",
        "    # set the path according to the environment\n",
        "    if hostname.startswith('visiongpu'):\n",
        "        opt.model_path = '/path/to/my/student_model'\n",
        "        opt.tb_path = '/path/to/my/student_tensorboards'\n",
        "    else:\n",
        "        opt.model_path = './save/student_model'\n",
        "        opt.tb_path = './save/student_tensorboards'\n",
        "\n",
        "    iterations = opt.lr_decay_epochs.split(',')\n",
        "    opt.lr_decay_epochs = list([])\n",
        "    for it in iterations:\n",
        "        opt.lr_decay_epochs.append(int(it))\n",
        "\n",
        "\n",
        "    opt.model_t = 'resnet32x4'\n",
        "\n",
        "    opt.model_name = 'S:{}_T:{}_{}_{}_r:{}_a:{}_b:{}_{}'.format(opt.model_s, opt.model_t, opt.dataset, opt.distill,\n",
        "                                                                opt.gamma, opt.alpha, opt.beta, opt.trial)\n",
        "\n",
        "    opt.tb_folder = os.path.join(opt.tb_path, opt.model_name)\n",
        "    if not os.path.isdir(opt.tb_folder):\n",
        "        os.makedirs(opt.tb_folder)\n",
        "\n",
        "    opt.save_folder = os.path.join(opt.model_path, opt.model_name)\n",
        "    if not os.path.isdir(opt.save_folder):\n",
        "        os.makedirs(opt.save_folder)\n",
        "\n",
        "    return opt\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "def get_teacher_name(model_path):\n",
        "    \"\"\"Parse le nom du modèle enseignant à partir du nom de fichier\"\"\"\n",
        "    filename = os.path.basename(model_path)  # ex: resnet32x4_best.pth\n",
        "    if filename.startswith(\"wrn\"):\n",
        "        return \"_\".join(filename.split('_')[:3])  # wrn_40_2\n",
        "    else:\n",
        "        return filename.split('_')[0] if 'x4' not in filename else filename.split('_')[0]\n",
        "\n",
        "\n",
        "def load_teacher(model_path, n_cls):\n",
        "    print('==> loading teacher model')\n",
        "    model_t = get_teacher_name(model_path)\n",
        "    model = model_dict[model_t](num_classes=n_cls)\n",
        "    model.load_state_dict(torch.load(model_path)['model'])\n",
        "    print('==> done')\n",
        "    return model\n",
        "\n",
        "\n",
        "def set_random_seed(seed, deterministic=False):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def main():\n",
        "    best_acc = 0\n",
        "\n",
        "    opt = parse_option()\n",
        "\n",
        "    # set random seeds\n",
        "    set_random_seed(opt.seed, True)\n",
        "\n",
        "    # tensorboard logger\n",
        "    logger = tb_logger.Logger(logdir=opt.tb_folder, flush_secs=2)\n",
        "\n",
        "    # dataloader\n",
        "    if opt.dataset == 'cifar100':\n",
        "        if opt.distill in ['crd']:\n",
        "            train_loader, val_loader, n_data = get_cifar100_dataloaders_sample(batch_size=opt.batch_size,\n",
        "                                                                               num_workers=opt.num_workers,\n",
        "                                                                               k=opt.nce_k,\n",
        "                                                                               mode=opt.mode)\n",
        "        else:\n",
        "            train_loader, val_loader, n_data = get_cifar100_dataloaders(batch_size=opt.batch_size,\n",
        "                                                                        num_workers=opt.num_workers,\n",
        "                                                                        is_instance=True)\n",
        "        n_cls = 100\n",
        "    else:\n",
        "        raise NotImplementedError(opt.dataset)\n",
        "    # model\n",
        "    model_t = load_teacher(opt.path_t, n_cls)\n",
        "    model_s = model_dict[opt.model_s](num_classes=n_cls)\n",
        "\n",
        "    data = torch.randn(2, 3, 32, 32)\n",
        "    model_t.eval()\n",
        "    model_s.eval()\n",
        "    feat_t, _ = model_t(data, is_feat=True)\n",
        "    feat_s, _ = model_s(data, is_feat=True)\n",
        "\n",
        "    module_list = nn.ModuleList([])\n",
        "    module_list.append(model_s)\n",
        "    trainable_list = nn.ModuleList([])\n",
        "    trainable_list.append(model_s)\n",
        "\n",
        "    criterion_cls = nn.CrossEntropyLoss()\n",
        "    criterion_div = DistillKL(opt.kd_T)\n",
        "    #criterion_fea = CCLoss(opt)\n",
        "\n",
        "    if opt.distill == 'kd':\n",
        "        criterion_kd = DistillKL(opt.kd_T)\n",
        "    elif opt.distill == 'afd':\n",
        "        opt.guide_layers = np.arange(14,16) #LAYER[opt.model_t]\n",
        "        opt.hint_layers = np.arange(3,4)#LAYER[opt.model_s]\n",
        "        opt.s_shapes = [feat_s[i].size() for i in opt.hint_layers]\n",
        "        opt.t_shapes = [feat_t[i].size() for i in opt.guide_layers]\n",
        "        opt.n_t, opt.unique_t_shapes = unique_shape(opt.t_shapes)\n",
        "        criterion_kd = AFD(opt)\n",
        "        module_list.append(criterion_kd)\n",
        "        trainable_list.append(criterion_kd)\n",
        "    elif opt.distill == 'hint':\n",
        "        criterion_kd = HintLoss()\n",
        "        regress_s = ConvReg(feat_s[opt.hint_layer].shape, feat_t[opt.hint_layer].shape)\n",
        "        module_list.append(regress_s)\n",
        "        trainable_list.append(regress_s)\n",
        "    elif opt.distill == 'crd':\n",
        "        opt.s_dim = feat_s[-1].shape[1]\n",
        "        opt.t_dim = feat_t[-1].shape[1]\n",
        "        #opt.feat_dim = opt.s_dim\n",
        "        opt.n_data = n_data\n",
        "        criterion_kd = CRDLoss(opt)\n",
        "        module_list.append(criterion_kd.embed_s)\n",
        "        module_list.append(criterion_kd.embed_t)\n",
        "        trainable_list.append(criterion_kd.embed_s)\n",
        "        trainable_list.append(criterion_kd.embed_t)\n",
        "        #criterion_fea = CCLoss()\n",
        "    elif opt.distill == 'attention':\n",
        "        criterion_kd = Attention()\n",
        "    elif opt.distill == 'nst':\n",
        "        criterion_kd = NSTLoss()\n",
        "    elif opt.distill == 'similarity':\n",
        "        criterion_kd = Similarity()\n",
        "    elif opt.distill == 'ickd':\n",
        "        opt.s_dim = feat_s[-2].shape[1]\n",
        "        opt.t_dim = feat_t[-2].shape[1]\n",
        "        opt.feat_dim = opt.t_dim\n",
        "        criterion_kd = ICKDLoss(opt)\n",
        "        module_list.append(criterion_kd.embed_s)\n",
        "        module_list.append(criterion_kd.embed_t)\n",
        "        trainable_list.append(criterion_kd.embed_s)\n",
        "        trainable_list.append(criterion_kd.embed_t)\n",
        "    elif opt.distill == 'rkd':\n",
        "        criterion_kd = RKDLoss()\n",
        "    elif opt.distill == 'pkt':\n",
        "        criterion_kd = PKT()\n",
        "    elif opt.distill == 'kdsvd':\n",
        "        criterion_kd = KDSVD()\n",
        "    elif opt.distill == 'correlation':\n",
        "        criterion_kd = Correlation()\n",
        "        embed_s = LinearEmbed(feat_s[-1].shape[1], opt.feat_dim)\n",
        "        embed_t = LinearEmbed(feat_t[-1].shape[1], opt.feat_dim)\n",
        "        module_list.append(embed_s)\n",
        "        module_list.append(embed_t)\n",
        "        trainable_list.append(embed_s)\n",
        "        trainable_list.append(embed_t)\n",
        "    elif opt.distill == 'vid':\n",
        "        s_n = [f.shape[1] for f in feat_s[1:-1]]\n",
        "        t_n = [f.shape[1] for f in feat_t[1:-1]]\n",
        "        criterion_kd = nn.ModuleList(\n",
        "            [VIDLoss(s, t, t) for s, t in zip(s_n, t_n)]\n",
        "        )\n",
        "        # add this as some parameters in VIDLoss need to be updated\n",
        "        trainable_list.append(criterion_kd)\n",
        "    elif opt.distill == 'abound':\n",
        "        s_shapes = [f.shape for f in feat_s[1:-1]]\n",
        "        t_shapes = [f.shape for f in feat_t[1:-1]]\n",
        "        connector = Connector(s_shapes, t_shapes)\n",
        "        # init stage training\n",
        "        init_trainable_list = nn.ModuleList([])\n",
        "        init_trainable_list.append(connector)\n",
        "        init_trainable_list.append(model_s.get_feat_modules())\n",
        "        criterion_kd = ABLoss(len(feat_s[1:-1]))\n",
        "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
        "        # classification\n",
        "        module_list.append(connector)\n",
        "    elif opt.distill == 'factor':\n",
        "        s_shape = feat_s[-2].shape\n",
        "        t_shape = feat_t[-2].shape\n",
        "        paraphraser = Paraphraser(t_shape)\n",
        "        translator = Translator(s_shape, t_shape)\n",
        "        # init stage training\n",
        "        init_trainable_list = nn.ModuleList([])\n",
        "        init_trainable_list.append(paraphraser)\n",
        "        criterion_init = nn.MSELoss()\n",
        "        init(model_s, model_t, init_trainable_list, criterion_init, train_loader, logger, opt)\n",
        "        # classification\n",
        "        criterion_kd = FactorTransfer()\n",
        "        module_list.append(translator)\n",
        "        module_list.append(paraphraser)\n",
        "        trainable_list.append(translator)\n",
        "    elif opt.distill == 'fsp':\n",
        "        s_shapes = [s.shape for s in feat_s[:-1]]\n",
        "        t_shapes = [t.shape for t in feat_t[:-1]]\n",
        "        criterion_kd = FSP(s_shapes, t_shapes)\n",
        "        # init stage training\n",
        "        init_trainable_list = nn.ModuleList([])\n",
        "        init_trainable_list.append(model_s.get_feat_modules())\n",
        "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
        "        # classification training\n",
        "        pass\n",
        "    elif opt.distill == 'dckd':\n",
        "        opt.s_dim = feat_s[-2].shape[1]\n",
        "        opt.t_dim = feat_t[-2].shape[1]\n",
        "        opt.feat_dim = opt.t_dim\n",
        "        criterion_kd = DCKDLoss(opt)\n",
        "        # S'il n'y a pas d'attribut embed_s/embed_t dans DCKDLoss, ne pas les ajouter\n",
        "        # Sinon, décommente les lignes suivantes si ces attributs existent :\n",
        "        # module_list.append(criterion_kd.embed_s)\n",
        "        # module_list.append(criterion_kd.embed_t)\n",
        "        # trainable_list.append(criterion_kd.embed_s)\n",
        "        # trainable_list.append(criterion_kd.embed_t)\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError(opt.distill)\n",
        "\n",
        "    criterion_list = nn.ModuleList([])\n",
        "    criterion_list.append(criterion_cls)    # classification loss\n",
        "    criterion_list.append(criterion_div)    # KL divergence loss, original knowledge distillation\n",
        "    criterion_list.append(criterion_kd)     # other knowledge distillation loss\n",
        "    #criterion_list.append(criterion_fea)     # other knowledge distillation loss\n",
        "\n",
        "    # optimizer\n",
        "    optimizer = optim.SGD(trainable_list.parameters(),\n",
        "                          lr=opt.learning_rate,\n",
        "                          momentum=opt.momentum,\n",
        "                          weight_decay=opt.weight_decay)\n",
        "\n",
        "    # append teacher after optimizer to avoid weight_decay\n",
        "    module_list.append(model_t)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        module_list.cuda()\n",
        "        criterion_list.cuda()\n",
        "        #cudnn.benchmark = True\n",
        "\n",
        "    # validate teacher accuracy\n",
        "    teacher_acc, _, _ = validate(val_loader, model_t, criterion_cls, opt)\n",
        "    print('teacher accuracy: ', teacher_acc)\n",
        "\n",
        "    # routine\n",
        "    for epoch in range(1, opt.epochs + 1):\n",
        "        adjust_learning_rate(epoch, opt, optimizer)\n",
        "        print(\"==> training...\")\n",
        "\n",
        "        time1 = time.time()\n",
        "        train_acc, train_loss = train(epoch, train_loader, module_list, criterion_list, optimizer, opt)\n",
        "        time2 = time.time()\n",
        "        print('epoch {}, total time {:.2f}'.format(epoch, time2 - time1))\n",
        "\n",
        "        logger.log_value('train_acc', train_acc, epoch)\n",
        "        logger.log_value('train_loss', train_loss, epoch)\n",
        "\n",
        "        test_acc, tect_acc_top5, test_loss = validate(val_loader, model_s, criterion_cls, opt)\n",
        "\n",
        "        logger.log_value('test_acc', test_acc, epoch)\n",
        "        logger.log_value('test_loss', test_loss, epoch)\n",
        "        logger.log_value('test_acc_top5', tect_acc_top5, epoch)\n",
        "\n",
        "        # save the best model\n",
        "        if test_acc > best_acc:\n",
        "            best_acc = test_acc\n",
        "            state = {\n",
        "                'epoch': epoch,\n",
        "                'model': model_s.state_dict(),\n",
        "                'best_acc': best_acc,\n",
        "            }\n",
        "            save_file = os.path.join(opt.save_folder, '{}_best.pth'.format(opt.model_s))\n",
        "            print('saving the best model!')\n",
        "            torch.save(state, save_file)\n",
        "\n",
        "        # regular saving\n",
        "        if epoch % opt.save_freq == 0:\n",
        "            print('==> Saving...')\n",
        "            state = {\n",
        "                'epoch': epoch,\n",
        "                'model': model_s.state_dict(),\n",
        "                'accuracy': test_acc,\n",
        "            }\n",
        "            save_file = os.path.join(opt.save_folder, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n",
        "            torch.save(state, save_file)\n",
        "\n",
        "    # This best accuracy is only for printing purpose.\n",
        "    # The results reported in the paper/README is from the last epoch.\n",
        "    print('best accuracy:', best_acc)\n",
        "\n",
        "    # save model\n",
        "    state = {\n",
        "        'opt': opt,\n",
        "        'model': model_s.state_dict(),\n",
        "    }\n",
        "    save_file = os.path.join(opt.save_folder, '{}_last.pth'.format(opt.model_s))\n",
        "    torch.save(state, save_file)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "eXQbKNbMux43",
        "outputId": "89c0c2d7-2343-4549-9089-dc3c71d3d68c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "usage: argument for training [-h] [--print_freq PRINT_FREQ]\n",
            "                             [--tb_freq TB_FREQ] [--save_freq SAVE_FREQ]\n",
            "                             [--batch_size BATCH_SIZE]\n",
            "                             [--num_workers NUM_WORKERS] [--epochs EPOCHS]\n",
            "                             [--init_epochs INIT_EPOCHS]\n",
            "                             [--learning_rate LEARNING_RATE]\n",
            "                             [--lr_decay_epochs LR_DECAY_EPOCHS]\n",
            "                             [--lr_decay_rate LR_DECAY_RATE]\n",
            "                             [--weight_decay WEIGHT_DECAY]\n",
            "                             [--momentum MOMENTUM] [--dataset {cifar100}]\n",
            "                             [--model_s {resnet8,resnet14,resnet20,resnet32,resnet44,resnet56,resnet110,resnet8x4,resnet32x4,wrn_16_1,wrn_16_2,wrn_40_1,wrn_40_2,vgg8,vgg11,vgg13,vgg16,vgg19,ResNet50,MobileNetV2,ShuffleV1,ShuffleV2}]\n",
            "                             --model_t MODEL_T [--path_t PATH_T]\n",
            "                             [--path_s PATH_S]\n",
            "                             [--distill {afd,ickd,kd,hint,attention,similarity,correlation,vid,crd,kdsvd,fsp,rkd,pkt,abound,factor,nst,dckd}]\n",
            "                             [--trial TRIAL] [--seed SEED] [-r GAMMA]\n",
            "                             [-a ALPHA] [-b BETA] [--kd_T KD_T]\n",
            "                             [--feat_dim FEAT_DIM] [--mode {exact,relax}]\n",
            "                             [--nce_k NCE_K] [--nce_t NCE_T] [--nce_m NCE_M]\n",
            "                             [--hint_layer {0,1,2,3,4}] [--qk_dim QK_DIM]\n",
            "argument for training: error: the following arguments are required: --model_t\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "2",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ICKD-DCKD/Cifar100/train_student.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usSdgS4N84IF",
        "outputId": "e0a52733-4e7a-44cd-d757-26399fc8bad6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/ICKD-DCKD/Cifar100/train_student.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/ICKD-DCKD/Cifar100/train_student.py\n",
        "    elif opt.distill == 'fsp':\n",
        "        s_shapes = [s.shape for s in feat_s[:-1]]\n",
        "        t_shapes = [t.shape for t in feat_t[:-1]]\n",
        "        criterion_kd = FSP(s_shapes, t_shapes)\n",
        "        # init stage training\n",
        "        init_trainable_list = nn.ModuleList([])\n",
        "        init_trainable_list.append(model_s.get_feat_modules())\n",
        "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
        "        # classification training\n",
        "        pass\n",
        "    elif opt.distill == 'dckd':\n",
        "        opt.s_dim = feat_s[-2].shape[1]\n",
        "        opt.t_dim = feat_t[-2].shape[1]\n",
        "        opt.feat_dim = opt.t_dim\n",
        "        criterion_kd = DCKDLoss(opt)\n",
        "        # S'il n'y a pas d'attribut embed_s/embed_t dans DCKDLoss, ne pas les ajouter\n",
        "        # Sinon, décommente les lignes suivantes si ces attributs existent :\n",
        "        # module_list.append(criterion_kd.embed_s)\n",
        "        # module_list.append(criterion_kd.embed_t)\n",
        "        # trainable_list.append(criterion_kd.embed_s)\n",
        "        # trainable_list.append(criterion_kd.embed_t)\n",
        "\n",
        "       else:\n",
        "          raise NotImplementedError(opt.distill)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Xx5bGY14FqJ",
        "outputId": "cef86f60-6870-49a7-d9b9-a87504305118"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/ICKD-DCKD/Cifar100/train_student.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '310,330p' /content/ICKD-DCKD/Cifar100/train_student.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXCQFtiBzFG4",
        "outputId": "f52a4dd1-3276-4e97-d72b-4c5cc3b14bfc"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        module_list.append(translator)\n",
            "        module_list.append(paraphraser)\n",
            "        trainable_list.append(translator)\n",
            "    elif opt.distill == 'fsp':\n",
            "        s_shapes = [s.shape for s in feat_s[:-1]]\n",
            "        t_shapes = [t.shape for t in feat_t[:-1]]\n",
            "        criterion_kd = FSP(s_shapes, t_shapes)\n",
            "        # init stage training\n",
            "        init_trainable_list = nn.ModuleList([])\n",
            "        init_trainable_list.append(model_s.get_feat_modules())\n",
            "        init(model_s, model_t, init_trainable_list, criterion_kd, train_loader, logger, opt)\n",
            "        # classification training\n",
            "        pass\n",
            "     elif opt.distill == 'dckd':\n",
            "        opt.s_dim = feat_s[-2].shape[1]\n",
            "        opt.t_dim = feat_t[-2].shape[1]\n",
            "        opt.feat_dim = opt.t_dim\n",
            "        criterion_kd = DCKDLoss(opt)\n",
            "        module_list.append(criterion_kd)\n",
            "        trainable_list.append(criterion_kd)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tail -n 20 /content/ICKD-DCKD/Cifar100/train_student.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hwhmGC6xz_J",
        "outputId": "ab426117-53ba-4320-b32f-10bcd51fac60"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                'accuracy': test_acc,\n",
            "            }\n",
            "            save_file = os.path.join(opt.save_folder, 'ckpt_epoch_{epoch}.pth'.format(epoch=epoch))\n",
            "            torch.save(state, save_file)\n",
            "\n",
            "    # This best accuracy is only for printing purpose.\n",
            "    # The results reported in the paper/README is from the last epoch. \n",
            "    print('best accuracy:', best_acc)\n",
            "\n",
            "    # save model\n",
            "    state = {\n",
            "        'opt': opt,\n",
            "        'model': model_s.state_dict(),\n",
            "    }\n",
            "    save_file = os.path.join(opt.save_folder, '{}_last.pth'.format(opt.model_s))\n",
            "    torch.save(state, save_file)\n",
            "\n",
            "\n",
            "if __name__ == '__main__':\n",
            "    main()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ICKD-DCKD/Cifar100\n",
        "\n",
        "!python train_student.py \\\n",
        "    --path_t ./save/models/resnet32x4_cifar100_lr_0.05_decay_0.0005_trial_0/resnet32x4_best.pth \\\n",
        "    --distill dckd \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --model_t resnet32x4 \\\n",
        "    -a 0.5 -b 0.5 --trial 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XZuxBrGurOh",
        "outputId": "dd28facc-c5bb-4675-e874-6c8a8bc61734"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/lrezqi/ICKD-DCKD.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1DhbL_etrQJ",
        "outputId": "c463a849-5114-4ae3-9ef1-42e09aee2bd5"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'ICKD-DCKD'...\n",
            "remote: Enumerating objects: 385, done.\u001b[K\n",
            "remote: Counting objects: 100% (385/385), done.\u001b[K\n",
            "remote: Compressing objects: 100% (274/274), done.\u001b[K\n",
            "remote: Total 385 (delta 140), reused 323 (delta 100), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (385/385), 749.38 KiB | 2.29 MiB/s, done.\n",
            "Resolving deltas: 100% (140/140), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/ICKD-DCKD/Cifar100/helper/util.py'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    for line in lines:\n",
        "        f.write(line.replace('view(-1)', 'reshape(-1)') if 'view(-1)' in line else line)\n",
        "\n",
        "print(\"✅ Remplacement de .view(-1) par .reshape(-1) effectué.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UStR_tmuNqd",
        "outputId": "447b89b9-3d4b-43c4-f182-2044ae2c29cd"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Remplacement de .view(-1) par .reshape(-1) effectué.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correction automatique de la fonction get_teacher_name\n",
        "file_path = '/content/ICKD/ICKD-DCKD/Cifar100/train_student.py'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "new_lines = []\n",
        "in_function = False\n",
        "for line in lines:\n",
        "    if line.strip().startswith(\"def get_teacher_name(\"):\n",
        "        in_function = True\n",
        "        new_lines.append(\"import os\\n\\n\")\n",
        "        new_lines.append(\"def get_teacher_name(model_path):\\n\")\n",
        "        new_lines.append(\"    \\\"\\\"\\\"Parse le nom du modèle enseignant à partir du chemin du fichier.\\\"\\\"\\\"\\n\")\n",
        "        new_lines.append(\"    filename = os.path.basename(model_path)  # ex: resnet32x4_best.pth\\n\")\n",
        "        new_lines.append(\"    if filename.startswith(\\\"wrn\\\"):\\n\")\n",
        "        new_lines.append(\"        return \\\"_\\\".join(filename.split('_')[:3])  # ex: wrn_40_2\\n\")\n",
        "        new_lines.append(\"    else:\\n\")\n",
        "        new_lines.append(\"        return filename.split('_')[0] if 'x4' not in filename else filename.split('_')[0]\\n\")\n",
        "    elif in_function:\n",
        "        if line.strip().startswith(\"def \") or line.strip() == \"\":\n",
        "            in_function = False\n",
        "        continue  # skip old function body\n",
        "    new_lines.append(line)\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    f.writelines(new_lines)\n",
        "\n",
        "print(\"✅ Fonction `get_teacher_name` corrigée avec succès.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKUgN3KHyuQV",
        "outputId": "8e00eb67-004e-425a-9952-6bfb65d15e39"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Fonction `get_teacher_name` corrigée avec succès.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "--model_s resnet8x4 \\\n",
        "--path_t /content/ICKD/ICKD-DCKD/Cifar100/save/resnet32x4_best.pth \\\n",
        "--distill dckd \\\n",
        "--trial 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmz3Y0fry1Gd",
        "outputId": "9e40949e-6956-4baa-b460-f2617a6f333e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/content/ICKD/ICKD-DCKD/Cifar100/train_student.py\", line 159\n",
            "    def load_teacher(model_path, n_cls):\n",
            "    ^\n",
            "IndentationError: expected an indented block after function definition on line 157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_teacher_name(model_path):\n",
        "    # Essaie de retrouver le nom de modèle à partir du nom de fichier\n",
        "    filename = os.path.basename(model_path)\n",
        "    return filename.split('_')[0] if not filename.startswith(\"wrn\") else \"_\".join(filename.split('_')[:3])\n"
      ],
      "metadata": {
        "id": "3R-1dLU1wn7w"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --path_t /content/ICKD/ICKD-DCKD/Cifar100/save/resnet32x4_best.pth \\\n",
        "  --distill dckd \\\n",
        "  --trial test_dckd \\\n",
        "  --model_t resnet32x4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sb4mbnPuuNg7",
        "outputId": "cfb64793-2027-453c-887c-b1d6acfc192f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-18 15:47:06.090837: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750261626.112939   97977 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750261626.119551   97977 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "100% 169M/169M [00:03<00:00, 43.2MB/s]\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD/ICKD-DCKD/Cifar100/train_student.py\", line 414, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD/ICKD-DCKD/Cifar100/train_student.py\", line 202, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD/ICKD-DCKD/Cifar100/train_student.py\", line 160, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'save'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# corriger automatiquement le fichier\n",
        "!python /content/ICKD/ICKD-DCKD/Cifar100/scripts/setup_train_student.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3CjF4GvuG-W",
        "outputId": "55accb24-ff13-4054-e951-4f88be1e1b4f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/ICKD/ICKD-DCKD/Cifar100/scripts/setup_train_student.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ICKD/ICKD-DCKD/Cifar100/distiller_zoo/DCKD.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cPG0a0xt-7Y",
        "outputId": "8f825c13-24ae-4c3b-898c-2464538bf80c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD/ICKD-DCKD/Cifar100/distiller_zoo/DCKD.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ICKD\n",
        "!git clone https://github.com/lrezqi/ICKD-DCKD.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbqfNmEHpXV3",
        "outputId": "1f605503-81af-4f93-d27a-d2a444b50ffa"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD\n",
            "Cloning into 'ICKD-DCKD'...\n",
            "remote: Enumerating objects: 354, done.\u001b[K\n",
            "remote: Counting objects: 100% (354/354), done.\u001b[K\n",
            "remote: Compressing objects: 100% (243/243), done.\u001b[K\n",
            "remote: Total 354 (delta 118), reused 324 (delta 100), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (354/354), 626.51 KiB | 2.38 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --distill dckd \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --path_s save/student_resnet8x4_dckd.pth \\\n",
        "  --model_t resnet32x4 \\\n",
        "  --path_t save/models/ckpt_resnet32x4_best.pth \\\n",
        "  --dataset cifar100 \\\n",
        "  --trial 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEfWapSVSWlq",
        "outputId": "bba39e77-b7b2-43f3-dc7d-96b8b8ed6819"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-18 15:21:10.816828: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750260070.838616   91510 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750260070.845085   91510 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "usage: argument for training [-h] [--print_freq PRINT_FREQ]\n",
            "                             [--tb_freq TB_FREQ] [--save_freq SAVE_FREQ]\n",
            "                             [--batch_size BATCH_SIZE]\n",
            "                             [--num_workers NUM_WORKERS] [--epochs EPOCHS]\n",
            "                             [--init_epochs INIT_EPOCHS]\n",
            "                             [--learning_rate LEARNING_RATE]\n",
            "                             [--lr_decay_epochs LR_DECAY_EPOCHS]\n",
            "                             [--lr_decay_rate LR_DECAY_RATE]\n",
            "                             [--weight_decay WEIGHT_DECAY]\n",
            "                             [--momentum MOMENTUM] [--dataset {cifar100}]\n",
            "                             [--model_s {resnet8,resnet14,resnet20,resnet32,resnet44,resnet56,resnet110,resnet8x4,resnet32x4,wrn_16_1,wrn_16_2,wrn_40_1,wrn_40_2,vgg8,vgg11,vgg13,vgg16,vgg19,ResNet50,MobileNetV2,ShuffleV1,ShuffleV2}]\n",
            "                             --model_t MODEL_T [--path_t PATH_T]\n",
            "                             [--distill {afd,ickd,kd,hint,attention,similarity,correlation,vid,crd,kdsvd,fsp,rkd,pkt,abound,factor,nst,dckd}]\n",
            "                             [--trial TRIAL] [--seed SEED] [-r GAMMA]\n",
            "                             [-a ALPHA] [-b BETA] [--kd_T KD_T]\n",
            "                             [--feat_dim FEAT_DIM] [--mode {exact,relax}]\n",
            "                             [--nce_k NCE_K] [--nce_t NCE_T] [--nce_m NCE_M]\n",
            "                             [--hint_layer {0,1,2,3,4}] [--qk_dim QK_DIM]\n",
            "argument for training: error: unrecognized arguments: --path_s save/student_resnet8x4_dckd.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --model_t resnet32x4 \\\n",
        "    --path_t /content/ICKD-DCKD/save/teacher_resnet32x4_best.pth \\\n",
        "    --distill dckd \\\n",
        "    --trial 1 \\\n",
        "    --kd_T 4 \\\n",
        "    --gamma 1 \\\n",
        "    --alpha 0.9 \\\n",
        "    --beta 0.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BICN6i5LbzVa",
        "outputId": "15391d58-1dd8-46b5-e334-bfd0979cb238"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-18 14:27:10.044408: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750256830.066561   77968 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750256830.073134   77968 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 411, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 199, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 157, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'save'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Is GPU available:\", tf.config.list_physical_devices('GPU'))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rezabQdhgQ1F",
        "outputId": "96d27be9-7333-43ea-8901-fcc08fdf63a5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Is GPU available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pudb\n",
        "!pip install tensorboard_logger\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b829v_jhgpe",
        "outputId": "423e1bb5-4e21-4f9e-dfbb-0c451eab8dca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pudb in /usr/local/lib/python3.11/dist-packages (2025.1)\n",
            "Requirement already satisfied: jedi<1,>=0.18 in /usr/local/lib/python3.11/dist-packages (from pudb) (0.19.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pudb) (24.2)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from pudb) (2.19.1)\n",
            "Requirement already satisfied: urwid-readline in /usr/local/lib/python3.11/dist-packages (from pudb) (0.15.1)\n",
            "Requirement already satisfied: urwid in /usr/local/lib/python3.11/dist-packages (from pudb) (3.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi<1,>=0.18->pudb) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from urwid->pudb) (0.2.13)\n",
            "Requirement already satisfied: tensorboard_logger in /usr/local/lib/python3.11/dist-packages (0.1.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (1.15.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (11.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ICKD-DCKD/Cifar100\n",
        "\n",
        "!python train_student.py \\\n",
        "  --path_t ./save/models/resnet32x4_cifar100_lr_0.05_decay_0.0005_trial_0/resnet32x4_best.pth \\\n",
        "  --distill dckd \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --model_t resnet32x4 \\\n",
        "  -a 0.5 -b 0.5 --trial 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbcvdMQDcliJ",
        "outputId": "5a1d1195-c118-4d98-b1e9-26fa2b4d1b65"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_student.py \\\n",
        "  --path_t ./save/models/resnet32x4_cifar100_lr_0.05_decay_0.0005_trial_0/resnet32x4_best.pth \\\n",
        "  --distill dckd \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --model_t resnet32x4 \\\n",
        "  -a 0.5 -b 0.5 --trial 1\n"
      ],
      "metadata": {
        "id": "XNRy1G8d_cLU"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ICKD-DCKD/Cifar100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sV2pfd1U_3aF",
        "outputId": "f2f3683a-f1a4-483b-b0eb-8d9dd56c3d35"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 20 train_student.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGr-hfdg_9t-",
        "outputId": "e66b59cc-0f08-4e11-b3e3-1ea334c13f67"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --model_t resnet32x4 \\\n",
        "  --path_t /content/ICKD-DCKD/save/teacher_resnet32x4.pth \\\n",
        "  --distill dckd \\\n",
        "  --trial 1 \\\n",
        "  --batch_size 64 \\\n",
        "  --epochs 5 \\\n",
        "  --kd_T 4 \\\n",
        "  --gamma 1 \\\n",
        "  --alpha 0.9 \\\n",
        "  --beta 0.1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8D2Y935nZ-tu",
        "outputId": "a5073a05-ae24-4d7b-be4e-1dd46e06f5d6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-18 14:26:52.287225: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750256812.309422   77853 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750256812.316012   77853 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 411, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 199, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 157, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'save'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --distill dckd \\\n",
        "  --model_s 'resnet8x4' \\\n",
        "  --model_t 'resnet32x4' \\\n",
        "  --path_t save/models/ckpt_resnet32x4_best.pth \\\n",
        "  --dataset cifar100 \\\n",
        "  --trial 0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP2pdGmNS2HV",
        "outputId": "ed239c6e-a37b-4831-f69b-95519552bc37"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-18 13:47:28.147380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750254448.169451   68145 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750254448.175977   68145 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 411, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 199, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 157, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'models'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/ICKD-DCKD/Cifar100/helper/util.py'\n",
        "\n",
        "# Lire le contenu\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Remplacer la ligne fautive\n",
        "with open(file_path, 'w') as f:\n",
        "    for line in lines:\n",
        "        if 'view(-1)' in line:\n",
        "            f.write(line.replace('view(-1)', 'reshape(-1)'))\n",
        "        else:\n",
        "            f.write(line)\n",
        "\n",
        "print(\"✅ Remplacement de .view(-1) par .reshape(-1) effectué.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_jLyjISPjzG",
        "outputId": "1855924c-7e09-4c86-fd7b-874a2774a3e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Remplacement de .view(-1) par .reshape(-1) effectué.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ICKD-DCKD/Cifar100/train_teacher.py --epochs 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZZo6X8-RbvD",
        "outputId": "7de23ff4-4319-4521-e0f5-56df4229158e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-17 23:42:26.306827: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-17 23:42:26.324253: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750203746.345873   16748 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750203746.352353   16748 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-17 23:42:26.373515: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "==> training...\n",
            "Epoch: [1][0/782]\tTime 0.900 (0.900)\tData 0.174 (0.174)\tLoss 5.9258 (5.9258)\tAcc@1 0.000 (0.000)\tAcc@5 3.125 (3.125)\n",
            "Epoch: [1][100/782]\tTime 0.051 (0.060)\tData 0.001 (0.003)\tLoss 4.5685 (4.7963)\tAcc@1 4.688 (1.454)\tAcc@5 10.938 (5.693)\n",
            "Epoch: [1][200/782]\tTime 0.053 (0.056)\tData 0.002 (0.002)\tLoss 4.5379 (4.6863)\tAcc@1 0.000 (1.500)\tAcc@5 9.375 (6.359)\n",
            "Epoch: [1][300/782]\tTime 0.050 (0.055)\tData 0.001 (0.002)\tLoss 4.4925 (4.6425)\tAcc@1 1.562 (1.573)\tAcc@5 10.938 (6.619)\n",
            "Epoch: [1][400/782]\tTime 0.049 (0.054)\tData 0.001 (0.002)\tLoss 4.3702 (4.5977)\tAcc@1 3.125 (1.808)\tAcc@5 9.375 (7.738)\n",
            "Epoch: [1][500/782]\tTime 0.053 (0.054)\tData 0.002 (0.002)\tLoss 4.3107 (4.5509)\tAcc@1 6.250 (2.090)\tAcc@5 20.312 (8.982)\n",
            "Epoch: [1][600/782]\tTime 0.052 (0.053)\tData 0.001 (0.002)\tLoss 4.0620 (4.4974)\tAcc@1 3.125 (2.444)\tAcc@5 20.312 (10.503)\n",
            "Epoch: [1][700/782]\tTime 0.049 (0.053)\tData 0.001 (0.002)\tLoss 3.9716 (4.4489)\tAcc@1 3.125 (2.849)\tAcc@5 18.750 (11.793)\n",
            " * Acc@1 3.120 Acc@5 12.836\n",
            "epoch 1, total time 41.46\n",
            "makedirs /mnt_venus/luis.ll/venus/vis/channel/\n",
            "Test: [0/313]\tTime 0.159 (0.159)\tLoss 4.0236 (4.0236)\tAcc@1 3.125 (3.125)\tAcc@5 21.875 (21.875)\n",
            "Test: [100/313]\tTime 0.018 (0.020)\tLoss 3.7537 (4.2016)\tAcc@1 3.125 (5.786)\tAcc@5 34.375 (21.597)\n",
            "Test: [200/313]\tTime 0.019 (0.019)\tLoss 3.9420 (4.2006)\tAcc@1 9.375 (5.784)\tAcc@5 25.000 (21.766)\n",
            "Test: [300/313]\tTime 0.017 (0.019)\tLoss 4.4204 (4.2206)\tAcc@1 3.125 (5.534)\tAcc@5 18.750 (21.117)\n",
            " * Acc@1 5.520 Acc@5 21.180\n",
            "saving the best model!\n",
            "==> training...\n",
            "Epoch: [2][0/782]\tTime 0.291 (0.291)\tData 0.203 (0.203)\tLoss 4.0739 (4.0739)\tAcc@1 9.375 (9.375)\tAcc@5 18.750 (18.750)\n",
            "Epoch: [2][100/782]\tTime 0.049 (0.053)\tData 0.001 (0.003)\tLoss 4.1609 (4.0451)\tAcc@1 6.250 (6.436)\tAcc@5 15.625 (23.886)\n",
            "Epoch: [2][200/782]\tTime 0.051 (0.053)\tData 0.001 (0.002)\tLoss 4.2209 (4.0328)\tAcc@1 1.562 (6.856)\tAcc@5 17.188 (24.674)\n",
            "Epoch: [2][300/782]\tTime 0.050 (0.053)\tData 0.001 (0.002)\tLoss 3.8887 (4.0070)\tAcc@1 10.938 (7.241)\tAcc@5 31.250 (25.234)\n",
            "Epoch: [2][400/782]\tTime 0.053 (0.052)\tData 0.002 (0.002)\tLoss 3.7011 (3.9803)\tAcc@1 10.938 (7.555)\tAcc@5 37.500 (26.048)\n",
            "Epoch: [2][500/782]\tTime 0.049 (0.052)\tData 0.001 (0.002)\tLoss 3.4737 (3.9595)\tAcc@1 17.188 (7.887)\tAcc@5 40.625 (26.793)\n",
            "Epoch: [2][600/782]\tTime 0.072 (0.052)\tData 0.001 (0.002)\tLoss 3.6569 (3.9385)\tAcc@1 12.500 (8.299)\tAcc@5 32.812 (27.397)\n",
            "Epoch: [2][700/782]\tTime 0.052 (0.052)\tData 0.001 (0.002)\tLoss 3.6605 (3.9105)\tAcc@1 7.812 (8.657)\tAcc@5 31.250 (28.192)\n",
            " * Acc@1 8.966 Acc@5 28.884\n",
            "epoch 2, total time 40.63\n",
            "Test: [0/313]\tTime 0.129 (0.129)\tLoss 3.6787 (3.6787)\tAcc@1 9.375 (9.375)\tAcc@5 37.500 (37.500)\n",
            "Test: [100/313]\tTime 0.018 (0.021)\tLoss 3.6253 (3.7097)\tAcc@1 9.375 (12.129)\tAcc@5 37.500 (35.056)\n",
            "Test: [200/313]\tTime 0.017 (0.020)\tLoss 3.6902 (3.7036)\tAcc@1 15.625 (12.142)\tAcc@5 37.500 (35.028)\n",
            "Test: [300/313]\tTime 0.025 (0.020)\tLoss 4.0215 (3.7033)\tAcc@1 9.375 (12.012)\tAcc@5 25.000 (35.060)\n",
            " * Acc@1 12.050 Acc@5 35.110\n",
            "saving the best model!\n",
            "best accuracy: tensor(12.0500, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --path_t /content/ICKD-DCKD/Cifar100/save/models/resnet32x4_vanilla_best.pth \\\n",
        "    --model_t resnet32x4 \\\n",
        "    --distill DCKD \\\n",
        "    --trial 0 \\\n",
        "    --batch_size 128 \\\n",
        "    --learning_rate 0.05 \\\n",
        "    --epochs 10 \\\n",
        "    --kd_T 4 \\\n",
        "    --gamma 1.0 \\\n",
        "    --alpha 0.5 \\\n",
        "    --beta 0.5 \\\n",
        "    --print_freq 100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVqmyr_ETDSv",
        "outputId": "7c97ec3c-6284-45ab-efc0-d0472b40a6ff"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-17 23:49:35.114579: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-17 23:49:35.132371: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750204175.153988   18658 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750204175.160502   18658 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-17 23:49:35.181905: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: argument for training [-h] [--print_freq PRINT_FREQ]\n",
            "                             [--tb_freq TB_FREQ] [--save_freq SAVE_FREQ]\n",
            "                             [--batch_size BATCH_SIZE]\n",
            "                             [--num_workers NUM_WORKERS] [--epochs EPOCHS]\n",
            "                             [--init_epochs INIT_EPOCHS]\n",
            "                             [--learning_rate LEARNING_RATE]\n",
            "                             [--lr_decay_epochs LR_DECAY_EPOCHS]\n",
            "                             [--lr_decay_rate LR_DECAY_RATE]\n",
            "                             [--weight_decay WEIGHT_DECAY]\n",
            "                             [--momentum MOMENTUM] [--dataset {cifar100}]\n",
            "                             [--model_s {resnet8,resnet14,resnet20,resnet32,resnet44,resnet56,resnet110,resnet8x4,resnet32x4,wrn_16_1,wrn_16_2,wrn_40_1,wrn_40_2,vgg8,vgg11,vgg13,vgg16,vgg19,ResNet50,MobileNetV2,ShuffleV1,ShuffleV2}]\n",
            "                             [--path_t PATH_T]\n",
            "                             [--distill {afd,ickd,kd,hint,attention,similarity,correlation,vid,crd,kdsvd,fsp,rkd,pkt,abound,factor,nst,dckd}]\n",
            "                             [--trial TRIAL] [--seed SEED] [-r GAMMA]\n",
            "                             [-a ALPHA] [-b BETA] [--kd_T KD_T]\n",
            "                             [--feat_dim FEAT_DIM] [--mode {exact,relax}]\n",
            "                             [--nce_k NCE_K] [--nce_t NCE_T] [--nce_m NCE_M]\n",
            "                             [--hint_layer {0,1,2,3,4}] [--qk_dim QK_DIM]\n",
            "argument for training: error: argument --distill: invalid choice: 'DCKD' (choose from 'afd', 'ickd', 'kd', 'hint', 'attention', 'similarity', 'correlation', 'vid', 'crd', 'kdsvd', 'fsp', 'rkd', 'pkt', 'abound', 'factor', 'nst', 'dckd')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --path_t /content/ICKD-DCKD/Cifar100/save/models/resnet32x4_vanilla_best.pth \\\n",
        "    --model_t resnet32x4 \\\n",
        "    --distill dckd \\\n",
        "    --trial 0 \\\n",
        "    --batch_size 128 \\\n",
        "    --learning_rate 0.05 \\\n",
        "    --epochs 5 \\\n",
        "    --kd_T 4 \\\n",
        "    --gamma 1.0 \\\n",
        "    --alpha 0.5 \\\n",
        "    --beta 0.5 \\\n",
        "    --print_freq 100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBNl1Ro0TmYb",
        "outputId": "e2d37dc3-8c10-4cb4-ba9b-73c55a329f45"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-17 23:52:03.146471: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-17 23:52:03.164321: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750204323.186452   19308 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750204323.193083   19308 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-17 23:52:03.214924: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: argument for training [-h] [--print_freq PRINT_FREQ]\n",
            "                             [--tb_freq TB_FREQ] [--save_freq SAVE_FREQ]\n",
            "                             [--batch_size BATCH_SIZE]\n",
            "                             [--num_workers NUM_WORKERS] [--epochs EPOCHS]\n",
            "                             [--init_epochs INIT_EPOCHS]\n",
            "                             [--learning_rate LEARNING_RATE]\n",
            "                             [--lr_decay_epochs LR_DECAY_EPOCHS]\n",
            "                             [--lr_decay_rate LR_DECAY_RATE]\n",
            "                             [--weight_decay WEIGHT_DECAY]\n",
            "                             [--momentum MOMENTUM] [--dataset {cifar100}]\n",
            "                             [--model_s {resnet8,resnet14,resnet20,resnet32,resnet44,resnet56,resnet110,resnet8x4,resnet32x4,wrn_16_1,wrn_16_2,wrn_40_1,wrn_40_2,vgg8,vgg11,vgg13,vgg16,vgg19,ResNet50,MobileNetV2,ShuffleV1,ShuffleV2}]\n",
            "                             [--path_t PATH_T]\n",
            "                             [--distill {afd,ickd,kd,hint,attention,similarity,correlation,vid,crd,kdsvd,fsp,rkd,pkt,abound,factor,nst,dckd}]\n",
            "                             [--trial TRIAL] [--seed SEED] [-r GAMMA]\n",
            "                             [-a ALPHA] [-b BETA] [--kd_T KD_T]\n",
            "                             [--feat_dim FEAT_DIM] [--mode {exact,relax}]\n",
            "                             [--nce_k NCE_K] [--nce_t NCE_T] [--nce_m NCE_M]\n",
            "                             [--hint_layer {0,1,2,3,4}] [--qk_dim QK_DIM]\n",
            "argument for training: error: unrecognized arguments: --model_t resnet32x4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "    --model_s resnet8x4 \\\n",
        "    --path_t /content/ICKD-DCKD/Cifar100/save/models/resnet32x4_vanilla_best.pth \\\n",
        "    --distill dckd \\\n",
        "    --trial 0 \\\n",
        "    --batch_size 128 \\\n",
        "    --learning_rate 0.05 \\\n",
        "    --epochs 5 \\\n",
        "    --kd_T 4 \\\n",
        "    --gamma 1.0 \\\n",
        "    --alpha 0.5 \\\n",
        "    --beta 0.5 \\\n",
        "    --print_freq 100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6wfL-fIUD86",
        "outputId": "7a5f5b0e-be80-4ac4-beb7-83e60b7e00d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-17 23:54:10.015767: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-17 23:54:10.032911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750204450.055011   19929 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750204450.061676   19929 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-17 23:54:10.082938: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "==> loading teacher model\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 409, in <module>\n",
            "    main()\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 197, in main\n",
            "    model_t = load_teacher(opt.path_t, n_cls)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 155, in load_teacher\n",
            "    model = model_dict[model_t](num_classes=n_cls)\n",
            "            ~~~~~~~~~~^^^^^^^^^\n",
            "KeyError: 'models'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -name train_student.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Fw5o5t8Ur6T",
        "outputId": "b3c776f5-db26-4ee0-d4f3-5998801473a2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100/train_student.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1WtoOKVdVtby",
        "outputId": "01a0faaf-b23c-42b9-df9b-41f692584a0b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data  ICKD  ICKD-DCKD  sample_data  save\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --model_s resnet8 \\\n",
        "  --model_t resnet32x4 \\\n",
        "  --path_t /content/ICKD-DCKD/save/models/ckpt_resnet32x4.pth \\\n",
        "  --distill dckd \\\n",
        "  --trial 1 \\\n",
        "  --batch_size 128 \\\n",
        "  --learning_rate 0.05 \\\n",
        "  --epochs 1 \\\n",
        "  --kd_T 4 \\\n",
        "  --gamma 1.0 \\\n",
        "  --print_freq 50\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wngZsBODV4aH",
        "outputId": "7c0552a2-027b-4874-96f2-d23871d9df6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-06-18 00:01:52.385692: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-06-18 00:01:52.403395: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1750204912.424859   21910 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1750204912.431378   21910 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-18 00:01:52.452841: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "usage: argument for training [-h] [--print_freq PRINT_FREQ]\n",
            "                             [--tb_freq TB_FREQ] [--save_freq SAVE_FREQ]\n",
            "                             [--batch_size BATCH_SIZE]\n",
            "                             [--num_workers NUM_WORKERS] [--epochs EPOCHS]\n",
            "                             [--init_epochs INIT_EPOCHS]\n",
            "                             [--learning_rate LEARNING_RATE]\n",
            "                             [--lr_decay_epochs LR_DECAY_EPOCHS]\n",
            "                             [--lr_decay_rate LR_DECAY_RATE]\n",
            "                             [--weight_decay WEIGHT_DECAY]\n",
            "                             [--momentum MOMENTUM] [--dataset {cifar100}]\n",
            "                             [--model_s {resnet8,resnet14,resnet20,resnet32,resnet44,resnet56,resnet110,resnet8x4,resnet32x4,wrn_16_1,wrn_16_2,wrn_40_1,wrn_40_2,vgg8,vgg11,vgg13,vgg16,vgg19,ResNet50,MobileNetV2,ShuffleV1,ShuffleV2}]\n",
            "                             [--path_t PATH_T]\n",
            "                             [--distill {afd,ickd,kd,hint,attention,similarity,correlation,vid,crd,kdsvd,fsp,rkd,pkt,abound,factor,nst,dckd}]\n",
            "                             [--trial TRIAL] [--seed SEED] [-r GAMMA]\n",
            "                             [-a ALPHA] [-b BETA] [--kd_T KD_T]\n",
            "                             [--feat_dim FEAT_DIM] [--mode {exact,relax}]\n",
            "                             [--nce_k NCE_K] [--nce_t NCE_T] [--nce_m NCE_M]\n",
            "                             [--hint_layer {0,1,2,3,4}] [--qk_dim QK_DIM]\n",
            "argument for training: error: unrecognized arguments: --model_t resnet32x4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/ICKD\n"
      ],
      "metadata": {
        "id": "sHUsDrDe98YJ"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/lrezqi/ICKD-DCKD.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGCVmigU9_Yx",
        "outputId": "e12d873a-fb0e-4dfb-bc80-687476ff4118"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'ICKD-DCKD' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ICKD-DCKD/Cifar100\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZ16b-13-Ewe",
        "outputId": "efe2d413-d3b8-4f38-fd08-ef9d48d78ff8"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "crd\t       helper\t  README.md\t    train_student.sh\n",
            "dataset        ICKD-DCKD  scripts\t    train_teacher.py\n",
            "distiller_zoo  models\t  train_student.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -name \"train_student.py\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrJVfZHyWdhr",
        "outputId": "cd1ba420-72d0-4d17-f438-0efa3ca16fa8"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100/train_student.py\n",
            "/content/ICKD-DCKD/Cifar100/ICKD-DCKD/Cifar100/train_student.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ICKD-DCKD/Cifar100\n",
        "!rm -rf ICKD-DCKD  # Supprime la mauvaise copie dans le sous-dossier\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tYQmg5YBSve",
        "outputId": "f105df3a-df18-446f-9467-16229a754b69"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 20 train_student.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTEien3XBWJu",
        "outputId": "2fe481e9-0077-43cb-aaee-2cd8f8a765c4"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -name \"train_student.py\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAk_EIeOWvx0",
        "outputId": "460efe1c-0ce8-4eec-e07e-5ac4b660e17a"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ICKD-DCKD/Cifar100/train_student.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/ICKD-DCKD/Cifar100/train_student.py\"\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "new_lines = []\n",
        "inserted = False\n",
        "for line in lines:\n",
        "    if \"--model_t\" in line:\n",
        "        continue\n",
        "    if \"parser.add_argument('--model_s'\" in line and not inserted:\n",
        "        new_lines.append(line)\n",
        "        new_lines.append(\"    parser.add_argument('--model_t', type=str, required=True, help='teacher model')\\n\")\n",
        "        inserted = True\n",
        "    else:\n",
        "        new_lines.append(line)\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    f.writelines(new_lines)\n",
        "\n",
        "print(\"Argument --model_t ajouté avec succès.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vm_q9Qh0XEvg",
        "outputId": "05bae86c-6650-4dcf-9007-ef700bd697e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Argument --model_t ajouté avec succès.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!save/models/resnet32x4_cifar100_best.pth\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbayAk3Mdug_",
        "outputId": "2c2028d0-bb2c-4a9c-ebb5-2e12361b6eae"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: save/models/resnet32x4_cifar100_best.pth: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_student.py \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --path_s save/student_model.ckpt \\\n",
        "  --model_t resnet32x4 \\\n",
        "  --path_t save/ckpt_teacher.pth \\\n",
        "  --dataset cifar100 \\\n",
        "  --batch_size 64 \\\n",
        "  --learning_rate 0.05 \\\n",
        "  --epochs 5 \\\n",
        "  --kd_loss_type dckd \\\n",
        "  --distill dckd \\\n",
        "  --trial 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpB0exn8d3cf",
        "outputId": "fbbde145-918c-4a08-b358-5365e13948a6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/train_student.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 /content/ICKD-DCKD/Cifar100/train_student.py \\\n",
        "  --model_s resnet8x4 \\\n",
        "  --model_t resnet32x4 \\\n",
        "  --path_t /content/ICKD-DCKD/save/models/ckpt_teacher_resnet32x4.pth \\\n",
        "  --distill dckd \\\n",
        "  --trial 0 \\\n",
        "  --batch_size 128 \\\n",
        "  --learning_rate 0.05 \\\n",
        "  --epochs 5 \\\n",
        "  --kd_T 4 \\\n",
        "  --gamma 1 \\\n",
        "  --lambda_kd 0.5 \\\n",
        "  --lambda_dckd 1.0 \\\n",
        "  --kd_mode 'logits'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SriZQfh5XlFF",
        "outputId": "82c6b3e7-8cfc-464e-bbc5-75e5fd09a15b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  File \"/content/ICKD-DCKD/Cifar100/train_student.py\", line 75\n",
            "    parser.add_argument('--model_t', type=str, required=True, help='teacher model')\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "SyntaxError: invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 Cifar100/train_teacher.py \\\n",
        "    --model_s resnet32x4 \\\n",
        "    --dataset cifar100 \\\n",
        "    --trial DCKD-Teacher \\\n",
        "    --epochs 2 \\\n",
        "    --batch_size 64 \\\n",
        "    --learning_rate 0.05 \\\n",
        "    --lr_decay_epochs 5,8 \\\n",
        "    --lr_decay_rate 0.1 \\\n",
        "    --weight_decay 5e-4 \\\n",
        "    --momentum 0.9\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml5pe3YXPOXJ",
        "outputId": "601509cf-a7d8-46cc-df1a-5da88bb4ca41"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/Cifar100/train_teacher.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/lrezqi/ICKD-DCKD.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe86nNZFOCNp",
        "outputId": "92d72559-01eb-4977-8792-8a564054300e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'ICKD-DCKD'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Counting objects: 100% (333/333), done.\u001b[K\n",
            "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
            "remote: Total 333 (delta 103), reused 326 (delta 100), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (333/333), 483.32 KiB | 1.89 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/ICKD-DCKD/Cifar100/helper/util.py\"\n",
        "\n",
        "with open(file_path, \"r\") as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "with open(file_path, \"w\") as f:\n",
        "    for line in lines:\n",
        "        f.write(line.replace(\".view(-1).float().sum(0, keepdim=True)\", \".reshape(-1).float().sum(0, keepdim=True)\"))\n",
        "\n",
        "print(\"✅ Correction faite dans util.py\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "pQHXEwabMKn_",
        "outputId": "295a39c7-1cd5-4a04-b0b2-730ad67c0dae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/ICKD-DCKD/Cifar100/helper/util.py'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1315102861>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/ICKD-DCKD/Cifar100/helper/util.py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/ICKD-DCKD/Cifar100/helper/util.py'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7uETYJWdN39W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/ICKD-DCKD\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SbKmuF_LfR7",
        "outputId": "7b63027d-a7a1-4fcd-d2ff-20d7d77141b2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cifar100  Dockerfile  ImageNet\tREADME.md  Segmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pudb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Je7RP7-HP3G",
        "outputId": "810cefd3-3987-40a9-e11a-d1109034b246"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pudb\n",
            "  Downloading pudb-2025.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting jedi<1,>=0.18 (from pudb)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pudb) (24.2)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from pudb) (2.19.1)\n",
            "Collecting urwid-readline (from pudb)\n",
            "  Downloading urwid_readline-0.15.1.tar.gz (9.0 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting urwid (from pudb)\n",
            "  Downloading urwid-3.0.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi<1,>=0.18->pudb) (0.8.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from urwid->pudb) (0.2.13)\n",
            "Downloading pudb-2025.1-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urwid-3.0.2-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.0/296.0 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: urwid-readline\n",
            "  Building wheel for urwid-readline (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for urwid-readline: filename=urwid_readline-0.15.1-py3-none-any.whl size=9326 sha256=f17920e863df67b8b9cc2b1650b2dadf1173f4262cd079cef01cebf6adeb783e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/a1/b6/f1e168ef992a1302e1bfab45f07ddd0e9f6039f69c107089d4\n",
            "Successfully built urwid-readline\n",
            "Installing collected packages: urwid, jedi, urwid-readline, pudb\n",
            "Successfully installed jedi-0.19.2 pudb-2025.1 urwid-3.0.2 urwid-readline-0.15.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboard_logger\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6aotkZHHF9H",
        "outputId": "e1c2e0db-e3f7-4756-b567-2f1811ca3d30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboard_logger\n",
            "  Downloading tensorboard_logger-0.1.0-py2.py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (5.29.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (1.15.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard_logger) (11.2.1)\n",
            "Downloading tensorboard_logger-0.1.0-py2.py3-none-any.whl (17 kB)\n",
            "Installing collected packages: tensorboard_logger\n",
            "Successfully installed tensorboard_logger-0.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lrezqi/ICKD-DCKD.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKXtZtzkDLY6",
        "outputId": "762e05fa-716a-431e-aaaa-0286fc3da902"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ICKD-DCKD'...\n",
            "remote: Enumerating objects: 333, done.\u001b[K\n",
            "remote: Counting objects: 100% (333/333), done.\u001b[K\n",
            "remote: Compressing objects: 100% (222/222), done.\u001b[K\n",
            "remote: Total 333 (delta 103), reused 326 (delta 100), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (333/333), 483.32 KiB | 21.97 MiB/s, done.\n",
            "Resolving deltas: 100% (103/103), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur2bTpuW64r5"
      },
      "source": [
        "## 2. Install dependencies and ***torchdistill***\n",
        "As of January 6, 2021, it seems that Google Colab requires us to use **CUDA ver. 10.1** for PyTorch.\n",
        "Thus, install `torch` and `torchvision` with +cu101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJSCmbJH_yuC",
        "outputId": "9f5262bf-c4b6-419d-9517-1e5cd1eef0c7"
      },
      "source": [
        "!pip install pyyaml --upgrade\n",
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install torchdistill"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyyaml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c2/b80047c7ac2478f9501676c988a5411ed5572f35d1beff9cae07d321512c/PyYAML-5.3.1.tar.gz (269kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 31.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 25.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40kB 21.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 19.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61kB 15.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71kB 15.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81kB 15.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92kB 14.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235kB 15.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245kB 15.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256kB 15.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266kB 15.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 15.1MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44621 sha256=db69fac543e6e884645da5e37d4361779c9bf2296573b6ce02686515efe6d3f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/c1/ea/cf5bd31012e735dc1dfea3131a2d5eae7978b251083d6247bd\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.3.1\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp36-cp36m-linux_x86_64.whl (735.4MB)\n",
            "\u001b[K     |████████████████████████████████| 735.4MB 24kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu101\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8MB 213kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/f9/618434cf4e46dc975871e1516f5499abef6564ab4366f9b2321ee536be14/torchaudio-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (1.19.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch==1.7.1+cu101) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.8.2+cu101) (7.0.0)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.7.1+cu101 torchaudio-0.7.2 torchvision-0.8.2+cu101\n",
            "Collecting torchdistill\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/d2/3aef90eb55e95e2d75d1ff0ccf999390ee150c9e02f759d7708c4ae5e403/torchdistill-0.1.1-py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torchdistill) (5.3.1)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from torchdistill) (1.7.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchdistill) (1.19.4)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.6/dist-packages (from torchdistill) (0.8.2+cu101)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torchdistill) (1.4.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from torchdistill) (0.29.21)\n",
            "Requirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from torchdistill) (2.0.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.1->torchdistill) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.7.1->torchdistill) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.8.2->torchdistill) (7.0.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->torchdistill) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools>=2.0.1->torchdistill) (51.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->torchdistill) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->torchdistill) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->torchdistill) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->torchdistill) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools>=2.0.1->torchdistill) (1.15.0)\n",
            "Installing collected packages: torchdistill\n",
            "Successfully installed torchdistill-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOKnpfrD7DFC"
      },
      "source": [
        "## 3. Clone ***torchdistill*** repository to use its example code and configuration files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa4hqLn57Hkz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf343d5f-1833-4573-f0bb-c06749d19a43"
      },
      "source": [
        "!git clone https://github.com/yoshitomo-matsubara/torchdistill.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'torchdistill'...\n",
            "remote: Enumerating objects: 447, done.\u001b[K\n",
            "remote: Counting objects: 100% (447/447), done.\u001b[K\n",
            "remote: Compressing objects: 100% (224/224), done.\u001b[K\n",
            "remote: Total 4091 (delta 294), reused 341 (delta 212), pack-reused 3644\u001b[K\n",
            "Receiving objects: 100% (4091/4091), 822.43 KiB | 19.58 MiB/s, done.\n",
            "Resolving deltas: 100% (2518/2518), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGrp0OmZ7a_u"
      },
      "source": [
        "## 4. Distill knowledge in models pretrained on CIFAR-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VETfswVJ7Xj0"
      },
      "source": [
        "Note that the hyperparameters of ResNet, WRN (Wide ResNet), and DenseNet-BC were chosen based on either train/val (splitting 50k samples into train:val = 45k:5k) or cross-validation, according to the original papers.  \n",
        "For the final run (once the hyperparameters are finalized), the authors used all the training images (50k samples).  \n",
        "- ResNet: https://github.com/facebookarchive/fb.resnet.torch\n",
        "- WRN (Wide ResNet): https://github.com/szagoruyko/wide-residual-networks\n",
        "- DenseNet-BC: https://github.com/liuzhuang13/DenseNet\n",
        "\n",
        "The following examples demonstrate how to 1) tune hyperparameter and 2) do final-run with ResNet-20 on CIFAR-10 dataset, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TpYnaQs781n"
      },
      "source": [
        "### 4.1 Hyperparameter tuning based on train:val = 45k:5k\n",
        "Let's start with a small **student model**, ResNet-20, with a pretrained DenseNet-BC (k=12, depth=100) as a **teacher model** for tutorial.  \n",
        "\n",
        "Open `torchdistill/configs/sample/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-hyperparameter_tuning.yaml` and update hyperparameters as you wish e.g., number of epochs (*num_epochs*), batch size (*batch_size* in *train_data_loader* entry), learning rate (*lr* within *optimizer* entry), and so on.  \n",
        "By default, the hyperparameters in the example config are identical to those in the final run config.\n",
        "  \n",
        "You will find a lot of module names from [PyTorch documentation](https://pytorch.org/docs/stable/index.html) and [torchvision](https://pytorch.org/docs/stable/torchvision/) such as [`SGD`](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD), [`MultiStepLR`](https://pytorch.org/docs/stable/optim.html#torch.optim.lr_scheduler.MultiStepLR), [`CrossEntropyLoss`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss), [`CIFAR10`](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.CIFAR10), [`RandomCrop`](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomCrop) (, and more). You can update their parameters or replace such modules with other modules in the packages. For instance, `SGD` could be replaced with [`Adam`](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam), and then you will change the parameters under `params` (at least delete `momentum` entry as the parameter is not for `Adam`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy9Yr2tB8avA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2043a073-7c02-4d44-b719-747c2ef8540d"
      },
      "source": [
        "!python torchdistill/examples/image_classification.py --config torchdistill/configs/sample/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-hyperparameter_tuning.yaml --log log/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-hyperparameter_tuning.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/01/10 20:29:25\tINFO\ttorchdistill.common.main_util\tNot using distributed mode\n",
            "2021/01/10 20:29:25\tINFO\t__main__\tNamespace(adjust_lr=False, config='torchdistill/configs/sample/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-hyperparameter_tuning.yaml', device='cuda', dist_url='env://', log='log/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-hyperparameter_tuning.log', start_epoch=0, student_only=False, sync_bn=False, test_only=False, world_size=1)\n",
            "2021/01/10 20:29:25\tINFO\ttorchdistill.datasets.util\tLoading dummy data\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./resource/dataset/cifar10/cifar-10-python.tar.gz\n",
            "170500096it [00:01, 99619332.72it/s]                   \n",
            "Extracting ./resource/dataset/cifar10/cifar-10-python.tar.gz to ./resource/dataset/cifar10\n",
            "2021/01/10 20:29:30\tINFO\ttorchdistill.datasets.util\tSplitting `dummy` dataset (50000 samples in total)\n",
            "2021/01/10 20:29:30\tINFO\ttorchdistill.datasets.util\tnew dataset_id: `cifar10/train` (45000 samples)\n",
            "2021/01/10 20:29:30\tINFO\ttorchdistill.datasets.util\tnew dataset_id: `cifar10/val` (5000 samples)\n",
            "2021/01/10 20:29:30\tINFO\ttorchdistill.datasets.util\t4.421539545059204 sec\n",
            "2021/01/10 20:29:30\tINFO\ttorchdistill.datasets.util\tLoading test data\n",
            "Files already downloaded and verified\n",
            "2021/01/10 20:29:30\tINFO\ttorchdistill.datasets.util\t0.7895796298980713 sec\n",
            "2021/01/10 20:29:30\tINFO\ttorchdistill.common.main_util\tckpt file is not found at `./resource/ckpt/cifar10/teacher/cifar10-densenet_bc_k12_depth100.pt`\n",
            "2021/01/10 20:29:35\tINFO\ttorchdistill.common.main_util\tckpt file is not found at `./resource/ckpt/cifar10/kd/cifar10-resnet20_from_densenet_bc_k12_depth100-hyperparameter_tuning.pt`\n",
            "2021/01/10 20:29:35\tINFO\t__main__\tStart training\n",
            "2021/01/10 20:29:35\tINFO\ttorchdistill.models.util\t[teacher model]\n",
            "2021/01/10 20:29:35\tINFO\ttorchdistill.models.util\tUsing the original teacher model\n",
            "2021/01/10 20:29:35\tINFO\ttorchdistill.models.util\t[student model]\n",
            "2021/01/10 20:29:35\tINFO\ttorchdistill.models.util\tUsing the original student model\n",
            "2021/01/10 20:29:35\tINFO\ttorchdistill.core.distillation\tFreezing the whole teacher model\n",
            "2021/01/10 20:29:37\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [  0/352]  eta: 0:10:50  lr: 0.1  img/s: 138.40078801722976  loss: 2.1517 (2.1517)  time: 1.8487  data: 0.9238  max mem: 700\n",
            "2021/01/10 20:29:48\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1154.1614881729122  loss: 1.5843 (1.7534)  time: 0.1110  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:29:59\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1156.486090826451  loss: 1.3460 (1.6073)  time: 0.1108  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:30:10\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1157.6232011557454  loss: 1.2431 (1.5044)  time: 0.1112  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:30:16\tINFO\ttorchdistill.misc.log\tEpoch: [0] Total time: 0:00:41\n",
            "2021/01/10 20:30:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 41.4062 (41.4062)  acc5: 85.1562 (85.1562)  time: 0.7232  data: 0.6756  max mem: 700\n",
            "2021/01/10 20:30:18\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:30:18\tINFO\t__main__\t * Acc@1 47.4600\tAcc@5 89.6200\n",
            "\n",
            "2021/01/10 20:30:18\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 0.0000 -> 47.4600)\n",
            "2021/01/10 20:30:20\tINFO\ttorchdistill.misc.log\tEpoch: [1]  [  0/352]  eta: 0:08:02  lr: 0.1  img/s: 182.10205526311594  loss: 1.3507 (1.3507)  time: 1.3719  data: 0.6690  max mem: 700\n",
            "2021/01/10 20:30:31\tINFO\ttorchdistill.misc.log\tEpoch: [1]  [100/352]  eta: 0:00:31  lr: 0.1  img/s: 1139.6234559908298  loss: 1.0405 (1.1119)  time: 0.1132  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:30:42\tINFO\ttorchdistill.misc.log\tEpoch: [1]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1130.8544996503408  loss: 1.0697 (1.0835)  time: 0.1134  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:30:54\tINFO\ttorchdistill.misc.log\tEpoch: [1]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1121.2397837178557  loss: 0.9391 (1.0463)  time: 0.1140  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:31:00\tINFO\ttorchdistill.misc.log\tEpoch: [1] Total time: 0:00:41\n",
            "2021/01/10 20:31:01\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 54.6875 (54.6875)  acc5: 95.3125 (95.3125)  time: 0.7716  data: 0.7124  max mem: 700\n",
            "2021/01/10 20:31:02\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:31:02\tINFO\t__main__\t * Acc@1 59.1600\tAcc@5 94.5200\n",
            "\n",
            "2021/01/10 20:31:02\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 47.4600 -> 59.1600)\n",
            "2021/01/10 20:31:03\tINFO\ttorchdistill.misc.log\tEpoch: [2]  [  0/352]  eta: 0:07:12  lr: 0.1  img/s: 244.02213908424696  loss: 1.0115 (1.0115)  time: 1.2275  data: 0.7029  max mem: 700\n",
            "2021/01/10 20:31:15\tINFO\ttorchdistill.misc.log\tEpoch: [2]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1106.1133369182494  loss: 0.8547 (0.8859)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:31:26\tINFO\ttorchdistill.misc.log\tEpoch: [2]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1101.7188730625503  loss: 0.8519 (0.8694)  time: 0.1165  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:31:38\tINFO\ttorchdistill.misc.log\tEpoch: [2]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1104.4295021466467  loss: 0.8161 (0.8570)  time: 0.1170  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:31:44\tINFO\ttorchdistill.misc.log\tEpoch: [2] Total time: 0:00:42\n",
            "2021/01/10 20:31:45\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 67.9688 (67.9688)  acc5: 99.2188 (99.2188)  time: 0.8017  data: 0.7625  max mem: 700\n",
            "2021/01/10 20:31:46\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:31:46\tINFO\t__main__\t * Acc@1 74.5600\tAcc@5 98.4600\n",
            "\n",
            "2021/01/10 20:31:46\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 59.1600 -> 74.5600)\n",
            "2021/01/10 20:31:48\tINFO\ttorchdistill.misc.log\tEpoch: [3]  [  0/352]  eta: 0:08:15  lr: 0.1  img/s: 299.51408584676034  loss: 0.7433 (0.7433)  time: 1.4080  data: 0.9806  max mem: 700\n",
            "2021/01/10 20:31:59\tINFO\ttorchdistill.misc.log\tEpoch: [3]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1106.4758041911923  loss: 0.7410 (0.7562)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:32:11\tINFO\ttorchdistill.misc.log\tEpoch: [3]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1114.7327777016449  loss: 0.7274 (0.7523)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:32:22\tINFO\ttorchdistill.misc.log\tEpoch: [3]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1104.445406295001  loss: 0.7673 (0.7520)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:32:29\tINFO\ttorchdistill.misc.log\tEpoch: [3] Total time: 0:00:42\n",
            "2021/01/10 20:32:29\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 60.9375 (60.9375)  acc5: 96.0938 (96.0938)  time: 0.7190  data: 0.6722  max mem: 700\n",
            "2021/01/10 20:32:30\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:32:30\tINFO\t__main__\t * Acc@1 69.0600\tAcc@5 96.1600\n",
            "\n",
            "2021/01/10 20:32:32\tINFO\ttorchdistill.misc.log\tEpoch: [4]  [  0/352]  eta: 0:07:49  lr: 0.1  img/s: 224.70269415088416  loss: 0.6743 (0.6743)  time: 1.3330  data: 0.7633  max mem: 700\n",
            "2021/01/10 20:32:43\tINFO\ttorchdistill.misc.log\tEpoch: [4]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1110.3569549463095  loss: 0.6584 (0.6760)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:32:55\tINFO\ttorchdistill.misc.log\tEpoch: [4]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1111.384414105762  loss: 0.6577 (0.6752)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:33:07\tINFO\ttorchdistill.misc.log\tEpoch: [4]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1103.3060118947312  loss: 0.6577 (0.6761)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:33:13\tINFO\ttorchdistill.misc.log\tEpoch: [4] Total time: 0:00:42\n",
            "2021/01/10 20:33:14\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 69.5312 (69.5312)  acc5: 97.6562 (97.6562)  time: 0.7373  data: 0.6659  max mem: 700\n",
            "2021/01/10 20:33:15\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:33:15\tINFO\t__main__\t * Acc@1 76.1200\tAcc@5 98.5000\n",
            "\n",
            "2021/01/10 20:33:15\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 74.5600 -> 76.1200)\n",
            "2021/01/10 20:33:16\tINFO\ttorchdistill.misc.log\tEpoch: [5]  [  0/352]  eta: 0:07:18  lr: 0.1  img/s: 267.15325395763034  loss: 0.6751 (0.6751)  time: 1.2444  data: 0.7653  max mem: 700\n",
            "2021/01/10 20:33:28\tINFO\ttorchdistill.misc.log\tEpoch: [5]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1107.4778131439923  loss: 0.5976 (0.6135)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:33:39\tINFO\ttorchdistill.misc.log\tEpoch: [5]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1103.3921786239837  loss: 0.6340 (0.6219)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:33:51\tINFO\ttorchdistill.misc.log\tEpoch: [5]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1109.113677399629  loss: 0.6287 (0.6260)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:33:57\tINFO\ttorchdistill.misc.log\tEpoch: [5] Total time: 0:00:42\n",
            "2021/01/10 20:33:58\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 73.4375 (73.4375)  acc5: 98.4375 (98.4375)  time: 0.8148  data: 0.7550  max mem: 700\n",
            "2021/01/10 20:33:59\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:33:59\tINFO\t__main__\t * Acc@1 76.6000\tAcc@5 98.6600\n",
            "\n",
            "2021/01/10 20:33:59\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 76.1200 -> 76.6000)\n",
            "2021/01/10 20:34:01\tINFO\ttorchdistill.misc.log\tEpoch: [6]  [  0/352]  eta: 0:08:40  lr: 0.1  img/s: 270.5589378235078  loss: 0.5965 (0.5965)  time: 1.4780  data: 1.0049  max mem: 700\n",
            "2021/01/10 20:34:13\tINFO\ttorchdistill.misc.log\tEpoch: [6]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1098.4323871994698  loss: 0.5804 (0.5754)  time: 0.1170  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:34:24\tINFO\ttorchdistill.misc.log\tEpoch: [6]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1083.6376025868228  loss: 0.6039 (0.5864)  time: 0.1169  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:34:36\tINFO\ttorchdistill.misc.log\tEpoch: [6]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1101.7482648935952  loss: 0.5783 (0.5904)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:34:42\tINFO\ttorchdistill.misc.log\tEpoch: [6] Total time: 0:00:42\n",
            "2021/01/10 20:34:43\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 67.1875 (67.1875)  acc5: 96.8750 (96.8750)  time: 0.8127  data: 0.7876  max mem: 700\n",
            "2021/01/10 20:34:44\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:34:44\tINFO\t__main__\t * Acc@1 74.3600\tAcc@5 97.6200\n",
            "\n",
            "2021/01/10 20:34:46\tINFO\ttorchdistill.misc.log\tEpoch: [7]  [  0/352]  eta: 0:07:23  lr: 0.1  img/s: 219.70131115876316  loss: 0.6672 (0.6672)  time: 1.2599  data: 0.6772  max mem: 700\n",
            "2021/01/10 20:34:57\tINFO\ttorchdistill.misc.log\tEpoch: [7]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1104.1932658866212  loss: 0.5244 (0.5336)  time: 0.1165  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:35:09\tINFO\ttorchdistill.misc.log\tEpoch: [7]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1108.0812623192744  loss: 0.5478 (0.5411)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:35:21\tINFO\ttorchdistill.misc.log\tEpoch: [7]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1104.8545274942378  loss: 0.5648 (0.5513)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:35:27\tINFO\ttorchdistill.misc.log\tEpoch: [7] Total time: 0:00:42\n",
            "2021/01/10 20:35:27\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 77.3438 (77.3438)  acc5: 98.4375 (98.4375)  time: 0.7216  data: 0.6567  max mem: 700\n",
            "2021/01/10 20:35:29\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:35:29\tINFO\t__main__\t * Acc@1 77.6000\tAcc@5 98.0400\n",
            "\n",
            "2021/01/10 20:35:29\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 76.6000 -> 77.6000)\n",
            "2021/01/10 20:35:30\tINFO\ttorchdistill.misc.log\tEpoch: [8]  [  0/352]  eta: 0:07:45  lr: 0.1  img/s: 229.4186799399693  loss: 0.5276 (0.5276)  time: 1.3234  data: 0.7654  max mem: 700\n",
            "2021/01/10 20:35:42\tINFO\ttorchdistill.misc.log\tEpoch: [8]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1113.5420437268863  loss: 0.4878 (0.5008)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:35:53\tINFO\ttorchdistill.misc.log\tEpoch: [8]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1091.8379461189759  loss: 0.5321 (0.5164)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:36:05\tINFO\ttorchdistill.misc.log\tEpoch: [8]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1108.5892174616909  loss: 0.5128 (0.5237)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:36:11\tINFO\ttorchdistill.misc.log\tEpoch: [8] Total time: 0:00:42\n",
            "2021/01/10 20:36:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 72.6562 (72.6562)  acc5: 95.3125 (95.3125)  time: 0.7471  data: 0.7088  max mem: 700\n",
            "2021/01/10 20:36:13\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:36:13\tINFO\t__main__\t * Acc@1 77.2000\tAcc@5 98.2400\n",
            "\n",
            "2021/01/10 20:36:15\tINFO\ttorchdistill.misc.log\tEpoch: [9]  [  0/352]  eta: 0:08:12  lr: 0.1  img/s: 330.4518504521262  loss: 0.4910 (0.4910)  time: 1.3994  data: 1.0120  max mem: 700\n",
            "2021/01/10 20:36:26\tINFO\ttorchdistill.misc.log\tEpoch: [9]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1086.2357071031  loss: 0.4622 (0.4647)  time: 0.1170  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:36:38\tINFO\ttorchdistill.misc.log\tEpoch: [9]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.1137943952936  loss: 0.5022 (0.4781)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:36:49\tINFO\ttorchdistill.misc.log\tEpoch: [9]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1108.6578957693603  loss: 0.4887 (0.4887)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:36:56\tINFO\ttorchdistill.misc.log\tEpoch: [9] Total time: 0:00:42\n",
            "2021/01/10 20:36:56\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.6502  data: 0.6133  max mem: 700\n",
            "2021/01/10 20:36:58\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:36:58\tINFO\t__main__\t * Acc@1 78.8800\tAcc@5 99.1000\n",
            "\n",
            "2021/01/10 20:36:58\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 77.6000 -> 78.8800)\n",
            "2021/01/10 20:36:59\tINFO\ttorchdistill.misc.log\tEpoch: [10]  [  0/352]  eta: 0:06:47  lr: 0.1  img/s: 253.2155552295925  loss: 0.5497 (0.5497)  time: 1.1572  data: 0.6517  max mem: 700\n",
            "2021/01/10 20:37:11\tINFO\ttorchdistill.misc.log\tEpoch: [10]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1095.426894809652  loss: 0.4677 (0.4582)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:37:22\tINFO\ttorchdistill.misc.log\tEpoch: [10]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1097.6957404480574  loss: 0.4612 (0.4653)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:37:34\tINFO\ttorchdistill.misc.log\tEpoch: [10]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1111.4097223084789  loss: 0.4825 (0.4702)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:37:40\tINFO\ttorchdistill.misc.log\tEpoch: [10] Total time: 0:00:42\n",
            "2021/01/10 20:37:41\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 71.8750 (71.8750)  acc5: 98.4375 (98.4375)  time: 0.7238  data: 0.6693  max mem: 700\n",
            "2021/01/10 20:37:42\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:37:42\tINFO\t__main__\t * Acc@1 75.0600\tAcc@5 98.2800\n",
            "\n",
            "2021/01/10 20:37:43\tINFO\ttorchdistill.misc.log\tEpoch: [11]  [  0/352]  eta: 0:08:15  lr: 0.1  img/s: 229.99491147779202  loss: 0.4660 (0.4660)  time: 1.4079  data: 0.8513  max mem: 700\n",
            "2021/01/10 20:37:55\tINFO\ttorchdistill.misc.log\tEpoch: [11]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1102.4201826309618  loss: 0.4265 (0.4335)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:38:06\tINFO\ttorchdistill.misc.log\tEpoch: [11]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1102.3273775547498  loss: 0.4288 (0.4393)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:38:18\tINFO\ttorchdistill.misc.log\tEpoch: [11]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.5405636155278  loss: 0.4514 (0.4472)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:38:24\tINFO\ttorchdistill.misc.log\tEpoch: [11] Total time: 0:00:42\n",
            "2021/01/10 20:38:25\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 67.9688 (67.9688)  acc5: 97.6562 (97.6562)  time: 0.7047  data: 0.6393  max mem: 700\n",
            "2021/01/10 20:38:26\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:38:26\tINFO\t__main__\t * Acc@1 74.6000\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 20:38:27\tINFO\ttorchdistill.misc.log\tEpoch: [12]  [  0/352]  eta: 0:07:13  lr: 0.1  img/s: 252.37043726052536  loss: 0.4437 (0.4437)  time: 1.2321  data: 0.7249  max mem: 700\n",
            "2021/01/10 20:38:39\tINFO\ttorchdistill.misc.log\tEpoch: [12]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1106.9594635832048  loss: 0.4033 (0.4083)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:38:51\tINFO\ttorchdistill.misc.log\tEpoch: [12]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1099.50318359155  loss: 0.4441 (0.4209)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:39:02\tINFO\ttorchdistill.misc.log\tEpoch: [12]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1105.3322188136954  loss: 0.4898 (0.4348)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:39:08\tINFO\ttorchdistill.misc.log\tEpoch: [12] Total time: 0:00:42\n",
            "2021/01/10 20:39:09\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 73.4375 (73.4375)  acc5: 96.8750 (96.8750)  time: 0.6939  data: 0.6567  max mem: 700\n",
            "2021/01/10 20:39:10\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:39:10\tINFO\t__main__\t * Acc@1 77.9600\tAcc@5 98.2600\n",
            "\n",
            "2021/01/10 20:39:12\tINFO\ttorchdistill.misc.log\tEpoch: [13]  [  0/352]  eta: 0:06:53  lr: 0.1  img/s: 251.8341697770427  loss: 0.4269 (0.4269)  time: 1.1742  data: 0.6659  max mem: 700\n",
            "2021/01/10 20:39:23\tINFO\ttorchdistill.misc.log\tEpoch: [13]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1106.017630493048  loss: 0.3665 (0.3873)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:39:35\tINFO\ttorchdistill.misc.log\tEpoch: [13]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1113.9463766251552  loss: 0.4028 (0.3972)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:39:46\tINFO\ttorchdistill.misc.log\tEpoch: [13]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1103.5917743115797  loss: 0.4664 (0.4160)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:39:53\tINFO\ttorchdistill.misc.log\tEpoch: [13] Total time: 0:00:42\n",
            "2021/01/10 20:39:53\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:35  acc1: 71.0938 (71.0938)  acc5: 97.6562 (97.6562)  time: 0.8963  data: 0.8620  max mem: 700\n",
            "2021/01/10 20:39:55\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:39:55\tINFO\t__main__\t * Acc@1 75.5200\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 20:39:56\tINFO\ttorchdistill.misc.log\tEpoch: [14]  [  0/352]  eta: 0:08:01  lr: 0.1  img/s: 227.597229853014  loss: 0.3807 (0.3807)  time: 1.3672  data: 0.8048  max mem: 700\n",
            "2021/01/10 20:40:08\tINFO\ttorchdistill.misc.log\tEpoch: [14]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1107.2973632973633  loss: 0.3762 (0.3813)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:40:19\tINFO\ttorchdistill.misc.log\tEpoch: [14]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1108.772378527188  loss: 0.4110 (0.3840)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:40:31\tINFO\ttorchdistill.misc.log\tEpoch: [14]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1102.343221217715  loss: 0.4094 (0.3949)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:40:37\tINFO\ttorchdistill.misc.log\tEpoch: [14] Total time: 0:00:42\n",
            "2021/01/10 20:40:38\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 69.5312 (69.5312)  acc5: 94.5312 (94.5312)  time: 0.7592  data: 0.7263  max mem: 700\n",
            "2021/01/10 20:40:39\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:40:39\tINFO\t__main__\t * Acc@1 77.0400\tAcc@5 97.0400\n",
            "\n",
            "2021/01/10 20:40:40\tINFO\ttorchdistill.misc.log\tEpoch: [15]  [  0/352]  eta: 0:06:32  lr: 0.1  img/s: 257.8234430827154  loss: 0.3724 (0.3724)  time: 1.1147  data: 0.6182  max mem: 700\n",
            "2021/01/10 20:40:52\tINFO\ttorchdistill.misc.log\tEpoch: [15]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1107.260823653643  loss: 0.3554 (0.3694)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:41:03\tINFO\ttorchdistill.misc.log\tEpoch: [15]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1108.6601851928335  loss: 0.3877 (0.3751)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:41:15\tINFO\ttorchdistill.misc.log\tEpoch: [15]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1113.7476392000665  loss: 0.3903 (0.3845)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:41:21\tINFO\ttorchdistill.misc.log\tEpoch: [15] Total time: 0:00:42\n",
            "2021/01/10 20:41:22\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:38  acc1: 71.0938 (71.0938)  acc5: 94.5312 (94.5312)  time: 0.9635  data: 0.9212  max mem: 700\n",
            "2021/01/10 20:41:23\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:41:23\tINFO\t__main__\t * Acc@1 79.5400\tAcc@5 97.9800\n",
            "\n",
            "2021/01/10 20:41:23\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 78.8800 -> 79.5400)\n",
            "2021/01/10 20:41:24\tINFO\ttorchdistill.misc.log\tEpoch: [16]  [  0/352]  eta: 0:07:23  lr: 0.1  img/s: 269.77759955780004  loss: 0.4130 (0.4130)  time: 1.2589  data: 0.7844  max mem: 700\n",
            "2021/01/10 20:41:36\tINFO\ttorchdistill.misc.log\tEpoch: [16]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1111.3384021445502  loss: 0.3389 (0.3504)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:41:48\tINFO\ttorchdistill.misc.log\tEpoch: [16]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1108.4907933912282  loss: 0.3893 (0.3578)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:41:59\tINFO\ttorchdistill.misc.log\tEpoch: [16]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1107.2220029244288  loss: 0.4075 (0.3699)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:42:05\tINFO\ttorchdistill.misc.log\tEpoch: [16] Total time: 0:00:42\n",
            "2021/01/10 20:42:06\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 70.3125 (70.3125)  acc5: 98.4375 (98.4375)  time: 0.6845  data: 0.6274  max mem: 700\n",
            "2021/01/10 20:42:07\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:42:07\tINFO\t__main__\t * Acc@1 80.6200\tAcc@5 98.3600\n",
            "\n",
            "2021/01/10 20:42:07\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 79.5400 -> 80.6200)\n",
            "2021/01/10 20:42:08\tINFO\ttorchdistill.misc.log\tEpoch: [17]  [  0/352]  eta: 0:07:03  lr: 0.1  img/s: 242.11752333140015  loss: 0.2991 (0.2991)  time: 1.2022  data: 0.6735  max mem: 700\n",
            "2021/01/10 20:42:20\tINFO\ttorchdistill.misc.log\tEpoch: [17]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1111.395917691384  loss: 0.3607 (0.3504)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:42:32\tINFO\ttorchdistill.misc.log\tEpoch: [17]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1108.3832335823838  loss: 0.3588 (0.3518)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:42:43\tINFO\ttorchdistill.misc.log\tEpoch: [17]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1108.8868849310031  loss: 0.3795 (0.3601)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:42:49\tINFO\ttorchdistill.misc.log\tEpoch: [17] Total time: 0:00:42\n",
            "2021/01/10 20:42:50\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 75.7812 (75.7812)  acc5: 97.6562 (97.6562)  time: 0.7759  data: 0.7435  max mem: 700\n",
            "2021/01/10 20:42:51\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:42:51\tINFO\t__main__\t * Acc@1 78.6800\tAcc@5 98.4400\n",
            "\n",
            "2021/01/10 20:42:53\tINFO\ttorchdistill.misc.log\tEpoch: [18]  [  0/352]  eta: 0:07:34  lr: 0.1  img/s: 219.8891983459701  loss: 0.3872 (0.3872)  time: 1.2907  data: 0.7086  max mem: 700\n",
            "2021/01/10 20:43:04\tINFO\ttorchdistill.misc.log\tEpoch: [18]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1101.1381409467554  loss: 0.3433 (0.3496)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:43:16\tINFO\ttorchdistill.misc.log\tEpoch: [18]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.2821555919725  loss: 0.3463 (0.3536)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:43:27\tINFO\ttorchdistill.misc.log\tEpoch: [18]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1113.0087735301436  loss: 0.3776 (0.3564)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:43:34\tINFO\ttorchdistill.misc.log\tEpoch: [18] Total time: 0:00:42\n",
            "2021/01/10 20:43:34\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 75.7812 (75.7812)  acc5: 96.8750 (96.8750)  time: 0.6936  data: 0.6444  max mem: 700\n",
            "2021/01/10 20:43:36\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:43:36\tINFO\t__main__\t * Acc@1 79.1000\tAcc@5 98.0200\n",
            "\n",
            "2021/01/10 20:43:37\tINFO\ttorchdistill.misc.log\tEpoch: [19]  [  0/352]  eta: 0:06:43  lr: 0.1  img/s: 254.88718269123035  loss: 0.3379 (0.3379)  time: 1.1470  data: 0.6448  max mem: 700\n",
            "2021/01/10 20:43:48\tINFO\ttorchdistill.misc.log\tEpoch: [19]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1110.899179764772  loss: 0.3102 (0.3364)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:44:00\tINFO\ttorchdistill.misc.log\tEpoch: [19]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1112.9972365325013  loss: 0.3586 (0.3423)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:44:12\tINFO\ttorchdistill.misc.log\tEpoch: [19]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1103.3967140878244  loss: 0.3517 (0.3483)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:44:18\tINFO\ttorchdistill.misc.log\tEpoch: [19] Total time: 0:00:42\n",
            "2021/01/10 20:44:18\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 67.9688 (67.9688)  acc5: 93.7500 (93.7500)  time: 0.6750  data: 0.6402  max mem: 700\n",
            "2021/01/10 20:44:20\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:44:20\tINFO\t__main__\t * Acc@1 78.5200\tAcc@5 97.3000\n",
            "\n",
            "2021/01/10 20:44:21\tINFO\ttorchdistill.misc.log\tEpoch: [20]  [  0/352]  eta: 0:06:54  lr: 0.1  img/s: 243.91238305178229  loss: 0.3227 (0.3227)  time: 1.1782  data: 0.6534  max mem: 700\n",
            "2021/01/10 20:44:33\tINFO\ttorchdistill.misc.log\tEpoch: [20]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1109.3038880428785  loss: 0.3151 (0.3253)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:44:44\tINFO\ttorchdistill.misc.log\tEpoch: [20]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1106.6651110538521  loss: 0.3377 (0.3318)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:44:56\tINFO\ttorchdistill.misc.log\tEpoch: [20]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1115.3580640872224  loss: 0.3430 (0.3409)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:45:02\tINFO\ttorchdistill.misc.log\tEpoch: [20] Total time: 0:00:42\n",
            "2021/01/10 20:45:02\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 71.8750 (71.8750)  acc5: 97.6562 (97.6562)  time: 0.6686  data: 0.6245  max mem: 700\n",
            "2021/01/10 20:45:04\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:45:04\tINFO\t__main__\t * Acc@1 79.6200\tAcc@5 98.4000\n",
            "\n",
            "2021/01/10 20:45:05\tINFO\ttorchdistill.misc.log\tEpoch: [21]  [  0/352]  eta: 0:06:57  lr: 0.1  img/s: 251.51008484064855  loss: 0.3031 (0.3031)  time: 1.1852  data: 0.6762  max mem: 700\n",
            "2021/01/10 20:45:17\tINFO\ttorchdistill.misc.log\tEpoch: [21]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1114.3255609290354  loss: 0.3254 (0.3256)  time: 0.1166  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:45:28\tINFO\ttorchdistill.misc.log\tEpoch: [21]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.3362873587703  loss: 0.3328 (0.3270)  time: 0.1165  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:45:40\tINFO\ttorchdistill.misc.log\tEpoch: [21]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1110.11817640442  loss: 0.3374 (0.3324)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:45:46\tINFO\ttorchdistill.misc.log\tEpoch: [21] Total time: 0:00:42\n",
            "2021/01/10 20:45:47\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 71.0938 (71.0938)  acc5: 91.4062 (91.4062)  time: 0.7080  data: 0.6541  max mem: 700\n",
            "2021/01/10 20:45:48\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:45:48\tINFO\t__main__\t * Acc@1 75.7400\tAcc@5 95.6600\n",
            "\n",
            "2021/01/10 20:45:49\tINFO\ttorchdistill.misc.log\tEpoch: [22]  [  0/352]  eta: 0:06:28  lr: 0.1  img/s: 267.3650599823606  loss: 0.3419 (0.3419)  time: 1.1041  data: 0.6253  max mem: 700\n",
            "2021/01/10 20:46:01\tINFO\ttorchdistill.misc.log\tEpoch: [22]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1109.8175533905119  loss: 0.3020 (0.3132)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:46:12\tINFO\ttorchdistill.misc.log\tEpoch: [22]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1108.6807904295983  loss: 0.3305 (0.3182)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:46:24\tINFO\ttorchdistill.misc.log\tEpoch: [22]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1102.2300621872928  loss: 0.3475 (0.3276)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:46:30\tINFO\ttorchdistill.misc.log\tEpoch: [22] Total time: 0:00:42\n",
            "2021/01/10 20:46:31\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 75.0000 (75.0000)  acc5: 96.8750 (96.8750)  time: 0.6742  data: 0.6197  max mem: 700\n",
            "2021/01/10 20:46:32\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:46:32\tINFO\t__main__\t * Acc@1 80.0400\tAcc@5 97.9800\n",
            "\n",
            "2021/01/10 20:46:33\tINFO\ttorchdistill.misc.log\tEpoch: [23]  [  0/352]  eta: 0:06:47  lr: 0.1  img/s: 246.5182572983735  loss: 0.3064 (0.3064)  time: 1.1584  data: 0.6392  max mem: 700\n",
            "2021/01/10 20:46:45\tINFO\ttorchdistill.misc.log\tEpoch: [23]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1114.3972650225528  loss: 0.2935 (0.3139)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:46:56\tINFO\ttorchdistill.misc.log\tEpoch: [23]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1109.9988256407287  loss: 0.3371 (0.3166)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:47:08\tINFO\ttorchdistill.misc.log\tEpoch: [23]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1106.6422995661  loss: 0.3269 (0.3205)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:47:14\tINFO\ttorchdistill.misc.log\tEpoch: [23] Total time: 0:00:42\n",
            "2021/01/10 20:47:15\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:34  acc1: 75.0000 (75.0000)  acc5: 98.4375 (98.4375)  time: 0.8728  data: 0.8213  max mem: 700\n",
            "2021/01/10 20:47:16\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:47:16\tINFO\t__main__\t * Acc@1 80.6600\tAcc@5 97.6600\n",
            "\n",
            "2021/01/10 20:47:16\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 80.6200 -> 80.6600)\n",
            "2021/01/10 20:47:18\tINFO\ttorchdistill.misc.log\tEpoch: [24]  [  0/352]  eta: 0:07:09  lr: 0.1  img/s: 247.70273691981177  loss: 0.3110 (0.3110)  time: 1.2209  data: 0.7041  max mem: 700\n",
            "2021/01/10 20:47:29\tINFO\ttorchdistill.misc.log\tEpoch: [24]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1112.549785622069  loss: 0.3165 (0.3107)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:47:41\tINFO\ttorchdistill.misc.log\tEpoch: [24]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.5962635452663  loss: 0.3171 (0.3176)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:47:52\tINFO\ttorchdistill.misc.log\tEpoch: [24]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1103.7006751256095  loss: 0.3516 (0.3264)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:47:58\tINFO\ttorchdistill.misc.log\tEpoch: [24] Total time: 0:00:42\n",
            "2021/01/10 20:47:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 69.5312 (69.5312)  acc5: 94.5312 (94.5312)  time: 0.6845  data: 0.6601  max mem: 700\n",
            "2021/01/10 20:48:00\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:48:00\tINFO\t__main__\t * Acc@1 77.6600\tAcc@5 97.7600\n",
            "\n",
            "2021/01/10 20:48:02\tINFO\ttorchdistill.misc.log\tEpoch: [25]  [  0/352]  eta: 0:07:53  lr: 0.1  img/s: 229.87732731826225  loss: 0.3163 (0.3163)  time: 1.3450  data: 0.7881  max mem: 700\n",
            "2021/01/10 20:48:13\tINFO\ttorchdistill.misc.log\tEpoch: [25]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1105.5416232511975  loss: 0.3050 (0.3162)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:48:25\tINFO\ttorchdistill.misc.log\tEpoch: [25]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1106.5282562321588  loss: 0.3286 (0.3221)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:48:37\tINFO\ttorchdistill.misc.log\tEpoch: [25]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1093.4100846018175  loss: 0.3359 (0.3308)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:48:43\tINFO\ttorchdistill.misc.log\tEpoch: [25] Total time: 0:00:42\n",
            "2021/01/10 20:48:44\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 70.3125 (70.3125)  acc5: 96.0938 (96.0938)  time: 0.7226  data: 0.6857  max mem: 700\n",
            "2021/01/10 20:48:45\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:48:45\tINFO\t__main__\t * Acc@1 79.2800\tAcc@5 97.9400\n",
            "\n",
            "2021/01/10 20:48:46\tINFO\ttorchdistill.misc.log\tEpoch: [26]  [  0/352]  eta: 0:06:44  lr: 0.1  img/s: 253.08532487564253  loss: 0.2849 (0.2849)  time: 1.1484  data: 0.6426  max mem: 700\n",
            "2021/01/10 20:48:58\tINFO\ttorchdistill.misc.log\tEpoch: [26]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1106.9092528524714  loss: 0.2938 (0.3087)  time: 0.1166  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:49:09\tINFO\ttorchdistill.misc.log\tEpoch: [26]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1099.4378862780916  loss: 0.3327 (0.3143)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:49:21\tINFO\ttorchdistill.misc.log\tEpoch: [26]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1111.8631644565576  loss: 0.3380 (0.3220)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:49:27\tINFO\ttorchdistill.misc.log\tEpoch: [26] Total time: 0:00:42\n",
            "2021/01/10 20:49:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 68.7500 (68.7500)  acc5: 95.3125 (95.3125)  time: 0.7520  data: 0.7262  max mem: 700\n",
            "2021/01/10 20:49:29\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:49:29\tINFO\t__main__\t * Acc@1 74.9800\tAcc@5 96.6200\n",
            "\n",
            "2021/01/10 20:49:30\tINFO\ttorchdistill.misc.log\tEpoch: [27]  [  0/352]  eta: 0:07:00  lr: 0.1  img/s: 236.49242425577276  loss: 0.3254 (0.3254)  time: 1.1933  data: 0.6521  max mem: 700\n",
            "2021/01/10 20:49:42\tINFO\ttorchdistill.misc.log\tEpoch: [27]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1109.7349679505066  loss: 0.3011 (0.3064)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:49:53\tINFO\ttorchdistill.misc.log\tEpoch: [27]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1109.9804662625395  loss: 0.3083 (0.3065)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:50:05\tINFO\ttorchdistill.misc.log\tEpoch: [27]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1110.740593158096  loss: 0.3283 (0.3119)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:50:11\tINFO\ttorchdistill.misc.log\tEpoch: [27] Total time: 0:00:42\n",
            "2021/01/10 20:50:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 65.6250 (65.6250)  acc5: 98.4375 (98.4375)  time: 0.7218  data: 0.6700  max mem: 700\n",
            "2021/01/10 20:50:13\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:50:13\tINFO\t__main__\t * Acc@1 76.8000\tAcc@5 97.3400\n",
            "\n",
            "2021/01/10 20:50:14\tINFO\ttorchdistill.misc.log\tEpoch: [28]  [  0/352]  eta: 0:06:46  lr: 0.1  img/s: 276.07003477673317  loss: 0.3458 (0.3458)  time: 1.1543  data: 0.6906  max mem: 700\n",
            "2021/01/10 20:50:26\tINFO\ttorchdistill.misc.log\tEpoch: [28]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1076.4480143079702  loss: 0.3102 (0.3125)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:50:37\tINFO\ttorchdistill.misc.log\tEpoch: [28]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.9635466675495  loss: 0.3069 (0.3116)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:50:49\tINFO\ttorchdistill.misc.log\tEpoch: [28]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1105.402770142419  loss: 0.3287 (0.3181)  time: 0.1179  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:50:55\tINFO\ttorchdistill.misc.log\tEpoch: [28] Total time: 0:00:42\n",
            "2021/01/10 20:50:56\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 78.9062 (78.9062)  acc5: 96.0938 (96.0938)  time: 0.7533  data: 0.7152  max mem: 700\n",
            "2021/01/10 20:50:57\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:50:57\tINFO\t__main__\t * Acc@1 80.2000\tAcc@5 98.0600\n",
            "\n",
            "2021/01/10 20:50:58\tINFO\ttorchdistill.misc.log\tEpoch: [29]  [  0/352]  eta: 0:07:05  lr: 0.1  img/s: 232.82721151214918  loss: 0.2655 (0.2655)  time: 1.2090  data: 0.6592  max mem: 700\n",
            "2021/01/10 20:51:10\tINFO\ttorchdistill.misc.log\tEpoch: [29]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1105.8741019049503  loss: 0.2981 (0.2938)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:51:22\tINFO\ttorchdistill.misc.log\tEpoch: [29]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.471054197579  loss: 0.3181 (0.3016)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:51:33\tINFO\ttorchdistill.misc.log\tEpoch: [29]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1107.6857460004373  loss: 0.3067 (0.3056)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:51:39\tINFO\ttorchdistill.misc.log\tEpoch: [29] Total time: 0:00:42\n",
            "2021/01/10 20:51:40\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 64.8438 (64.8438)  acc5: 96.8750 (96.8750)  time: 0.7083  data: 0.6665  max mem: 700\n",
            "2021/01/10 20:51:41\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:51:41\tINFO\t__main__\t * Acc@1 74.0800\tAcc@5 96.9400\n",
            "\n",
            "2021/01/10 20:51:42\tINFO\ttorchdistill.misc.log\tEpoch: [30]  [  0/352]  eta: 0:07:04  lr: 0.1  img/s: 232.9569307899486  loss: 0.3561 (0.3561)  time: 1.2066  data: 0.6571  max mem: 700\n",
            "2021/01/10 20:51:54\tINFO\ttorchdistill.misc.log\tEpoch: [30]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1111.6674714561998  loss: 0.3126 (0.3162)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:52:06\tINFO\ttorchdistill.misc.log\tEpoch: [30]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.6622944404971  loss: 0.3006 (0.3142)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:52:17\tINFO\ttorchdistill.misc.log\tEpoch: [30]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1107.0781616021643  loss: 0.3390 (0.3202)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:52:23\tINFO\ttorchdistill.misc.log\tEpoch: [30] Total time: 0:00:42\n",
            "2021/01/10 20:52:24\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 72.6562 (72.6562)  acc5: 96.0938 (96.0938)  time: 0.7631  data: 0.7225  max mem: 700\n",
            "2021/01/10 20:52:25\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:52:25\tINFO\t__main__\t * Acc@1 77.3200\tAcc@5 97.2800\n",
            "\n",
            "2021/01/10 20:52:27\tINFO\ttorchdistill.misc.log\tEpoch: [31]  [  0/352]  eta: 0:07:27  lr: 0.1  img/s: 260.27290722021326  loss: 0.3460 (0.3460)  time: 1.2703  data: 0.7784  max mem: 700\n",
            "2021/01/10 20:52:38\tINFO\ttorchdistill.misc.log\tEpoch: [31]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1111.2371892393128  loss: 0.3223 (0.3170)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:52:50\tINFO\ttorchdistill.misc.log\tEpoch: [31]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1112.9880071065927  loss: 0.2915 (0.3112)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:53:01\tINFO\ttorchdistill.misc.log\tEpoch: [31]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1109.2809676412917  loss: 0.3420 (0.3141)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:53:07\tINFO\ttorchdistill.misc.log\tEpoch: [31] Total time: 0:00:42\n",
            "2021/01/10 20:53:08\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:34  acc1: 70.3125 (70.3125)  acc5: 94.5312 (94.5312)  time: 0.8624  data: 0.8134  max mem: 700\n",
            "2021/01/10 20:53:09\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:53:09\tINFO\t__main__\t * Acc@1 79.5600\tAcc@5 96.9200\n",
            "\n",
            "2021/01/10 20:53:11\tINFO\ttorchdistill.misc.log\tEpoch: [32]  [  0/352]  eta: 0:07:13  lr: 0.1  img/s: 233.3971723024407  loss: 0.3722 (0.3722)  time: 1.2320  data: 0.6836  max mem: 700\n",
            "2021/01/10 20:53:22\tINFO\ttorchdistill.misc.log\tEpoch: [32]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1110.290362140956  loss: 0.3048 (0.3022)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:53:34\tINFO\ttorchdistill.misc.log\tEpoch: [32]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.6008171469052  loss: 0.3011 (0.3039)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:53:46\tINFO\ttorchdistill.misc.log\tEpoch: [32]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1098.493069849857  loss: 0.3209 (0.3072)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:53:52\tINFO\ttorchdistill.misc.log\tEpoch: [32] Total time: 0:00:42\n",
            "2021/01/10 20:53:52\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 75.0000 (75.0000)  acc5: 94.5312 (94.5312)  time: 0.7296  data: 0.6970  max mem: 700\n",
            "2021/01/10 20:53:54\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:53:54\tINFO\t__main__\t * Acc@1 79.6400\tAcc@5 98.0400\n",
            "\n",
            "2021/01/10 20:53:55\tINFO\ttorchdistill.misc.log\tEpoch: [33]  [  0/352]  eta: 0:06:54  lr: 0.1  img/s: 239.88087609296034  loss: 0.3169 (0.3169)  time: 1.1762  data: 0.6426  max mem: 700\n",
            "2021/01/10 20:54:07\tINFO\ttorchdistill.misc.log\tEpoch: [33]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1112.342327447068  loss: 0.2783 (0.2856)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:54:18\tINFO\ttorchdistill.misc.log\tEpoch: [33]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1104.868170087711  loss: 0.3058 (0.2886)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:54:30\tINFO\ttorchdistill.misc.log\tEpoch: [33]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1105.4278066498102  loss: 0.3000 (0.2972)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:54:36\tINFO\ttorchdistill.misc.log\tEpoch: [33] Total time: 0:00:42\n",
            "2021/01/10 20:54:37\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 69.5312 (69.5312)  acc5: 96.0938 (96.0938)  time: 0.6766  data: 0.6358  max mem: 700\n",
            "2021/01/10 20:54:38\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:54:38\tINFO\t__main__\t * Acc@1 79.2400\tAcc@5 97.4400\n",
            "\n",
            "2021/01/10 20:54:39\tINFO\ttorchdistill.misc.log\tEpoch: [34]  [  0/352]  eta: 0:06:31  lr: 0.1  img/s: 271.36374214144837  loss: 0.2715 (0.2715)  time: 1.1125  data: 0.6408  max mem: 700\n",
            "2021/01/10 20:54:51\tINFO\ttorchdistill.misc.log\tEpoch: [34]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1106.7860276412573  loss: 0.2904 (0.2927)  time: 0.1170  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:55:02\tINFO\ttorchdistill.misc.log\tEpoch: [34]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1113.7915402026053  loss: 0.2885 (0.2920)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:55:14\tINFO\ttorchdistill.misc.log\tEpoch: [34]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1111.5155691003047  loss: 0.3463 (0.3011)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:55:20\tINFO\ttorchdistill.misc.log\tEpoch: [34] Total time: 0:00:42\n",
            "2021/01/10 20:55:21\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 67.9688 (67.9688)  acc5: 95.3125 (95.3125)  time: 0.6785  data: 0.6201  max mem: 700\n",
            "2021/01/10 20:55:22\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:55:22\tINFO\t__main__\t * Acc@1 77.6400\tAcc@5 98.0800\n",
            "\n",
            "2021/01/10 20:55:23\tINFO\ttorchdistill.misc.log\tEpoch: [35]  [  0/352]  eta: 0:06:43  lr: 0.1  img/s: 249.53910711380698  loss: 0.2819 (0.2819)  time: 1.1470  data: 0.6340  max mem: 700\n",
            "2021/01/10 20:55:35\tINFO\ttorchdistill.misc.log\tEpoch: [35]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1098.0594485475337  loss: 0.2922 (0.3006)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:55:46\tINFO\ttorchdistill.misc.log\tEpoch: [35]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1094.6786478181702  loss: 0.3016 (0.3039)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:55:58\tINFO\ttorchdistill.misc.log\tEpoch: [35]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1104.3931515274942  loss: 0.3395 (0.3147)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:56:04\tINFO\ttorchdistill.misc.log\tEpoch: [35] Total time: 0:00:42\n",
            "2021/01/10 20:56:05\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 70.3125 (70.3125)  acc5: 97.6562 (97.6562)  time: 0.7732  data: 0.7309  max mem: 700\n",
            "2021/01/10 20:56:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:56:06\tINFO\t__main__\t * Acc@1 80.7600\tAcc@5 97.9200\n",
            "\n",
            "2021/01/10 20:56:06\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 80.6600 -> 80.7600)\n",
            "2021/01/10 20:56:07\tINFO\ttorchdistill.misc.log\tEpoch: [36]  [  0/352]  eta: 0:07:23  lr: 0.1  img/s: 268.9174906019039  loss: 0.2676 (0.2676)  time: 1.2613  data: 0.7852  max mem: 700\n",
            "2021/01/10 20:56:19\tINFO\ttorchdistill.misc.log\tEpoch: [36]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1104.518116806702  loss: 0.3093 (0.3090)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:56:30\tINFO\ttorchdistill.misc.log\tEpoch: [36]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1111.2762920399412  loss: 0.3288 (0.3118)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:56:42\tINFO\ttorchdistill.misc.log\tEpoch: [36]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1111.7365317076403  loss: 0.3021 (0.3157)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:56:48\tINFO\ttorchdistill.misc.log\tEpoch: [36] Total time: 0:00:42\n",
            "2021/01/10 20:56:49\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 70.3125 (70.3125)  acc5: 96.0938 (96.0938)  time: 0.6793  data: 0.6278  max mem: 700\n",
            "2021/01/10 20:56:50\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:56:50\tINFO\t__main__\t * Acc@1 77.9800\tAcc@5 97.1600\n",
            "\n",
            "2021/01/10 20:56:51\tINFO\ttorchdistill.misc.log\tEpoch: [37]  [  0/352]  eta: 0:06:46  lr: 0.1  img/s: 249.04736748839588  loss: 0.3028 (0.3028)  time: 1.1553  data: 0.6413  max mem: 700\n",
            "2021/01/10 20:57:03\tINFO\ttorchdistill.misc.log\tEpoch: [37]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1107.9714953782145  loss: 0.2852 (0.2929)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:57:15\tINFO\ttorchdistill.misc.log\tEpoch: [37]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1101.0274871874801  loss: 0.3083 (0.2970)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:57:26\tINFO\ttorchdistill.misc.log\tEpoch: [37]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1114.6702876208628  loss: 0.2880 (0.2981)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:57:32\tINFO\ttorchdistill.misc.log\tEpoch: [37] Total time: 0:00:42\n",
            "2021/01/10 20:57:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 70.3125 (70.3125)  acc5: 96.0938 (96.0938)  time: 0.6942  data: 0.6374  max mem: 700\n",
            "2021/01/10 20:57:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:57:34\tINFO\t__main__\t * Acc@1 80.7200\tAcc@5 97.6600\n",
            "\n",
            "2021/01/10 20:57:35\tINFO\ttorchdistill.misc.log\tEpoch: [38]  [  0/352]  eta: 0:07:09  lr: 0.1  img/s: 228.1179955291719  loss: 0.2934 (0.2934)  time: 1.2197  data: 0.6586  max mem: 700\n",
            "2021/01/10 20:57:47\tINFO\ttorchdistill.misc.log\tEpoch: [38]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1110.2719931175538  loss: 0.2952 (0.3007)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:57:59\tINFO\ttorchdistill.misc.log\tEpoch: [38]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1106.8841491952028  loss: 0.2982 (0.3030)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:58:10\tINFO\ttorchdistill.misc.log\tEpoch: [38]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1111.9368549681562  loss: 0.3250 (0.3106)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:58:16\tINFO\ttorchdistill.misc.log\tEpoch: [38] Total time: 0:00:42\n",
            "2021/01/10 20:58:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 75.7812 (75.7812)  acc5: 96.8750 (96.8750)  time: 0.6881  data: 0.6227  max mem: 700\n",
            "2021/01/10 20:58:18\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 20:58:18\tINFO\t__main__\t * Acc@1 81.0400\tAcc@5 98.1000\n",
            "\n",
            "2021/01/10 20:58:18\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 80.7600 -> 81.0400)\n",
            "2021/01/10 20:58:20\tINFO\ttorchdistill.misc.log\tEpoch: [39]  [  0/352]  eta: 0:07:39  lr: 0.1  img/s: 334.2033291418185  loss: 0.2835 (0.2835)  time: 1.3063  data: 0.9233  max mem: 700\n",
            "2021/01/10 20:58:31\tINFO\ttorchdistill.misc.log\tEpoch: [39]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1109.2970118229491  loss: 0.2829 (0.2918)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:58:43\tINFO\ttorchdistill.misc.log\tEpoch: [39]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1114.6216890682679  loss: 0.3041 (0.2950)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:58:54\tINFO\ttorchdistill.misc.log\tEpoch: [39]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1109.9942357392438  loss: 0.2997 (0.3006)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:59:01\tINFO\ttorchdistill.misc.log\tEpoch: [39] Total time: 0:00:42\n",
            "2021/01/10 20:59:01\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 66.4062 (66.4062)  acc5: 94.5312 (94.5312)  time: 0.6976  data: 0.6579  max mem: 700\n",
            "2021/01/10 20:59:03\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:59:03\tINFO\t__main__\t * Acc@1 76.3400\tAcc@5 97.0800\n",
            "\n",
            "2021/01/10 20:59:04\tINFO\ttorchdistill.misc.log\tEpoch: [40]  [  0/352]  eta: 0:07:17  lr: 0.1  img/s: 269.8100030605922  loss: 0.2730 (0.2730)  time: 1.2422  data: 0.7678  max mem: 700\n",
            "2021/01/10 20:59:15\tINFO\ttorchdistill.misc.log\tEpoch: [40]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1108.8960464650345  loss: 0.2970 (0.2899)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:59:27\tINFO\ttorchdistill.misc.log\tEpoch: [40]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1099.9672430077917  loss: 0.2866 (0.2894)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:59:39\tINFO\ttorchdistill.misc.log\tEpoch: [40]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1109.235129679484  loss: 0.3058 (0.2934)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 20:59:45\tINFO\ttorchdistill.misc.log\tEpoch: [40] Total time: 0:00:42\n",
            "2021/01/10 20:59:45\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 73.4375 (73.4375)  acc5: 97.6562 (97.6562)  time: 0.6785  data: 0.6184  max mem: 700\n",
            "2021/01/10 20:59:47\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 20:59:47\tINFO\t__main__\t * Acc@1 79.4000\tAcc@5 97.7800\n",
            "\n",
            "2021/01/10 20:59:48\tINFO\ttorchdistill.misc.log\tEpoch: [41]  [  0/352]  eta: 0:07:16  lr: 0.1  img/s: 245.96270455433623  loss: 0.3389 (0.3389)  time: 1.2393  data: 0.7189  max mem: 700\n",
            "2021/01/10 20:59:59\tINFO\ttorchdistill.misc.log\tEpoch: [41]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1092.7313086822808  loss: 0.2813 (0.2982)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:00:11\tINFO\ttorchdistill.misc.log\tEpoch: [41]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1108.9143699872557  loss: 0.2984 (0.2948)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:00:23\tINFO\ttorchdistill.misc.log\tEpoch: [41]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1106.43931874763  loss: 0.2909 (0.2968)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:00:29\tINFO\ttorchdistill.misc.log\tEpoch: [41] Total time: 0:00:42\n",
            "2021/01/10 21:00:30\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:34  acc1: 69.5312 (69.5312)  acc5: 97.6562 (97.6562)  time: 0.8520  data: 0.7979  max mem: 700\n",
            "2021/01/10 21:00:31\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:00:31\tINFO\t__main__\t * Acc@1 77.2400\tAcc@5 97.8400\n",
            "\n",
            "2021/01/10 21:00:32\tINFO\ttorchdistill.misc.log\tEpoch: [42]  [  0/352]  eta: 0:07:39  lr: 0.1  img/s: 304.23424302543884  loss: 0.3110 (0.3110)  time: 1.3055  data: 0.8847  max mem: 700\n",
            "2021/01/10 21:00:44\tINFO\ttorchdistill.misc.log\tEpoch: [42]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1106.8225359546113  loss: 0.2942 (0.2949)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:00:55\tINFO\ttorchdistill.misc.log\tEpoch: [42]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1112.7826919648965  loss: 0.2973 (0.2993)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:01:07\tINFO\ttorchdistill.misc.log\tEpoch: [42]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1102.8255391176097  loss: 0.3049 (0.3027)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:01:13\tINFO\ttorchdistill.misc.log\tEpoch: [42] Total time: 0:00:42\n",
            "2021/01/10 21:01:14\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:33  acc1: 66.4062 (66.4062)  acc5: 96.8750 (96.8750)  time: 0.8495  data: 0.8065  max mem: 700\n",
            "2021/01/10 21:01:15\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:01:15\tINFO\t__main__\t * Acc@1 78.2600\tAcc@5 98.2400\n",
            "\n",
            "2021/01/10 21:01:16\tINFO\ttorchdistill.misc.log\tEpoch: [43]  [  0/352]  eta: 0:07:32  lr: 0.1  img/s: 266.3579968039278  loss: 0.3610 (0.3610)  time: 1.2850  data: 0.8044  max mem: 700\n",
            "2021/01/10 21:01:28\tINFO\ttorchdistill.misc.log\tEpoch: [43]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1091.4361874712845  loss: 0.2788 (0.2903)  time: 0.1166  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:01:39\tINFO\ttorchdistill.misc.log\tEpoch: [43]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1099.786979242419  loss: 0.3137 (0.2979)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:01:51\tINFO\ttorchdistill.misc.log\tEpoch: [43]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.6904401676277  loss: 0.3152 (0.3021)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:01:57\tINFO\ttorchdistill.misc.log\tEpoch: [43] Total time: 0:00:42\n",
            "2021/01/10 21:01:58\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 66.4062 (66.4062)  acc5: 92.9688 (92.9688)  time: 0.6777  data: 0.6365  max mem: 700\n",
            "2021/01/10 21:01:59\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:01:59\tINFO\t__main__\t * Acc@1 78.6000\tAcc@5 97.3400\n",
            "\n",
            "2021/01/10 21:02:00\tINFO\ttorchdistill.misc.log\tEpoch: [44]  [  0/352]  eta: 0:07:15  lr: 0.1  img/s: 250.72839025893813  loss: 0.3605 (0.3605)  time: 1.2376  data: 0.7270  max mem: 700\n",
            "2021/01/10 21:02:12\tINFO\ttorchdistill.misc.log\tEpoch: [44]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1106.238691810629  loss: 0.2809 (0.2959)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:02:24\tINFO\ttorchdistill.misc.log\tEpoch: [44]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1113.2557226186254  loss: 0.3235 (0.3026)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:02:35\tINFO\ttorchdistill.misc.log\tEpoch: [44]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1105.2980843069638  loss: 0.3004 (0.3019)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:02:41\tINFO\ttorchdistill.misc.log\tEpoch: [44] Total time: 0:00:42\n",
            "2021/01/10 21:02:42\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 78.9062 (78.9062)  acc5: 96.0938 (96.0938)  time: 0.6823  data: 0.6263  max mem: 700\n",
            "2021/01/10 21:02:43\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:02:43\tINFO\t__main__\t * Acc@1 80.8000\tAcc@5 97.7800\n",
            "\n",
            "2021/01/10 21:02:45\tINFO\ttorchdistill.misc.log\tEpoch: [45]  [  0/352]  eta: 0:07:20  lr: 0.1  img/s: 221.732403347684  loss: 0.2849 (0.2849)  time: 1.2507  data: 0.6733  max mem: 700\n",
            "2021/01/10 21:02:56\tINFO\ttorchdistill.misc.log\tEpoch: [45]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1102.0173860923578  loss: 0.2856 (0.2883)  time: 0.1166  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:03:08\tINFO\ttorchdistill.misc.log\tEpoch: [45]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1107.5600629624969  loss: 0.2880 (0.2875)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:03:19\tINFO\ttorchdistill.misc.log\tEpoch: [45]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1105.5780495137994  loss: 0.2998 (0.2939)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:03:26\tINFO\ttorchdistill.misc.log\tEpoch: [45] Total time: 0:00:42\n",
            "2021/01/10 21:03:26\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:33  acc1: 72.6562 (72.6562)  acc5: 93.7500 (93.7500)  time: 0.8462  data: 0.8066  max mem: 700\n",
            "2021/01/10 21:03:28\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:03:28\tINFO\t__main__\t * Acc@1 80.3600\tAcc@5 97.1000\n",
            "\n",
            "2021/01/10 21:03:29\tINFO\ttorchdistill.misc.log\tEpoch: [46]  [  0/352]  eta: 0:06:52  lr: 0.1  img/s: 249.21731218793926  loss: 0.2786 (0.2786)  time: 1.1711  data: 0.6575  max mem: 700\n",
            "2021/01/10 21:03:41\tINFO\ttorchdistill.misc.log\tEpoch: [46]  [100/352]  eta: 0:00:31  lr: 0.1  img/s: 1112.808063890956  loss: 0.2796 (0.2927)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:03:52\tINFO\ttorchdistill.misc.log\tEpoch: [46]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.0676787183802  loss: 0.3066 (0.3004)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:04:04\tINFO\ttorchdistill.misc.log\tEpoch: [46]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1104.122868859539  loss: 0.3173 (0.3027)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:04:10\tINFO\ttorchdistill.misc.log\tEpoch: [46] Total time: 0:00:42\n",
            "2021/01/10 21:04:11\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 75.0000 (75.0000)  acc5: 96.8750 (96.8750)  time: 0.6969  data: 0.6283  max mem: 700\n",
            "2021/01/10 21:04:12\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:04:12\tINFO\t__main__\t * Acc@1 80.4800\tAcc@5 98.2200\n",
            "\n",
            "2021/01/10 21:04:13\tINFO\ttorchdistill.misc.log\tEpoch: [47]  [  0/352]  eta: 0:07:03  lr: 0.1  img/s: 234.06255114537296  loss: 0.2898 (0.2898)  time: 1.2030  data: 0.6561  max mem: 700\n",
            "2021/01/10 21:04:25\tINFO\ttorchdistill.misc.log\tEpoch: [47]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1113.0410783960062  loss: 0.2778 (0.2784)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:04:36\tINFO\ttorchdistill.misc.log\tEpoch: [47]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1113.371156960865  loss: 0.2878 (0.2832)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:04:48\tINFO\ttorchdistill.misc.log\tEpoch: [47]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1108.3077253378365  loss: 0.3199 (0.2896)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:04:54\tINFO\ttorchdistill.misc.log\tEpoch: [47] Total time: 0:00:42\n",
            "2021/01/10 21:04:55\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 68.7500 (68.7500)  acc5: 95.3125 (95.3125)  time: 0.7104  data: 0.6562  max mem: 700\n",
            "2021/01/10 21:04:56\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:04:56\tINFO\t__main__\t * Acc@1 78.9800\tAcc@5 97.4200\n",
            "\n",
            "2021/01/10 21:04:57\tINFO\ttorchdistill.misc.log\tEpoch: [48]  [  0/352]  eta: 0:07:13  lr: 0.1  img/s: 229.0848619997218  loss: 0.2680 (0.2680)  time: 1.2321  data: 0.6733  max mem: 700\n",
            "2021/01/10 21:05:09\tINFO\ttorchdistill.misc.log\tEpoch: [48]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1102.5786664421273  loss: 0.2919 (0.2917)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:05:20\tINFO\ttorchdistill.misc.log\tEpoch: [48]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.6486796239024  loss: 0.2897 (0.2967)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:05:32\tINFO\ttorchdistill.misc.log\tEpoch: [48]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1115.2260007768991  loss: 0.3095 (0.3007)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:05:38\tINFO\ttorchdistill.misc.log\tEpoch: [48] Total time: 0:00:42\n",
            "2021/01/10 21:05:39\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 74.2188 (74.2188)  acc5: 94.5312 (94.5312)  time: 0.6965  data: 0.6361  max mem: 700\n",
            "2021/01/10 21:05:40\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:05:40\tINFO\t__main__\t * Acc@1 79.4000\tAcc@5 97.3400\n",
            "\n",
            "2021/01/10 21:05:42\tINFO\ttorchdistill.misc.log\tEpoch: [49]  [  0/352]  eta: 0:08:25  lr: 0.1  img/s: 245.31422255304196  loss: 0.2651 (0.2651)  time: 1.4368  data: 0.9150  max mem: 700\n",
            "2021/01/10 21:05:53\tINFO\ttorchdistill.misc.log\tEpoch: [49]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1112.4253014319963  loss: 0.2798 (0.2894)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:06:05\tINFO\ttorchdistill.misc.log\tEpoch: [49]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1099.3770991991253  loss: 0.3183 (0.2955)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:06:16\tINFO\ttorchdistill.misc.log\tEpoch: [49]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.494455875984  loss: 0.2983 (0.3017)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:06:22\tINFO\ttorchdistill.misc.log\tEpoch: [49] Total time: 0:00:42\n",
            "2021/01/10 21:06:23\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 68.7500 (68.7500)  acc5: 97.6562 (97.6562)  time: 0.7364  data: 0.6962  max mem: 700\n",
            "2021/01/10 21:06:24\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:06:24\tINFO\t__main__\t * Acc@1 79.3600\tAcc@5 97.5200\n",
            "\n",
            "2021/01/10 21:06:26\tINFO\ttorchdistill.misc.log\tEpoch: [50]  [  0/352]  eta: 0:06:44  lr: 0.1  img/s: 249.8918559885832  loss: 0.2739 (0.2739)  time: 1.1505  data: 0.6383  max mem: 700\n",
            "2021/01/10 21:06:37\tINFO\ttorchdistill.misc.log\tEpoch: [50]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1109.1824207064112  loss: 0.3045 (0.3014)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:06:49\tINFO\ttorchdistill.misc.log\tEpoch: [50]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.5498895388764  loss: 0.3073 (0.3010)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:07:00\tINFO\ttorchdistill.misc.log\tEpoch: [50]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1098.6684129530795  loss: 0.2993 (0.3030)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:07:06\tINFO\ttorchdistill.misc.log\tEpoch: [50] Total time: 0:00:42\n",
            "2021/01/10 21:07:07\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 68.7500 (68.7500)  acc5: 94.5312 (94.5312)  time: 0.7100  data: 0.6526  max mem: 700\n",
            "2021/01/10 21:07:08\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:07:08\tINFO\t__main__\t * Acc@1 79.0200\tAcc@5 97.0200\n",
            "\n",
            "2021/01/10 21:07:10\tINFO\ttorchdistill.misc.log\tEpoch: [51]  [  0/352]  eta: 0:07:33  lr: 0.1  img/s: 265.2745767803735  loss: 0.3315 (0.3315)  time: 1.2891  data: 0.8066  max mem: 700\n",
            "2021/01/10 21:07:21\tINFO\ttorchdistill.misc.log\tEpoch: [51]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1112.399946956637  loss: 0.2671 (0.2802)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:07:33\tINFO\ttorchdistill.misc.log\tEpoch: [51]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.4095981683263  loss: 0.2932 (0.2822)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:07:45\tINFO\ttorchdistill.misc.log\tEpoch: [51]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1106.12701061684  loss: 0.2799 (0.2866)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:07:51\tINFO\ttorchdistill.misc.log\tEpoch: [51] Total time: 0:00:42\n",
            "2021/01/10 21:07:51\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 71.8750 (71.8750)  acc5: 94.5312 (94.5312)  time: 0.6889  data: 0.6521  max mem: 700\n",
            "2021/01/10 21:07:53\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:07:53\tINFO\t__main__\t * Acc@1 77.5400\tAcc@5 96.9600\n",
            "\n",
            "2021/01/10 21:07:54\tINFO\ttorchdistill.misc.log\tEpoch: [52]  [  0/352]  eta: 0:07:36  lr: 0.1  img/s: 207.6001919506775  loss: 0.3049 (0.3049)  time: 1.2979  data: 0.6812  max mem: 700\n",
            "2021/01/10 21:08:06\tINFO\ttorchdistill.misc.log\tEpoch: [52]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1104.2068921545438  loss: 0.2938 (0.2945)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:08:17\tINFO\ttorchdistill.misc.log\tEpoch: [52]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.6827883910403  loss: 0.3095 (0.2925)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:08:29\tINFO\ttorchdistill.misc.log\tEpoch: [52]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1106.0472521405204  loss: 0.2981 (0.2967)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:08:35\tINFO\ttorchdistill.misc.log\tEpoch: [52] Total time: 0:00:42\n",
            "2021/01/10 21:08:36\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 63.2812 (63.2812)  acc5: 98.4375 (98.4375)  time: 0.6823  data: 0.6383  max mem: 700\n",
            "2021/01/10 21:08:37\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:08:37\tINFO\t__main__\t * Acc@1 75.8800\tAcc@5 97.7400\n",
            "\n",
            "2021/01/10 21:08:38\tINFO\ttorchdistill.misc.log\tEpoch: [53]  [  0/352]  eta: 0:06:50  lr: 0.1  img/s: 244.6861007209721  loss: 0.3444 (0.3444)  time: 1.1668  data: 0.6437  max mem: 700\n",
            "2021/01/10 21:08:50\tINFO\ttorchdistill.misc.log\tEpoch: [53]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1085.7809633213067  loss: 0.2745 (0.2793)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:09:02\tINFO\ttorchdistill.misc.log\tEpoch: [53]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.4763827410748  loss: 0.3085 (0.2897)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:09:13\tINFO\ttorchdistill.misc.log\tEpoch: [53]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1107.4115652292294  loss: 0.3144 (0.2971)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:09:19\tINFO\ttorchdistill.misc.log\tEpoch: [53] Total time: 0:00:42\n",
            "2021/01/10 21:09:20\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 70.3125 (70.3125)  acc5: 96.8750 (96.8750)  time: 0.8129  data: 0.7810  max mem: 700\n",
            "2021/01/10 21:09:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:09:21\tINFO\t__main__\t * Acc@1 81.5400\tAcc@5 97.6800\n",
            "\n",
            "2021/01/10 21:09:21\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 81.0400 -> 81.5400)\n",
            "2021/01/10 21:09:22\tINFO\ttorchdistill.misc.log\tEpoch: [54]  [  0/352]  eta: 0:07:06  lr: 0.1  img/s: 236.64680853314667  loss: 0.2677 (0.2677)  time: 1.2116  data: 0.6707  max mem: 700\n",
            "2021/01/10 21:09:34\tINFO\ttorchdistill.misc.log\tEpoch: [54]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1111.2509899135416  loss: 0.2749 (0.2856)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:09:46\tINFO\ttorchdistill.misc.log\tEpoch: [54]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1107.135237018966  loss: 0.2821 (0.2859)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:09:57\tINFO\ttorchdistill.misc.log\tEpoch: [54]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.3377181441663  loss: 0.3123 (0.2915)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:10:03\tINFO\ttorchdistill.misc.log\tEpoch: [54] Total time: 0:00:42\n",
            "2021/01/10 21:10:04\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 66.4062 (66.4062)  acc5: 96.8750 (96.8750)  time: 0.6733  data: 0.6414  max mem: 700\n",
            "2021/01/10 21:10:05\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:10:05\tINFO\t__main__\t * Acc@1 80.5600\tAcc@5 97.7800\n",
            "\n",
            "2021/01/10 21:10:07\tINFO\ttorchdistill.misc.log\tEpoch: [55]  [  0/352]  eta: 0:07:55  lr: 0.1  img/s: 243.40800184254743  loss: 0.3164 (0.3164)  time: 1.3508  data: 0.8249  max mem: 700\n",
            "2021/01/10 21:10:18\tINFO\ttorchdistill.misc.log\tEpoch: [55]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1112.0266784869486  loss: 0.2713 (0.2807)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:10:30\tINFO\ttorchdistill.misc.log\tEpoch: [55]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.1297182579626  loss: 0.2759 (0.2803)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:10:42\tINFO\ttorchdistill.misc.log\tEpoch: [55]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1100.0033028522957  loss: 0.2892 (0.2828)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:10:48\tINFO\ttorchdistill.misc.log\tEpoch: [55] Total time: 0:00:42\n",
            "2021/01/10 21:10:48\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 71.0938 (71.0938)  acc5: 96.0938 (96.0938)  time: 0.7315  data: 0.6546  max mem: 700\n",
            "2021/01/10 21:10:50\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:10:50\tINFO\t__main__\t * Acc@1 80.8400\tAcc@5 98.2600\n",
            "\n",
            "2021/01/10 21:10:51\tINFO\ttorchdistill.misc.log\tEpoch: [56]  [  0/352]  eta: 0:07:04  lr: 0.1  img/s: 279.1785248133422  loss: 0.2693 (0.2693)  time: 1.2046  data: 0.7461  max mem: 700\n",
            "2021/01/10 21:11:03\tINFO\ttorchdistill.misc.log\tEpoch: [56]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1107.918906425411  loss: 0.2658 (0.2697)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:11:14\tINFO\ttorchdistill.misc.log\tEpoch: [56]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1100.1498202861487  loss: 0.2915 (0.2743)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:11:26\tINFO\ttorchdistill.misc.log\tEpoch: [56]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1098.475089106318  loss: 0.3013 (0.2835)  time: 0.1173  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:11:32\tINFO\ttorchdistill.misc.log\tEpoch: [56] Total time: 0:00:42\n",
            "2021/01/10 21:11:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 71.0938 (71.0938)  acc5: 97.6562 (97.6562)  time: 0.6981  data: 0.6416  max mem: 700\n",
            "2021/01/10 21:11:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:11:34\tINFO\t__main__\t * Acc@1 78.4000\tAcc@5 97.8000\n",
            "\n",
            "2021/01/10 21:11:36\tINFO\ttorchdistill.misc.log\tEpoch: [57]  [  0/352]  eta: 0:07:33  lr: 0.1  img/s: 248.38713665225026  loss: 0.2824 (0.2824)  time: 1.2895  data: 0.7742  max mem: 700\n",
            "2021/01/10 21:11:47\tINFO\ttorchdistill.misc.log\tEpoch: [57]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1109.7716710730579  loss: 0.2847 (0.2919)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:11:59\tINFO\ttorchdistill.misc.log\tEpoch: [57]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1114.943444030711  loss: 0.2912 (0.2920)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:12:10\tINFO\ttorchdistill.misc.log\tEpoch: [57]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.6673796082137  loss: 0.3111 (0.2980)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:12:16\tINFO\ttorchdistill.misc.log\tEpoch: [57] Total time: 0:00:42\n",
            "2021/01/10 21:12:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 69.5312 (69.5312)  acc5: 96.0938 (96.0938)  time: 0.7012  data: 0.6415  max mem: 700\n",
            "2021/01/10 21:12:18\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:12:18\tINFO\t__main__\t * Acc@1 76.9800\tAcc@5 97.9000\n",
            "\n",
            "2021/01/10 21:12:20\tINFO\ttorchdistill.misc.log\tEpoch: [58]  [  0/352]  eta: 0:07:20  lr: 0.1  img/s: 263.24260083463554  loss: 0.3247 (0.3247)  time: 1.2507  data: 0.7645  max mem: 700\n",
            "2021/01/10 21:12:31\tINFO\ttorchdistill.misc.log\tEpoch: [58]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1111.3384021445502  loss: 0.2792 (0.2928)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:12:43\tINFO\ttorchdistill.misc.log\tEpoch: [58]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1112.6812158291573  loss: 0.2905 (0.2938)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:12:54\tINFO\ttorchdistill.misc.log\tEpoch: [58]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1113.2003226361614  loss: 0.3007 (0.2982)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:13:01\tINFO\ttorchdistill.misc.log\tEpoch: [58] Total time: 0:00:42\n",
            "2021/01/10 21:13:01\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 74.2188 (74.2188)  acc5: 96.0938 (96.0938)  time: 0.6937  data: 0.6551  max mem: 700\n",
            "2021/01/10 21:13:03\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:13:03\tINFO\t__main__\t * Acc@1 77.7200\tAcc@5 96.9600\n",
            "\n",
            "2021/01/10 21:13:04\tINFO\ttorchdistill.misc.log\tEpoch: [59]  [  0/352]  eta: 0:06:39  lr: 0.1  img/s: 267.10234818023247  loss: 0.3249 (0.3249)  time: 1.1346  data: 0.6553  max mem: 700\n",
            "2021/01/10 21:13:15\tINFO\ttorchdistill.misc.log\tEpoch: [59]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1098.7898371271506  loss: 0.2696 (0.2806)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:13:27\tINFO\ttorchdistill.misc.log\tEpoch: [59]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1115.3186735111485  loss: 0.2980 (0.2804)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:13:39\tINFO\ttorchdistill.misc.log\tEpoch: [59]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1107.8846119717452  loss: 0.3017 (0.2895)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:13:45\tINFO\ttorchdistill.misc.log\tEpoch: [59] Total time: 0:00:42\n",
            "2021/01/10 21:13:46\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:33  acc1: 73.4375 (73.4375)  acc5: 99.2188 (99.2188)  time: 0.8473  data: 0.8114  max mem: 700\n",
            "2021/01/10 21:13:47\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:13:47\tINFO\t__main__\t * Acc@1 77.7800\tAcc@5 97.6600\n",
            "\n",
            "2021/01/10 21:13:48\tINFO\ttorchdistill.misc.log\tEpoch: [60]  [  0/352]  eta: 0:07:25  lr: 0.1  img/s: 212.7547675263709  loss: 0.3161 (0.3161)  time: 1.2657  data: 0.6641  max mem: 700\n",
            "2021/01/10 21:14:00\tINFO\ttorchdistill.misc.log\tEpoch: [60]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1107.6971731456053  loss: 0.2765 (0.2982)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:14:11\tINFO\ttorchdistill.misc.log\tEpoch: [60]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1111.948369992958  loss: 0.2929 (0.2950)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:14:23\tINFO\ttorchdistill.misc.log\tEpoch: [60]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1091.518290885359  loss: 0.2943 (0.2923)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:14:29\tINFO\ttorchdistill.misc.log\tEpoch: [60] Total time: 0:00:42\n",
            "2021/01/10 21:14:30\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 75.7812 (75.7812)  acc5: 96.8750 (96.8750)  time: 0.6894  data: 0.6595  max mem: 700\n",
            "2021/01/10 21:14:31\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:14:31\tINFO\t__main__\t * Acc@1 80.6000\tAcc@5 97.9200\n",
            "\n",
            "2021/01/10 21:14:32\tINFO\ttorchdistill.misc.log\tEpoch: [61]  [  0/352]  eta: 0:06:45  lr: 0.1  img/s: 248.27089399012226  loss: 0.2611 (0.2611)  time: 1.1513  data: 0.6357  max mem: 700\n",
            "2021/01/10 21:14:44\tINFO\ttorchdistill.misc.log\tEpoch: [61]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1113.5582114070712  loss: 0.2696 (0.2801)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:14:55\tINFO\ttorchdistill.misc.log\tEpoch: [61]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.30643553504  loss: 0.3036 (0.2819)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:15:07\tINFO\ttorchdistill.misc.log\tEpoch: [61]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1106.548782297558  loss: 0.3013 (0.2898)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:15:13\tINFO\ttorchdistill.misc.log\tEpoch: [61] Total time: 0:00:42\n",
            "2021/01/10 21:15:14\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 74.2188 (74.2188)  acc5: 99.2188 (99.2188)  time: 0.7727  data: 0.7363  max mem: 700\n",
            "2021/01/10 21:15:15\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:15:15\tINFO\t__main__\t * Acc@1 79.0400\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 21:15:16\tINFO\ttorchdistill.misc.log\tEpoch: [62]  [  0/352]  eta: 0:06:32  lr: 0.1  img/s: 278.6490585936932  loss: 0.2968 (0.2968)  time: 1.1144  data: 0.6550  max mem: 700\n",
            "2021/01/10 21:15:28\tINFO\ttorchdistill.misc.log\tEpoch: [62]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1094.4711067620738  loss: 0.2851 (0.2920)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:15:40\tINFO\ttorchdistill.misc.log\tEpoch: [62]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1104.6931157161346  loss: 0.2881 (0.2971)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:15:51\tINFO\ttorchdistill.misc.log\tEpoch: [62]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1110.6027285609375  loss: 0.3139 (0.3049)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:15:57\tINFO\ttorchdistill.misc.log\tEpoch: [62] Total time: 0:00:42\n",
            "2021/01/10 21:15:58\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 70.3125 (70.3125)  acc5: 91.4062 (91.4062)  time: 0.6760  data: 0.6230  max mem: 700\n",
            "2021/01/10 21:15:59\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:15:59\tINFO\t__main__\t * Acc@1 78.6400\tAcc@5 96.7400\n",
            "\n",
            "2021/01/10 21:16:00\tINFO\ttorchdistill.misc.log\tEpoch: [63]  [  0/352]  eta: 0:06:57  lr: 0.1  img/s: 233.8197308553806  loss: 0.3209 (0.3209)  time: 1.1853  data: 0.6379  max mem: 700\n",
            "2021/01/10 21:16:12\tINFO\ttorchdistill.misc.log\tEpoch: [63]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1104.9341140393303  loss: 0.2720 (0.2874)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:16:24\tINFO\ttorchdistill.misc.log\tEpoch: [63]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1107.7177426010596  loss: 0.2918 (0.2856)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:16:35\tINFO\ttorchdistill.misc.log\tEpoch: [63]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1095.9389719376247  loss: 0.3133 (0.2911)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:16:41\tINFO\ttorchdistill.misc.log\tEpoch: [63] Total time: 0:00:42\n",
            "2021/01/10 21:16:42\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:33  acc1: 71.8750 (71.8750)  acc5: 96.0938 (96.0938)  time: 0.8359  data: 0.8042  max mem: 700\n",
            "2021/01/10 21:16:43\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:16:43\tINFO\t__main__\t * Acc@1 80.5800\tAcc@5 97.3000\n",
            "\n",
            "2021/01/10 21:16:45\tINFO\ttorchdistill.misc.log\tEpoch: [64]  [  0/352]  eta: 0:07:12  lr: 0.1  img/s: 245.86943620993415  loss: 0.2702 (0.2702)  time: 1.2288  data: 0.7082  max mem: 700\n",
            "2021/01/10 21:16:56\tINFO\ttorchdistill.misc.log\tEpoch: [64]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1118.5579675269341  loss: 0.2673 (0.2806)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:17:08\tINFO\ttorchdistill.misc.log\tEpoch: [64]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1112.0934797423963  loss: 0.2769 (0.2804)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:17:19\tINFO\ttorchdistill.misc.log\tEpoch: [64]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1107.301930922396  loss: 0.3065 (0.2904)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:17:26\tINFO\ttorchdistill.misc.log\tEpoch: [64] Total time: 0:00:42\n",
            "2021/01/10 21:17:26\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 74.2188 (74.2188)  acc5: 96.8750 (96.8750)  time: 0.7081  data: 0.6393  max mem: 700\n",
            "2021/01/10 21:17:28\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:17:28\tINFO\t__main__\t * Acc@1 78.8200\tAcc@5 97.4800\n",
            "\n",
            "2021/01/10 21:17:29\tINFO\ttorchdistill.misc.log\tEpoch: [65]  [  0/352]  eta: 0:07:34  lr: 0.1  img/s: 254.03617739300944  loss: 0.2917 (0.2917)  time: 1.2899  data: 0.7860  max mem: 700\n",
            "2021/01/10 21:17:41\tINFO\ttorchdistill.misc.log\tEpoch: [65]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1107.681175208385  loss: 0.2671 (0.2756)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:17:52\tINFO\ttorchdistill.misc.log\tEpoch: [65]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1114.1752435898766  loss: 0.2927 (0.2801)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:18:04\tINFO\ttorchdistill.misc.log\tEpoch: [65]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1107.9051883891684  loss: 0.2904 (0.2842)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:18:10\tINFO\ttorchdistill.misc.log\tEpoch: [65] Total time: 0:00:42\n",
            "2021/01/10 21:18:11\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 73.4375 (73.4375)  acc5: 96.8750 (96.8750)  time: 0.7513  data: 0.6731  max mem: 700\n",
            "2021/01/10 21:18:12\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:18:12\tINFO\t__main__\t * Acc@1 78.8000\tAcc@5 97.7800\n",
            "\n",
            "2021/01/10 21:18:13\tINFO\ttorchdistill.misc.log\tEpoch: [66]  [  0/352]  eta: 0:06:55  lr: 0.1  img/s: 239.01540795760974  loss: 0.2621 (0.2621)  time: 1.1790  data: 0.6435  max mem: 700\n",
            "2021/01/10 21:18:25\tINFO\ttorchdistill.misc.log\tEpoch: [66]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1111.7066045452193  loss: 0.2743 (0.2759)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:18:36\tINFO\ttorchdistill.misc.log\tEpoch: [66]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1115.2769688748367  loss: 0.2786 (0.2763)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:18:48\tINFO\ttorchdistill.misc.log\tEpoch: [66]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1114.8878759498034  loss: 0.3044 (0.2846)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:18:54\tINFO\ttorchdistill.misc.log\tEpoch: [66] Total time: 0:00:42\n",
            "2021/01/10 21:18:55\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:33  acc1: 79.6875 (79.6875)  acc5: 96.0938 (96.0938)  time: 0.8486  data: 0.8176  max mem: 700\n",
            "2021/01/10 21:18:56\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:18:56\tINFO\t__main__\t * Acc@1 79.9800\tAcc@5 97.7800\n",
            "\n",
            "2021/01/10 21:18:57\tINFO\ttorchdistill.misc.log\tEpoch: [67]  [  0/352]  eta: 0:07:09  lr: 0.1  img/s: 227.58565212820434  loss: 0.2650 (0.2650)  time: 1.2206  data: 0.6581  max mem: 700\n",
            "2021/01/10 21:19:09\tINFO\ttorchdistill.misc.log\tEpoch: [67]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1114.6772306171856  loss: 0.2735 (0.2843)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:19:20\tINFO\ttorchdistill.misc.log\tEpoch: [67]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1104.2296033484508  loss: 0.2804 (0.2821)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:19:32\tINFO\ttorchdistill.misc.log\tEpoch: [67]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1099.7531863638785  loss: 0.2793 (0.2812)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:19:38\tINFO\ttorchdistill.misc.log\tEpoch: [67] Total time: 0:00:42\n",
            "2021/01/10 21:19:39\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:36  acc1: 71.8750 (71.8750)  acc5: 92.1875 (92.1875)  time: 0.9125  data: 0.8436  max mem: 700\n",
            "2021/01/10 21:19:40\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:19:40\tINFO\t__main__\t * Acc@1 78.9400\tAcc@5 95.8800\n",
            "\n",
            "2021/01/10 21:19:41\tINFO\ttorchdistill.misc.log\tEpoch: [68]  [  0/352]  eta: 0:07:00  lr: 0.1  img/s: 245.75283770873986  loss: 0.2595 (0.2595)  time: 1.1933  data: 0.6724  max mem: 700\n",
            "2021/01/10 21:19:53\tINFO\ttorchdistill.misc.log\tEpoch: [68]  [100/352]  eta: 0:00:31  lr: 0.1  img/s: 1102.9637454725498  loss: 0.2629 (0.2741)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:20:05\tINFO\ttorchdistill.misc.log\tEpoch: [68]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1107.1900349560215  loss: 0.2782 (0.2760)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:20:16\tINFO\ttorchdistill.misc.log\tEpoch: [68]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1111.7319274239305  loss: 0.2961 (0.2820)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:20:22\tINFO\ttorchdistill.misc.log\tEpoch: [68] Total time: 0:00:42\n",
            "2021/01/10 21:20:23\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:36  acc1: 77.3438 (77.3438)  acc5: 97.6562 (97.6562)  time: 0.9098  data: 0.8471  max mem: 700\n",
            "2021/01/10 21:20:24\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:20:24\tINFO\t__main__\t * Acc@1 81.3400\tAcc@5 98.1400\n",
            "\n",
            "2021/01/10 21:20:26\tINFO\ttorchdistill.misc.log\tEpoch: [69]  [  0/352]  eta: 0:07:21  lr: 0.1  img/s: 212.7538400998321  loss: 0.2675 (0.2675)  time: 1.2542  data: 0.6526  max mem: 700\n",
            "2021/01/10 21:20:37\tINFO\ttorchdistill.misc.log\tEpoch: [69]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1107.0393536799866  loss: 0.3036 (0.2892)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:20:49\tINFO\ttorchdistill.misc.log\tEpoch: [69]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1111.1290958160173  loss: 0.3003 (0.2928)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:21:01\tINFO\ttorchdistill.misc.log\tEpoch: [69]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1093.6350454772307  loss: 0.2940 (0.2954)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:21:07\tINFO\ttorchdistill.misc.log\tEpoch: [69] Total time: 0:00:42\n",
            "2021/01/10 21:21:07\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 69.5312 (69.5312)  acc5: 96.8750 (96.8750)  time: 0.6738  data: 0.6244  max mem: 700\n",
            "2021/01/10 21:21:09\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:21:09\tINFO\t__main__\t * Acc@1 78.4800\tAcc@5 98.0000\n",
            "\n",
            "2021/01/10 21:21:10\tINFO\ttorchdistill.misc.log\tEpoch: [70]  [  0/352]  eta: 0:07:12  lr: 0.1  img/s: 257.0536351431324  loss: 0.2724 (0.2724)  time: 1.2287  data: 0.7307  max mem: 700\n",
            "2021/01/10 21:21:22\tINFO\ttorchdistill.misc.log\tEpoch: [70]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1115.603738690627  loss: 0.2540 (0.2765)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:21:33\tINFO\ttorchdistill.misc.log\tEpoch: [70]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1108.8639817582095  loss: 0.2746 (0.2749)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:21:45\tINFO\ttorchdistill.misc.log\tEpoch: [70]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1104.404510838932  loss: 0.2870 (0.2801)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:21:51\tINFO\ttorchdistill.misc.log\tEpoch: [70] Total time: 0:00:42\n",
            "2021/01/10 21:21:52\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:34  acc1: 74.2188 (74.2188)  acc5: 97.6562 (97.6562)  time: 0.8608  data: 0.8170  max mem: 700\n",
            "2021/01/10 21:21:53\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:21:53\tINFO\t__main__\t * Acc@1 78.4400\tAcc@5 97.5800\n",
            "\n",
            "2021/01/10 21:21:54\tINFO\ttorchdistill.misc.log\tEpoch: [71]  [  0/352]  eta: 0:06:48  lr: 0.1  img/s: 240.41690882067527  loss: 0.2772 (0.2772)  time: 1.1609  data: 0.6285  max mem: 700\n",
            "2021/01/10 21:22:06\tINFO\ttorchdistill.misc.log\tEpoch: [71]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1108.2528167124249  loss: 0.2751 (0.2812)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:22:17\tINFO\ttorchdistill.misc.log\tEpoch: [71]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.7260558927537  loss: 0.2678 (0.2829)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:22:29\tINFO\ttorchdistill.misc.log\tEpoch: [71]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1107.834317279974  loss: 0.3052 (0.2898)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:22:35\tINFO\ttorchdistill.misc.log\tEpoch: [71] Total time: 0:00:42\n",
            "2021/01/10 21:22:36\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 71.8750 (71.8750)  acc5: 96.0938 (96.0938)  time: 0.7901  data: 0.7421  max mem: 700\n",
            "2021/01/10 21:22:37\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:22:37\tINFO\t__main__\t * Acc@1 77.9600\tAcc@5 97.7600\n",
            "\n",
            "2021/01/10 21:22:38\tINFO\ttorchdistill.misc.log\tEpoch: [72]  [  0/352]  eta: 0:07:45  lr: 0.1  img/s: 261.56747871147286  loss: 0.2834 (0.2834)  time: 1.3227  data: 0.8333  max mem: 700\n",
            "2021/01/10 21:22:50\tINFO\ttorchdistill.misc.log\tEpoch: [72]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1108.3603512096834  loss: 0.2686 (0.2773)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:23:02\tINFO\ttorchdistill.misc.log\tEpoch: [72]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1094.593836586982  loss: 0.2798 (0.2803)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:23:13\tINFO\ttorchdistill.misc.log\tEpoch: [72]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1114.2561786559295  loss: 0.3248 (0.2863)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:23:19\tINFO\ttorchdistill.misc.log\tEpoch: [72] Total time: 0:00:42\n",
            "2021/01/10 21:23:20\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 71.0938 (71.0938)  acc5: 96.8750 (96.8750)  time: 0.6851  data: 0.6166  max mem: 700\n",
            "2021/01/10 21:23:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:23:21\tINFO\t__main__\t * Acc@1 79.8000\tAcc@5 97.6600\n",
            "\n",
            "2021/01/10 21:23:22\tINFO\ttorchdistill.misc.log\tEpoch: [73]  [  0/352]  eta: 0:07:36  lr: 0.1  img/s: 205.7163474231185  loss: 0.2630 (0.2630)  time: 1.2973  data: 0.6751  max mem: 700\n",
            "2021/01/10 21:23:34\tINFO\ttorchdistill.misc.log\tEpoch: [73]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1109.212212119146  loss: 0.3031 (0.3153)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:23:46\tINFO\ttorchdistill.misc.log\tEpoch: [73]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.6167550480347  loss: 0.2857 (0.3063)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:23:57\tINFO\ttorchdistill.misc.log\tEpoch: [73]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1115.585193435374  loss: 0.3081 (0.3060)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:24:03\tINFO\ttorchdistill.misc.log\tEpoch: [73] Total time: 0:00:42\n",
            "2021/01/10 21:24:04\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 72.6562 (72.6562)  acc5: 97.6562 (97.6562)  time: 0.8063  data: 0.7607  max mem: 700\n",
            "2021/01/10 21:24:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:24:06\tINFO\t__main__\t * Acc@1 80.5400\tAcc@5 97.6600\n",
            "\n",
            "2021/01/10 21:24:07\tINFO\ttorchdistill.misc.log\tEpoch: [74]  [  0/352]  eta: 0:07:13  lr: 0.1  img/s: 244.99640494272458  loss: 0.3213 (0.3213)  time: 1.2309  data: 0.7084  max mem: 700\n",
            "2021/01/10 21:24:19\tINFO\ttorchdistill.misc.log\tEpoch: [74]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1112.0220717996306  loss: 0.2790 (0.2852)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:24:30\tINFO\ttorchdistill.misc.log\tEpoch: [74]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1107.6194732075253  loss: 0.2754 (0.2849)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:24:42\tINFO\ttorchdistill.misc.log\tEpoch: [74]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1109.2374214876033  loss: 0.2925 (0.2885)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:24:48\tINFO\ttorchdistill.misc.log\tEpoch: [74] Total time: 0:00:42\n",
            "2021/01/10 21:24:48\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 75.0000 (75.0000)  acc5: 96.0938 (96.0938)  time: 0.7087  data: 0.6601  max mem: 700\n",
            "2021/01/10 21:24:50\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:24:50\tINFO\t__main__\t * Acc@1 80.4200\tAcc@5 97.3600\n",
            "\n",
            "2021/01/10 21:24:51\tINFO\ttorchdistill.misc.log\tEpoch: [75]  [  0/352]  eta: 0:07:50  lr: 0.1  img/s: 246.7065315290476  loss: 0.3142 (0.3142)  time: 1.3362  data: 0.8173  max mem: 700\n",
            "2021/01/10 21:25:03\tINFO\ttorchdistill.misc.log\tEpoch: [75]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1112.598203664789  loss: 0.2757 (0.2851)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:25:14\tINFO\ttorchdistill.misc.log\tEpoch: [75]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1109.0884736553976  loss: 0.2826 (0.2827)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:25:26\tINFO\ttorchdistill.misc.log\tEpoch: [75]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.0566228848754  loss: 0.2794 (0.2822)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:25:32\tINFO\ttorchdistill.misc.log\tEpoch: [75] Total time: 0:00:42\n",
            "2021/01/10 21:25:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:36  acc1: 72.6562 (72.6562)  acc5: 100.0000 (100.0000)  time: 0.9175  data: 0.8713  max mem: 700\n",
            "2021/01/10 21:25:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:25:34\tINFO\t__main__\t * Acc@1 81.5200\tAcc@5 97.7400\n",
            "\n",
            "2021/01/10 21:25:35\tINFO\ttorchdistill.misc.log\tEpoch: [76]  [  0/352]  eta: 0:08:13  lr: 0.1  img/s: 277.0030209360413  loss: 0.2608 (0.2608)  time: 1.4027  data: 0.9406  max mem: 700\n",
            "2021/01/10 21:25:47\tINFO\ttorchdistill.misc.log\tEpoch: [76]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1110.0562026122575  loss: 0.2689 (0.2721)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:25:58\tINFO\ttorchdistill.misc.log\tEpoch: [76]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1114.5129362332862  loss: 0.2775 (0.2793)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:26:10\tINFO\ttorchdistill.misc.log\tEpoch: [76]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.5935922410576  loss: 0.2926 (0.2874)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:26:16\tINFO\ttorchdistill.misc.log\tEpoch: [76] Total time: 0:00:42\n",
            "2021/01/10 21:26:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 74.2188 (74.2188)  acc5: 95.3125 (95.3125)  time: 0.6936  data: 0.6387  max mem: 700\n",
            "2021/01/10 21:26:18\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:26:18\tINFO\t__main__\t * Acc@1 79.1000\tAcc@5 97.6200\n",
            "\n",
            "2021/01/10 21:26:19\tINFO\ttorchdistill.misc.log\tEpoch: [77]  [  0/352]  eta: 0:06:58  lr: 0.1  img/s: 266.24070078309455  loss: 0.2966 (0.2966)  time: 1.1882  data: 0.7074  max mem: 700\n",
            "2021/01/10 21:26:31\tINFO\ttorchdistill.misc.log\tEpoch: [77]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1112.6051208720612  loss: 0.2849 (0.2858)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:26:42\tINFO\ttorchdistill.misc.log\tEpoch: [77]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1107.877753335782  loss: 0.2789 (0.2867)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:26:54\tINFO\ttorchdistill.misc.log\tEpoch: [77]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1109.5973528603286  loss: 0.2937 (0.2919)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:27:00\tINFO\ttorchdistill.misc.log\tEpoch: [77] Total time: 0:00:42\n",
            "2021/01/10 21:27:01\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 69.5312 (69.5312)  acc5: 99.2188 (99.2188)  time: 0.6953  data: 0.6220  max mem: 700\n",
            "2021/01/10 21:27:02\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:27:02\tINFO\t__main__\t * Acc@1 78.2600\tAcc@5 97.2200\n",
            "\n",
            "2021/01/10 21:27:03\tINFO\ttorchdistill.misc.log\tEpoch: [78]  [  0/352]  eta: 0:06:48  lr: 0.1  img/s: 245.1454157743572  loss: 0.3117 (0.3117)  time: 1.1609  data: 0.6387  max mem: 700\n",
            "2021/01/10 21:27:15\tINFO\ttorchdistill.misc.log\tEpoch: [78]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1115.8240107410895  loss: 0.2709 (0.2729)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:27:27\tINFO\ttorchdistill.misc.log\tEpoch: [78]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1103.7483259903743  loss: 0.2654 (0.2730)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:27:38\tINFO\ttorchdistill.misc.log\tEpoch: [78]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.1994568178475  loss: 0.2872 (0.2778)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:27:44\tINFO\ttorchdistill.misc.log\tEpoch: [78] Total time: 0:00:42\n",
            "2021/01/10 21:27:45\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 69.5312 (69.5312)  acc5: 96.8750 (96.8750)  time: 0.6886  data: 0.6230  max mem: 700\n",
            "2021/01/10 21:27:46\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:27:46\tINFO\t__main__\t * Acc@1 77.9200\tAcc@5 97.4600\n",
            "\n",
            "2021/01/10 21:27:47\tINFO\ttorchdistill.misc.log\tEpoch: [79]  [  0/352]  eta: 0:06:49  lr: 0.1  img/s: 268.99846979728574  loss: 0.2549 (0.2549)  time: 1.1634  data: 0.6875  max mem: 700\n",
            "2021/01/10 21:27:59\tINFO\ttorchdistill.misc.log\tEpoch: [79]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1105.0137120510446  loss: 0.2693 (0.2732)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:28:11\tINFO\ttorchdistill.misc.log\tEpoch: [79]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.7382951343345  loss: 0.2831 (0.2784)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:28:22\tINFO\ttorchdistill.misc.log\tEpoch: [79]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1113.8955300678872  loss: 0.2940 (0.2863)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:28:28\tINFO\ttorchdistill.misc.log\tEpoch: [79] Total time: 0:00:42\n",
            "2021/01/10 21:28:29\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:37  acc1: 75.0000 (75.0000)  acc5: 96.8750 (96.8750)  time: 0.9380  data: 0.8997  max mem: 700\n",
            "2021/01/10 21:28:30\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:28:30\tINFO\t__main__\t * Acc@1 80.3600\tAcc@5 98.3000\n",
            "\n",
            "2021/01/10 21:28:32\tINFO\ttorchdistill.misc.log\tEpoch: [80]  [  0/352]  eta: 0:07:36  lr: 0.1  img/s: 207.76850648571624  loss: 0.2899 (0.2899)  time: 1.2959  data: 0.6798  max mem: 700\n",
            "2021/01/10 21:28:43\tINFO\ttorchdistill.misc.log\tEpoch: [80]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1110.9497531318934  loss: 0.2937 (0.2856)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:28:55\tINFO\ttorchdistill.misc.log\tEpoch: [80]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1109.3680702066151  loss: 0.2766 (0.2831)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:29:06\tINFO\ttorchdistill.misc.log\tEpoch: [80]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1105.0159864484644  loss: 0.3252 (0.2895)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:29:13\tINFO\ttorchdistill.misc.log\tEpoch: [80] Total time: 0:00:42\n",
            "2021/01/10 21:29:13\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 72.6562 (72.6562)  acc5: 96.0938 (96.0938)  time: 0.6873  data: 0.6445  max mem: 700\n",
            "2021/01/10 21:29:15\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:29:15\tINFO\t__main__\t * Acc@1 77.4200\tAcc@5 97.4800\n",
            "\n",
            "2021/01/10 21:29:16\tINFO\ttorchdistill.misc.log\tEpoch: [81]  [  0/352]  eta: 0:06:57  lr: 0.1  img/s: 233.13345561669723  loss: 0.2706 (0.2706)  time: 1.1870  data: 0.6379  max mem: 700\n",
            "2021/01/10 21:29:27\tINFO\ttorchdistill.misc.log\tEpoch: [81]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1110.740593158096  loss: 0.2924 (0.2947)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:29:39\tINFO\ttorchdistill.misc.log\tEpoch: [81]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1103.991182397697  loss: 0.2811 (0.2908)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:29:51\tINFO\ttorchdistill.misc.log\tEpoch: [81]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1109.9781713829684  loss: 0.3171 (0.2935)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:29:57\tINFO\ttorchdistill.misc.log\tEpoch: [81] Total time: 0:00:42\n",
            "2021/01/10 21:29:57\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 72.6562 (72.6562)  acc5: 96.0938 (96.0938)  time: 0.6900  data: 0.6376  max mem: 700\n",
            "2021/01/10 21:29:59\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:29:59\tINFO\t__main__\t * Acc@1 80.3000\tAcc@5 97.7200\n",
            "\n",
            "2021/01/10 21:30:00\tINFO\ttorchdistill.misc.log\tEpoch: [82]  [  0/352]  eta: 0:07:39  lr: 0.1  img/s: 242.9052627197362  loss: 0.3067 (0.3067)  time: 1.3059  data: 0.7789  max mem: 700\n",
            "2021/01/10 21:30:12\tINFO\ttorchdistill.misc.log\tEpoch: [82]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1114.0249667994688  loss: 0.2752 (0.2894)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:30:23\tINFO\ttorchdistill.misc.log\tEpoch: [82]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1114.5453284754876  loss: 0.2921 (0.2884)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:30:35\tINFO\ttorchdistill.misc.log\tEpoch: [82]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1103.9389706018428  loss: 0.2836 (0.2876)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:30:41\tINFO\ttorchdistill.misc.log\tEpoch: [82] Total time: 0:00:42\n",
            "2021/01/10 21:30:42\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:35  acc1: 65.6250 (65.6250)  acc5: 98.4375 (98.4375)  time: 0.8906  data: 0.8341  max mem: 700\n",
            "2021/01/10 21:30:43\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:30:43\tINFO\t__main__\t * Acc@1 75.6400\tAcc@5 96.9800\n",
            "\n",
            "2021/01/10 21:30:44\tINFO\ttorchdistill.misc.log\tEpoch: [83]  [  0/352]  eta: 0:06:48  lr: 0.1  img/s: 254.6690650212133  loss: 0.3717 (0.3717)  time: 1.1593  data: 0.6567  max mem: 700\n",
            "2021/01/10 21:30:56\tINFO\ttorchdistill.misc.log\tEpoch: [83]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1113.3642302252565  loss: 0.2771 (0.2842)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:31:07\tINFO\ttorchdistill.misc.log\tEpoch: [83]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1110.0332511118509  loss: 0.2790 (0.2803)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:31:19\tINFO\ttorchdistill.misc.log\tEpoch: [83]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1097.1259668576029  loss: 0.2821 (0.2807)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:31:25\tINFO\ttorchdistill.misc.log\tEpoch: [83] Total time: 0:00:42\n",
            "2021/01/10 21:31:26\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 74.2188 (74.2188)  acc5: 96.0938 (96.0938)  time: 0.6587  data: 0.6111  max mem: 700\n",
            "2021/01/10 21:31:27\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:31:27\tINFO\t__main__\t * Acc@1 80.0800\tAcc@5 97.9200\n",
            "\n",
            "2021/01/10 21:31:28\tINFO\ttorchdistill.misc.log\tEpoch: [84]  [  0/352]  eta: 0:07:32  lr: 0.1  img/s: 273.38745975222184  loss: 0.2641 (0.2641)  time: 1.2849  data: 0.8167  max mem: 700\n",
            "2021/01/10 21:31:40\tINFO\ttorchdistill.misc.log\tEpoch: [84]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1111.5063642311163  loss: 0.2603 (0.2681)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:31:51\tINFO\ttorchdistill.misc.log\tEpoch: [84]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1111.1290958160173  loss: 0.2705 (0.2741)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:32:03\tINFO\ttorchdistill.misc.log\tEpoch: [84]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1112.877265933829  loss: 0.2935 (0.2804)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:32:09\tINFO\ttorchdistill.misc.log\tEpoch: [84] Total time: 0:00:42\n",
            "2021/01/10 21:32:10\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 67.9688 (67.9688)  acc5: 96.8750 (96.8750)  time: 0.7397  data: 0.7057  max mem: 700\n",
            "2021/01/10 21:32:11\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:32:11\tINFO\t__main__\t * Acc@1 77.7000\tAcc@5 97.1200\n",
            "\n",
            "2021/01/10 21:32:12\tINFO\ttorchdistill.misc.log\tEpoch: [85]  [  0/352]  eta: 0:07:33  lr: 0.1  img/s: 267.3307118333487  loss: 0.2913 (0.2913)  time: 1.2896  data: 0.8108  max mem: 700\n",
            "2021/01/10 21:32:24\tINFO\ttorchdistill.misc.log\tEpoch: [85]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1105.6531862618906  loss: 0.2729 (0.2826)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:32:35\tINFO\ttorchdistill.misc.log\tEpoch: [85]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1107.0713129476005  loss: 0.2855 (0.2828)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:32:47\tINFO\ttorchdistill.misc.log\tEpoch: [85]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1081.5026872839496  loss: 0.2857 (0.2850)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:32:53\tINFO\ttorchdistill.misc.log\tEpoch: [85] Total time: 0:00:42\n",
            "2021/01/10 21:32:54\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 71.8750 (71.8750)  acc5: 96.8750 (96.8750)  time: 0.6542  data: 0.6200  max mem: 700\n",
            "2021/01/10 21:32:55\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:32:55\tINFO\t__main__\t * Acc@1 76.5600\tAcc@5 97.3000\n",
            "\n",
            "2021/01/10 21:32:56\tINFO\ttorchdistill.misc.log\tEpoch: [86]  [  0/352]  eta: 0:06:58  lr: 0.1  img/s: 234.2911520950098  loss: 0.3063 (0.3063)  time: 1.1900  data: 0.6437  max mem: 700\n",
            "2021/01/10 21:33:08\tINFO\ttorchdistill.misc.log\tEpoch: [86]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1102.2934283819493  loss: 0.2678 (0.2766)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:33:20\tINFO\ttorchdistill.misc.log\tEpoch: [86]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1111.5063642311163  loss: 0.2871 (0.2815)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:33:31\tINFO\ttorchdistill.misc.log\tEpoch: [86]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1108.772378527188  loss: 0.2986 (0.2874)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:33:37\tINFO\ttorchdistill.misc.log\tEpoch: [86] Total time: 0:00:42\n",
            "2021/01/10 21:33:38\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:41  acc1: 75.0000 (75.0000)  acc5: 94.5312 (94.5312)  time: 1.0393  data: 0.9821  max mem: 700\n",
            "2021/01/10 21:33:39\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:33:39\tINFO\t__main__\t * Acc@1 78.7000\tAcc@5 97.9400\n",
            "\n",
            "2021/01/10 21:33:41\tINFO\ttorchdistill.misc.log\tEpoch: [87]  [  0/352]  eta: 0:06:54  lr: 0.1  img/s: 236.34136250759929  loss: 0.2895 (0.2895)  time: 1.1789  data: 0.6373  max mem: 700\n",
            "2021/01/10 21:33:52\tINFO\ttorchdistill.misc.log\tEpoch: [87]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1104.6476561230095  loss: 0.2723 (0.2809)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:34:04\tINFO\ttorchdistill.misc.log\tEpoch: [87]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1113.2257136103312  loss: 0.2869 (0.2848)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:34:15\tINFO\ttorchdistill.misc.log\tEpoch: [87]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1103.5554788156846  loss: 0.2888 (0.2868)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:34:21\tINFO\ttorchdistill.misc.log\tEpoch: [87] Total time: 0:00:42\n",
            "2021/01/10 21:34:22\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 76.5625 (76.5625)  acc5: 97.6562 (97.6562)  time: 0.7424  data: 0.6919  max mem: 700\n",
            "2021/01/10 21:34:23\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:34:23\tINFO\t__main__\t * Acc@1 79.8400\tAcc@5 98.0800\n",
            "\n",
            "2021/01/10 21:34:25\tINFO\ttorchdistill.misc.log\tEpoch: [88]  [  0/352]  eta: 0:06:55  lr: 0.1  img/s: 264.89447905128196  loss: 0.2579 (0.2579)  time: 1.1794  data: 0.6961  max mem: 700\n",
            "2021/01/10 21:34:36\tINFO\ttorchdistill.misc.log\tEpoch: [88]  [100/352]  eta: 0:00:31  lr: 0.1  img/s: 1115.1310272057694  loss: 0.2623 (0.2753)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:34:48\tINFO\ttorchdistill.misc.log\tEpoch: [88]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1113.0203107669663  loss: 0.2630 (0.2740)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:34:59\tINFO\ttorchdistill.misc.log\tEpoch: [88]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1113.6598475765334  loss: 0.3025 (0.2813)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:35:05\tINFO\ttorchdistill.misc.log\tEpoch: [88] Total time: 0:00:42\n",
            "2021/01/10 21:35:06\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 70.3125 (70.3125)  acc5: 95.3125 (95.3125)  time: 0.7997  data: 0.7483  max mem: 700\n",
            "2021/01/10 21:35:08\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:35:08\tINFO\t__main__\t * Acc@1 78.6000\tAcc@5 96.9200\n",
            "\n",
            "2021/01/10 21:35:09\tINFO\ttorchdistill.misc.log\tEpoch: [89]  [  0/352]  eta: 0:07:53  lr: 0.1  img/s: 298.396891035047  loss: 0.3055 (0.3055)  time: 1.3443  data: 0.9153  max mem: 700\n",
            "2021/01/10 21:35:20\tINFO\ttorchdistill.misc.log\tEpoch: [89]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1117.535817620929  loss: 0.2972 (0.2931)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:35:32\tINFO\ttorchdistill.misc.log\tEpoch: [89]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1117.6149151074583  loss: 0.2907 (0.2922)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:35:44\tINFO\ttorchdistill.misc.log\tEpoch: [89]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1106.9069706547577  loss: 0.2905 (0.2949)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:35:50\tINFO\ttorchdistill.misc.log\tEpoch: [89] Total time: 0:00:42\n",
            "2021/01/10 21:35:50\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 71.0938 (71.0938)  acc5: 96.0938 (96.0938)  time: 0.7693  data: 0.7176  max mem: 700\n",
            "2021/01/10 21:35:52\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:35:52\tINFO\t__main__\t * Acc@1 79.5600\tAcc@5 97.3600\n",
            "\n",
            "2021/01/10 21:35:53\tINFO\ttorchdistill.misc.log\tEpoch: [90]  [  0/352]  eta: 0:07:09  lr: 0.1  img/s: 230.20832731231687  loss: 0.2927 (0.2927)  time: 1.2207  data: 0.6647  max mem: 700\n",
            "2021/01/10 21:36:05\tINFO\ttorchdistill.misc.log\tEpoch: [90]  [100/352]  eta: 0:00:32  lr: 0.1  img/s: 1113.2718819855427  loss: 0.2751 (0.2875)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:36:16\tINFO\ttorchdistill.misc.log\tEpoch: [90]  [200/352]  eta: 0:00:18  lr: 0.1  img/s: 1105.7579393767135  loss: 0.2798 (0.2828)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:36:28\tINFO\ttorchdistill.misc.log\tEpoch: [90]  [300/352]  eta: 0:00:06  lr: 0.1  img/s: 1116.2021539357145  loss: 0.2750 (0.2819)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:36:34\tINFO\ttorchdistill.misc.log\tEpoch: [90] Total time: 0:00:42\n",
            "2021/01/10 21:36:34\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 71.8750 (71.8750)  acc5: 98.4375 (98.4375)  time: 0.7405  data: 0.7095  max mem: 700\n",
            "2021/01/10 21:36:36\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:36:36\tINFO\t__main__\t * Acc@1 78.3200\tAcc@5 97.5800\n",
            "\n",
            "2021/01/10 21:36:37\tINFO\ttorchdistill.misc.log\tEpoch: [91]  [  0/352]  eta: 0:06:40  lr: 0.010000000000000002  img/s: 253.1508410919696  loss: 0.2399 (0.2399)  time: 1.1386  data: 0.6329  max mem: 700\n",
            "2021/01/10 21:36:49\tINFO\ttorchdistill.misc.log\tEpoch: [91]  [100/352]  eta: 0:00:31  lr: 0.010000000000000002  img/s: 1103.1382521431096  loss: 0.2369 (0.2511)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:37:00\tINFO\ttorchdistill.misc.log\tEpoch: [91]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1115.0754404256998  loss: 0.2344 (0.2440)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:37:12\tINFO\ttorchdistill.misc.log\tEpoch: [91]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1110.70842169071  loss: 0.2253 (0.2398)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:37:18\tINFO\ttorchdistill.misc.log\tEpoch: [91] Total time: 0:00:41\n",
            "2021/01/10 21:37:18\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.6730  data: 0.6251  max mem: 700\n",
            "2021/01/10 21:37:20\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:37:20\tINFO\t__main__\t * Acc@1 84.3000\tAcc@5 98.3800\n",
            "\n",
            "2021/01/10 21:37:20\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 81.5400 -> 84.3000)\n",
            "2021/01/10 21:37:21\tINFO\ttorchdistill.misc.log\tEpoch: [92]  [  0/352]  eta: 0:07:51  lr: 0.010000000000000002  img/s: 265.40112493857725  loss: 0.2240 (0.2240)  time: 1.3402  data: 0.8579  max mem: 700\n",
            "2021/01/10 21:37:33\tINFO\ttorchdistill.misc.log\tEpoch: [92]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1113.6921902485976  loss: 0.2224 (0.2232)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:37:44\tINFO\ttorchdistill.misc.log\tEpoch: [92]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1114.3856992220258  loss: 0.2216 (0.2233)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:37:56\tINFO\ttorchdistill.misc.log\tEpoch: [92]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1097.6104610867935  loss: 0.2212 (0.2231)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:38:02\tINFO\ttorchdistill.misc.log\tEpoch: [92] Total time: 0:00:42\n",
            "2021/01/10 21:38:03\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7198  data: 0.6663  max mem: 700\n",
            "2021/01/10 21:38:04\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:38:04\tINFO\t__main__\t * Acc@1 84.8200\tAcc@5 98.3000\n",
            "\n",
            "2021/01/10 21:38:04\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 84.3000 -> 84.8200)\n",
            "2021/01/10 21:38:05\tINFO\ttorchdistill.misc.log\tEpoch: [93]  [  0/352]  eta: 0:06:58  lr: 0.010000000000000002  img/s: 242.073964388986  loss: 0.2204 (0.2204)  time: 1.1902  data: 0.6614  max mem: 700\n",
            "2021/01/10 21:38:17\tINFO\ttorchdistill.misc.log\tEpoch: [93]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1108.3969634595255  loss: 0.2189 (0.2204)  time: 0.1166  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:38:28\tINFO\ttorchdistill.misc.log\tEpoch: [93]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1111.5408832767077  loss: 0.2186 (0.2204)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:38:40\tINFO\ttorchdistill.misc.log\tEpoch: [93]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1109.2053370357055  loss: 0.2188 (0.2201)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:38:46\tINFO\ttorchdistill.misc.log\tEpoch: [93] Total time: 0:00:42\n",
            "2021/01/10 21:38:47\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 79.6875 (79.6875)  acc5: 99.2188 (99.2188)  time: 0.7312  data: 0.6871  max mem: 700\n",
            "2021/01/10 21:38:48\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:38:48\tINFO\t__main__\t * Acc@1 84.7200\tAcc@5 98.4000\n",
            "\n",
            "2021/01/10 21:38:49\tINFO\ttorchdistill.misc.log\tEpoch: [94]  [  0/352]  eta: 0:06:55  lr: 0.010000000000000002  img/s: 239.22745797362606  loss: 0.2162 (0.2162)  time: 1.1812  data: 0.6461  max mem: 700\n",
            "2021/01/10 21:39:01\tINFO\ttorchdistill.misc.log\tEpoch: [94]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1107.5257907201267  loss: 0.2183 (0.2184)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:39:13\tINFO\ttorchdistill.misc.log\tEpoch: [94]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1089.9139674490084  loss: 0.2180 (0.2183)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:39:24\tINFO\ttorchdistill.misc.log\tEpoch: [94]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1094.9286942334165  loss: 0.2176 (0.2184)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:39:30\tINFO\ttorchdistill.misc.log\tEpoch: [94] Total time: 0:00:42\n",
            "2021/01/10 21:39:31\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.6656  data: 0.6289  max mem: 700\n",
            "2021/01/10 21:39:32\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:39:32\tINFO\t__main__\t * Acc@1 84.7000\tAcc@5 98.4000\n",
            "\n",
            "2021/01/10 21:39:33\tINFO\ttorchdistill.misc.log\tEpoch: [95]  [  0/352]  eta: 0:07:04  lr: 0.010000000000000002  img/s: 254.40441642321844  loss: 0.2153 (0.2153)  time: 1.2057  data: 0.7026  max mem: 700\n",
            "2021/01/10 21:39:45\tINFO\ttorchdistill.misc.log\tEpoch: [95]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1095.784627568161  loss: 0.2169 (0.2176)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:39:57\tINFO\ttorchdistill.misc.log\tEpoch: [95]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1099.8725971634083  loss: 0.2164 (0.2174)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:40:08\tINFO\ttorchdistill.misc.log\tEpoch: [95]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1105.8854917018048  loss: 0.2177 (0.2173)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:40:14\tINFO\ttorchdistill.misc.log\tEpoch: [95] Total time: 0:00:42\n",
            "2021/01/10 21:40:15\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7909  data: 0.7569  max mem: 700\n",
            "2021/01/10 21:40:16\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:40:16\tINFO\t__main__\t * Acc@1 84.7800\tAcc@5 98.3400\n",
            "\n",
            "2021/01/10 21:40:18\tINFO\ttorchdistill.misc.log\tEpoch: [96]  [  0/352]  eta: 0:07:12  lr: 0.010000000000000002  img/s: 220.4084538960506  loss: 0.2192 (0.2192)  time: 1.2282  data: 0.6474  max mem: 700\n",
            "2021/01/10 21:40:29\tINFO\ttorchdistill.misc.log\tEpoch: [96]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1108.5045259332674  loss: 0.2161 (0.2166)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:40:41\tINFO\ttorchdistill.misc.log\tEpoch: [96]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1103.8322922877644  loss: 0.2158 (0.2166)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:40:53\tINFO\ttorchdistill.misc.log\tEpoch: [96]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1107.0439191766727  loss: 0.2159 (0.2166)  time: 0.1176  data: 0.0002  max mem: 700\n",
            "2021/01/10 21:40:59\tINFO\ttorchdistill.misc.log\tEpoch: [96] Total time: 0:00:42\n",
            "2021/01/10 21:40:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7327  data: 0.6995  max mem: 700\n",
            "2021/01/10 21:41:01\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:41:01\tINFO\t__main__\t * Acc@1 84.5600\tAcc@5 98.3600\n",
            "\n",
            "2021/01/10 21:41:02\tINFO\ttorchdistill.misc.log\tEpoch: [97]  [  0/352]  eta: 0:07:08  lr: 0.010000000000000002  img/s: 226.90560401410957  loss: 0.2177 (0.2177)  time: 1.2183  data: 0.6541  max mem: 700\n",
            "2021/01/10 21:41:14\tINFO\ttorchdistill.misc.log\tEpoch: [97]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1111.1819899700508  loss: 0.2152 (0.2161)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:41:25\tINFO\ttorchdistill.misc.log\tEpoch: [97]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1106.3184779002509  loss: 0.2155 (0.2161)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:41:37\tINFO\ttorchdistill.misc.log\tEpoch: [97]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1111.5339792960663  loss: 0.2147 (0.2161)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:41:43\tINFO\ttorchdistill.misc.log\tEpoch: [97] Total time: 0:00:42\n",
            "2021/01/10 21:41:44\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.6822  data: 0.6335  max mem: 700\n",
            "2021/01/10 21:41:45\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:41:45\tINFO\t__main__\t * Acc@1 84.7400\tAcc@5 98.3800\n",
            "\n",
            "2021/01/10 21:41:46\tINFO\ttorchdistill.misc.log\tEpoch: [98]  [  0/352]  eta: 0:06:47  lr: 0.010000000000000002  img/s: 254.1782184592907  loss: 0.2160 (0.2160)  time: 1.1563  data: 0.6527  max mem: 700\n",
            "2021/01/10 21:41:58\tINFO\ttorchdistill.misc.log\tEpoch: [98]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1099.23303815481  loss: 0.2154 (0.2159)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:42:09\tINFO\ttorchdistill.misc.log\tEpoch: [98]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1111.3775120686942  loss: 0.2150 (0.2156)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:42:21\tINFO\ttorchdistill.misc.log\tEpoch: [98]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1114.5106225737477  loss: 0.2138 (0.2155)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:42:27\tINFO\ttorchdistill.misc.log\tEpoch: [98] Total time: 0:00:42\n",
            "2021/01/10 21:42:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.7358  data: 0.6754  max mem: 700\n",
            "2021/01/10 21:42:29\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:42:29\tINFO\t__main__\t * Acc@1 84.5200\tAcc@5 98.4400\n",
            "\n",
            "2021/01/10 21:42:30\tINFO\ttorchdistill.misc.log\tEpoch: [99]  [  0/352]  eta: 0:08:01  lr: 0.010000000000000002  img/s: 219.29872563748762  loss: 0.2148 (0.2148)  time: 1.3689  data: 0.7852  max mem: 700\n",
            "2021/01/10 21:42:42\tINFO\ttorchdistill.misc.log\tEpoch: [99]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1110.3225093945116  loss: 0.2148 (0.2152)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:42:54\tINFO\ttorchdistill.misc.log\tEpoch: [99]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1108.7311620107348  loss: 0.2139 (0.2150)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:43:05\tINFO\ttorchdistill.misc.log\tEpoch: [99]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1109.9391598820741  loss: 0.2145 (0.2149)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:43:11\tINFO\ttorchdistill.misc.log\tEpoch: [99] Total time: 0:00:42\n",
            "2021/01/10 21:43:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.7846  data: 0.7340  max mem: 700\n",
            "2021/01/10 21:43:13\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:43:13\tINFO\t__main__\t * Acc@1 84.5800\tAcc@5 98.4200\n",
            "\n",
            "2021/01/10 21:43:14\tINFO\ttorchdistill.misc.log\tEpoch: [100]  [  0/352]  eta: 0:06:34  lr: 0.010000000000000002  img/s: 255.18764461733565  loss: 0.2147 (0.2147)  time: 1.1195  data: 0.6179  max mem: 700\n",
            "2021/01/10 21:43:26\tINFO\ttorchdistill.misc.log\tEpoch: [100]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1110.0676787183802  loss: 0.2137 (0.2150)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:43:38\tINFO\ttorchdistill.misc.log\tEpoch: [100]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1111.9230372532004  loss: 0.2136 (0.2148)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:43:49\tINFO\ttorchdistill.misc.log\tEpoch: [100]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1110.6073234961304  loss: 0.2141 (0.2147)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:43:55\tINFO\ttorchdistill.misc.log\tEpoch: [100] Total time: 0:00:42\n",
            "2021/01/10 21:43:56\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6739  data: 0.6083  max mem: 700\n",
            "2021/01/10 21:43:57\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:43:57\tINFO\t__main__\t * Acc@1 84.6000\tAcc@5 98.4400\n",
            "\n",
            "2021/01/10 21:43:59\tINFO\ttorchdistill.misc.log\tEpoch: [101]  [  0/352]  eta: 0:07:02  lr: 0.010000000000000002  img/s: 236.9993837417295  loss: 0.2122 (0.2122)  time: 1.2000  data: 0.6599  max mem: 700\n",
            "2021/01/10 21:44:10\tINFO\ttorchdistill.misc.log\tEpoch: [101]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1111.8792834213523  loss: 0.2145 (0.2142)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:44:22\tINFO\ttorchdistill.misc.log\tEpoch: [101]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1089.6153402771577  loss: 0.2135 (0.2144)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:44:34\tINFO\ttorchdistill.misc.log\tEpoch: [101]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1105.8308228164888  loss: 0.2135 (0.2145)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:44:40\tINFO\ttorchdistill.misc.log\tEpoch: [101] Total time: 0:00:42\n",
            "2021/01/10 21:44:40\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.6990  data: 0.6674  max mem: 700\n",
            "2021/01/10 21:44:42\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:44:42\tINFO\t__main__\t * Acc@1 84.7000\tAcc@5 98.3600\n",
            "\n",
            "2021/01/10 21:44:43\tINFO\ttorchdistill.misc.log\tEpoch: [102]  [  0/352]  eta: 0:07:37  lr: 0.010000000000000002  img/s: 290.9987733918723  loss: 0.2160 (0.2160)  time: 1.3006  data: 0.8607  max mem: 700\n",
            "2021/01/10 21:44:54\tINFO\ttorchdistill.misc.log\tEpoch: [102]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1107.7771697638236  loss: 0.2138 (0.2145)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:45:06\tINFO\ttorchdistill.misc.log\tEpoch: [102]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1111.421226418024  loss: 0.2140 (0.2141)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:45:18\tINFO\ttorchdistill.misc.log\tEpoch: [102]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1091.8357256453955  loss: 0.2126 (0.2140)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:45:24\tINFO\ttorchdistill.misc.log\tEpoch: [102] Total time: 0:00:42\n",
            "2021/01/10 21:45:24\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.6663  data: 0.6243  max mem: 700\n",
            "2021/01/10 21:45:26\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:45:26\tINFO\t__main__\t * Acc@1 84.6400\tAcc@5 98.4200\n",
            "\n",
            "2021/01/10 21:45:27\tINFO\ttorchdistill.misc.log\tEpoch: [103]  [  0/352]  eta: 0:06:58  lr: 0.010000000000000002  img/s: 241.19024422677694  loss: 0.2135 (0.2135)  time: 1.1890  data: 0.6582  max mem: 700\n",
            "2021/01/10 21:45:38\tINFO\ttorchdistill.misc.log\tEpoch: [103]  [100/352]  eta: 0:00:31  lr: 0.010000000000000002  img/s: 1113.846999047712  loss: 0.2126 (0.2139)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:45:50\tINFO\ttorchdistill.misc.log\tEpoch: [103]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1111.9783101736305  loss: 0.2139 (0.2139)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:46:02\tINFO\ttorchdistill.misc.log\tEpoch: [103]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1111.0601110085554  loss: 0.2128 (0.2138)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:46:08\tINFO\ttorchdistill.misc.log\tEpoch: [103] Total time: 0:00:42\n",
            "2021/01/10 21:46:08\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 78.9062 (78.9062)  acc5: 99.2188 (99.2188)  time: 0.7860  data: 0.7334  max mem: 700\n",
            "2021/01/10 21:46:10\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:46:10\tINFO\t__main__\t * Acc@1 84.8000\tAcc@5 98.4000\n",
            "\n",
            "2021/01/10 21:46:11\tINFO\ttorchdistill.misc.log\tEpoch: [104]  [  0/352]  eta: 0:06:40  lr: 0.010000000000000002  img/s: 267.4173979659437  loss: 0.2120 (0.2120)  time: 1.1388  data: 0.6601  max mem: 700\n",
            "2021/01/10 21:46:23\tINFO\ttorchdistill.misc.log\tEpoch: [104]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1101.7934861575718  loss: 0.2132 (0.2137)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:46:35\tINFO\ttorchdistill.misc.log\tEpoch: [104]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1105.8809357549092  loss: 0.2129 (0.2136)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:46:46\tINFO\ttorchdistill.misc.log\tEpoch: [104]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1111.927643120028  loss: 0.2137 (0.2136)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:46:52\tINFO\ttorchdistill.misc.log\tEpoch: [104] Total time: 0:00:42\n",
            "2021/01/10 21:46:53\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6703  data: 0.6184  max mem: 700\n",
            "2021/01/10 21:46:54\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:46:54\tINFO\t__main__\t * Acc@1 84.6200\tAcc@5 98.3600\n",
            "\n",
            "2021/01/10 21:46:55\tINFO\ttorchdistill.misc.log\tEpoch: [105]  [  0/352]  eta: 0:06:43  lr: 0.010000000000000002  img/s: 247.80254850274196  loss: 0.2156 (0.2156)  time: 1.1471  data: 0.6305  max mem: 700\n",
            "2021/01/10 21:47:07\tINFO\ttorchdistill.misc.log\tEpoch: [105]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1110.058497814499  loss: 0.2134 (0.2140)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:47:19\tINFO\ttorchdistill.misc.log\tEpoch: [105]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1106.0814329361883  loss: 0.2124 (0.2136)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:47:30\tINFO\ttorchdistill.misc.log\tEpoch: [105]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1098.3335113184194  loss: 0.2130 (0.2136)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:47:36\tINFO\ttorchdistill.misc.log\tEpoch: [105] Total time: 0:00:42\n",
            "2021/01/10 21:47:37\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.6930  data: 0.6425  max mem: 700\n",
            "2021/01/10 21:47:38\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:47:38\tINFO\t__main__\t * Acc@1 84.6000\tAcc@5 98.4200\n",
            "\n",
            "2021/01/10 21:47:39\tINFO\ttorchdistill.misc.log\tEpoch: [106]  [  0/352]  eta: 0:07:07  lr: 0.010000000000000002  img/s: 262.5032757235611  loss: 0.2116 (0.2116)  time: 1.2136  data: 0.7259  max mem: 700\n",
            "2021/01/10 21:47:51\tINFO\ttorchdistill.misc.log\tEpoch: [106]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1110.7382951343345  loss: 0.2133 (0.2136)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:48:03\tINFO\ttorchdistill.misc.log\tEpoch: [106]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1102.9003021892802  loss: 0.2123 (0.2134)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:48:14\tINFO\ttorchdistill.misc.log\tEpoch: [106]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1060.8797182953867  loss: 0.2119 (0.2133)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:48:20\tINFO\ttorchdistill.misc.log\tEpoch: [106] Total time: 0:00:42\n",
            "2021/01/10 21:48:21\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7205  data: 0.6552  max mem: 700\n",
            "2021/01/10 21:48:22\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:48:22\tINFO\t__main__\t * Acc@1 84.8600\tAcc@5 98.1400\n",
            "\n",
            "2021/01/10 21:48:22\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 84.8200 -> 84.8600)\n",
            "2021/01/10 21:48:24\tINFO\ttorchdistill.misc.log\tEpoch: [107]  [  0/352]  eta: 0:07:36  lr: 0.010000000000000002  img/s: 262.77244699481474  loss: 0.2128 (0.2128)  time: 1.2961  data: 0.8089  max mem: 700\n",
            "2021/01/10 21:48:35\tINFO\ttorchdistill.misc.log\tEpoch: [107]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1115.541150925166  loss: 0.2131 (0.2132)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:48:47\tINFO\ttorchdistill.misc.log\tEpoch: [107]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1101.9653608213566  loss: 0.2122 (0.2132)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:48:58\tINFO\ttorchdistill.misc.log\tEpoch: [107]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1105.1001457353873  loss: 0.2123 (0.2131)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:49:05\tINFO\ttorchdistill.misc.log\tEpoch: [107] Total time: 0:00:42\n",
            "2021/01/10 21:49:05\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 75.0000 (75.0000)  acc5: 99.2188 (99.2188)  time: 0.7243  data: 0.6617  max mem: 700\n",
            "2021/01/10 21:49:07\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:49:07\tINFO\t__main__\t * Acc@1 84.5600\tAcc@5 98.3800\n",
            "\n",
            "2021/01/10 21:49:08\tINFO\ttorchdistill.misc.log\tEpoch: [108]  [  0/352]  eta: 0:06:54  lr: 0.010000000000000002  img/s: 238.63527895259705  loss: 0.2111 (0.2111)  time: 1.1774  data: 0.6410  max mem: 700\n",
            "2021/01/10 21:49:20\tINFO\ttorchdistill.misc.log\tEpoch: [108]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1114.827683445708  loss: 0.2120 (0.2132)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:49:31\tINFO\ttorchdistill.misc.log\tEpoch: [108]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1108.3511985251462  loss: 0.2130 (0.2130)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:49:43\tINFO\ttorchdistill.misc.log\tEpoch: [108]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1112.363069782861  loss: 0.2128 (0.2130)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:49:49\tINFO\ttorchdistill.misc.log\tEpoch: [108] Total time: 0:00:42\n",
            "2021/01/10 21:49:50\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:38  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.9742  data: 0.9246  max mem: 700\n",
            "2021/01/10 21:49:51\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:49:51\tINFO\t__main__\t * Acc@1 84.5400\tAcc@5 98.3400\n",
            "\n",
            "2021/01/10 21:49:52\tINFO\ttorchdistill.misc.log\tEpoch: [109]  [  0/352]  eta: 0:07:44  lr: 0.010000000000000002  img/s: 281.3308166424395  loss: 0.2125 (0.2125)  time: 1.3203  data: 0.8652  max mem: 700\n",
            "2021/01/10 21:50:04\tINFO\ttorchdistill.misc.log\tEpoch: [109]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1110.4763827410748  loss: 0.2122 (0.2127)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:50:16\tINFO\ttorchdistill.misc.log\tEpoch: [109]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1107.470959543868  loss: 0.2121 (0.2128)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:50:27\tINFO\ttorchdistill.misc.log\tEpoch: [109]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1106.3047994675271  loss: 0.2128 (0.2128)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:50:33\tINFO\ttorchdistill.misc.log\tEpoch: [109] Total time: 0:00:42\n",
            "2021/01/10 21:50:34\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 78.9062 (78.9062)  acc5: 99.2188 (99.2188)  time: 0.7407  data: 0.7086  max mem: 700\n",
            "2021/01/10 21:50:35\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:50:35\tINFO\t__main__\t * Acc@1 84.7600\tAcc@5 98.3400\n",
            "\n",
            "2021/01/10 21:50:36\tINFO\ttorchdistill.misc.log\tEpoch: [110]  [  0/352]  eta: 0:06:54  lr: 0.010000000000000002  img/s: 247.42236904200095  loss: 0.2108 (0.2108)  time: 1.1789  data: 0.6616  max mem: 700\n",
            "2021/01/10 21:50:48\tINFO\ttorchdistill.misc.log\tEpoch: [110]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1108.4015401608292  loss: 0.2121 (0.2128)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:51:00\tINFO\ttorchdistill.misc.log\tEpoch: [110]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1106.8019997319948  loss: 0.2116 (0.2127)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:51:11\tINFO\ttorchdistill.misc.log\tEpoch: [110]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1112.515203885829  loss: 0.2126 (0.2127)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:51:17\tINFO\ttorchdistill.misc.log\tEpoch: [110] Total time: 0:00:42\n",
            "2021/01/10 21:51:18\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:34  acc1: 76.5625 (76.5625)  acc5: 98.4375 (98.4375)  time: 0.8619  data: 0.8081  max mem: 700\n",
            "2021/01/10 21:51:20\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:51:20\tINFO\t__main__\t * Acc@1 84.3000\tAcc@5 98.2800\n",
            "\n",
            "2021/01/10 21:51:21\tINFO\ttorchdistill.misc.log\tEpoch: [111]  [  0/352]  eta: 0:07:08  lr: 0.010000000000000002  img/s: 226.40028169786217  loss: 0.2139 (0.2139)  time: 1.2171  data: 0.6517  max mem: 700\n",
            "2021/01/10 21:51:32\tINFO\ttorchdistill.misc.log\tEpoch: [111]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1109.484992518992  loss: 0.2120 (0.2128)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:51:44\tINFO\ttorchdistill.misc.log\tEpoch: [111]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1110.1204718629488  loss: 0.2128 (0.2128)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:51:56\tINFO\ttorchdistill.misc.log\tEpoch: [111]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1108.0629663187572  loss: 0.2121 (0.2127)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:52:02\tINFO\ttorchdistill.misc.log\tEpoch: [111] Total time: 0:00:42\n",
            "2021/01/10 21:52:02\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:25  acc1: 75.0000 (75.0000)  acc5: 99.2188 (99.2188)  time: 0.6481  data: 0.6222  max mem: 700\n",
            "2021/01/10 21:52:04\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:52:04\tINFO\t__main__\t * Acc@1 84.7000\tAcc@5 98.3400\n",
            "\n",
            "2021/01/10 21:52:05\tINFO\ttorchdistill.misc.log\tEpoch: [112]  [  0/352]  eta: 0:06:45  lr: 0.010000000000000002  img/s: 267.34548844361535  loss: 0.2114 (0.2114)  time: 1.1526  data: 0.6738  max mem: 700\n",
            "2021/01/10 21:52:16\tINFO\ttorchdistill.misc.log\tEpoch: [112]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1113.0895392111129  loss: 0.2121 (0.2126)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:52:28\tINFO\ttorchdistill.misc.log\tEpoch: [112]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1108.9212414642107  loss: 0.2126 (0.2127)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:52:40\tINFO\ttorchdistill.misc.log\tEpoch: [112]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1096.5343877844884  loss: 0.2118 (0.2127)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:52:46\tINFO\ttorchdistill.misc.log\tEpoch: [112] Total time: 0:00:42\n",
            "2021/01/10 21:52:46\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 78.1250 (78.1250)  acc5: 98.4375 (98.4375)  time: 0.7016  data: 0.6767  max mem: 700\n",
            "2021/01/10 21:52:48\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:52:48\tINFO\t__main__\t * Acc@1 84.7000\tAcc@5 98.2800\n",
            "\n",
            "2021/01/10 21:52:49\tINFO\ttorchdistill.misc.log\tEpoch: [113]  [  0/352]  eta: 0:07:49  lr: 0.010000000000000002  img/s: 214.97684218787728  loss: 0.2127 (0.2127)  time: 1.3324  data: 0.7370  max mem: 700\n",
            "2021/01/10 21:53:01\tINFO\ttorchdistill.misc.log\tEpoch: [113]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1103.802789159983  loss: 0.2121 (0.2123)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:53:12\tINFO\ttorchdistill.misc.log\tEpoch: [113]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1093.6617796546295  loss: 0.2117 (0.2123)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:53:24\tINFO\ttorchdistill.misc.log\tEpoch: [113]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1110.5177291174537  loss: 0.2114 (0.2122)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:53:30\tINFO\ttorchdistill.misc.log\tEpoch: [113] Total time: 0:00:42\n",
            "2021/01/10 21:53:31\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.6983  data: 0.6646  max mem: 700\n",
            "2021/01/10 21:53:32\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:53:32\tINFO\t__main__\t * Acc@1 84.5800\tAcc@5 98.1800\n",
            "\n",
            "2021/01/10 21:53:33\tINFO\ttorchdistill.misc.log\tEpoch: [114]  [  0/352]  eta: 0:07:26  lr: 0.010000000000000002  img/s: 249.29415239110608  loss: 0.2159 (0.2159)  time: 1.2687  data: 0.7552  max mem: 700\n",
            "2021/01/10 21:53:45\tINFO\ttorchdistill.misc.log\tEpoch: [114]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1110.0791550617928  loss: 0.2119 (0.2122)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:53:56\tINFO\ttorchdistill.misc.log\tEpoch: [114]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1107.9486300027036  loss: 0.2120 (0.2122)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:54:08\tINFO\ttorchdistill.misc.log\tEpoch: [114]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1105.6509092406861  loss: 0.2127 (0.2123)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:54:14\tINFO\ttorchdistill.misc.log\tEpoch: [114] Total time: 0:00:42\n",
            "2021/01/10 21:54:15\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7167  data: 0.6592  max mem: 700\n",
            "2021/01/10 21:54:16\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:54:16\tINFO\t__main__\t * Acc@1 84.6400\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 21:54:17\tINFO\ttorchdistill.misc.log\tEpoch: [115]  [  0/352]  eta: 0:06:52  lr: 0.010000000000000002  img/s: 238.3960092592716  loss: 0.2107 (0.2107)  time: 1.1717  data: 0.6347  max mem: 700\n",
            "2021/01/10 21:54:29\tINFO\ttorchdistill.misc.log\tEpoch: [115]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1108.5319920381246  loss: 0.2113 (0.2119)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:54:41\tINFO\ttorchdistill.misc.log\tEpoch: [115]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1091.4051245354822  loss: 0.2127 (0.2121)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:54:52\tINFO\ttorchdistill.misc.log\tEpoch: [115]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1107.2265699277552  loss: 0.2120 (0.2120)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:54:58\tINFO\ttorchdistill.misc.log\tEpoch: [115] Total time: 0:00:42\n",
            "2021/01/10 21:54:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 78.9062 (78.9062)  acc5: 99.2188 (99.2188)  time: 0.7671  data: 0.7474  max mem: 700\n",
            "2021/01/10 21:55:00\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:55:00\tINFO\t__main__\t * Acc@1 84.6600\tAcc@5 98.3200\n",
            "\n",
            "2021/01/10 21:55:02\tINFO\ttorchdistill.misc.log\tEpoch: [116]  [  0/352]  eta: 0:06:46  lr: 0.010000000000000002  img/s: 253.7506520171174  loss: 0.2117 (0.2117)  time: 1.1536  data: 0.6492  max mem: 700\n",
            "2021/01/10 21:55:13\tINFO\ttorchdistill.misc.log\tEpoch: [116]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1111.6030229620887  loss: 0.2114 (0.2120)  time: 0.1167  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:55:25\tINFO\ttorchdistill.misc.log\tEpoch: [116]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1107.2425547360954  loss: 0.2123 (0.2122)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:55:36\tINFO\ttorchdistill.misc.log\tEpoch: [116]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1112.4345215277792  loss: 0.2121 (0.2122)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:55:43\tINFO\ttorchdistill.misc.log\tEpoch: [116] Total time: 0:00:42\n",
            "2021/01/10 21:55:43\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.8143  data: 0.7703  max mem: 700\n",
            "2021/01/10 21:55:45\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:55:45\tINFO\t__main__\t * Acc@1 84.5400\tAcc@5 98.2800\n",
            "\n",
            "2021/01/10 21:55:46\tINFO\ttorchdistill.misc.log\tEpoch: [117]  [  0/352]  eta: 0:07:36  lr: 0.010000000000000002  img/s: 289.6815714984077  loss: 0.2137 (0.2137)  time: 1.2976  data: 0.8557  max mem: 700\n",
            "2021/01/10 21:55:57\tINFO\ttorchdistill.misc.log\tEpoch: [117]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1113.059539161335  loss: 0.2111 (0.2117)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:56:09\tINFO\ttorchdistill.misc.log\tEpoch: [117]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1106.4849259280631  loss: 0.2119 (0.2118)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:56:21\tINFO\ttorchdistill.misc.log\tEpoch: [117]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1106.6765171503957  loss: 0.2124 (0.2120)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:56:27\tINFO\ttorchdistill.misc.log\tEpoch: [117] Total time: 0:00:42\n",
            "2021/01/10 21:56:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 78.9062 (78.9062)  acc5: 99.2188 (99.2188)  time: 0.7826  data: 0.7417  max mem: 700\n",
            "2021/01/10 21:56:29\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:56:29\tINFO\t__main__\t * Acc@1 84.5400\tAcc@5 98.3400\n",
            "\n",
            "2021/01/10 21:56:30\tINFO\ttorchdistill.misc.log\tEpoch: [118]  [  0/352]  eta: 0:07:40  lr: 0.010000000000000002  img/s: 285.34333249534546  loss: 0.2116 (0.2116)  time: 1.3088  data: 0.8602  max mem: 700\n",
            "2021/01/10 21:56:42\tINFO\ttorchdistill.misc.log\tEpoch: [118]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1097.4735929744802  loss: 0.2117 (0.2120)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:56:53\tINFO\ttorchdistill.misc.log\tEpoch: [118]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1110.526917619219  loss: 0.2118 (0.2120)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:57:05\tINFO\ttorchdistill.misc.log\tEpoch: [118]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1113.442738275968  loss: 0.2112 (0.2120)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:57:11\tINFO\ttorchdistill.misc.log\tEpoch: [118] Total time: 0:00:42\n",
            "2021/01/10 21:57:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.7017  data: 0.6503  max mem: 700\n",
            "2021/01/10 21:57:13\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:57:13\tINFO\t__main__\t * Acc@1 84.6600\tAcc@5 98.3800\n",
            "\n",
            "2021/01/10 21:57:14\tINFO\ttorchdistill.misc.log\tEpoch: [119]  [  0/352]  eta: 0:06:47  lr: 0.010000000000000002  img/s: 263.69811928700886  loss: 0.2082 (0.2082)  time: 1.1588  data: 0.6734  max mem: 700\n",
            "2021/01/10 21:57:26\tINFO\ttorchdistill.misc.log\tEpoch: [119]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1094.0361954251364  loss: 0.2112 (0.2118)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:57:37\tINFO\ttorchdistill.misc.log\tEpoch: [119]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1108.3306055376179  loss: 0.2114 (0.2118)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:57:49\tINFO\ttorchdistill.misc.log\tEpoch: [119]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1112.363069782861  loss: 0.2110 (0.2119)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:57:55\tINFO\ttorchdistill.misc.log\tEpoch: [119] Total time: 0:00:42\n",
            "2021/01/10 21:57:56\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 75.0000 (75.0000)  acc5: 99.2188 (99.2188)  time: 0.7666  data: 0.7372  max mem: 700\n",
            "2021/01/10 21:57:57\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 21:57:57\tINFO\t__main__\t * Acc@1 84.4800\tAcc@5 98.2200\n",
            "\n",
            "2021/01/10 21:57:58\tINFO\ttorchdistill.misc.log\tEpoch: [120]  [  0/352]  eta: 0:07:27  lr: 0.010000000000000002  img/s: 239.70800919949974  loss: 0.2135 (0.2135)  time: 1.2714  data: 0.7374  max mem: 700\n",
            "2021/01/10 21:58:10\tINFO\ttorchdistill.misc.log\tEpoch: [120]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1117.2706900857404  loss: 0.2120 (0.2119)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:58:21\tINFO\ttorchdistill.misc.log\tEpoch: [120]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1107.918906425411  loss: 0.2115 (0.2118)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:58:33\tINFO\ttorchdistill.misc.log\tEpoch: [120]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1109.2236707809407  loss: 0.2112 (0.2118)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:58:39\tINFO\ttorchdistill.misc.log\tEpoch: [120] Total time: 0:00:42\n",
            "2021/01/10 21:58:40\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:37  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.9259  data: 0.8824  max mem: 700\n",
            "2021/01/10 21:58:41\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:58:41\tINFO\t__main__\t * Acc@1 84.6200\tAcc@5 98.3200\n",
            "\n",
            "2021/01/10 21:58:42\tINFO\ttorchdistill.misc.log\tEpoch: [121]  [  0/352]  eta: 0:07:37  lr: 0.010000000000000002  img/s: 295.288879013003  loss: 0.2099 (0.2099)  time: 1.3000  data: 0.8665  max mem: 700\n",
            "2021/01/10 21:58:54\tINFO\ttorchdistill.misc.log\tEpoch: [121]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1114.1081920130155  loss: 0.2115 (0.2117)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:59:06\tINFO\ttorchdistill.misc.log\tEpoch: [121]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1113.3780837826628  loss: 0.2107 (0.2116)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:59:17\tINFO\ttorchdistill.misc.log\tEpoch: [121]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1110.9796395587296  loss: 0.2114 (0.2116)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:59:23\tINFO\ttorchdistill.misc.log\tEpoch: [121] Total time: 0:00:42\n",
            "2021/01/10 21:59:24\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 75.0000 (75.0000)  acc5: 99.2188 (99.2188)  time: 0.7021  data: 0.6545  max mem: 700\n",
            "2021/01/10 21:59:25\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 21:59:25\tINFO\t__main__\t * Acc@1 84.4400\tAcc@5 98.2800\n",
            "\n",
            "2021/01/10 21:59:26\tINFO\ttorchdistill.misc.log\tEpoch: [122]  [  0/352]  eta: 0:07:42  lr: 0.010000000000000002  img/s: 273.13501710429654  loss: 0.2087 (0.2087)  time: 1.3152  data: 0.8465  max mem: 700\n",
            "2021/01/10 21:59:38\tINFO\ttorchdistill.misc.log\tEpoch: [122]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1118.15726695811  loss: 0.2112 (0.2116)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 21:59:50\tINFO\ttorchdistill.misc.log\tEpoch: [122]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1106.0518094578838  loss: 0.2115 (0.2116)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:00:01\tINFO\ttorchdistill.misc.log\tEpoch: [122]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1102.732665783447  loss: 0.2123 (0.2116)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:00:07\tINFO\ttorchdistill.misc.log\tEpoch: [122] Total time: 0:00:42\n",
            "2021/01/10 22:00:08\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7483  data: 0.7152  max mem: 700\n",
            "2021/01/10 22:00:09\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:00:09\tINFO\t__main__\t * Acc@1 84.4000\tAcc@5 98.2400\n",
            "\n",
            "2021/01/10 22:00:10\tINFO\ttorchdistill.misc.log\tEpoch: [123]  [  0/352]  eta: 0:07:10  lr: 0.010000000000000002  img/s: 278.3523138868467  loss: 0.2099 (0.2099)  time: 1.2221  data: 0.7622  max mem: 700\n",
            "2021/01/10 22:00:22\tINFO\ttorchdistill.misc.log\tEpoch: [123]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1093.1295700544863  loss: 0.2118 (0.2116)  time: 0.1168  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:00:34\tINFO\ttorchdistill.misc.log\tEpoch: [123]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1105.0910468160785  loss: 0.2113 (0.2116)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:00:45\tINFO\ttorchdistill.misc.log\tEpoch: [123]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1111.7940884720442  loss: 0.2120 (0.2116)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:00:51\tINFO\ttorchdistill.misc.log\tEpoch: [123] Total time: 0:00:42\n",
            "2021/01/10 22:00:52\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7182  data: 0.6585  max mem: 700\n",
            "2021/01/10 22:00:54\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:00:54\tINFO\t__main__\t * Acc@1 84.5400\tAcc@5 98.3200\n",
            "\n",
            "2021/01/10 22:00:55\tINFO\ttorchdistill.misc.log\tEpoch: [124]  [  0/352]  eta: 0:06:43  lr: 0.010000000000000002  img/s: 245.19557427467228  loss: 0.2152 (0.2152)  time: 1.1474  data: 0.6253  max mem: 700\n",
            "2021/01/10 22:01:06\tINFO\ttorchdistill.misc.log\tEpoch: [124]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1096.5523050496427  loss: 0.2111 (0.2114)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:01:18\tINFO\ttorchdistill.misc.log\tEpoch: [124]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1099.6675870318631  loss: 0.2113 (0.2113)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:01:30\tINFO\ttorchdistill.misc.log\tEpoch: [124]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1105.849045177689  loss: 0.2109 (0.2115)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:01:36\tINFO\ttorchdistill.misc.log\tEpoch: [124] Total time: 0:00:42\n",
            "2021/01/10 22:01:36\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 78.1250 (78.1250)  acc5: 98.4375 (98.4375)  time: 0.7398  data: 0.6485  max mem: 700\n",
            "2021/01/10 22:01:38\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:01:38\tINFO\t__main__\t * Acc@1 84.6400\tAcc@5 98.2600\n",
            "\n",
            "2021/01/10 22:01:39\tINFO\ttorchdistill.misc.log\tEpoch: [125]  [  0/352]  eta: 0:06:37  lr: 0.010000000000000002  img/s: 273.7626024816912  loss: 0.2133 (0.2133)  time: 1.1296  data: 0.6620  max mem: 700\n",
            "2021/01/10 22:01:51\tINFO\ttorchdistill.misc.log\tEpoch: [125]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1112.0451056179031  loss: 0.2112 (0.2114)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:02:02\tINFO\ttorchdistill.misc.log\tEpoch: [125]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1105.6873427054456  loss: 0.2106 (0.2115)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:02:14\tINFO\ttorchdistill.misc.log\tEpoch: [125]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1104.3954233710879  loss: 0.2109 (0.2115)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:02:20\tINFO\ttorchdistill.misc.log\tEpoch: [125] Total time: 0:00:42\n",
            "2021/01/10 22:02:21\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 78.9062 (78.9062)  acc5: 99.2188 (99.2188)  time: 0.7426  data: 0.6940  max mem: 700\n",
            "2021/01/10 22:02:22\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:02:22\tINFO\t__main__\t * Acc@1 84.5800\tAcc@5 98.3200\n",
            "\n",
            "2021/01/10 22:02:23\tINFO\ttorchdistill.misc.log\tEpoch: [126]  [  0/352]  eta: 0:07:10  lr: 0.010000000000000002  img/s: 245.7996438939813  loss: 0.2123 (0.2123)  time: 1.2229  data: 0.7021  max mem: 700\n",
            "2021/01/10 22:02:35\tINFO\ttorchdistill.misc.log\tEpoch: [126]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1119.6263511216682  loss: 0.2116 (0.2113)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:02:46\tINFO\ttorchdistill.misc.log\tEpoch: [126]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1111.2440895335792  loss: 0.2103 (0.2114)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:02:58\tINFO\ttorchdistill.misc.log\tEpoch: [126]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1103.1405188267324  loss: 0.2117 (0.2114)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:03:04\tINFO\ttorchdistill.misc.log\tEpoch: [126] Total time: 0:00:42\n",
            "2021/01/10 22:03:05\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 78.9062 (78.9062)  acc5: 98.4375 (98.4375)  time: 0.6824  data: 0.6382  max mem: 700\n",
            "2021/01/10 22:03:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:03:06\tINFO\t__main__\t * Acc@1 84.5000\tAcc@5 98.2400\n",
            "\n",
            "2021/01/10 22:03:07\tINFO\ttorchdistill.misc.log\tEpoch: [127]  [  0/352]  eta: 0:07:14  lr: 0.010000000000000002  img/s: 274.9004267869624  loss: 0.2129 (0.2129)  time: 1.2343  data: 0.7687  max mem: 700\n",
            "2021/01/10 22:03:19\tINFO\ttorchdistill.misc.log\tEpoch: [127]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1111.7273231783581  loss: 0.2115 (0.2113)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:03:31\tINFO\ttorchdistill.misc.log\tEpoch: [127]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1114.6656590046985  loss: 0.2108 (0.2113)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:03:42\tINFO\ttorchdistill.misc.log\tEpoch: [127]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1113.276499033684  loss: 0.2105 (0.2113)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:03:48\tINFO\ttorchdistill.misc.log\tEpoch: [127] Total time: 0:00:42\n",
            "2021/01/10 22:03:49\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.6755  data: 0.6239  max mem: 700\n",
            "2021/01/10 22:03:50\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:03:50\tINFO\t__main__\t * Acc@1 84.5000\tAcc@5 98.4000\n",
            "\n",
            "2021/01/10 22:03:51\tINFO\ttorchdistill.misc.log\tEpoch: [128]  [  0/352]  eta: 0:06:53  lr: 0.010000000000000002  img/s: 245.43332231589332  loss: 0.2107 (0.2107)  time: 1.1756  data: 0.6540  max mem: 700\n",
            "2021/01/10 22:04:03\tINFO\ttorchdistill.misc.log\tEpoch: [128]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1110.70382591893  loss: 0.2110 (0.2113)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:04:15\tINFO\ttorchdistill.misc.log\tEpoch: [128]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1105.1501924699974  loss: 0.2118 (0.2114)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:04:26\tINFO\ttorchdistill.misc.log\tEpoch: [128]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1110.8210299807577  loss: 0.2110 (0.2113)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:04:32\tINFO\ttorchdistill.misc.log\tEpoch: [128] Total time: 0:00:42\n",
            "2021/01/10 22:04:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6849  data: 0.6321  max mem: 700\n",
            "2021/01/10 22:04:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:04:34\tINFO\t__main__\t * Acc@1 84.4400\tAcc@5 98.1800\n",
            "\n",
            "2021/01/10 22:04:35\tINFO\ttorchdistill.misc.log\tEpoch: [129]  [  0/352]  eta: 0:07:40  lr: 0.010000000000000002  img/s: 269.99630463710713  loss: 0.2093 (0.2093)  time: 1.3086  data: 0.8345  max mem: 700\n",
            "2021/01/10 22:04:47\tINFO\ttorchdistill.misc.log\tEpoch: [129]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1112.8149837079536  loss: 0.2107 (0.2109)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:04:59\tINFO\ttorchdistill.misc.log\tEpoch: [129]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1107.9051883891684  loss: 0.2110 (0.2112)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:05:10\tINFO\ttorchdistill.misc.log\tEpoch: [129]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1108.4724838644406  loss: 0.2111 (0.2112)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:05:16\tINFO\ttorchdistill.misc.log\tEpoch: [129] Total time: 0:00:42\n",
            "2021/01/10 22:05:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7903  data: 0.7513  max mem: 700\n",
            "2021/01/10 22:05:18\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:05:18\tINFO\t__main__\t * Acc@1 84.3600\tAcc@5 98.1600\n",
            "\n",
            "2021/01/10 22:05:20\tINFO\ttorchdistill.misc.log\tEpoch: [130]  [  0/352]  eta: 0:07:15  lr: 0.010000000000000002  img/s: 289.72721964445105  loss: 0.2096 (0.2096)  time: 1.2362  data: 0.7944  max mem: 700\n",
            "2021/01/10 22:05:31\tINFO\ttorchdistill.misc.log\tEpoch: [130]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1110.8049416842362  loss: 0.2106 (0.2108)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:05:43\tINFO\ttorchdistill.misc.log\tEpoch: [130]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1110.453413862287  loss: 0.2113 (0.2111)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:05:54\tINFO\ttorchdistill.misc.log\tEpoch: [130]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1102.3002180492192  loss: 0.2107 (0.2111)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:06:01\tINFO\ttorchdistill.misc.log\tEpoch: [130] Total time: 0:00:42\n",
            "2021/01/10 22:06:01\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.6903  data: 0.6518  max mem: 700\n",
            "2021/01/10 22:06:03\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:06:03\tINFO\t__main__\t * Acc@1 84.3800\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:06:04\tINFO\ttorchdistill.misc.log\tEpoch: [131]  [  0/352]  eta: 0:07:30  lr: 0.010000000000000002  img/s: 293.02829521866965  loss: 0.2140 (0.2140)  time: 1.2785  data: 0.8417  max mem: 700\n",
            "2021/01/10 22:06:15\tINFO\ttorchdistill.misc.log\tEpoch: [131]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1109.3451471527194  loss: 0.2108 (0.2113)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:06:27\tINFO\ttorchdistill.misc.log\tEpoch: [131]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1114.0342134313864  loss: 0.2113 (0.2113)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:06:39\tINFO\ttorchdistill.misc.log\tEpoch: [131]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1099.4716597822237  loss: 0.2102 (0.2112)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:06:45\tINFO\ttorchdistill.misc.log\tEpoch: [131] Total time: 0:00:42\n",
            "2021/01/10 22:06:45\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6720  data: 0.6310  max mem: 700\n",
            "2021/01/10 22:06:47\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:06:47\tINFO\t__main__\t * Acc@1 84.2200\tAcc@5 98.3600\n",
            "\n",
            "2021/01/10 22:06:48\tINFO\ttorchdistill.misc.log\tEpoch: [132]  [  0/352]  eta: 0:07:58  lr: 0.010000000000000002  img/s: 323.07523144247756  loss: 0.2129 (0.2129)  time: 1.3598  data: 0.9636  max mem: 700\n",
            "2021/01/10 22:07:00\tINFO\ttorchdistill.misc.log\tEpoch: [132]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1116.1859093904825  loss: 0.2108 (0.2110)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:07:11\tINFO\ttorchdistill.misc.log\tEpoch: [132]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1111.1083994743215  loss: 0.2108 (0.2111)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:07:23\tINFO\ttorchdistill.misc.log\tEpoch: [132]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1113.1218487656304  loss: 0.2110 (0.2111)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:07:29\tINFO\ttorchdistill.misc.log\tEpoch: [132] Total time: 0:00:42\n",
            "2021/01/10 22:07:30\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.8099  data: 0.7742  max mem: 700\n",
            "2021/01/10 22:07:31\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:07:31\tINFO\t__main__\t * Acc@1 84.4200\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:07:32\tINFO\ttorchdistill.misc.log\tEpoch: [133]  [  0/352]  eta: 0:06:31  lr: 0.010000000000000002  img/s: 269.760519672632  loss: 0.2120 (0.2120)  time: 1.1109  data: 0.6363  max mem: 700\n",
            "2021/01/10 22:07:44\tINFO\ttorchdistill.misc.log\tEpoch: [133]  [100/352]  eta: 0:00:31  lr: 0.010000000000000002  img/s: 1112.7665467961406  loss: 0.2114 (0.2109)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:07:55\tINFO\ttorchdistill.misc.log\tEpoch: [133]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1104.4158703840465  loss: 0.2118 (0.2109)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:08:07\tINFO\ttorchdistill.misc.log\tEpoch: [133]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1111.4695462788907  loss: 0.2103 (0.2109)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:08:13\tINFO\ttorchdistill.misc.log\tEpoch: [133] Total time: 0:00:42\n",
            "2021/01/10 22:08:14\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:25  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6493  data: 0.6069  max mem: 700\n",
            "2021/01/10 22:08:15\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:08:15\tINFO\t__main__\t * Acc@1 84.6000\tAcc@5 98.1400\n",
            "\n",
            "2021/01/10 22:08:16\tINFO\ttorchdistill.misc.log\tEpoch: [134]  [  0/352]  eta: 0:06:56  lr: 0.010000000000000002  img/s: 238.9228672119453  loss: 0.2123 (0.2123)  time: 1.1829  data: 0.6471  max mem: 700\n",
            "2021/01/10 22:08:28\tINFO\ttorchdistill.misc.log\tEpoch: [134]  [100/352]  eta: 0:00:32  lr: 0.010000000000000002  img/s: 1115.7521229326605  loss: 0.2107 (0.2113)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:08:39\tINFO\ttorchdistill.misc.log\tEpoch: [134]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1114.1012561036093  loss: 0.2107 (0.2111)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:08:51\tINFO\ttorchdistill.misc.log\tEpoch: [134]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1111.5638971649341  loss: 0.2109 (0.2110)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:08:57\tINFO\ttorchdistill.misc.log\tEpoch: [134] Total time: 0:00:41\n",
            "2021/01/10 22:08:58\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.8115  data: 0.7763  max mem: 700\n",
            "2021/01/10 22:08:59\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:08:59\tINFO\t__main__\t * Acc@1 84.3000\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 22:09:00\tINFO\ttorchdistill.misc.log\tEpoch: [135]  [  0/352]  eta: 0:06:48  lr: 0.010000000000000002  img/s: 248.2472452726891  loss: 0.2120 (0.2120)  time: 1.1600  data: 0.6444  max mem: 700\n",
            "2021/01/10 22:09:12\tINFO\ttorchdistill.misc.log\tEpoch: [135]  [100/352]  eta: 0:00:31  lr: 0.010000000000000002  img/s: 1109.8519676184333  loss: 0.2105 (0.2107)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:09:23\tINFO\ttorchdistill.misc.log\tEpoch: [135]  [200/352]  eta: 0:00:18  lr: 0.010000000000000002  img/s: 1110.2421447508282  loss: 0.2110 (0.2110)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:09:35\tINFO\ttorchdistill.misc.log\tEpoch: [135]  [300/352]  eta: 0:00:06  lr: 0.010000000000000002  img/s: 1100.7994750979065  loss: 0.2104 (0.2109)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:09:41\tINFO\ttorchdistill.misc.log\tEpoch: [135] Total time: 0:00:42\n",
            "2021/01/10 22:09:42\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7364  data: 0.7062  max mem: 700\n",
            "2021/01/10 22:09:43\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:09:43\tINFO\t__main__\t * Acc@1 84.3000\tAcc@5 98.3200\n",
            "\n",
            "2021/01/10 22:09:44\tINFO\ttorchdistill.misc.log\tEpoch: [136]  [  0/352]  eta: 0:06:59  lr: 0.0010000000000000002  img/s: 266.5048945439238  loss: 0.2140 (0.2140)  time: 1.1905  data: 0.7102  max mem: 700\n",
            "2021/01/10 22:09:56\tINFO\ttorchdistill.misc.log\tEpoch: [136]  [100/352]  eta: 0:00:31  lr: 0.0010000000000000002  img/s: 1102.5356449022677  loss: 0.2106 (0.2108)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:10:07\tINFO\ttorchdistill.misc.log\tEpoch: [136]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1111.5109666466533  loss: 0.2105 (0.2108)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:10:19\tINFO\ttorchdistill.misc.log\tEpoch: [136]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1115.3372099062435  loss: 0.2115 (0.2109)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:10:25\tINFO\ttorchdistill.misc.log\tEpoch: [136] Total time: 0:00:42\n",
            "2021/01/10 22:10:25\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.6875  data: 0.6412  max mem: 700\n",
            "2021/01/10 22:10:27\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:10:27\tINFO\t__main__\t * Acc@1 84.4600\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 22:10:28\tINFO\ttorchdistill.misc.log\tEpoch: [137]  [  0/352]  eta: 0:07:16  lr: 0.0010000000000000002  img/s: 251.7845650372398  loss: 0.2119 (0.2119)  time: 1.2413  data: 0.7329  max mem: 700\n",
            "2021/01/10 22:10:40\tINFO\ttorchdistill.misc.log\tEpoch: [137]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1112.9972365325013  loss: 0.2106 (0.2106)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:10:51\tINFO\ttorchdistill.misc.log\tEpoch: [137]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1108.3328936095543  loss: 0.2099 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:11:03\tINFO\ttorchdistill.misc.log\tEpoch: [137]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1102.7009565201317  loss: 0.2102 (0.2108)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:11:09\tINFO\ttorchdistill.misc.log\tEpoch: [137] Total time: 0:00:42\n",
            "2021/01/10 22:11:10\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6622  data: 0.6220  max mem: 700\n",
            "2021/01/10 22:11:11\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:11:11\tINFO\t__main__\t * Acc@1 84.2600\tAcc@5 98.1000\n",
            "\n",
            "2021/01/10 22:11:12\tINFO\ttorchdistill.misc.log\tEpoch: [138]  [  0/352]  eta: 0:07:17  lr: 0.0010000000000000002  img/s: 277.5687158093487  loss: 0.2108 (0.2108)  time: 1.2426  data: 0.7814  max mem: 700\n",
            "2021/01/10 22:11:24\tINFO\ttorchdistill.misc.log\tEpoch: [138]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1102.8708488600928  loss: 0.2105 (0.2107)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:11:35\tINFO\ttorchdistill.misc.log\tEpoch: [138]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1107.2105855809407  loss: 0.2113 (0.2109)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:11:47\tINFO\ttorchdistill.misc.log\tEpoch: [138]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1100.5016214266095  loss: 0.2103 (0.2109)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:11:53\tINFO\ttorchdistill.misc.log\tEpoch: [138] Total time: 0:00:42\n",
            "2021/01/10 22:11:54\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7836  data: 0.7397  max mem: 700\n",
            "2021/01/10 22:11:55\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:11:55\tINFO\t__main__\t * Acc@1 84.3000\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:11:56\tINFO\ttorchdistill.misc.log\tEpoch: [139]  [  0/352]  eta: 0:07:45  lr: 0.0010000000000000002  img/s: 340.2816789998257  loss: 0.2119 (0.2119)  time: 1.3215  data: 0.9454  max mem: 700\n",
            "2021/01/10 22:12:08\tINFO\ttorchdistill.misc.log\tEpoch: [139]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1100.7498216233505  loss: 0.2102 (0.2112)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:12:19\tINFO\ttorchdistill.misc.log\tEpoch: [139]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1110.143426970358  loss: 0.2105 (0.2109)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:12:31\tINFO\ttorchdistill.misc.log\tEpoch: [139]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1110.6211085298419  loss: 0.2111 (0.2109)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:12:37\tINFO\ttorchdistill.misc.log\tEpoch: [139] Total time: 0:00:42\n",
            "2021/01/10 22:12:38\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.7197  data: 0.6818  max mem: 700\n",
            "2021/01/10 22:12:39\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:12:39\tINFO\t__main__\t * Acc@1 84.5000\tAcc@5 98.3200\n",
            "\n",
            "2021/01/10 22:12:40\tINFO\ttorchdistill.misc.log\tEpoch: [140]  [  0/352]  eta: 0:08:02  lr: 0.0010000000000000002  img/s: 281.53248811327353  loss: 0.2096 (0.2096)  time: 1.3711  data: 0.9164  max mem: 700\n",
            "2021/01/10 22:12:52\tINFO\ttorchdistill.misc.log\tEpoch: [140]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1110.4809766308551  loss: 0.2104 (0.2107)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:13:04\tINFO\ttorchdistill.misc.log\tEpoch: [140]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1107.2105855809407  loss: 0.2102 (0.2109)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:13:15\tINFO\ttorchdistill.misc.log\tEpoch: [140]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1114.8114788820133  loss: 0.2103 (0.2109)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:13:21\tINFO\ttorchdistill.misc.log\tEpoch: [140] Total time: 0:00:42\n",
            "2021/01/10 22:13:22\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7761  data: 0.7433  max mem: 700\n",
            "2021/01/10 22:13:23\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:13:23\tINFO\t__main__\t * Acc@1 84.4200\tAcc@5 98.1400\n",
            "\n",
            "2021/01/10 22:13:25\tINFO\ttorchdistill.misc.log\tEpoch: [141]  [  0/352]  eta: 0:07:29  lr: 0.0010000000000000002  img/s: 280.82679805058297  loss: 0.2104 (0.2104)  time: 1.2763  data: 0.8204  max mem: 700\n",
            "2021/01/10 22:13:36\tINFO\ttorchdistill.misc.log\tEpoch: [141]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1103.632609598362  loss: 0.2103 (0.2108)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:13:48\tINFO\ttorchdistill.misc.log\tEpoch: [141]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1105.389114343659  loss: 0.2107 (0.2108)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:13:59\tINFO\ttorchdistill.misc.log\tEpoch: [141]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1106.9503340206186  loss: 0.2106 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:14:05\tINFO\ttorchdistill.misc.log\tEpoch: [141] Total time: 0:00:42\n",
            "2021/01/10 22:14:06\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7378  data: 0.6791  max mem: 700\n",
            "2021/01/10 22:14:07\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:14:07\tINFO\t__main__\t * Acc@1 84.5000\tAcc@5 98.0800\n",
            "\n",
            "2021/01/10 22:14:09\tINFO\ttorchdistill.misc.log\tEpoch: [142]  [  0/352]  eta: 0:06:58  lr: 0.0010000000000000002  img/s: 242.1673241789817  loss: 0.2109 (0.2109)  time: 1.1898  data: 0.6612  max mem: 700\n",
            "2021/01/10 22:14:20\tINFO\ttorchdistill.misc.log\tEpoch: [142]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1106.380035033488  loss: 0.2106 (0.2107)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:14:32\tINFO\ttorchdistill.misc.log\tEpoch: [142]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1098.6594196373758  loss: 0.2107 (0.2108)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:14:44\tINFO\ttorchdistill.misc.log\tEpoch: [142]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1103.1133192380319  loss: 0.2107 (0.2109)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:14:50\tINFO\ttorchdistill.misc.log\tEpoch: [142] Total time: 0:00:42\n",
            "2021/01/10 22:14:50\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7156  data: 0.6699  max mem: 700\n",
            "2021/01/10 22:14:52\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:14:52\tINFO\t__main__\t * Acc@1 84.2800\tAcc@5 98.1600\n",
            "\n",
            "2021/01/10 22:14:53\tINFO\ttorchdistill.misc.log\tEpoch: [143]  [  0/352]  eta: 0:07:19  lr: 0.0010000000000000002  img/s: 227.23309648004525  loss: 0.2143 (0.2143)  time: 1.2487  data: 0.6854  max mem: 700\n",
            "2021/01/10 22:15:05\tINFO\ttorchdistill.misc.log\tEpoch: [143]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1099.6270446306044  loss: 0.2105 (0.2108)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:15:16\tINFO\ttorchdistill.misc.log\tEpoch: [143]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1108.2368027215098  loss: 0.2105 (0.2109)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:15:28\tINFO\ttorchdistill.misc.log\tEpoch: [143]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1110.7543815003548  loss: 0.2099 (0.2108)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:15:34\tINFO\ttorchdistill.misc.log\tEpoch: [143] Total time: 0:00:42\n",
            "2021/01/10 22:15:35\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7053  data: 0.6559  max mem: 700\n",
            "2021/01/10 22:15:36\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:15:36\tINFO\t__main__\t * Acc@1 84.4400\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:15:38\tINFO\ttorchdistill.misc.log\tEpoch: [144]  [  0/352]  eta: 0:08:07  lr: 0.0010000000000000002  img/s: 250.01276535899197  loss: 0.2109 (0.2109)  time: 1.3857  data: 0.8737  max mem: 700\n",
            "2021/01/10 22:15:49\tINFO\ttorchdistill.misc.log\tEpoch: [144]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1104.4999382812564  loss: 0.2111 (0.2109)  time: 0.1166  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:16:01\tINFO\ttorchdistill.misc.log\tEpoch: [144]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1094.6340086898545  loss: 0.2102 (0.2108)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:16:13\tINFO\ttorchdistill.misc.log\tEpoch: [144]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1101.8929860064939  loss: 0.2106 (0.2109)  time: 0.1165  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:16:19\tINFO\ttorchdistill.misc.log\tEpoch: [144] Total time: 0:00:42\n",
            "2021/01/10 22:16:19\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.7186  data: 0.6588  max mem: 700\n",
            "2021/01/10 22:16:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:16:21\tINFO\t__main__\t * Acc@1 84.2200\tAcc@5 98.1800\n",
            "\n",
            "2021/01/10 22:16:22\tINFO\ttorchdistill.misc.log\tEpoch: [145]  [  0/352]  eta: 0:07:30  lr: 0.0010000000000000002  img/s: 228.03631448884224  loss: 0.2081 (0.2081)  time: 1.2812  data: 0.7199  max mem: 700\n",
            "2021/01/10 22:16:34\tINFO\ttorchdistill.misc.log\tEpoch: [145]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1097.7383850982476  loss: 0.2100 (0.2107)  time: 0.1171  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:16:45\tINFO\ttorchdistill.misc.log\tEpoch: [145]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1092.2888893410104  loss: 0.2113 (0.2108)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:16:57\tINFO\ttorchdistill.misc.log\tEpoch: [145]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1100.3414789111994  loss: 0.2107 (0.2108)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:17:03\tINFO\ttorchdistill.misc.log\tEpoch: [145] Total time: 0:00:42\n",
            "2021/01/10 22:17:04\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7989  data: 0.7374  max mem: 700\n",
            "2021/01/10 22:17:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:17:06\tINFO\t__main__\t * Acc@1 84.4000\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 22:17:07\tINFO\ttorchdistill.misc.log\tEpoch: [146]  [  0/352]  eta: 0:08:19  lr: 0.0010000000000000002  img/s: 238.87428542952537  loss: 0.2131 (0.2131)  time: 1.4195  data: 0.8836  max mem: 700\n",
            "2021/01/10 22:17:19\tINFO\ttorchdistill.misc.log\tEpoch: [146]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1096.1112626481229  loss: 0.2103 (0.2108)  time: 0.1172  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:17:30\tINFO\ttorchdistill.misc.log\tEpoch: [146]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1105.6509092406861  loss: 0.2104 (0.2109)  time: 0.1168  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:17:42\tINFO\ttorchdistill.misc.log\tEpoch: [146]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1088.8639667705088  loss: 0.2101 (0.2109)  time: 0.1165  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:17:48\tINFO\ttorchdistill.misc.log\tEpoch: [146] Total time: 0:00:42\n",
            "2021/01/10 22:17:49\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.8226  data: 0.7531  max mem: 700\n",
            "2021/01/10 22:17:50\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:17:50\tINFO\t__main__\t * Acc@1 84.4600\tAcc@5 98.2800\n",
            "\n",
            "2021/01/10 22:17:52\tINFO\ttorchdistill.misc.log\tEpoch: [147]  [  0/352]  eta: 0:07:53  lr: 0.0010000000000000002  img/s: 244.1556423064749  loss: 0.2135 (0.2135)  time: 1.3444  data: 0.8201  max mem: 700\n",
            "2021/01/10 22:18:04\tINFO\ttorchdistill.misc.log\tEpoch: [147]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1092.769119915977  loss: 0.2106 (0.2107)  time: 0.1167  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:18:15\tINFO\ttorchdistill.misc.log\tEpoch: [147]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1100.4835748693247  loss: 0.2114 (0.2108)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:18:27\tINFO\ttorchdistill.misc.log\tEpoch: [147]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1086.827223774242  loss: 0.2106 (0.2108)  time: 0.1166  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:18:33\tINFO\ttorchdistill.misc.log\tEpoch: [147] Total time: 0:00:42\n",
            "2021/01/10 22:18:34\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7853  data: 0.7341  max mem: 700\n",
            "2021/01/10 22:18:35\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:18:35\tINFO\t__main__\t * Acc@1 84.3000\tAcc@5 98.1000\n",
            "\n",
            "2021/01/10 22:18:36\tINFO\ttorchdistill.misc.log\tEpoch: [148]  [  0/352]  eta: 0:07:13  lr: 0.0010000000000000002  img/s: 235.70954304379896  loss: 0.2105 (0.2105)  time: 1.2309  data: 0.6878  max mem: 700\n",
            "2021/01/10 22:18:48\tINFO\ttorchdistill.misc.log\tEpoch: [148]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1064.8418756037042  loss: 0.2110 (0.2108)  time: 0.1174  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:19:00\tINFO\ttorchdistill.misc.log\tEpoch: [148]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1107.8571779374045  loss: 0.2112 (0.2109)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:19:11\tINFO\ttorchdistill.misc.log\tEpoch: [148]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1114.0434602168032  loss: 0.2108 (0.2108)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:19:18\tINFO\ttorchdistill.misc.log\tEpoch: [148] Total time: 0:00:42\n",
            "2021/01/10 22:19:18\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:34  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.8677  data: 0.8344  max mem: 700\n",
            "2021/01/10 22:19:20\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:19:20\tINFO\t__main__\t * Acc@1 84.2800\tAcc@5 98.2400\n",
            "\n",
            "2021/01/10 22:19:21\tINFO\ttorchdistill.misc.log\tEpoch: [149]  [  0/352]  eta: 0:08:13  lr: 0.0010000000000000002  img/s: 281.55079595245525  loss: 0.2115 (0.2115)  time: 1.4030  data: 0.9483  max mem: 700\n",
            "2021/01/10 22:19:33\tINFO\ttorchdistill.misc.log\tEpoch: [149]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1110.8302235022945  loss: 0.2109 (0.2108)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:19:44\tINFO\ttorchdistill.misc.log\tEpoch: [149]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1111.2716915676217  loss: 0.2104 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:19:56\tINFO\ttorchdistill.misc.log\tEpoch: [149]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1094.6250813010618  loss: 0.2097 (0.2107)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:20:02\tINFO\ttorchdistill.misc.log\tEpoch: [149] Total time: 0:00:42\n",
            "2021/01/10 22:20:03\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.7169  data: 0.6585  max mem: 700\n",
            "2021/01/10 22:20:04\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:20:04\tINFO\t__main__\t * Acc@1 84.4200\tAcc@5 98.0400\n",
            "\n",
            "2021/01/10 22:20:05\tINFO\ttorchdistill.misc.log\tEpoch: [150]  [  0/352]  eta: 0:07:21  lr: 0.0010000000000000002  img/s: 257.1900770701833  loss: 0.2133 (0.2133)  time: 1.2539  data: 0.7562  max mem: 700\n",
            "2021/01/10 22:20:17\tINFO\ttorchdistill.misc.log\tEpoch: [150]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1102.1010892280153  loss: 0.2105 (0.2108)  time: 0.1163  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:20:28\tINFO\ttorchdistill.misc.log\tEpoch: [150]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1098.2593660885611  loss: 0.2100 (0.2107)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:20:40\tINFO\ttorchdistill.misc.log\tEpoch: [150]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1108.1384412153236  loss: 0.2104 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:20:46\tINFO\ttorchdistill.misc.log\tEpoch: [150] Total time: 0:00:42\n",
            "2021/01/10 22:20:47\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.7512  data: 0.7205  max mem: 700\n",
            "2021/01/10 22:20:48\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:20:48\tINFO\t__main__\t * Acc@1 84.2800\tAcc@5 98.1400\n",
            "\n",
            "2021/01/10 22:20:49\tINFO\ttorchdistill.misc.log\tEpoch: [151]  [  0/352]  eta: 0:07:06  lr: 0.0010000000000000002  img/s: 230.518504524101  loss: 0.2103 (0.2103)  time: 1.2119  data: 0.6566  max mem: 700\n",
            "2021/01/10 22:21:01\tINFO\ttorchdistill.misc.log\tEpoch: [151]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1100.76561997027  loss: 0.2105 (0.2109)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:21:12\tINFO\ttorchdistill.misc.log\tEpoch: [151]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1109.9644023048154  loss: 0.2103 (0.2108)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:21:24\tINFO\ttorchdistill.misc.log\tEpoch: [151]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1106.6263320842145  loss: 0.2109 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:21:30\tINFO\ttorchdistill.misc.log\tEpoch: [151] Total time: 0:00:42\n",
            "2021/01/10 22:21:31\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:35  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.8864  data: 0.8342  max mem: 700\n",
            "2021/01/10 22:21:32\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:21:32\tINFO\t__main__\t * Acc@1 84.4800\tAcc@5 98.2400\n",
            "\n",
            "2021/01/10 22:21:33\tINFO\ttorchdistill.misc.log\tEpoch: [152]  [  0/352]  eta: 0:07:35  lr: 0.0010000000000000002  img/s: 268.12322650273757  loss: 0.2099 (0.2099)  time: 1.2948  data: 0.8174  max mem: 700\n",
            "2021/01/10 22:21:45\tINFO\ttorchdistill.misc.log\tEpoch: [152]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1114.3139966168183  loss: 0.2112 (0.2109)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:21:57\tINFO\ttorchdistill.misc.log\tEpoch: [152]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1108.9441470024456  loss: 0.2108 (0.2108)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:22:08\tINFO\ttorchdistill.misc.log\tEpoch: [152]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1111.3982184370852  loss: 0.2102 (0.2108)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:22:14\tINFO\ttorchdistill.misc.log\tEpoch: [152] Total time: 0:00:42\n",
            "2021/01/10 22:22:15\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.6905  data: 0.6410  max mem: 700\n",
            "2021/01/10 22:22:16\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:22:16\tINFO\t__main__\t * Acc@1 84.5000\tAcc@5 98.1600\n",
            "\n",
            "2021/01/10 22:22:18\tINFO\ttorchdistill.misc.log\tEpoch: [153]  [  0/352]  eta: 0:07:27  lr: 0.0010000000000000002  img/s: 212.6431971482325  loss: 0.2107 (0.2107)  time: 1.2708  data: 0.6688  max mem: 700\n",
            "2021/01/10 22:22:29\tINFO\ttorchdistill.misc.log\tEpoch: [153]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1117.803398356413  loss: 0.2103 (0.2110)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:22:41\tINFO\ttorchdistill.misc.log\tEpoch: [153]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1129.070809971861  loss: 0.2108 (0.2109)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:22:52\tINFO\ttorchdistill.misc.log\tEpoch: [153]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1108.891465679096  loss: 0.2102 (0.2108)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:22:59\tINFO\ttorchdistill.misc.log\tEpoch: [153] Total time: 0:00:42\n",
            "2021/01/10 22:22:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.6932  data: 0.6513  max mem: 700\n",
            "2021/01/10 22:23:01\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:23:01\tINFO\t__main__\t * Acc@1 84.3200\tAcc@5 98.2600\n",
            "\n",
            "2021/01/10 22:23:02\tINFO\ttorchdistill.misc.log\tEpoch: [154]  [  0/352]  eta: 0:07:30  lr: 0.0010000000000000002  img/s: 254.17761676517432  loss: 0.2104 (0.2104)  time: 1.2809  data: 0.7773  max mem: 700\n",
            "2021/01/10 22:23:13\tINFO\ttorchdistill.misc.log\tEpoch: [154]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1114.647144924437  loss: 0.2112 (0.2106)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:23:25\tINFO\ttorchdistill.misc.log\tEpoch: [154]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1108.575482821208  loss: 0.2101 (0.2106)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:23:37\tINFO\ttorchdistill.misc.log\tEpoch: [154]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1108.8754332263434  loss: 0.2104 (0.2107)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:23:43\tINFO\ttorchdistill.misc.log\tEpoch: [154] Total time: 0:00:42\n",
            "2021/01/10 22:23:44\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7930  data: 0.7493  max mem: 700\n",
            "2021/01/10 22:23:45\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:23:45\tINFO\t__main__\t * Acc@1 84.6000\tAcc@5 98.0600\n",
            "\n",
            "2021/01/10 22:23:46\tINFO\ttorchdistill.misc.log\tEpoch: [155]  [  0/352]  eta: 0:06:42  lr: 0.0010000000000000002  img/s: 245.22603766517912  loss: 0.2123 (0.2123)  time: 1.1421  data: 0.6201  max mem: 700\n",
            "2021/01/10 22:23:58\tINFO\ttorchdistill.misc.log\tEpoch: [155]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1111.2969946367546  loss: 0.2111 (0.2109)  time: 0.1162  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:24:09\tINFO\ttorchdistill.misc.log\tEpoch: [155]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1102.295691595079  loss: 0.2109 (0.2108)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:24:21\tINFO\ttorchdistill.misc.log\tEpoch: [155]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1113.8978411743349  loss: 0.2101 (0.2108)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:24:27\tINFO\ttorchdistill.misc.log\tEpoch: [155] Total time: 0:00:42\n",
            "2021/01/10 22:24:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:33  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.8378  data: 0.7875  max mem: 700\n",
            "2021/01/10 22:24:29\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:24:29\tINFO\t__main__\t * Acc@1 84.3600\tAcc@5 98.0600\n",
            "\n",
            "2021/01/10 22:24:30\tINFO\ttorchdistill.misc.log\tEpoch: [156]  [  0/352]  eta: 0:07:35  lr: 0.0010000000000000002  img/s: 254.21805694717244  loss: 0.2095 (0.2095)  time: 1.2950  data: 0.7915  max mem: 700\n",
            "2021/01/10 22:24:42\tINFO\ttorchdistill.misc.log\tEpoch: [156]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1112.568230093814  loss: 0.2108 (0.2109)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:24:53\tINFO\ttorchdistill.misc.log\tEpoch: [156]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1107.966922227611  loss: 0.2102 (0.2108)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:25:05\tINFO\ttorchdistill.misc.log\tEpoch: [156]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1099.07326460256  loss: 0.2110 (0.2108)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:25:11\tINFO\ttorchdistill.misc.log\tEpoch: [156] Total time: 0:00:42\n",
            "2021/01/10 22:25:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7155  data: 0.6804  max mem: 700\n",
            "2021/01/10 22:25:13\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:25:13\tINFO\t__main__\t * Acc@1 84.2200\tAcc@5 98.1600\n",
            "\n",
            "2021/01/10 22:25:14\tINFO\ttorchdistill.misc.log\tEpoch: [157]  [  0/352]  eta: 0:07:52  lr: 0.0010000000000000002  img/s: 308.6724537023728  loss: 0.2110 (0.2110)  time: 1.3413  data: 0.9266  max mem: 700\n",
            "2021/01/10 22:25:26\tINFO\ttorchdistill.misc.log\tEpoch: [157]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1110.667061113789  loss: 0.2106 (0.2109)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:25:37\tINFO\ttorchdistill.misc.log\tEpoch: [157]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1103.7596720408221  loss: 0.2099 (0.2108)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:25:49\tINFO\ttorchdistill.misc.log\tEpoch: [157]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1107.206018709475  loss: 0.2107 (0.2109)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:25:55\tINFO\ttorchdistill.misc.log\tEpoch: [157] Total time: 0:00:42\n",
            "2021/01/10 22:25:56\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6887  data: 0.6399  max mem: 700\n",
            "2021/01/10 22:25:57\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:25:57\tINFO\t__main__\t * Acc@1 84.4000\tAcc@5 98.0600\n",
            "\n",
            "2021/01/10 22:25:58\tINFO\ttorchdistill.misc.log\tEpoch: [158]  [  0/352]  eta: 0:07:02  lr: 0.0010000000000000002  img/s: 230.58266056728382  loss: 0.2110 (0.2110)  time: 1.2001  data: 0.6449  max mem: 700\n",
            "2021/01/10 22:26:10\tINFO\ttorchdistill.misc.log\tEpoch: [158]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1109.2259625417094  loss: 0.2108 (0.2109)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:26:21\tINFO\ttorchdistill.misc.log\tEpoch: [158]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1095.8696234364284  loss: 0.2104 (0.2108)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:26:33\tINFO\ttorchdistill.misc.log\tEpoch: [158]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1109.0770177866837  loss: 0.2096 (0.2108)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:26:39\tINFO\ttorchdistill.misc.log\tEpoch: [158] Total time: 0:00:42\n",
            "2021/01/10 22:26:40\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6934  data: 0.6491  max mem: 700\n",
            "2021/01/10 22:26:41\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:26:41\tINFO\t__main__\t * Acc@1 84.4800\tAcc@5 98.1600\n",
            "\n",
            "2021/01/10 22:26:42\tINFO\ttorchdistill.misc.log\tEpoch: [159]  [  0/352]  eta: 0:06:49  lr: 0.0010000000000000002  img/s: 254.08426835478502  loss: 0.2091 (0.2091)  time: 1.1628  data: 0.6590  max mem: 700\n",
            "2021/01/10 22:26:54\tINFO\ttorchdistill.misc.log\tEpoch: [159]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1111.4419344153694  loss: 0.2103 (0.2108)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:27:05\tINFO\ttorchdistill.misc.log\tEpoch: [159]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1113.6067172646397  loss: 0.2102 (0.2107)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:27:17\tINFO\ttorchdistill.misc.log\tEpoch: [159]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1115.4739348506318  loss: 0.2106 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:27:23\tINFO\ttorchdistill.misc.log\tEpoch: [159] Total time: 0:00:42\n",
            "2021/01/10 22:27:24\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.7374  data: 0.7105  max mem: 700\n",
            "2021/01/10 22:27:25\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:27:25\tINFO\t__main__\t * Acc@1 84.5200\tAcc@5 98.2600\n",
            "\n",
            "2021/01/10 22:27:26\tINFO\ttorchdistill.misc.log\tEpoch: [160]  [  0/352]  eta: 0:07:03  lr: 0.0010000000000000002  img/s: 229.73685681213746  loss: 0.2107 (0.2107)  time: 1.2041  data: 0.6469  max mem: 700\n",
            "2021/01/10 22:27:38\tINFO\ttorchdistill.misc.log\tEpoch: [160]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1055.2973371414419  loss: 0.2108 (0.2110)  time: 0.1165  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:27:50\tINFO\ttorchdistill.misc.log\tEpoch: [160]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1103.129185501767  loss: 0.2106 (0.2108)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:28:01\tINFO\ttorchdistill.misc.log\tEpoch: [160]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1101.8206206978643  loss: 0.2100 (0.2106)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:28:07\tINFO\ttorchdistill.misc.log\tEpoch: [160] Total time: 0:00:42\n",
            "2021/01/10 22:28:08\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7342  data: 0.6594  max mem: 700\n",
            "2021/01/10 22:28:09\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:28:09\tINFO\t__main__\t * Acc@1 84.3600\tAcc@5 98.2200\n",
            "\n",
            "2021/01/10 22:28:10\tINFO\ttorchdistill.misc.log\tEpoch: [161]  [  0/352]  eta: 0:06:34  lr: 0.0010000000000000002  img/s: 265.5065208156225  loss: 0.2107 (0.2107)  time: 1.1199  data: 0.6378  max mem: 700\n",
            "2021/01/10 22:28:22\tINFO\ttorchdistill.misc.log\tEpoch: [161]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1114.3371254812832  loss: 0.2104 (0.2106)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:28:34\tINFO\ttorchdistill.misc.log\tEpoch: [161]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1100.2016742660996  loss: 0.2105 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:28:45\tINFO\ttorchdistill.misc.log\tEpoch: [161]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1132.0395992839235  loss: 0.2101 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:28:51\tINFO\ttorchdistill.misc.log\tEpoch: [161] Total time: 0:00:42\n",
            "2021/01/10 22:28:52\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7076  data: 0.6826  max mem: 700\n",
            "2021/01/10 22:28:53\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:28:53\tINFO\t__main__\t * Acc@1 84.5200\tAcc@5 98.2600\n",
            "\n",
            "2021/01/10 22:28:55\tINFO\ttorchdistill.misc.log\tEpoch: [162]  [  0/352]  eta: 0:07:12  lr: 0.0010000000000000002  img/s: 251.13525084012545  loss: 0.2090 (0.2090)  time: 1.2275  data: 0.7178  max mem: 700\n",
            "2021/01/10 22:29:06\tINFO\ttorchdistill.misc.log\tEpoch: [162]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1115.1889359951974  loss: 0.2108 (0.2106)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:29:18\tINFO\ttorchdistill.misc.log\tEpoch: [162]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1099.1362683438156  loss: 0.2109 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:29:29\tINFO\ttorchdistill.misc.log\tEpoch: [162]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1107.7108860310275  loss: 0.2106 (0.2107)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:29:35\tINFO\ttorchdistill.misc.log\tEpoch: [162] Total time: 0:00:42\n",
            "2021/01/10 22:29:36\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.6976  data: 0.6497  max mem: 700\n",
            "2021/01/10 22:29:37\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:29:37\tINFO\t__main__\t * Acc@1 84.5400\tAcc@5 98.1000\n",
            "\n",
            "2021/01/10 22:29:39\tINFO\ttorchdistill.misc.log\tEpoch: [163]  [  0/352]  eta: 0:08:02  lr: 0.0010000000000000002  img/s: 237.16124039089328  loss: 0.2118 (0.2118)  time: 1.3716  data: 0.8318  max mem: 700\n",
            "2021/01/10 22:29:50\tINFO\ttorchdistill.misc.log\tEpoch: [163]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1112.3284996529612  loss: 0.2105 (0.2109)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:30:02\tINFO\ttorchdistill.misc.log\tEpoch: [163]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1110.8417156182172  loss: 0.2104 (0.2107)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:30:14\tINFO\ttorchdistill.misc.log\tEpoch: [163]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1107.6263286459364  loss: 0.2099 (0.2108)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:30:20\tINFO\ttorchdistill.misc.log\tEpoch: [163] Total time: 0:00:42\n",
            "2021/01/10 22:30:20\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7113  data: 0.6429  max mem: 700\n",
            "2021/01/10 22:30:22\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:30:22\tINFO\t__main__\t * Acc@1 84.5200\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 22:30:23\tINFO\ttorchdistill.misc.log\tEpoch: [164]  [  0/352]  eta: 0:07:24  lr: 0.0010000000000000002  img/s: 210.64913267808447  loss: 0.2094 (0.2094)  time: 1.2623  data: 0.6547  max mem: 700\n",
            "2021/01/10 22:30:34\tINFO\ttorchdistill.misc.log\tEpoch: [164]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1101.5990610559836  loss: 0.2105 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:30:46\tINFO\ttorchdistill.misc.log\tEpoch: [164]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1103.190388223231  loss: 0.2106 (0.2108)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:30:58\tINFO\ttorchdistill.misc.log\tEpoch: [164]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1110.2122979889366  loss: 0.2100 (0.2107)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:31:04\tINFO\ttorchdistill.misc.log\tEpoch: [164] Total time: 0:00:42\n",
            "2021/01/10 22:31:04\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7290  data: 0.7020  max mem: 700\n",
            "2021/01/10 22:31:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:31:06\tINFO\t__main__\t * Acc@1 84.4600\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:31:07\tINFO\ttorchdistill.misc.log\tEpoch: [165]  [  0/352]  eta: 0:07:19  lr: 0.0010000000000000002  img/s: 262.77643410336697  loss: 0.2107 (0.2107)  time: 1.2482  data: 0.7611  max mem: 700\n",
            "2021/01/10 22:31:19\tINFO\ttorchdistill.misc.log\tEpoch: [165]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1110.4924615215957  loss: 0.2104 (0.2108)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:31:30\tINFO\ttorchdistill.misc.log\tEpoch: [165]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1105.7738818082205  loss: 0.2105 (0.2108)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:31:42\tINFO\ttorchdistill.misc.log\tEpoch: [165]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1114.3047453398617  loss: 0.2100 (0.2107)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:31:48\tINFO\ttorchdistill.misc.log\tEpoch: [165] Total time: 0:00:42\n",
            "2021/01/10 22:31:48\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 78.9062 (78.9062)  acc5: 99.2188 (99.2188)  time: 0.6894  data: 0.6304  max mem: 700\n",
            "2021/01/10 22:31:50\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:31:50\tINFO\t__main__\t * Acc@1 84.5600\tAcc@5 98.1600\n",
            "\n",
            "2021/01/10 22:31:51\tINFO\ttorchdistill.misc.log\tEpoch: [166]  [  0/352]  eta: 0:07:19  lr: 0.0010000000000000002  img/s: 253.45057115624383  loss: 0.2093 (0.2093)  time: 1.2497  data: 0.7447  max mem: 700\n",
            "2021/01/10 22:32:03\tINFO\ttorchdistill.misc.log\tEpoch: [166]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1111.464944206364  loss: 0.2109 (0.2110)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:32:14\tINFO\ttorchdistill.misc.log\tEpoch: [166]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1108.5709046833413  loss: 0.2100 (0.2108)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:32:26\tINFO\ttorchdistill.misc.log\tEpoch: [166]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1108.2711189830354  loss: 0.2112 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:32:32\tINFO\ttorchdistill.misc.log\tEpoch: [166] Total time: 0:00:42\n",
            "2021/01/10 22:32:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7434  data: 0.7018  max mem: 700\n",
            "2021/01/10 22:32:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:32:34\tINFO\t__main__\t * Acc@1 84.4000\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:32:35\tINFO\ttorchdistill.misc.log\tEpoch: [167]  [  0/352]  eta: 0:06:59  lr: 0.0010000000000000002  img/s: 251.30005888482074  loss: 0.2090 (0.2090)  time: 1.1921  data: 0.6828  max mem: 700\n",
            "2021/01/10 22:32:47\tINFO\ttorchdistill.misc.log\tEpoch: [167]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1113.2464889052933  loss: 0.2104 (0.2107)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:32:58\tINFO\ttorchdistill.misc.log\tEpoch: [167]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1111.741136029488  loss: 0.2106 (0.2107)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:33:10\tINFO\ttorchdistill.misc.log\tEpoch: [167]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1101.4318199536344  loss: 0.2107 (0.2107)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:33:16\tINFO\ttorchdistill.misc.log\tEpoch: [167] Total time: 0:00:42\n",
            "2021/01/10 22:33:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.7783  data: 0.7380  max mem: 700\n",
            "2021/01/10 22:33:18\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:33:18\tINFO\t__main__\t * Acc@1 84.3600\tAcc@5 98.1800\n",
            "\n",
            "2021/01/10 22:33:19\tINFO\ttorchdistill.misc.log\tEpoch: [168]  [  0/352]  eta: 0:06:51  lr: 0.0010000000000000002  img/s: 239.00774669237472  loss: 0.2127 (0.2127)  time: 1.1686  data: 0.6330  max mem: 700\n",
            "2021/01/10 22:33:31\tINFO\ttorchdistill.misc.log\tEpoch: [168]  [100/352]  eta: 0:00:31  lr: 0.0010000000000000002  img/s: 1102.7892940040672  loss: 0.2107 (0.2105)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:33:42\tINFO\ttorchdistill.misc.log\tEpoch: [168]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1107.765740968094  loss: 0.2099 (0.2106)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:33:54\tINFO\ttorchdistill.misc.log\tEpoch: [168]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1108.0744012482767  loss: 0.2100 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:34:00\tINFO\ttorchdistill.misc.log\tEpoch: [168] Total time: 0:00:41\n",
            "2021/01/10 22:34:01\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7963  data: 0.7543  max mem: 700\n",
            "2021/01/10 22:34:02\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:34:02\tINFO\t__main__\t * Acc@1 84.5200\tAcc@5 98.0600\n",
            "\n",
            "2021/01/10 22:34:03\tINFO\ttorchdistill.misc.log\tEpoch: [169]  [  0/352]  eta: 0:07:07  lr: 0.0010000000000000002  img/s: 225.9847800327904  loss: 0.2119 (0.2119)  time: 1.2151  data: 0.6487  max mem: 700\n",
            "2021/01/10 22:34:15\tINFO\ttorchdistill.misc.log\tEpoch: [169]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1099.5099389287338  loss: 0.2105 (0.2109)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:34:26\tINFO\ttorchdistill.misc.log\tEpoch: [169]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1104.8204224844887  loss: 0.2102 (0.2108)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:34:38\tINFO\ttorchdistill.misc.log\tEpoch: [169]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1103.5532104264605  loss: 0.2101 (0.2107)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:34:44\tINFO\ttorchdistill.misc.log\tEpoch: [169] Total time: 0:00:42\n",
            "2021/01/10 22:34:45\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.6906  data: 0.6375  max mem: 700\n",
            "2021/01/10 22:34:46\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:34:46\tINFO\t__main__\t * Acc@1 84.4800\tAcc@5 98.1400\n",
            "\n",
            "2021/01/10 22:34:47\tINFO\ttorchdistill.misc.log\tEpoch: [170]  [  0/352]  eta: 0:07:07  lr: 0.0010000000000000002  img/s: 270.3924211480591  loss: 0.2087 (0.2087)  time: 1.2151  data: 0.7417  max mem: 700\n",
            "2021/01/10 22:34:59\tINFO\ttorchdistill.misc.log\tEpoch: [170]  [100/352]  eta: 0:00:31  lr: 0.0010000000000000002  img/s: 1113.9163303711664  loss: 0.2103 (0.2106)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:35:10\tINFO\ttorchdistill.misc.log\tEpoch: [170]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1113.1657004470321  loss: 0.2105 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:35:22\tINFO\ttorchdistill.misc.log\tEpoch: [170]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1109.6890924611878  loss: 0.2105 (0.2107)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:35:28\tINFO\ttorchdistill.misc.log\tEpoch: [170] Total time: 0:00:42\n",
            "2021/01/10 22:35:29\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:29  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.7430  data: 0.7102  max mem: 700\n",
            "2021/01/10 22:35:30\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:35:30\tINFO\t__main__\t * Acc@1 84.5600\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 22:35:31\tINFO\ttorchdistill.misc.log\tEpoch: [171]  [  0/352]  eta: 0:07:39  lr: 0.0010000000000000002  img/s: 257.5399700279956  loss: 0.2087 (0.2087)  time: 1.3042  data: 0.8072  max mem: 700\n",
            "2021/01/10 22:35:43\tINFO\ttorchdistill.misc.log\tEpoch: [171]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1113.6875697518597  loss: 0.2100 (0.2107)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:35:54\tINFO\ttorchdistill.misc.log\tEpoch: [171]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1092.8914683076873  loss: 0.2103 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:36:06\tINFO\ttorchdistill.misc.log\tEpoch: [171]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1116.552687129936  loss: 0.2106 (0.2107)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:36:12\tINFO\ttorchdistill.misc.log\tEpoch: [171] Total time: 0:00:42\n",
            "2021/01/10 22:36:13\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 75.7812 (75.7812)  acc5: 99.2188 (99.2188)  time: 0.7826  data: 0.7609  max mem: 700\n",
            "2021/01/10 22:36:14\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:36:14\tINFO\t__main__\t * Acc@1 84.3200\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:36:15\tINFO\ttorchdistill.misc.log\tEpoch: [172]  [  0/352]  eta: 0:07:40  lr: 0.0010000000000000002  img/s: 295.1049781943588  loss: 0.2093 (0.2093)  time: 1.3068  data: 0.8731  max mem: 700\n",
            "2021/01/10 22:36:27\tINFO\ttorchdistill.misc.log\tEpoch: [172]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1115.9794128162703  loss: 0.2098 (0.2108)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:36:38\tINFO\ttorchdistill.misc.log\tEpoch: [172]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1114.9087133310352  loss: 0.2098 (0.2107)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:36:50\tINFO\ttorchdistill.misc.log\tEpoch: [172]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1110.8624020261043  loss: 0.2109 (0.2108)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:36:56\tINFO\ttorchdistill.misc.log\tEpoch: [172] Total time: 0:00:42\n",
            "2021/01/10 22:36:57\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:34  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.8719  data: 0.8278  max mem: 700\n",
            "2021/01/10 22:36:58\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:36:58\tINFO\t__main__\t * Acc@1 84.5000\tAcc@5 98.2200\n",
            "\n",
            "2021/01/10 22:36:59\tINFO\ttorchdistill.misc.log\tEpoch: [173]  [  0/352]  eta: 0:07:30  lr: 0.0010000000000000002  img/s: 261.78940829169863  loss: 0.2086 (0.2086)  time: 1.2794  data: 0.7904  max mem: 700\n",
            "2021/01/10 22:37:11\tINFO\ttorchdistill.misc.log\tEpoch: [173]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1114.8925064116543  loss: 0.2102 (0.2106)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:37:22\tINFO\ttorchdistill.misc.log\tEpoch: [173]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1113.465830986266  loss: 0.2106 (0.2107)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:37:34\tINFO\ttorchdistill.misc.log\tEpoch: [173]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1117.305568100228  loss: 0.2108 (0.2107)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:37:40\tINFO\ttorchdistill.misc.log\tEpoch: [173] Total time: 0:00:41\n",
            "2021/01/10 22:37:41\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7646  data: 0.7227  max mem: 700\n",
            "2021/01/10 22:37:42\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:37:42\tINFO\t__main__\t * Acc@1 84.3400\tAcc@5 98.1400\n",
            "\n",
            "2021/01/10 22:37:43\tINFO\ttorchdistill.misc.log\tEpoch: [174]  [  0/352]  eta: 0:07:23  lr: 0.0010000000000000002  img/s: 220.1499643246701  loss: 0.2097 (0.2097)  time: 1.2596  data: 0.6782  max mem: 700\n",
            "2021/01/10 22:37:55\tINFO\ttorchdistill.misc.log\tEpoch: [174]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1101.8658479018468  loss: 0.2102 (0.2105)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:38:06\tINFO\ttorchdistill.misc.log\tEpoch: [174]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1094.5670568231167  loss: 0.2101 (0.2106)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:38:18\tINFO\ttorchdistill.misc.log\tEpoch: [174]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1114.7420360872904  loss: 0.2105 (0.2107)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:38:24\tINFO\ttorchdistill.misc.log\tEpoch: [174] Total time: 0:00:42\n",
            "2021/01/10 22:38:25\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:32  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.8102  data: 0.7731  max mem: 700\n",
            "2021/01/10 22:38:26\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:38:26\tINFO\t__main__\t * Acc@1 84.5200\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:38:27\tINFO\ttorchdistill.misc.log\tEpoch: [175]  [  0/352]  eta: 0:07:30  lr: 0.0010000000000000002  img/s: 260.0346466868125  loss: 0.2100 (0.2100)  time: 1.2806  data: 0.7883  max mem: 700\n",
            "2021/01/10 22:38:39\tINFO\ttorchdistill.misc.log\tEpoch: [175]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1123.7839220488347  loss: 0.2101 (0.2104)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:38:50\tINFO\ttorchdistill.misc.log\tEpoch: [175]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1116.371589517308  loss: 0.2107 (0.2105)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:39:02\tINFO\ttorchdistill.misc.log\tEpoch: [175]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1116.5689423528872  loss: 0.2105 (0.2107)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:39:08\tINFO\ttorchdistill.misc.log\tEpoch: [175] Total time: 0:00:41\n",
            "2021/01/10 22:39:09\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:27  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.6953  data: 0.6606  max mem: 700\n",
            "2021/01/10 22:39:10\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:39:10\tINFO\t__main__\t * Acc@1 84.5800\tAcc@5 98.1200\n",
            "\n",
            "2021/01/10 22:39:11\tINFO\ttorchdistill.misc.log\tEpoch: [176]  [  0/352]  eta: 0:07:39  lr: 0.0010000000000000002  img/s: 301.39343040123595  loss: 0.2173 (0.2173)  time: 1.3060  data: 0.8813  max mem: 700\n",
            "2021/01/10 22:39:23\tINFO\ttorchdistill.misc.log\tEpoch: [176]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1112.5359526695886  loss: 0.2106 (0.2107)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:39:34\tINFO\ttorchdistill.misc.log\tEpoch: [176]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1108.6418700697973  loss: 0.2100 (0.2107)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:39:46\tINFO\ttorchdistill.misc.log\tEpoch: [176]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1110.1112900857906  loss: 0.2108 (0.2108)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:39:52\tINFO\ttorchdistill.misc.log\tEpoch: [176] Total time: 0:00:42\n",
            "2021/01/10 22:39:53\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:31  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7781  data: 0.7398  max mem: 700\n",
            "2021/01/10 22:39:54\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:39:54\tINFO\t__main__\t * Acc@1 84.3600\tAcc@5 98.1000\n",
            "\n",
            "2021/01/10 22:39:55\tINFO\ttorchdistill.misc.log\tEpoch: [177]  [  0/352]  eta: 0:06:46  lr: 0.0010000000000000002  img/s: 257.85254300376783  loss: 0.2204 (0.2204)  time: 1.1557  data: 0.6593  max mem: 700\n",
            "2021/01/10 22:40:07\tINFO\ttorchdistill.misc.log\tEpoch: [177]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1113.3272890909166  loss: 0.2104 (0.2109)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:40:18\tINFO\ttorchdistill.misc.log\tEpoch: [177]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1112.6005093909896  loss: 0.2105 (0.2108)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:40:30\tINFO\ttorchdistill.misc.log\tEpoch: [177]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1108.4290011623755  loss: 0.2102 (0.2107)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:40:36\tINFO\ttorchdistill.misc.log\tEpoch: [177] Total time: 0:00:42\n",
            "2021/01/10 22:40:37\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.7035  data: 0.6517  max mem: 700\n",
            "2021/01/10 22:40:38\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:40:38\tINFO\t__main__\t * Acc@1 84.5600\tAcc@5 98.0800\n",
            "\n",
            "2021/01/10 22:40:39\tINFO\ttorchdistill.misc.log\tEpoch: [178]  [  0/352]  eta: 0:06:35  lr: 0.0010000000000000002  img/s: 276.4456056464075  loss: 0.2094 (0.2094)  time: 1.1231  data: 0.6601  max mem: 700\n",
            "2021/01/10 22:40:51\tINFO\ttorchdistill.misc.log\tEpoch: [178]  [100/352]  eta: 0:00:31  lr: 0.0010000000000000002  img/s: 1112.8634248367098  loss: 0.2104 (0.2108)  time: 0.1161  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:41:03\tINFO\ttorchdistill.misc.log\tEpoch: [178]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1115.34184410129  loss: 0.2105 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:41:14\tINFO\ttorchdistill.misc.log\tEpoch: [178]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1110.7314011201017  loss: 0.2108 (0.2107)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:41:20\tINFO\ttorchdistill.misc.log\tEpoch: [178] Total time: 0:00:42\n",
            "2021/01/10 22:41:21\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:26  acc1: 78.1250 (78.1250)  acc5: 99.2188 (99.2188)  time: 0.6717  data: 0.6231  max mem: 700\n",
            "2021/01/10 22:41:22\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:41:22\tINFO\t__main__\t * Acc@1 84.4000\tAcc@5 98.1600\n",
            "\n",
            "2021/01/10 22:41:23\tINFO\ttorchdistill.misc.log\tEpoch: [179]  [  0/352]  eta: 0:06:39  lr: 0.0010000000000000002  img/s: 257.75189759652176  loss: 0.2115 (0.2115)  time: 1.1339  data: 0.6372  max mem: 700\n",
            "2021/01/10 22:41:35\tINFO\ttorchdistill.misc.log\tEpoch: [179]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1111.9230372532004  loss: 0.2106 (0.2109)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:41:46\tINFO\ttorchdistill.misc.log\tEpoch: [179]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1102.605839670905  loss: 0.2100 (0.2107)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:41:58\tINFO\ttorchdistill.misc.log\tEpoch: [179]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1114.6679733079757  loss: 0.2098 (0.2107)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:42:04\tINFO\ttorchdistill.misc.log\tEpoch: [179] Total time: 0:00:42\n",
            "2021/01/10 22:42:05\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:30  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7553  data: 0.7266  max mem: 700\n",
            "2021/01/10 22:42:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:42:06\tINFO\t__main__\t * Acc@1 84.3200\tAcc@5 98.1600\n",
            "\n",
            "2021/01/10 22:42:07\tINFO\ttorchdistill.misc.log\tEpoch: [180]  [  0/352]  eta: 0:06:51  lr: 0.0010000000000000002  img/s: 231.94294473332675  loss: 0.2092 (0.2092)  time: 1.1695  data: 0.6176  max mem: 700\n",
            "2021/01/10 22:42:19\tINFO\ttorchdistill.misc.log\tEpoch: [180]  [100/352]  eta: 0:00:32  lr: 0.0010000000000000002  img/s: 1110.4763827410748  loss: 0.2105 (0.2107)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:42:31\tINFO\ttorchdistill.misc.log\tEpoch: [180]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1105.0864974126114  loss: 0.2108 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:42:42\tINFO\ttorchdistill.misc.log\tEpoch: [180]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1107.6743190910347  loss: 0.2105 (0.2107)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:42:48\tINFO\ttorchdistill.misc.log\tEpoch: [180] Total time: 0:00:42\n",
            "2021/01/10 22:42:49\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:33  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.8441  data: 0.7984  max mem: 700\n",
            "2021/01/10 22:42:50\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:01\n",
            "2021/01/10 22:42:50\tINFO\t__main__\t * Acc@1 84.2400\tAcc@5 98.1800\n",
            "\n",
            "2021/01/10 22:42:51\tINFO\ttorchdistill.misc.log\tEpoch: [181]  [  0/352]  eta: 0:06:55  lr: 0.0010000000000000002  img/s: 258.5601393189227  loss: 0.2124 (0.2124)  time: 1.1811  data: 0.6860  max mem: 700\n",
            "2021/01/10 22:43:03\tINFO\ttorchdistill.misc.log\tEpoch: [181]  [100/352]  eta: 0:00:31  lr: 0.0010000000000000002  img/s: 1099.3230718827106  loss: 0.2105 (0.2107)  time: 0.1164  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:43:15\tINFO\ttorchdistill.misc.log\tEpoch: [181]  [200/352]  eta: 0:00:18  lr: 0.0010000000000000002  img/s: 1108.884594571149  loss: 0.2100 (0.2107)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:43:26\tINFO\ttorchdistill.misc.log\tEpoch: [181]  [300/352]  eta: 0:00:06  lr: 0.0010000000000000002  img/s: 1094.2145787687637  loss: 0.2101 (0.2107)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:43:32\tINFO\ttorchdistill.misc.log\tEpoch: [181] Total time: 0:00:41\n",
            "2021/01/10 22:43:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/40]  eta: 0:00:28  acc1: 77.3438 (77.3438)  acc5: 99.2188 (99.2188)  time: 0.7152  data: 0.6320  max mem: 700\n",
            "2021/01/10 22:43:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:43:34\tINFO\t__main__\t * Acc@1 84.4600\tAcc@5 98.1400\n",
            "\n",
            "2021/01/10 22:43:34\tINFO\t__main__\tTraining time 2:13:59\n",
            "2021/01/10 22:43:34\tINFO\ttorchdistill.common.main_util\tLoading model parameters\n",
            "2021/01/10 22:43:34\tINFO\t__main__\t[Teacher: densenet_bc_k12_depth100]\n",
            "2021/01/10 22:43:35\tINFO\ttorchdistill.misc.log\tTest:  [    0/10000]  eta: 1:55:20  acc1: 0.0000 (0.0000)  acc5: 0.0000 (0.0000)  time: 0.6920  data: 0.5160  max mem: 700\n",
            "2021/01/10 22:43:53\tINFO\ttorchdistill.misc.log\tTest:  [ 1000/10000]  eta: 0:02:51  acc1: 0.0000 (8.6913)  acc5: 100.0000 (51.1489)  time: 0.0178  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:44:11\tINFO\ttorchdistill.misc.log\tTest:  [ 2000/10000]  eta: 0:02:28  acc1: 0.0000 (9.2454)  acc5: 0.0000 (50.6247)  time: 0.0175  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:44:29\tINFO\ttorchdistill.misc.log\tTest:  [ 3000/10000]  eta: 0:02:08  acc1: 0.0000 (9.6968)  acc5: 100.0000 (51.6161)  time: 0.0175  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:44:48\tINFO\ttorchdistill.misc.log\tTest:  [ 4000/10000]  eta: 0:01:50  acc1: 0.0000 (9.6976)  acc5: 100.0000 (51.6371)  time: 0.0177  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:45:06\tINFO\ttorchdistill.misc.log\tTest:  [ 5000/10000]  eta: 0:01:31  acc1: 0.0000 (9.7580)  acc5: 0.0000 (51.5897)  time: 0.0175  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:45:24\tINFO\ttorchdistill.misc.log\tTest:  [ 6000/10000]  eta: 0:01:13  acc1: 0.0000 (9.9817)  acc5: 100.0000 (51.8414)  time: 0.0176  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:45:43\tINFO\ttorchdistill.misc.log\tTest:  [ 7000/10000]  eta: 0:00:55  acc1: 0.0000 (10.0986)  acc5: 100.0000 (52.1211)  time: 0.0177  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:46:01\tINFO\ttorchdistill.misc.log\tTest:  [ 8000/10000]  eta: 0:00:36  acc1: 0.0000 (10.1362)  acc5: 0.0000 (52.1935)  time: 0.0210  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:46:19\tINFO\ttorchdistill.misc.log\tTest:  [ 9000/10000]  eta: 0:00:18  acc1: 0.0000 (9.9767)  acc5: 100.0000 (51.8498)  time: 0.0175  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:46:37\tINFO\ttorchdistill.misc.log\tTest: Total time: 0:03:03\n",
            "2021/01/10 22:46:37\tINFO\t__main__\t * Acc@1 10.0000\tAcc@5 51.8900\n",
            "\n",
            "2021/01/10 22:46:37\tINFO\t__main__\t[Student: resnet20]\n",
            "2021/01/10 22:46:38\tINFO\ttorchdistill.misc.log\tTest:  [    0/10000]  eta: 1:34:44  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5685  data: 0.5264  max mem: 700\n",
            "2021/01/10 22:46:44\tINFO\ttorchdistill.misc.log\tTest:  [ 1000/10000]  eta: 0:00:54  acc1: 100.0000 (83.1169)  acc5: 100.0000 (98.0020)  time: 0.0060  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:46:49\tINFO\ttorchdistill.misc.log\tTest:  [ 2000/10000]  eta: 0:00:46  acc1: 100.0000 (83.2084)  acc5: 100.0000 (97.9010)  time: 0.0052  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:46:55\tINFO\ttorchdistill.misc.log\tTest:  [ 3000/10000]  eta: 0:00:40  acc1: 100.0000 (83.0390)  acc5: 100.0000 (98.0340)  time: 0.0054  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:47:00\tINFO\ttorchdistill.misc.log\tTest:  [ 4000/10000]  eta: 0:00:34  acc1: 100.0000 (83.3792)  acc5: 100.0000 (98.1005)  time: 0.0053  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:47:06\tINFO\ttorchdistill.misc.log\tTest:  [ 5000/10000]  eta: 0:00:28  acc1: 100.0000 (83.8432)  acc5: 100.0000 (98.1604)  time: 0.0063  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:47:11\tINFO\ttorchdistill.misc.log\tTest:  [ 6000/10000]  eta: 0:00:22  acc1: 100.0000 (83.8360)  acc5: 100.0000 (98.1836)  time: 0.0053  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:47:17\tINFO\ttorchdistill.misc.log\tTest:  [ 7000/10000]  eta: 0:00:16  acc1: 100.0000 (83.9309)  acc5: 100.0000 (98.1717)  time: 0.0055  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:47:22\tINFO\ttorchdistill.misc.log\tTest:  [ 8000/10000]  eta: 0:00:11  acc1: 100.0000 (83.9645)  acc5: 100.0000 (98.0252)  time: 0.0056  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:47:27\tINFO\ttorchdistill.misc.log\tTest:  [ 9000/10000]  eta: 0:00:05  acc1: 100.0000 (83.9018)  acc5: 100.0000 (98.0113)  time: 0.0054  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:47:33\tINFO\ttorchdistill.misc.log\tTest: Total time: 0:00:55\n",
            "2021/01/10 22:47:33\tINFO\t__main__\t * Acc@1 83.8700\tAcc@5 98.0900\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t8BdOEI8kHJ"
      },
      "source": [
        "### 4.2 Final run with hyperparameters determinded by the above hyperparameter-tuning\n",
        "Once you tune the hyperparameters, you can update the values in **a config file whose name ends with \"-final_run.yaml\"**. Notice that the only difference between default example configs for hyperparameter tuning and final run is datasets entry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlkskjjK8kxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d077b87c-1791-49b0-be03-f170bedc3fee"
      },
      "source": [
        "!python torchdistill/examples/image_classification.py --config torchdistill/configs/sample/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-final_run.yaml --log log/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-final_run.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/01/10 22:47:35\tINFO\ttorchdistill.common.main_util\tNot using distributed mode\n",
            "2021/01/10 22:47:35\tINFO\t__main__\tNamespace(adjust_lr=False, config='torchdistill/configs/sample/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-final_run.yaml', device='cuda', dist_url='env://', log='log/cifar10/kd/resnet20_from_densenet_bc_k12_depth100-final_run.log', start_epoch=0, student_only=False, sync_bn=False, test_only=False, world_size=1)\n",
            "2021/01/10 22:47:35\tINFO\ttorchdistill.datasets.util\tLoading train data\n",
            "Files already downloaded and verified\n",
            "2021/01/10 22:47:36\tINFO\ttorchdistill.datasets.util\t0.9210293292999268 sec\n",
            "2021/01/10 22:47:36\tINFO\ttorchdistill.datasets.util\tLoading val data\n",
            "Files already downloaded and verified\n",
            "2021/01/10 22:47:36\tINFO\ttorchdistill.datasets.util\t0.7336370944976807 sec\n",
            "2021/01/10 22:47:36\tINFO\ttorchdistill.datasets.util\tLoading test data\n",
            "Files already downloaded and verified\n",
            "2021/01/10 22:47:37\tINFO\ttorchdistill.datasets.util\t0.7437591552734375 sec\n",
            "2021/01/10 22:47:37\tINFO\ttorchdistill.common.main_util\tckpt file is not found at `./resource/ckpt/cifar10/teacher/cifar10-densenet_bc_k12_depth100.pt`\n",
            "2021/01/10 22:47:41\tINFO\ttorchdistill.common.main_util\tckpt file is not found at `./resource/ckpt/cifar10/kd/cifar10-resnet20_from_densenet_bc_k12_depth100-final_run.pt`\n",
            "2021/01/10 22:47:41\tINFO\t__main__\tStart training\n",
            "2021/01/10 22:47:41\tINFO\ttorchdistill.models.util\t[teacher model]\n",
            "2021/01/10 22:47:41\tINFO\ttorchdistill.models.util\tUsing the original teacher model\n",
            "2021/01/10 22:47:41\tINFO\ttorchdistill.models.util\t[student model]\n",
            "2021/01/10 22:47:41\tINFO\ttorchdistill.models.util\tUsing the original student model\n",
            "2021/01/10 22:47:41\tINFO\ttorchdistill.core.distillation\tFreezing the whole teacher model\n",
            "2021/01/10 22:47:43\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [  0/391]  eta: 0:12:50  lr: 0.1  img/s: 147.69988420516017  loss: 2.1781 (2.1781)  time: 1.9704  data: 1.1037  max mem: 700\n",
            "2021/01/10 22:47:55\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [100/391]  eta: 0:00:39  lr: 0.1  img/s: 1091.9023437817787  loss: 1.6287 (1.8129)  time: 0.1171  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:48:07\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [200/391]  eta: 0:00:24  lr: 0.1  img/s: 1095.9814801961402  loss: 1.4967 (1.6887)  time: 0.1170  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:48:18\tINFO\ttorchdistill.misc.log\tEpoch: [0]  [300/391]  eta: 0:00:11  lr: 0.1  img/s: 1118.2061743154807  loss: 1.3828 (1.6028)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:48:29\tINFO\ttorchdistill.misc.log\tEpoch: [0] Total time: 0:00:47\n",
            "2021/01/10 22:48:30\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 48.4375 (48.4375)  acc5: 89.8438 (89.8438)  time: 0.7015  data: 0.6433  max mem: 700\n",
            "2021/01/10 22:48:32\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:48:32\tINFO\t__main__\t * Acc@1 43.9000\tAcc@5 91.6400\n",
            "\n",
            "2021/01/10 22:48:32\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 0.0000 -> 43.9000)\n",
            "2021/01/10 22:48:33\tINFO\ttorchdistill.misc.log\tEpoch: [1]  [  0/391]  eta: 0:07:46  lr: 0.1  img/s: 230.67935808454862  loss: 1.3412 (1.3412)  time: 1.1932  data: 0.6383  max mem: 700\n",
            "2021/01/10 22:48:45\tINFO\ttorchdistill.misc.log\tEpoch: [1]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1123.0622246580845  loss: 1.1771 (1.2197)  time: 0.1138  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:48:57\tINFO\ttorchdistill.misc.log\tEpoch: [1]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1111.4787505382756  loss: 1.1000 (1.1839)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:49:08\tINFO\ttorchdistill.misc.log\tEpoch: [1]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1112.1418580756356  loss: 1.1060 (1.1543)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:49:19\tINFO\ttorchdistill.misc.log\tEpoch: [1] Total time: 0:00:46\n",
            "2021/01/10 22:49:20\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:51  acc1: 59.3750 (59.3750)  acc5: 94.5312 (94.5312)  time: 0.6482  data: 0.6017  max mem: 700\n",
            "2021/01/10 22:49:22\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:49:22\tINFO\t__main__\t * Acc@1 60.9700\tAcc@5 95.0700\n",
            "\n",
            "2021/01/10 22:49:22\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 43.9000 -> 60.9700)\n",
            "2021/01/10 22:49:23\tINFO\ttorchdistill.misc.log\tEpoch: [2]  [  0/391]  eta: 0:10:39  lr: 0.1  img/s: 226.80696536623347  loss: 0.9981 (0.9981)  time: 1.6343  data: 1.0699  max mem: 700\n",
            "2021/01/10 22:49:35\tINFO\ttorchdistill.misc.log\tEpoch: [2]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1115.0986009105713  loss: 0.9929 (0.9843)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:49:47\tINFO\ttorchdistill.misc.log\tEpoch: [2]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1119.1642231612213  loss: 0.8908 (0.9655)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:49:58\tINFO\ttorchdistill.misc.log\tEpoch: [2]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1117.824344864059  loss: 0.9005 (0.9516)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:50:09\tINFO\ttorchdistill.misc.log\tEpoch: [2] Total time: 0:00:46\n",
            "2021/01/10 22:50:09\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 69.5312 (69.5312)  acc5: 98.4375 (98.4375)  time: 0.7120  data: 0.6692  max mem: 700\n",
            "2021/01/10 22:50:12\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:50:12\tINFO\t__main__\t * Acc@1 70.0000\tAcc@5 97.1800\n",
            "\n",
            "2021/01/10 22:50:12\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 60.9700 -> 70.0000)\n",
            "2021/01/10 22:50:13\tINFO\ttorchdistill.misc.log\tEpoch: [3]  [  0/391]  eta: 0:09:47  lr: 0.1  img/s: 260.66503141356174  loss: 0.7922 (0.7922)  time: 1.5032  data: 1.0122  max mem: 700\n",
            "2021/01/10 22:50:25\tINFO\ttorchdistill.misc.log\tEpoch: [3]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1119.572650000417  loss: 0.8379 (0.8519)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:50:36\tINFO\ttorchdistill.misc.log\tEpoch: [3]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.9457594876246  loss: 0.8126 (0.8410)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:50:48\tINFO\ttorchdistill.misc.log\tEpoch: [3]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1111.7549492238622  loss: 0.7980 (0.8341)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:50:58\tINFO\ttorchdistill.misc.log\tEpoch: [3] Total time: 0:00:46\n",
            "2021/01/10 22:50:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:02  acc1: 70.3125 (70.3125)  acc5: 97.6562 (97.6562)  time: 0.7920  data: 0.7465  max mem: 700\n",
            "2021/01/10 22:51:01\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 22:51:01\tINFO\t__main__\t * Acc@1 70.0800\tAcc@5 96.9900\n",
            "\n",
            "2021/01/10 22:51:01\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 70.0000 -> 70.0800)\n",
            "2021/01/10 22:51:03\tINFO\ttorchdistill.misc.log\tEpoch: [4]  [  0/391]  eta: 0:07:42  lr: 0.1  img/s: 281.70384809730723  loss: 0.8234 (0.8234)  time: 1.1823  data: 0.7279  max mem: 700\n",
            "2021/01/10 22:51:15\tINFO\ttorchdistill.misc.log\tEpoch: [4]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1118.2341232977717  loss: 0.8078 (0.7780)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:51:26\tINFO\ttorchdistill.misc.log\tEpoch: [4]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1111.3038956737735  loss: 0.7778 (0.7773)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:51:38\tINFO\ttorchdistill.misc.log\tEpoch: [4]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1109.1228426815412  loss: 0.7423 (0.7671)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:51:48\tINFO\ttorchdistill.misc.log\tEpoch: [4] Total time: 0:00:46\n",
            "2021/01/10 22:51:49\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:00  acc1: 78.9062 (78.9062)  acc5: 100.0000 (100.0000)  time: 0.7601  data: 0.6931  max mem: 700\n",
            "2021/01/10 22:51:51\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:51:51\tINFO\t__main__\t * Acc@1 76.4700\tAcc@5 98.0700\n",
            "\n",
            "2021/01/10 22:51:51\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 70.0800 -> 76.4700)\n",
            "2021/01/10 22:51:53\tINFO\ttorchdistill.misc.log\tEpoch: [5]  [  0/391]  eta: 0:09:35  lr: 0.1  img/s: 239.25517686412118  loss: 0.6714 (0.6714)  time: 1.4724  data: 0.9374  max mem: 700\n",
            "2021/01/10 22:52:04\tINFO\ttorchdistill.misc.log\tEpoch: [5]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1117.0126604401298  loss: 0.7170 (0.7283)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:52:16\tINFO\ttorchdistill.misc.log\tEpoch: [5]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1117.9849608402938  loss: 0.7085 (0.7212)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:52:27\tINFO\ttorchdistill.misc.log\tEpoch: [5]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1115.0013333388715  loss: 0.7076 (0.7190)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:52:38\tINFO\ttorchdistill.misc.log\tEpoch: [5] Total time: 0:00:46\n",
            "2021/01/10 22:52:39\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:02  acc1: 84.3750 (84.3750)  acc5: 98.4375 (98.4375)  time: 0.7863  data: 0.7196  max mem: 700\n",
            "2021/01/10 22:52:41\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 22:52:41\tINFO\t__main__\t * Acc@1 76.7400\tAcc@5 97.8600\n",
            "\n",
            "2021/01/10 22:52:41\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 76.4700 -> 76.7400)\n",
            "2021/01/10 22:52:43\tINFO\ttorchdistill.misc.log\tEpoch: [6]  [  0/391]  eta: 0:09:11  lr: 0.1  img/s: 249.28269278898324  loss: 0.6512 (0.6512)  time: 1.4103  data: 0.8968  max mem: 700\n",
            "2021/01/10 22:52:55\tINFO\ttorchdistill.misc.log\tEpoch: [6]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1115.1611390256924  loss: 0.6591 (0.6792)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:53:06\tINFO\ttorchdistill.misc.log\tEpoch: [6]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1117.4799908415378  loss: 0.6847 (0.6778)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:53:18\tINFO\ttorchdistill.misc.log\tEpoch: [6]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1116.0095704720588  loss: 0.6728 (0.6808)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:53:28\tINFO\ttorchdistill.misc.log\tEpoch: [6] Total time: 0:00:46\n",
            "2021/01/10 22:53:29\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:07  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.8512  data: 0.8096  max mem: 700\n",
            "2021/01/10 22:53:31\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 22:53:31\tINFO\t__main__\t * Acc@1 72.8700\tAcc@5 97.0600\n",
            "\n",
            "2021/01/10 22:53:33\tINFO\ttorchdistill.misc.log\tEpoch: [7]  [  0/391]  eta: 0:09:49  lr: 0.1  img/s: 251.7457216382693  loss: 0.6746 (0.6746)  time: 1.5065  data: 0.9980  max mem: 700\n",
            "2021/01/10 22:53:44\tINFO\ttorchdistill.misc.log\tEpoch: [7]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1118.1642534615191  loss: 0.6558 (0.6504)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:53:56\tINFO\ttorchdistill.misc.log\tEpoch: [7]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1126.0962928470449  loss: 0.6707 (0.6565)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:54:08\tINFO\ttorchdistill.misc.log\tEpoch: [7]  [300/391]  eta: 0:00:11  lr: 0.1  img/s: 1112.914177209417  loss: 0.6424 (0.6582)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:54:18\tINFO\ttorchdistill.misc.log\tEpoch: [7] Total time: 0:00:47\n",
            "2021/01/10 22:54:19\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:02  acc1: 79.6875 (79.6875)  acc5: 100.0000 (100.0000)  time: 0.7960  data: 0.7556  max mem: 700\n",
            "2021/01/10 22:54:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 22:54:21\tINFO\t__main__\t * Acc@1 79.9700\tAcc@5 98.7900\n",
            "\n",
            "2021/01/10 22:54:21\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 76.7400 -> 79.9700)\n",
            "2021/01/10 22:54:23\tINFO\ttorchdistill.misc.log\tEpoch: [8]  [  0/391]  eta: 0:08:45  lr: 0.1  img/s: 243.03919666417534  loss: 0.6419 (0.6419)  time: 1.3440  data: 0.8174  max mem: 700\n",
            "2021/01/10 22:54:34\tINFO\ttorchdistill.misc.log\tEpoch: [8]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.386117729938  loss: 0.6562 (0.6302)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:54:46\tINFO\ttorchdistill.misc.log\tEpoch: [8]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1119.7991635988194  loss: 0.6210 (0.6307)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:54:57\tINFO\ttorchdistill.misc.log\tEpoch: [8]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1115.9910117217626  loss: 0.6441 (0.6341)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:55:08\tINFO\ttorchdistill.misc.log\tEpoch: [8] Total time: 0:00:46\n",
            "2021/01/10 22:55:09\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 72.6562 (72.6562)  acc5: 100.0000 (100.0000)  time: 0.7037  data: 0.6477  max mem: 700\n",
            "2021/01/10 22:55:11\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 22:55:11\tINFO\t__main__\t * Acc@1 73.6800\tAcc@5 97.3400\n",
            "\n",
            "2021/01/10 22:55:12\tINFO\ttorchdistill.misc.log\tEpoch: [9]  [  0/391]  eta: 0:09:09  lr: 0.1  img/s: 247.7963722565646  loss: 0.5888 (0.5888)  time: 1.4055  data: 0.8889  max mem: 700\n",
            "2021/01/10 22:55:24\tINFO\ttorchdistill.misc.log\tEpoch: [9]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.6143439488862  loss: 0.6190 (0.6242)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:55:36\tINFO\ttorchdistill.misc.log\tEpoch: [9]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1102.5628160105148  loss: 0.6125 (0.6218)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:55:47\tINFO\ttorchdistill.misc.log\tEpoch: [9]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1114.4898000701653  loss: 0.5907 (0.6134)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:55:58\tINFO\ttorchdistill.misc.log\tEpoch: [9] Total time: 0:00:46\n",
            "2021/01/10 22:55:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 82.0312 (82.0312)  acc5: 99.2188 (99.2188)  time: 0.6836  data: 0.6463  max mem: 700\n",
            "2021/01/10 22:56:01\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:56:01\tINFO\t__main__\t * Acc@1 81.3600\tAcc@5 98.2100\n",
            "\n",
            "2021/01/10 22:56:01\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 79.9700 -> 81.3600)\n",
            "2021/01/10 22:56:02\tINFO\ttorchdistill.misc.log\tEpoch: [10]  [  0/391]  eta: 0:10:05  lr: 0.1  img/s: 251.90660416754645  loss: 0.5639 (0.5639)  time: 1.5482  data: 1.0400  max mem: 700\n",
            "2021/01/10 22:56:14\tINFO\ttorchdistill.misc.log\tEpoch: [10]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1106.1703128927643  loss: 0.5872 (0.5890)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:56:25\tINFO\ttorchdistill.misc.log\tEpoch: [10]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1107.2471219089653  loss: 0.6004 (0.5956)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:56:37\tINFO\ttorchdistill.misc.log\tEpoch: [10]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.9209527662797  loss: 0.5701 (0.5935)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:56:48\tINFO\ttorchdistill.misc.log\tEpoch: [10] Total time: 0:00:46\n",
            "2021/01/10 22:56:48\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:03  acc1: 76.5625 (76.5625)  acc5: 99.2188 (99.2188)  time: 0.8014  data: 0.7599  max mem: 700\n",
            "2021/01/10 22:56:51\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 22:56:51\tINFO\t__main__\t * Acc@1 74.2200\tAcc@5 97.7500\n",
            "\n",
            "2021/01/10 22:56:52\tINFO\ttorchdistill.misc.log\tEpoch: [11]  [  0/391]  eta: 0:09:59  lr: 0.1  img/s: 251.38383882842885  loss: 0.5185 (0.5185)  time: 1.5327  data: 1.0235  max mem: 700\n",
            "2021/01/10 22:57:04\tINFO\ttorchdistill.misc.log\tEpoch: [11]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1123.4688000267856  loss: 0.5825 (0.5888)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:57:15\tINFO\ttorchdistill.misc.log\tEpoch: [11]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1111.0762066974476  loss: 0.6045 (0.5889)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:57:27\tINFO\ttorchdistill.misc.log\tEpoch: [11]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1116.2183989537875  loss: 0.5781 (0.5911)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:57:37\tINFO\ttorchdistill.misc.log\tEpoch: [11] Total time: 0:00:46\n",
            "2021/01/10 22:57:38\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 78.9062 (78.9062)  acc5: 97.6562 (97.6562)  time: 0.7327  data: 0.6964  max mem: 700\n",
            "2021/01/10 22:57:40\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 22:57:40\tINFO\t__main__\t * Acc@1 77.4600\tAcc@5 98.2000\n",
            "\n",
            "2021/01/10 22:57:42\tINFO\ttorchdistill.misc.log\tEpoch: [12]  [  0/391]  eta: 0:07:58  lr: 0.1  img/s: 268.05535350872464  loss: 0.5885 (0.5885)  time: 1.2228  data: 0.7453  max mem: 700\n",
            "2021/01/10 22:57:53\tINFO\ttorchdistill.misc.log\tEpoch: [12]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1116.3321273215727  loss: 0.5707 (0.5792)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:58:05\tINFO\ttorchdistill.misc.log\tEpoch: [12]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1122.3273761118835  loss: 0.5698 (0.5761)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:58:16\tINFO\ttorchdistill.misc.log\tEpoch: [12]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1109.3749473075175  loss: 0.5850 (0.5752)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:58:27\tINFO\ttorchdistill.misc.log\tEpoch: [12] Total time: 0:00:46\n",
            "2021/01/10 22:58:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 82.8125 (82.8125)  acc5: 99.2188 (99.2188)  time: 0.7119  data: 0.6778  max mem: 700\n",
            "2021/01/10 22:58:30\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 22:58:30\tINFO\t__main__\t * Acc@1 80.2100\tAcc@5 98.5800\n",
            "\n",
            "2021/01/10 22:58:31\tINFO\ttorchdistill.misc.log\tEpoch: [13]  [  0/391]  eta: 0:08:27  lr: 0.1  img/s: 274.63717537574746  loss: 0.6089 (0.6089)  time: 1.2983  data: 0.8322  max mem: 700\n",
            "2021/01/10 22:58:43\tINFO\ttorchdistill.misc.log\tEpoch: [13]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1115.888949627428  loss: 0.5631 (0.5688)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:58:55\tINFO\ttorchdistill.misc.log\tEpoch: [13]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1120.6804019555043  loss: 0.5451 (0.5666)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:59:06\tINFO\ttorchdistill.misc.log\tEpoch: [13]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1114.7165758968151  loss: 0.5677 (0.5676)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:59:17\tINFO\ttorchdistill.misc.log\tEpoch: [13] Total time: 0:00:46\n",
            "2021/01/10 22:59:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 82.8125 (82.8125)  acc5: 99.2188 (99.2188)  time: 0.7543  data: 0.6941  max mem: 700\n",
            "2021/01/10 22:59:20\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 22:59:20\tINFO\t__main__\t * Acc@1 82.5100\tAcc@5 98.7800\n",
            "\n",
            "2021/01/10 22:59:20\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 81.3600 -> 82.5100)\n",
            "2021/01/10 22:59:21\tINFO\ttorchdistill.misc.log\tEpoch: [14]  [  0/391]  eta: 0:09:24  lr: 0.1  img/s: 248.0471005469899  loss: 0.5232 (0.5232)  time: 1.4442  data: 0.9282  max mem: 700\n",
            "2021/01/10 22:59:33\tINFO\ttorchdistill.misc.log\tEpoch: [14]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1118.8493545792157  loss: 0.5452 (0.5541)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:59:44\tINFO\ttorchdistill.misc.log\tEpoch: [14]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1119.1035680263813  loss: 0.5799 (0.5575)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 22:59:56\tINFO\ttorchdistill.misc.log\tEpoch: [14]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1114.1636823973768  loss: 0.5492 (0.5553)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:00:07\tINFO\ttorchdistill.misc.log\tEpoch: [14] Total time: 0:00:46\n",
            "2021/01/10 23:00:07\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 81.2500 (81.2500)  acc5: 96.8750 (96.8750)  time: 0.7458  data: 0.6864  max mem: 700\n",
            "2021/01/10 23:00:10\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:00:10\tINFO\t__main__\t * Acc@1 78.1200\tAcc@5 98.2500\n",
            "\n",
            "2021/01/10 23:00:11\tINFO\ttorchdistill.misc.log\tEpoch: [15]  [  0/391]  eta: 0:08:16  lr: 0.1  img/s: 255.4883294183935  loss: 0.4765 (0.4765)  time: 1.2688  data: 0.7677  max mem: 700\n",
            "2021/01/10 23:00:23\tINFO\ttorchdistill.misc.log\tEpoch: [15]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1117.824344864059  loss: 0.5289 (0.5463)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:00:34\tINFO\ttorchdistill.misc.log\tEpoch: [15]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.2122410182653  loss: 0.5463 (0.5444)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:00:46\tINFO\ttorchdistill.misc.log\tEpoch: [15]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1107.9097610301706  loss: 0.5433 (0.5440)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:00:56\tINFO\ttorchdistill.misc.log\tEpoch: [15] Total time: 0:00:46\n",
            "2021/01/10 23:00:57\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 84.3750 (84.3750)  acc5: 100.0000 (100.0000)  time: 0.7118  data: 0.6567  max mem: 700\n",
            "2021/01/10 23:00:59\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:00:59\tINFO\t__main__\t * Acc@1 82.9900\tAcc@5 99.1000\n",
            "\n",
            "2021/01/10 23:00:59\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 82.5100 -> 82.9900)\n",
            "2021/01/10 23:01:01\tINFO\ttorchdistill.misc.log\tEpoch: [16]  [  0/391]  eta: 0:08:16  lr: 0.1  img/s: 261.32404476968264  loss: 0.4604 (0.4604)  time: 1.2705  data: 0.7807  max mem: 700\n",
            "2021/01/10 23:01:13\tINFO\ttorchdistill.misc.log\tEpoch: [16]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1100.197165030319  loss: 0.5156 (0.5300)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:01:24\tINFO\ttorchdistill.misc.log\tEpoch: [16]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.5859285225363  loss: 0.5173 (0.5386)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:01:36\tINFO\ttorchdistill.misc.log\tEpoch: [16]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1111.6122294322995  loss: 0.5543 (0.5392)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:01:46\tINFO\ttorchdistill.misc.log\tEpoch: [16] Total time: 0:00:46\n",
            "2021/01/10 23:01:47\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 83.5938 (83.5938)  acc5: 98.4375 (98.4375)  time: 0.7119  data: 0.6601  max mem: 700\n",
            "2021/01/10 23:01:49\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:01:49\tINFO\t__main__\t * Acc@1 82.9400\tAcc@5 98.7400\n",
            "\n",
            "2021/01/10 23:01:50\tINFO\ttorchdistill.misc.log\tEpoch: [17]  [  0/391]  eta: 0:09:02  lr: 0.1  img/s: 257.30027212331913  loss: 0.5720 (0.5720)  time: 1.3882  data: 0.8907  max mem: 700\n",
            "2021/01/10 23:02:02\tINFO\ttorchdistill.misc.log\tEpoch: [17]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1121.0150277189064  loss: 0.5247 (0.5234)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:02:14\tINFO\ttorchdistill.misc.log\tEpoch: [17]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1112.0681403904152  loss: 0.5218 (0.5256)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:02:25\tINFO\ttorchdistill.misc.log\tEpoch: [17]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1110.2880659797909  loss: 0.5378 (0.5330)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:02:36\tINFO\ttorchdistill.misc.log\tEpoch: [17] Total time: 0:00:46\n",
            "2021/01/10 23:02:37\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 85.9375 (85.9375)  acc5: 99.2188 (99.2188)  time: 0.6921  data: 0.6332  max mem: 700\n",
            "2021/01/10 23:02:39\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:02:39\tINFO\t__main__\t * Acc@1 81.4100\tAcc@5 98.7900\n",
            "\n",
            "2021/01/10 23:02:40\tINFO\ttorchdistill.misc.log\tEpoch: [18]  [  0/391]  eta: 0:08:16  lr: 0.1  img/s: 246.48486921453426  loss: 0.4469 (0.4469)  time: 1.2707  data: 0.7514  max mem: 700\n",
            "2021/01/10 23:02:52\tINFO\ttorchdistill.misc.log\tEpoch: [18]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1120.3062322366857  loss: 0.5145 (0.5205)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:03:04\tINFO\ttorchdistill.misc.log\tEpoch: [18]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.8670393474488  loss: 0.5316 (0.5252)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:03:15\tINFO\ttorchdistill.misc.log\tEpoch: [18]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1121.113347380203  loss: 0.5120 (0.5290)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:03:26\tINFO\ttorchdistill.misc.log\tEpoch: [18] Total time: 0:00:46\n",
            "2021/01/10 23:03:26\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 84.3750 (84.3750)  acc5: 98.4375 (98.4375)  time: 0.7482  data: 0.6668  max mem: 700\n",
            "2021/01/10 23:03:29\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:03:29\tINFO\t__main__\t * Acc@1 83.3800\tAcc@5 98.9300\n",
            "\n",
            "2021/01/10 23:03:29\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 82.9900 -> 83.3800)\n",
            "2021/01/10 23:03:30\tINFO\ttorchdistill.misc.log\tEpoch: [19]  [  0/391]  eta: 0:10:10  lr: 0.1  img/s: 232.68644182393754  loss: 0.4296 (0.4296)  time: 1.5615  data: 1.0113  max mem: 700\n",
            "2021/01/10 23:03:42\tINFO\ttorchdistill.misc.log\tEpoch: [19]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1117.6149151074583  loss: 0.5106 (0.5103)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:03:53\tINFO\ttorchdistill.misc.log\tEpoch: [19]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1106.2045012950032  loss: 0.5243 (0.5165)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:04:05\tINFO\ttorchdistill.misc.log\tEpoch: [19]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1115.3835535897185  loss: 0.5276 (0.5191)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:04:15\tINFO\ttorchdistill.misc.log\tEpoch: [19] Total time: 0:00:46\n",
            "2021/01/10 23:04:16\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:18  acc1: 89.8438 (89.8438)  acc5: 100.0000 (100.0000)  time: 0.9970  data: 0.9449  max mem: 700\n",
            "2021/01/10 23:04:18\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:04:18\tINFO\t__main__\t * Acc@1 85.2700\tAcc@5 99.2300\n",
            "\n",
            "2021/01/10 23:04:18\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 83.3800 -> 85.2700)\n",
            "2021/01/10 23:04:20\tINFO\ttorchdistill.misc.log\tEpoch: [20]  [  0/391]  eta: 0:09:08  lr: 0.1  img/s: 254.54385252061377  loss: 0.3936 (0.3936)  time: 1.4040  data: 0.9012  max mem: 700\n",
            "2021/01/10 23:04:32\tINFO\ttorchdistill.misc.log\tEpoch: [20]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1110.1480181057602  loss: 0.4929 (0.4971)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:04:43\tINFO\ttorchdistill.misc.log\tEpoch: [20]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1110.5935388046148  loss: 0.5443 (0.5101)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:04:55\tINFO\ttorchdistill.misc.log\tEpoch: [20]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1110.4786796812139  loss: 0.5085 (0.5111)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:05:05\tINFO\ttorchdistill.misc.log\tEpoch: [20] Total time: 0:00:46\n",
            "2021/01/10 23:05:06\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 88.2812 (88.2812)  acc5: 99.2188 (99.2188)  time: 0.7312  data: 0.7011  max mem: 700\n",
            "2021/01/10 23:05:08\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:05:08\tINFO\t__main__\t * Acc@1 85.0200\tAcc@5 99.1800\n",
            "\n",
            "2021/01/10 23:05:10\tINFO\ttorchdistill.misc.log\tEpoch: [21]  [  0/391]  eta: 0:10:25  lr: 0.1  img/s: 253.75437004392376  loss: 0.5569 (0.5569)  time: 1.5994  data: 1.0949  max mem: 700\n",
            "2021/01/10 23:05:21\tINFO\ttorchdistill.misc.log\tEpoch: [21]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.1971527536089  loss: 0.4986 (0.5028)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:05:33\tINFO\ttorchdistill.misc.log\tEpoch: [21]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.1032331229983  loss: 0.5124 (0.5072)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:05:44\tINFO\ttorchdistill.misc.log\tEpoch: [21]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1120.792701613745  loss: 0.5125 (0.5094)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:05:55\tINFO\ttorchdistill.misc.log\tEpoch: [21] Total time: 0:00:46\n",
            "2021/01/10 23:05:56\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 92.1875 (92.1875)  acc5: 99.2188 (99.2188)  time: 0.7335  data: 0.6834  max mem: 700\n",
            "2021/01/10 23:05:58\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:05:58\tINFO\t__main__\t * Acc@1 84.4800\tAcc@5 99.0800\n",
            "\n",
            "2021/01/10 23:05:59\tINFO\ttorchdistill.misc.log\tEpoch: [22]  [  0/391]  eta: 0:09:47  lr: 0.1  img/s: 252.16371003688488  loss: 0.5098 (0.5098)  time: 1.5028  data: 0.9951  max mem: 700\n",
            "2021/01/10 23:06:11\tINFO\ttorchdistill.misc.log\tEpoch: [22]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1108.6487381700213  loss: 0.5028 (0.4959)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:06:23\tINFO\ttorchdistill.misc.log\tEpoch: [22]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.209784631747  loss: 0.4966 (0.4997)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:06:34\tINFO\ttorchdistill.misc.log\tEpoch: [22]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1110.1158809553842  loss: 0.5045 (0.5024)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:06:45\tINFO\ttorchdistill.misc.log\tEpoch: [22] Total time: 0:00:46\n",
            "2021/01/10 23:06:46\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 85.9375 (85.9375)  acc5: 100.0000 (100.0000)  time: 0.6934  data: 0.6488  max mem: 700\n",
            "2021/01/10 23:06:48\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:06:48\tINFO\t__main__\t * Acc@1 84.3700\tAcc@5 99.0700\n",
            "\n",
            "2021/01/10 23:06:49\tINFO\ttorchdistill.misc.log\tEpoch: [23]  [  0/391]  eta: 0:09:11  lr: 0.1  img/s: 257.4151282374619  loss: 0.4057 (0.4057)  time: 1.4103  data: 0.9130  max mem: 700\n",
            "2021/01/10 23:07:01\tINFO\ttorchdistill.misc.log\tEpoch: [23]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.6120381653445  loss: 0.4774 (0.4836)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:07:12\tINFO\ttorchdistill.misc.log\tEpoch: [23]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1111.0302202521011  loss: 0.4869 (0.4884)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:07:24\tINFO\ttorchdistill.misc.log\tEpoch: [23]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1105.6418012496551  loss: 0.4681 (0.4945)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:07:35\tINFO\ttorchdistill.misc.log\tEpoch: [23] Total time: 0:00:46\n",
            "2021/01/10 23:07:35\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:01  acc1: 84.3750 (84.3750)  acc5: 99.2188 (99.2188)  time: 0.7796  data: 0.7386  max mem: 700\n",
            "2021/01/10 23:07:38\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:07:38\tINFO\t__main__\t * Acc@1 83.1200\tAcc@5 98.8800\n",
            "\n",
            "2021/01/10 23:07:39\tINFO\ttorchdistill.misc.log\tEpoch: [24]  [  0/391]  eta: 0:07:59  lr: 0.1  img/s: 243.13715644090234  loss: 0.4726 (0.4726)  time: 1.2275  data: 0.7010  max mem: 700\n",
            "2021/01/10 23:07:51\tINFO\ttorchdistill.misc.log\tEpoch: [24]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1111.6260394235549  loss: 0.4726 (0.4781)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:08:02\tINFO\ttorchdistill.misc.log\tEpoch: [24]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.170619084085  loss: 0.4877 (0.4882)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:08:14\tINFO\ttorchdistill.misc.log\tEpoch: [24]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1102.010599908862  loss: 0.5152 (0.4922)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:08:25\tINFO\ttorchdistill.misc.log\tEpoch: [24] Total time: 0:00:46\n",
            "2021/01/10 23:08:25\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 76.5625 (76.5625)  acc5: 97.6562 (97.6562)  time: 0.7502  data: 0.7112  max mem: 700\n",
            "2021/01/10 23:08:27\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:08:27\tINFO\t__main__\t * Acc@1 80.0400\tAcc@5 98.5600\n",
            "\n",
            "2021/01/10 23:08:29\tINFO\ttorchdistill.misc.log\tEpoch: [25]  [  0/391]  eta: 0:10:10  lr: 0.1  img/s: 252.79597990706927  loss: 0.3992 (0.3992)  time: 1.5603  data: 1.0539  max mem: 700\n",
            "2021/01/10 23:08:41\tINFO\ttorchdistill.misc.log\tEpoch: [25]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1122.2569938438705  loss: 0.4671 (0.4905)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:08:52\tINFO\ttorchdistill.misc.log\tEpoch: [25]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.9214219051717  loss: 0.4971 (0.4914)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:09:04\tINFO\ttorchdistill.misc.log\tEpoch: [25]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1105.0410054380266  loss: 0.4687 (0.4934)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:09:14\tINFO\ttorchdistill.misc.log\tEpoch: [25] Total time: 0:00:46\n",
            "2021/01/10 23:09:15\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 88.2812 (88.2812)  acc5: 100.0000 (100.0000)  time: 0.6858  data: 0.6508  max mem: 700\n",
            "2021/01/10 23:09:17\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:09:17\tINFO\t__main__\t * Acc@1 84.7700\tAcc@5 99.1900\n",
            "\n",
            "2021/01/10 23:09:19\tINFO\ttorchdistill.misc.log\tEpoch: [26]  [  0/391]  eta: 0:10:01  lr: 0.1  img/s: 285.80040266555653  loss: 0.5376 (0.5376)  time: 1.5389  data: 1.0911  max mem: 700\n",
            "2021/01/10 23:09:30\tINFO\ttorchdistill.misc.log\tEpoch: [26]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1109.0953472902231  loss: 0.4864 (0.4911)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:09:42\tINFO\ttorchdistill.misc.log\tEpoch: [26]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1102.3658558120148  loss: 0.4925 (0.4881)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:09:54\tINFO\ttorchdistill.misc.log\tEpoch: [26]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1111.7273231783581  loss: 0.4717 (0.4914)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:10:04\tINFO\ttorchdistill.misc.log\tEpoch: [26] Total time: 0:00:46\n",
            "2021/01/10 23:10:05\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 89.8438 (89.8438)  acc5: 97.6562 (97.6562)  time: 0.6935  data: 0.6438  max mem: 700\n",
            "2021/01/10 23:10:07\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:10:07\tINFO\t__main__\t * Acc@1 83.5900\tAcc@5 98.9500\n",
            "\n",
            "2021/01/10 23:10:08\tINFO\ttorchdistill.misc.log\tEpoch: [27]  [  0/391]  eta: 0:07:28  lr: 0.1  img/s: 262.7414545673438  loss: 0.3989 (0.3989)  time: 1.1479  data: 0.6607  max mem: 700\n",
            "2021/01/10 23:10:20\tINFO\ttorchdistill.misc.log\tEpoch: [27]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.1211239888553  loss: 0.4894 (0.4845)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:10:32\tINFO\ttorchdistill.misc.log\tEpoch: [27]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1111.7940884720442  loss: 0.4642 (0.4850)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:10:43\tINFO\ttorchdistill.misc.log\tEpoch: [27]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1115.1171299911932  loss: 0.4907 (0.4859)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:10:54\tINFO\ttorchdistill.misc.log\tEpoch: [27] Total time: 0:00:46\n",
            "2021/01/10 23:10:55\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:11  acc1: 82.8125 (82.8125)  acc5: 100.0000 (100.0000)  time: 0.9017  data: 0.8683  max mem: 700\n",
            "2021/01/10 23:10:57\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:10:57\tINFO\t__main__\t * Acc@1 83.1200\tAcc@5 98.6300\n",
            "\n",
            "2021/01/10 23:10:58\tINFO\ttorchdistill.misc.log\tEpoch: [28]  [  0/391]  eta: 0:08:41  lr: 0.1  img/s: 233.01587753525376  loss: 0.4012 (0.4012)  time: 1.3341  data: 0.7847  max mem: 700\n",
            "2021/01/10 23:11:10\tINFO\ttorchdistill.misc.log\tEpoch: [28]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1119.4185797271882  loss: 0.4953 (0.4806)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:11:22\tINFO\ttorchdistill.misc.log\tEpoch: [28]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1106.3823150588667  loss: 0.4685 (0.4784)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:11:33\tINFO\ttorchdistill.misc.log\tEpoch: [28]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.6760186777467  loss: 0.4973 (0.4769)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:11:44\tINFO\ttorchdistill.misc.log\tEpoch: [28] Total time: 0:00:46\n",
            "2021/01/10 23:11:45\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:02  acc1: 88.2812 (88.2812)  acc5: 99.2188 (99.2188)  time: 0.7884  data: 0.7444  max mem: 700\n",
            "2021/01/10 23:11:47\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:11:47\tINFO\t__main__\t * Acc@1 85.8900\tAcc@5 99.2300\n",
            "\n",
            "2021/01/10 23:11:47\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 85.2700 -> 85.8900)\n",
            "2021/01/10 23:11:48\tINFO\ttorchdistill.misc.log\tEpoch: [29]  [  0/391]  eta: 0:08:34  lr: 0.1  img/s: 244.30396536511293  loss: 0.5397 (0.5397)  time: 1.3165  data: 0.7926  max mem: 700\n",
            "2021/01/10 23:12:00\tINFO\ttorchdistill.misc.log\tEpoch: [29]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1015.1782226894887  loss: 0.4746 (0.4784)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:12:12\tINFO\ttorchdistill.misc.log\tEpoch: [29]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.3695075046028  loss: 0.4818 (0.4787)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:12:23\tINFO\ttorchdistill.misc.log\tEpoch: [29]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1117.1544457623238  loss: 0.4996 (0.4791)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:12:34\tINFO\ttorchdistill.misc.log\tEpoch: [29] Total time: 0:00:46\n",
            "2021/01/10 23:12:35\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 91.4062 (91.4062)  acc5: 99.2188 (99.2188)  time: 0.7097  data: 0.6497  max mem: 700\n",
            "2021/01/10 23:12:37\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:12:37\tINFO\t__main__\t * Acc@1 84.9100\tAcc@5 99.0000\n",
            "\n",
            "2021/01/10 23:12:38\tINFO\ttorchdistill.misc.log\tEpoch: [30]  [  0/391]  eta: 0:08:38  lr: 0.1  img/s: 247.59215778871484  loss: 0.4866 (0.4866)  time: 1.3273  data: 0.8103  max mem: 700\n",
            "2021/01/10 23:12:50\tINFO\ttorchdistill.misc.log\tEpoch: [30]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.0957833771097  loss: 0.4845 (0.4681)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:13:02\tINFO\ttorchdistill.misc.log\tEpoch: [30]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.5027813152033  loss: 0.4621 (0.4754)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:13:13\tINFO\ttorchdistill.misc.log\tEpoch: [30]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1103.4534105319842  loss: 0.4950 (0.4770)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:13:24\tINFO\ttorchdistill.misc.log\tEpoch: [30] Total time: 0:00:46\n",
            "2021/01/10 23:13:24\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 86.7188 (86.7188)  acc5: 99.2188 (99.2188)  time: 0.6926  data: 0.6291  max mem: 700\n",
            "2021/01/10 23:13:27\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:13:27\tINFO\t__main__\t * Acc@1 85.7400\tAcc@5 99.0000\n",
            "\n",
            "2021/01/10 23:13:28\tINFO\ttorchdistill.misc.log\tEpoch: [31]  [  0/391]  eta: 0:09:03  lr: 0.1  img/s: 242.50598822140293  loss: 0.4367 (0.4367)  time: 1.3903  data: 0.8625  max mem: 700\n",
            "2021/01/10 23:13:40\tINFO\ttorchdistill.misc.log\tEpoch: [31]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1110.3500656649742  loss: 0.4610 (0.4715)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:13:52\tINFO\ttorchdistill.misc.log\tEpoch: [31]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1116.0350897616058  loss: 0.4414 (0.4720)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:14:03\tINFO\ttorchdistill.misc.log\tEpoch: [31]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1117.5032513217602  loss: 0.4815 (0.4751)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:14:14\tINFO\ttorchdistill.misc.log\tEpoch: [31] Total time: 0:00:46\n",
            "2021/01/10 23:14:14\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 84.3750 (84.3750)  acc5: 99.2188 (99.2188)  time: 0.7425  data: 0.6778  max mem: 700\n",
            "2021/01/10 23:14:17\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:14:17\tINFO\t__main__\t * Acc@1 82.2200\tAcc@5 99.0800\n",
            "\n",
            "2021/01/10 23:14:18\tINFO\ttorchdistill.misc.log\tEpoch: [32]  [  0/391]  eta: 0:09:05  lr: 0.1  img/s: 237.27297283919188  loss: 0.4362 (0.4362)  time: 1.3964  data: 0.8569  max mem: 700\n",
            "2021/01/10 23:14:30\tINFO\ttorchdistill.misc.log\tEpoch: [32]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1115.626921126784  loss: 0.4588 (0.4617)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:14:41\tINFO\ttorchdistill.misc.log\tEpoch: [32]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.694500511344  loss: 0.4636 (0.4642)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:14:53\tINFO\ttorchdistill.misc.log\tEpoch: [32]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1112.6581556520873  loss: 0.4584 (0.4680)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:15:04\tINFO\ttorchdistill.misc.log\tEpoch: [32] Total time: 0:00:46\n",
            "2021/01/10 23:15:04\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:13  acc1: 86.7188 (86.7188)  acc5: 99.2188 (99.2188)  time: 0.9268  data: 0.8788  max mem: 700\n",
            "2021/01/10 23:15:07\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:15:07\tINFO\t__main__\t * Acc@1 85.5000\tAcc@5 98.9800\n",
            "\n",
            "2021/01/10 23:15:08\tINFO\ttorchdistill.misc.log\tEpoch: [33]  [  0/391]  eta: 0:08:56  lr: 0.1  img/s: 239.5054704692804  loss: 0.4521 (0.4521)  time: 1.3725  data: 0.8380  max mem: 700\n",
            "2021/01/10 23:15:20\tINFO\ttorchdistill.misc.log\tEpoch: [33]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1114.7258340133342  loss: 0.4460 (0.4626)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:15:31\tINFO\ttorchdistill.misc.log\tEpoch: [33]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1111.4304298771335  loss: 0.4553 (0.4616)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:15:43\tINFO\ttorchdistill.misc.log\tEpoch: [33]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.2557226186254  loss: 0.4696 (0.4666)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:15:53\tINFO\ttorchdistill.misc.log\tEpoch: [33] Total time: 0:00:46\n",
            "2021/01/10 23:15:54\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 84.3750 (84.3750)  acc5: 99.2188 (99.2188)  time: 0.6971  data: 0.6462  max mem: 700\n",
            "2021/01/10 23:15:56\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:15:56\tINFO\t__main__\t * Acc@1 82.3600\tAcc@5 98.5900\n",
            "\n",
            "2021/01/10 23:15:58\tINFO\ttorchdistill.misc.log\tEpoch: [34]  [  0/391]  eta: 0:09:54  lr: 0.1  img/s: 261.454872362786  loss: 0.3508 (0.3508)  time: 1.5208  data: 1.0312  max mem: 700\n",
            "2021/01/10 23:16:10\tINFO\ttorchdistill.misc.log\tEpoch: [34]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1116.817473971064  loss: 0.4640 (0.4613)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:16:21\tINFO\ttorchdistill.misc.log\tEpoch: [34]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1117.6777357940646  loss: 0.4519 (0.4675)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:16:33\tINFO\ttorchdistill.misc.log\tEpoch: [34]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1116.1511012428223  loss: 0.4745 (0.4655)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:16:43\tINFO\ttorchdistill.misc.log\tEpoch: [34] Total time: 0:00:46\n",
            "2021/01/10 23:16:44\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 87.5000 (87.5000)  acc5: 96.8750 (96.8750)  time: 0.7168  data: 0.6863  max mem: 700\n",
            "2021/01/10 23:16:46\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:16:46\tINFO\t__main__\t * Acc@1 85.8700\tAcc@5 99.1900\n",
            "\n",
            "2021/01/10 23:16:48\tINFO\ttorchdistill.misc.log\tEpoch: [35]  [  0/391]  eta: 0:09:28  lr: 0.1  img/s: 256.62174562909195  loss: 0.4124 (0.4124)  time: 1.4534  data: 0.9546  max mem: 700\n",
            "2021/01/10 23:17:00\tINFO\ttorchdistill.misc.log\tEpoch: [35]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1113.9140191879958  loss: 0.4745 (0.4606)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:17:11\tINFO\ttorchdistill.misc.log\tEpoch: [35]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1112.7065831279754  loss: 0.4604 (0.4543)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:17:23\tINFO\ttorchdistill.misc.log\tEpoch: [35]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1115.8912690131654  loss: 0.4818 (0.4596)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:17:33\tINFO\ttorchdistill.misc.log\tEpoch: [35] Total time: 0:00:46\n",
            "2021/01/10 23:17:34\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:10  acc1: 90.6250 (90.6250)  acc5: 99.2188 (99.2188)  time: 0.8967  data: 0.8608  max mem: 700\n",
            "2021/01/10 23:17:36\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:17:36\tINFO\t__main__\t * Acc@1 84.5400\tAcc@5 98.9500\n",
            "\n",
            "2021/01/10 23:17:38\tINFO\ttorchdistill.misc.log\tEpoch: [36]  [  0/391]  eta: 0:09:39  lr: 0.1  img/s: 248.10418629756646  loss: 0.3922 (0.3922)  time: 1.4810  data: 0.9651  max mem: 700\n",
            "2021/01/10 23:17:49\tINFO\ttorchdistill.misc.log\tEpoch: [36]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1111.4373325714948  loss: 0.4403 (0.4482)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:18:01\tINFO\ttorchdistill.misc.log\tEpoch: [36]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1110.164087378721  loss: 0.4801 (0.4601)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:18:12\tINFO\ttorchdistill.misc.log\tEpoch: [36]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1114.041148506058  loss: 0.4561 (0.4626)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:18:23\tINFO\ttorchdistill.misc.log\tEpoch: [36] Total time: 0:00:46\n",
            "2021/01/10 23:18:24\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:06  acc1: 85.9375 (85.9375)  acc5: 100.0000 (100.0000)  time: 0.8468  data: 0.8136  max mem: 700\n",
            "2021/01/10 23:18:26\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:18:26\tINFO\t__main__\t * Acc@1 85.2200\tAcc@5 99.2000\n",
            "\n",
            "2021/01/10 23:18:27\tINFO\ttorchdistill.misc.log\tEpoch: [37]  [  0/391]  eta: 0:09:02  lr: 0.1  img/s: 242.76950027651628  loss: 0.4303 (0.4303)  time: 1.3886  data: 0.8613  max mem: 700\n",
            "2021/01/10 23:18:39\tINFO\ttorchdistill.misc.log\tEpoch: [37]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1117.6661018007703  loss: 0.4622 (0.4575)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:18:51\tINFO\ttorchdistill.misc.log\tEpoch: [37]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.675607378945  loss: 0.4535 (0.4531)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:19:02\tINFO\ttorchdistill.misc.log\tEpoch: [37]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1116.715260660747  loss: 0.4481 (0.4541)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:19:13\tINFO\ttorchdistill.misc.log\tEpoch: [37] Total time: 0:00:46\n",
            "2021/01/10 23:19:14\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:05  acc1: 89.8438 (89.8438)  acc5: 99.2188 (99.2188)  time: 0.8296  data: 0.7780  max mem: 700\n",
            "2021/01/10 23:19:16\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:19:16\tINFO\t__main__\t * Acc@1 85.7700\tAcc@5 99.0000\n",
            "\n",
            "2021/01/10 23:19:17\tINFO\ttorchdistill.misc.log\tEpoch: [38]  [  0/391]  eta: 0:09:18  lr: 0.1  img/s: 247.99679974871006  loss: 0.4278 (0.4278)  time: 1.4281  data: 0.9119  max mem: 700\n",
            "2021/01/10 23:19:29\tINFO\ttorchdistill.misc.log\tEpoch: [38]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1115.601420500001  loss: 0.4344 (0.4507)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:19:41\tINFO\ttorchdistill.misc.log\tEpoch: [38]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1110.559078572847  loss: 0.4389 (0.4549)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:19:52\tINFO\ttorchdistill.misc.log\tEpoch: [38]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1114.0018508912083  loss: 0.4645 (0.4570)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:20:03\tINFO\ttorchdistill.misc.log\tEpoch: [38] Total time: 0:00:46\n",
            "2021/01/10 23:20:04\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:08  acc1: 85.1562 (85.1562)  acc5: 99.2188 (99.2188)  time: 0.8709  data: 0.8373  max mem: 700\n",
            "2021/01/10 23:20:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:20:06\tINFO\t__main__\t * Acc@1 86.0900\tAcc@5 98.8200\n",
            "\n",
            "2021/01/10 23:20:06\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 85.8900 -> 86.0900)\n",
            "2021/01/10 23:20:07\tINFO\ttorchdistill.misc.log\tEpoch: [39]  [  0/391]  eta: 0:09:08  lr: 0.1  img/s: 242.14012775624653  loss: 0.4584 (0.4584)  time: 1.4029  data: 0.8743  max mem: 700\n",
            "2021/01/10 23:20:19\tINFO\ttorchdistill.misc.log\tEpoch: [39]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1119.413911592994  loss: 0.4455 (0.4502)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:20:30\tINFO\ttorchdistill.misc.log\tEpoch: [39]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.819372538424  loss: 0.4619 (0.4547)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:20:42\tINFO\ttorchdistill.misc.log\tEpoch: [39]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1112.9280195690253  loss: 0.4565 (0.4562)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:20:53\tINFO\ttorchdistill.misc.log\tEpoch: [39] Total time: 0:00:46\n",
            "2021/01/10 23:20:53\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 91.4062 (91.4062)  acc5: 98.4375 (98.4375)  time: 0.7514  data: 0.6800  max mem: 700\n",
            "2021/01/10 23:20:56\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:20:56\tINFO\t__main__\t * Acc@1 86.5000\tAcc@5 99.1000\n",
            "\n",
            "2021/01/10 23:20:56\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 86.0900 -> 86.5000)\n",
            "2021/01/10 23:20:57\tINFO\ttorchdistill.misc.log\tEpoch: [40]  [  0/391]  eta: 0:09:22  lr: 0.1  img/s: 266.734357634188  loss: 0.3966 (0.3966)  time: 1.4380  data: 0.9581  max mem: 700\n",
            "2021/01/10 23:21:09\tINFO\ttorchdistill.misc.log\tEpoch: [40]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1112.0796581345298  loss: 0.4223 (0.4332)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:21:21\tINFO\ttorchdistill.misc.log\tEpoch: [40]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1106.272884439838  loss: 0.4421 (0.4444)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:21:32\tINFO\ttorchdistill.misc.log\tEpoch: [40]  [300/391]  eta: 0:00:11  lr: 0.1  img/s: 1112.3308042614378  loss: 0.4631 (0.4523)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:21:43\tINFO\ttorchdistill.misc.log\tEpoch: [40] Total time: 0:00:47\n",
            "2021/01/10 23:21:43\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 79.6875 (79.6875)  acc5: 100.0000 (100.0000)  time: 0.6953  data: 0.6520  max mem: 700\n",
            "2021/01/10 23:21:46\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:21:46\tINFO\t__main__\t * Acc@1 82.8700\tAcc@5 99.1100\n",
            "\n",
            "2021/01/10 23:21:47\tINFO\ttorchdistill.misc.log\tEpoch: [41]  [  0/391]  eta: 0:08:56  lr: 0.1  img/s: 254.16991533207212  loss: 0.4349 (0.4349)  time: 1.3723  data: 0.8686  max mem: 700\n",
            "2021/01/10 23:21:59\tINFO\ttorchdistill.misc.log\tEpoch: [41]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1111.946066968918  loss: 0.4328 (0.4433)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:22:11\tINFO\ttorchdistill.misc.log\tEpoch: [41]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1116.441235492652  loss: 0.4601 (0.4458)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:22:22\tINFO\ttorchdistill.misc.log\tEpoch: [41]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1112.964934211481  loss: 0.4527 (0.4474)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:22:33\tINFO\ttorchdistill.misc.log\tEpoch: [41] Total time: 0:00:46\n",
            "2021/01/10 23:22:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 87.5000 (87.5000)  acc5: 97.6562 (97.6562)  time: 0.7176  data: 0.6625  max mem: 700\n",
            "2021/01/10 23:22:36\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:22:36\tINFO\t__main__\t * Acc@1 84.0300\tAcc@5 98.9000\n",
            "\n",
            "2021/01/10 23:22:37\tINFO\ttorchdistill.misc.log\tEpoch: [42]  [  0/391]  eta: 0:09:24  lr: 0.1  img/s: 240.03156123304845  loss: 0.4065 (0.4065)  time: 1.4446  data: 0.9113  max mem: 700\n",
            "2021/01/10 23:22:49\tINFO\ttorchdistill.misc.log\tEpoch: [42]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1121.4201219028203  loss: 0.4411 (0.4459)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:23:00\tINFO\ttorchdistill.misc.log\tEpoch: [42]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.3642302252565  loss: 0.4612 (0.4514)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:23:12\tINFO\ttorchdistill.misc.log\tEpoch: [42]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1104.868170087711  loss: 0.4298 (0.4492)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:23:22\tINFO\ttorchdistill.misc.log\tEpoch: [42] Total time: 0:00:46\n",
            "2021/01/10 23:23:23\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 89.0625 (89.0625)  acc5: 100.0000 (100.0000)  time: 0.7209  data: 0.6674  max mem: 700\n",
            "2021/01/10 23:23:26\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:23:26\tINFO\t__main__\t * Acc@1 86.0000\tAcc@5 99.0700\n",
            "\n",
            "2021/01/10 23:23:27\tINFO\ttorchdistill.misc.log\tEpoch: [43]  [  0/391]  eta: 0:10:47  lr: 0.1  img/s: 267.15790688925557  loss: 0.4256 (0.4256)  time: 1.6562  data: 1.1770  max mem: 700\n",
            "2021/01/10 23:23:39\tINFO\ttorchdistill.misc.log\tEpoch: [43]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1111.5454859781157  loss: 0.4233 (0.4374)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:23:50\tINFO\ttorchdistill.misc.log\tEpoch: [43]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.0134087254241  loss: 0.4418 (0.4435)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:24:02\tINFO\ttorchdistill.misc.log\tEpoch: [43]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.7846082352746  loss: 0.4623 (0.4452)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:24:12\tINFO\ttorchdistill.misc.log\tEpoch: [43] Total time: 0:00:46\n",
            "2021/01/10 23:24:13\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 88.2812 (88.2812)  acc5: 100.0000 (100.0000)  time: 0.7355  data: 0.6796  max mem: 700\n",
            "2021/01/10 23:24:15\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:24:15\tINFO\t__main__\t * Acc@1 82.1300\tAcc@5 98.6200\n",
            "\n",
            "2021/01/10 23:24:17\tINFO\ttorchdistill.misc.log\tEpoch: [44]  [  0/391]  eta: 0:07:39  lr: 0.1  img/s: 259.73360116032563  loss: 0.4697 (0.4697)  time: 1.1754  data: 0.6826  max mem: 700\n",
            "2021/01/10 23:24:29\tINFO\ttorchdistill.misc.log\tEpoch: [44]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1111.8309279289913  loss: 0.4410 (0.4528)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:24:40\tINFO\ttorchdistill.misc.log\tEpoch: [44]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.248797319266  loss: 0.4283 (0.4514)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:24:52\tINFO\ttorchdistill.misc.log\tEpoch: [44]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.8054043961288  loss: 0.4480 (0.4507)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:25:02\tINFO\ttorchdistill.misc.log\tEpoch: [44] Total time: 0:00:46\n",
            "2021/01/10 23:25:03\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:06  acc1: 85.1562 (85.1562)  acc5: 100.0000 (100.0000)  time: 0.8428  data: 0.7984  max mem: 700\n",
            "2021/01/10 23:25:05\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:25:05\tINFO\t__main__\t * Acc@1 83.8800\tAcc@5 98.2500\n",
            "\n",
            "2021/01/10 23:25:06\tINFO\ttorchdistill.misc.log\tEpoch: [45]  [  0/391]  eta: 0:07:31  lr: 0.1  img/s: 274.9753318039595  loss: 0.5587 (0.5587)  time: 1.1539  data: 0.6884  max mem: 700\n",
            "2021/01/10 23:25:18\tINFO\ttorchdistill.misc.log\tEpoch: [45]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1116.3158789930364  loss: 0.4139 (0.4301)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:25:30\tINFO\ttorchdistill.misc.log\tEpoch: [45]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1119.5259575603898  loss: 0.4289 (0.4376)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:25:41\tINFO\ttorchdistill.misc.log\tEpoch: [45]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1112.923405410896  loss: 0.4445 (0.4447)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:25:52\tINFO\ttorchdistill.misc.log\tEpoch: [45] Total time: 0:00:46\n",
            "2021/01/10 23:25:53\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 89.8438 (89.8438)  acc5: 99.2188 (99.2188)  time: 0.7154  data: 0.6603  max mem: 700\n",
            "2021/01/10 23:25:55\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:25:55\tINFO\t__main__\t * Acc@1 85.2000\tAcc@5 98.7600\n",
            "\n",
            "2021/01/10 23:25:56\tINFO\ttorchdistill.misc.log\tEpoch: [46]  [  0/391]  eta: 0:08:33  lr: 0.1  img/s: 249.95095779375717  loss: 0.4321 (0.4321)  time: 1.3122  data: 0.8001  max mem: 700\n",
            "2021/01/10 23:26:08\tINFO\ttorchdistill.misc.log\tEpoch: [46]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1113.181857200618  loss: 0.4097 (0.4273)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:26:20\tINFO\ttorchdistill.misc.log\tEpoch: [46]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1116.2230404743736  loss: 0.4313 (0.4348)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:26:31\tINFO\ttorchdistill.misc.log\tEpoch: [46]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1115.2561177262417  loss: 0.4623 (0.4397)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:26:42\tINFO\ttorchdistill.misc.log\tEpoch: [46] Total time: 0:00:46\n",
            "2021/01/10 23:26:43\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 86.7188 (86.7188)  acc5: 99.2188 (99.2188)  time: 0.6823  data: 0.6438  max mem: 700\n",
            "2021/01/10 23:26:45\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:26:45\tINFO\t__main__\t * Acc@1 86.2600\tAcc@5 99.3100\n",
            "\n",
            "2021/01/10 23:26:46\tINFO\ttorchdistill.misc.log\tEpoch: [47]  [  0/391]  eta: 0:09:37  lr: 0.1  img/s: 265.15391119505006  loss: 0.4466 (0.4466)  time: 1.4778  data: 0.9950  max mem: 700\n",
            "2021/01/10 23:26:58\tINFO\ttorchdistill.misc.log\tEpoch: [47]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1118.6162327947961  loss: 0.4419 (0.4398)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:27:09\tINFO\ttorchdistill.misc.log\tEpoch: [47]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1117.3962611298198  loss: 0.4357 (0.4431)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:27:21\tINFO\ttorchdistill.misc.log\tEpoch: [47]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1107.5143671106728  loss: 0.4279 (0.4412)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:27:32\tINFO\ttorchdistill.misc.log\tEpoch: [47] Total time: 0:00:46\n",
            "2021/01/10 23:27:32\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:06  acc1: 92.1875 (92.1875)  acc5: 99.2188 (99.2188)  time: 0.8444  data: 0.7970  max mem: 700\n",
            "2021/01/10 23:27:35\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:27:35\tINFO\t__main__\t * Acc@1 86.1800\tAcc@5 99.1100\n",
            "\n",
            "2021/01/10 23:27:36\tINFO\ttorchdistill.misc.log\tEpoch: [48]  [  0/391]  eta: 0:09:22  lr: 0.1  img/s: 230.33573692337328  loss: 0.3560 (0.3560)  time: 1.4378  data: 0.8820  max mem: 700\n",
            "2021/01/10 23:27:48\tINFO\ttorchdistill.misc.log\tEpoch: [48]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1108.3511985251462  loss: 0.4029 (0.4266)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:27:59\tINFO\ttorchdistill.misc.log\tEpoch: [48]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1105.7101148402617  loss: 0.4475 (0.4338)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:28:11\tINFO\ttorchdistill.misc.log\tEpoch: [48]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1106.8430729393233  loss: 0.4465 (0.4385)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:28:21\tINFO\ttorchdistill.misc.log\tEpoch: [48] Total time: 0:00:46\n",
            "2021/01/10 23:28:22\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:13  acc1: 91.4062 (91.4062)  acc5: 99.2188 (99.2188)  time: 0.9275  data: 0.8817  max mem: 700\n",
            "2021/01/10 23:28:24\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:28:24\tINFO\t__main__\t * Acc@1 85.3700\tAcc@5 99.1900\n",
            "\n",
            "2021/01/10 23:28:26\tINFO\ttorchdistill.misc.log\tEpoch: [49]  [  0/391]  eta: 0:09:31  lr: 0.1  img/s: 227.7682348553918  loss: 0.4254 (0.4254)  time: 1.4604  data: 0.8984  max mem: 700\n",
            "2021/01/10 23:28:38\tINFO\ttorchdistill.misc.log\tEpoch: [49]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1114.9828081062333  loss: 0.4252 (0.4267)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:28:49\tINFO\ttorchdistill.misc.log\tEpoch: [49]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.924920721615  loss: 0.4172 (0.4314)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:29:01\tINFO\ttorchdistill.misc.log\tEpoch: [49]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1114.5800365387809  loss: 0.4540 (0.4391)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:29:11\tINFO\ttorchdistill.misc.log\tEpoch: [49] Total time: 0:00:46\n",
            "2021/01/10 23:29:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 93.7500 (93.7500)  acc5: 98.4375 (98.4375)  time: 0.7341  data: 0.7028  max mem: 700\n",
            "2021/01/10 23:29:14\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:29:14\tINFO\t__main__\t * Acc@1 84.9600\tAcc@5 99.0200\n",
            "\n",
            "2021/01/10 23:29:16\tINFO\ttorchdistill.misc.log\tEpoch: [50]  [  0/391]  eta: 0:07:22  lr: 0.1  img/s: 275.8636361300745  loss: 0.5046 (0.5046)  time: 1.1322  data: 0.6682  max mem: 700\n",
            "2021/01/10 23:29:28\tINFO\ttorchdistill.misc.log\tEpoch: [50]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1115.1680881381562  loss: 0.4158 (0.4326)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:29:39\tINFO\ttorchdistill.misc.log\tEpoch: [50]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.3850106906514  loss: 0.4269 (0.4358)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:29:51\tINFO\ttorchdistill.misc.log\tEpoch: [50]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1110.5338090953283  loss: 0.4275 (0.4386)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:30:01\tINFO\ttorchdistill.misc.log\tEpoch: [50] Total time: 0:00:46\n",
            "2021/01/10 23:30:02\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:07  acc1: 86.7188 (86.7188)  acc5: 99.2188 (99.2188)  time: 0.8503  data: 0.8128  max mem: 700\n",
            "2021/01/10 23:30:04\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:30:04\tINFO\t__main__\t * Acc@1 85.8200\tAcc@5 98.9900\n",
            "\n",
            "2021/01/10 23:30:06\tINFO\ttorchdistill.misc.log\tEpoch: [51]  [  0/391]  eta: 0:08:19  lr: 0.1  img/s: 229.98712790530305  loss: 0.4293 (0.4293)  time: 1.2777  data: 0.7211  max mem: 700\n",
            "2021/01/10 23:30:18\tINFO\ttorchdistill.misc.log\tEpoch: [51]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1117.4869688839303  loss: 0.4309 (0.4334)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:30:29\tINFO\ttorchdistill.misc.log\tEpoch: [51]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1118.029196533068  loss: 0.4263 (0.4340)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:30:41\tINFO\ttorchdistill.misc.log\tEpoch: [51]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1111.6973965117024  loss: 0.4377 (0.4397)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:30:51\tINFO\ttorchdistill.misc.log\tEpoch: [51] Total time: 0:00:46\n",
            "2021/01/10 23:30:52\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 85.9375 (85.9375)  acc5: 99.2188 (99.2188)  time: 0.7132  data: 0.6889  max mem: 700\n",
            "2021/01/10 23:30:54\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:30:54\tINFO\t__main__\t * Acc@1 84.3400\tAcc@5 98.8500\n",
            "\n",
            "2021/01/10 23:30:55\tINFO\ttorchdistill.misc.log\tEpoch: [52]  [  0/391]  eta: 0:08:25  lr: 0.1  img/s: 258.47847733532717  loss: 0.3852 (0.3852)  time: 1.2932  data: 0.7979  max mem: 700\n",
            "2021/01/10 23:31:07\tINFO\ttorchdistill.misc.log\tEpoch: [52]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1117.0103363904193  loss: 0.4117 (0.4261)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:31:19\tINFO\ttorchdistill.misc.log\tEpoch: [52]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1116.6339679779699  loss: 0.4568 (0.4311)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:31:30\tINFO\ttorchdistill.misc.log\tEpoch: [52]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1094.9666576927157  loss: 0.4394 (0.4368)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:31:41\tINFO\ttorchdistill.misc.log\tEpoch: [52] Total time: 0:00:46\n",
            "2021/01/10 23:31:42\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 88.2812 (88.2812)  acc5: 99.2188 (99.2188)  time: 0.7364  data: 0.6624  max mem: 700\n",
            "2021/01/10 23:31:44\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:31:44\tINFO\t__main__\t * Acc@1 86.4400\tAcc@5 99.1500\n",
            "\n",
            "2021/01/10 23:31:46\tINFO\ttorchdistill.misc.log\tEpoch: [53]  [  0/391]  eta: 0:10:08  lr: 0.1  img/s: 244.80782843827947  loss: 0.3816 (0.3816)  time: 1.5560  data: 1.0331  max mem: 700\n",
            "2021/01/10 23:31:57\tINFO\ttorchdistill.misc.log\tEpoch: [53]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1115.8077772004572  loss: 0.4290 (0.4240)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:32:09\tINFO\ttorchdistill.misc.log\tEpoch: [53]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1102.725870787786  loss: 0.4345 (0.4328)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:32:20\tINFO\ttorchdistill.misc.log\tEpoch: [53]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1116.2091160284172  loss: 0.4337 (0.4332)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:32:31\tINFO\ttorchdistill.misc.log\tEpoch: [53] Total time: 0:00:46\n",
            "2021/01/10 23:32:32\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 90.6250 (90.6250)  acc5: 99.2188 (99.2188)  time: 0.7435  data: 0.6736  max mem: 700\n",
            "2021/01/10 23:32:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:32:34\tINFO\t__main__\t * Acc@1 86.1900\tAcc@5 99.1300\n",
            "\n",
            "2021/01/10 23:32:36\tINFO\ttorchdistill.misc.log\tEpoch: [54]  [  0/391]  eta: 0:09:41  lr: 0.1  img/s: 213.28361822348836  loss: 0.4163 (0.4163)  time: 1.4878  data: 0.8876  max mem: 700\n",
            "2021/01/10 23:32:47\tINFO\ttorchdistill.misc.log\tEpoch: [54]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1110.7819592118794  loss: 0.4421 (0.4276)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:32:59\tINFO\ttorchdistill.misc.log\tEpoch: [54]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1106.0404162348914  loss: 0.4313 (0.4294)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:33:10\tINFO\ttorchdistill.misc.log\tEpoch: [54]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.981047393965  loss: 0.4421 (0.4346)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:33:21\tINFO\ttorchdistill.misc.log\tEpoch: [54] Total time: 0:00:46\n",
            "2021/01/10 23:33:22\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 89.8438 (89.8438)  acc5: 98.4375 (98.4375)  time: 0.6848  data: 0.6412  max mem: 700\n",
            "2021/01/10 23:33:24\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:33:24\tINFO\t__main__\t * Acc@1 87.1500\tAcc@5 99.0400\n",
            "\n",
            "2021/01/10 23:33:24\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 86.5000 -> 87.1500)\n",
            "2021/01/10 23:33:25\tINFO\ttorchdistill.misc.log\tEpoch: [55]  [  0/391]  eta: 0:07:45  lr: 0.1  img/s: 288.35889280084217  loss: 0.4845 (0.4845)  time: 1.1904  data: 0.7465  max mem: 700\n",
            "2021/01/10 23:33:37\tINFO\ttorchdistill.misc.log\tEpoch: [55]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.1211239888553  loss: 0.4246 (0.4272)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:33:49\tINFO\ttorchdistill.misc.log\tEpoch: [55]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1110.3799198348713  loss: 0.4430 (0.4311)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:34:00\tINFO\ttorchdistill.misc.log\tEpoch: [55]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1117.024280833746  loss: 0.4399 (0.4314)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:34:11\tINFO\ttorchdistill.misc.log\tEpoch: [55] Total time: 0:00:46\n",
            "2021/01/10 23:34:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 88.2812 (88.2812)  acc5: 99.2188 (99.2188)  time: 0.6951  data: 0.6490  max mem: 700\n",
            "2021/01/10 23:34:14\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:34:14\tINFO\t__main__\t * Acc@1 85.0800\tAcc@5 98.7700\n",
            "\n",
            "2021/01/10 23:34:16\tINFO\ttorchdistill.misc.log\tEpoch: [56]  [  0/391]  eta: 0:10:55  lr: 0.1  img/s: 235.32561291419816  loss: 0.5631 (0.5631)  time: 1.6762  data: 1.1323  max mem: 700\n",
            "2021/01/10 23:34:27\tINFO\ttorchdistill.misc.log\tEpoch: [56]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1115.165771757712  loss: 0.4161 (0.4226)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:34:39\tINFO\ttorchdistill.misc.log\tEpoch: [56]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1110.5912413892968  loss: 0.4295 (0.4257)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:34:50\tINFO\ttorchdistill.misc.log\tEpoch: [56]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1106.7928727665549  loss: 0.4395 (0.4291)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:35:01\tINFO\ttorchdistill.misc.log\tEpoch: [56] Total time: 0:00:46\n",
            "2021/01/10 23:35:02\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 83.5938 (83.5938)  acc5: 99.2188 (99.2188)  time: 0.7192  data: 0.6594  max mem: 700\n",
            "2021/01/10 23:35:04\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:35:04\tINFO\t__main__\t * Acc@1 81.4800\tAcc@5 98.6000\n",
            "\n",
            "2021/01/10 23:35:05\tINFO\ttorchdistill.misc.log\tEpoch: [57]  [  0/391]  eta: 0:07:54  lr: 0.1  img/s: 234.49274797674076  loss: 0.3955 (0.3955)  time: 1.2140  data: 0.6681  max mem: 700\n",
            "2021/01/10 23:35:17\tINFO\ttorchdistill.misc.log\tEpoch: [57]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1108.1315794362238  loss: 0.4239 (0.4184)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:35:29\tINFO\ttorchdistill.misc.log\tEpoch: [57]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.006466111481  loss: 0.4411 (0.4308)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:35:40\tINFO\ttorchdistill.misc.log\tEpoch: [57]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1118.728119126307  loss: 0.4484 (0.4336)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:35:51\tINFO\ttorchdistill.misc.log\tEpoch: [57] Total time: 0:00:46\n",
            "2021/01/10 23:35:51\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 90.6250 (90.6250)  acc5: 98.4375 (98.4375)  time: 0.6741  data: 0.6231  max mem: 700\n",
            "2021/01/10 23:35:54\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:35:54\tINFO\t__main__\t * Acc@1 86.1200\tAcc@5 99.0600\n",
            "\n",
            "2021/01/10 23:35:55\tINFO\ttorchdistill.misc.log\tEpoch: [58]  [  0/391]  eta: 0:08:13  lr: 0.1  img/s: 240.69197513955197  loss: 0.3846 (0.3846)  time: 1.2618  data: 0.7300  max mem: 700\n",
            "2021/01/10 23:36:07\tINFO\ttorchdistill.misc.log\tEpoch: [58]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1112.7065831279754  loss: 0.3947 (0.4166)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:36:19\tINFO\ttorchdistill.misc.log\tEpoch: [58]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1110.70842169071  loss: 0.4150 (0.4181)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:36:30\tINFO\ttorchdistill.misc.log\tEpoch: [58]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1117.3427737159436  loss: 0.4513 (0.4287)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:36:41\tINFO\ttorchdistill.misc.log\tEpoch: [58] Total time: 0:00:46\n",
            "2021/01/10 23:36:41\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 90.6250 (90.6250)  acc5: 100.0000 (100.0000)  time: 0.7055  data: 0.6606  max mem: 700\n",
            "2021/01/10 23:36:44\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:36:44\tINFO\t__main__\t * Acc@1 87.1300\tAcc@5 99.1800\n",
            "\n",
            "2021/01/10 23:36:45\tINFO\ttorchdistill.misc.log\tEpoch: [59]  [  0/391]  eta: 0:09:37  lr: 0.1  img/s: 256.57354774084524  loss: 0.3887 (0.3887)  time: 1.4778  data: 0.9789  max mem: 700\n",
            "2021/01/10 23:36:57\tINFO\ttorchdistill.misc.log\tEpoch: [59]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1120.5307040795456  loss: 0.4269 (0.4187)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:37:08\tINFO\ttorchdistill.misc.log\tEpoch: [59]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1116.7501040054583  loss: 0.4106 (0.4254)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:37:20\tINFO\ttorchdistill.misc.log\tEpoch: [59]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1109.540023312143  loss: 0.4127 (0.4260)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:37:31\tINFO\ttorchdistill.misc.log\tEpoch: [59] Total time: 0:00:46\n",
            "2021/01/10 23:37:31\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 88.2812 (88.2812)  acc5: 98.4375 (98.4375)  time: 0.6986  data: 0.6527  max mem: 700\n",
            "2021/01/10 23:37:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:37:34\tINFO\t__main__\t * Acc@1 84.9100\tAcc@5 98.9300\n",
            "\n",
            "2021/01/10 23:37:35\tINFO\ttorchdistill.misc.log\tEpoch: [60]  [  0/391]  eta: 0:08:01  lr: 0.1  img/s: 225.2442986274415  loss: 0.4353 (0.4353)  time: 1.2307  data: 0.6624  max mem: 700\n",
            "2021/01/10 23:37:47\tINFO\ttorchdistill.misc.log\tEpoch: [60]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1099.868090624699  loss: 0.4252 (0.4183)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:37:58\tINFO\ttorchdistill.misc.log\tEpoch: [60]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1106.3389961835521  loss: 0.4312 (0.4238)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:38:10\tINFO\ttorchdistill.misc.log\tEpoch: [60]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1107.5532083443359  loss: 0.4088 (0.4240)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:38:20\tINFO\ttorchdistill.misc.log\tEpoch: [60] Total time: 0:00:46\n",
            "2021/01/10 23:38:21\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:09  acc1: 80.4688 (80.4688)  acc5: 99.2188 (99.2188)  time: 0.8850  data: 0.8420  max mem: 700\n",
            "2021/01/10 23:38:23\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:38:23\tINFO\t__main__\t * Acc@1 82.3200\tAcc@5 98.2300\n",
            "\n",
            "2021/01/10 23:38:25\tINFO\ttorchdistill.misc.log\tEpoch: [61]  [  0/391]  eta: 0:07:57  lr: 0.1  img/s: 256.5003657322935  loss: 0.4124 (0.4124)  time: 1.2221  data: 0.7231  max mem: 700\n",
            "2021/01/10 23:38:37\tINFO\ttorchdistill.misc.log\tEpoch: [61]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1117.3288213196809  loss: 0.4117 (0.4170)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:38:48\tINFO\ttorchdistill.misc.log\tEpoch: [61]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.3764467544545  loss: 0.4298 (0.4231)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:39:00\tINFO\ttorchdistill.misc.log\tEpoch: [61]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1105.5165815880023  loss: 0.4440 (0.4300)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:39:10\tINFO\ttorchdistill.misc.log\tEpoch: [61] Total time: 0:00:46\n",
            "2021/01/10 23:39:11\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 85.9375 (85.9375)  acc5: 99.2188 (99.2188)  time: 0.7151  data: 0.6449  max mem: 700\n",
            "2021/01/10 23:39:13\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:39:13\tINFO\t__main__\t * Acc@1 85.6400\tAcc@5 98.6400\n",
            "\n",
            "2021/01/10 23:39:14\tINFO\ttorchdistill.misc.log\tEpoch: [62]  [  0/391]  eta: 0:07:30  lr: 0.1  img/s: 264.2996943823057  loss: 0.4100 (0.4100)  time: 1.1533  data: 0.6690  max mem: 700\n",
            "2021/01/10 23:39:26\tINFO\ttorchdistill.misc.log\tEpoch: [62]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1113.6020974770952  loss: 0.4101 (0.4212)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:39:38\tINFO\ttorchdistill.misc.log\tEpoch: [62]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1116.0907722627373  loss: 0.4089 (0.4223)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:39:50\tINFO\ttorchdistill.misc.log\tEpoch: [62]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1100.6640670807963  loss: 0.4327 (0.4244)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:40:00\tINFO\ttorchdistill.misc.log\tEpoch: [62] Total time: 0:00:46\n",
            "2021/01/10 23:40:01\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:00  acc1: 87.5000 (87.5000)  acc5: 99.2188 (99.2188)  time: 0.7683  data: 0.6985  max mem: 700\n",
            "2021/01/10 23:40:03\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:40:03\tINFO\t__main__\t * Acc@1 86.3000\tAcc@5 99.0100\n",
            "\n",
            "2021/01/10 23:40:05\tINFO\ttorchdistill.misc.log\tEpoch: [63]  [  0/391]  eta: 0:09:35  lr: 0.1  img/s: 231.74690778744605  loss: 0.4036 (0.4036)  time: 1.4709  data: 0.9185  max mem: 700\n",
            "2021/01/10 23:40:17\tINFO\ttorchdistill.misc.log\tEpoch: [63]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1115.8356064164543  loss: 0.4166 (0.4242)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:40:28\tINFO\ttorchdistill.misc.log\tEpoch: [63]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.135659687604  loss: 0.4192 (0.4224)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:40:40\tINFO\ttorchdistill.misc.log\tEpoch: [63]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1070.7394705246488  loss: 0.4386 (0.4221)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:40:50\tINFO\ttorchdistill.misc.log\tEpoch: [63] Total time: 0:00:46\n",
            "2021/01/10 23:40:51\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 87.5000 (87.5000)  acc5: 98.4375 (98.4375)  time: 0.7038  data: 0.6568  max mem: 700\n",
            "2021/01/10 23:40:53\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:40:53\tINFO\t__main__\t * Acc@1 86.9200\tAcc@5 99.1000\n",
            "\n",
            "2021/01/10 23:40:55\tINFO\ttorchdistill.misc.log\tEpoch: [64]  [  0/391]  eta: 0:09:44  lr: 0.1  img/s: 256.37714170559013  loss: 0.3937 (0.3937)  time: 1.4960  data: 0.9967  max mem: 700\n",
            "2021/01/10 23:41:06\tINFO\ttorchdistill.misc.log\tEpoch: [64]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1108.7769583292888  loss: 0.4164 (0.4131)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:41:18\tINFO\ttorchdistill.misc.log\tEpoch: [64]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1123.4688000267856  loss: 0.4159 (0.4230)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:41:29\tINFO\ttorchdistill.misc.log\tEpoch: [64]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1110.3408800895104  loss: 0.4397 (0.4256)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:41:40\tINFO\ttorchdistill.misc.log\tEpoch: [64] Total time: 0:00:46\n",
            "2021/01/10 23:41:41\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 89.0625 (89.0625)  acc5: 100.0000 (100.0000)  time: 0.6961  data: 0.6576  max mem: 700\n",
            "2021/01/10 23:41:43\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:41:43\tINFO\t__main__\t * Acc@1 86.9300\tAcc@5 99.2500\n",
            "\n",
            "2021/01/10 23:41:45\tINFO\ttorchdistill.misc.log\tEpoch: [65]  [  0/391]  eta: 0:09:52  lr: 0.1  img/s: 264.74465082287827  loss: 0.4584 (0.4584)  time: 1.5159  data: 1.0324  max mem: 700\n",
            "2021/01/10 23:41:56\tINFO\ttorchdistill.misc.log\tEpoch: [65]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.499066477959  loss: 0.4318 (0.4163)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:42:08\tINFO\ttorchdistill.misc.log\tEpoch: [65]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1100.0596510927428  loss: 0.4242 (0.4194)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:42:19\tINFO\ttorchdistill.misc.log\tEpoch: [65]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.4843058441909  loss: 0.4056 (0.4208)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:42:30\tINFO\ttorchdistill.misc.log\tEpoch: [65] Total time: 0:00:46\n",
            "2021/01/10 23:42:31\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 88.2812 (88.2812)  acc5: 98.4375 (98.4375)  time: 0.7112  data: 0.6892  max mem: 700\n",
            "2021/01/10 23:42:33\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:42:33\tINFO\t__main__\t * Acc@1 86.3700\tAcc@5 99.0900\n",
            "\n",
            "2021/01/10 23:42:34\tINFO\ttorchdistill.misc.log\tEpoch: [66]  [  0/391]  eta: 0:08:53  lr: 0.1  img/s: 241.40432716757442  loss: 0.4460 (0.4460)  time: 1.3633  data: 0.8330  max mem: 700\n",
            "2021/01/10 23:42:46\tINFO\ttorchdistill.misc.log\tEpoch: [66]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1120.7716437135061  loss: 0.4236 (0.4160)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:42:58\tINFO\ttorchdistill.misc.log\tEpoch: [66]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1114.7420360872904  loss: 0.4039 (0.4166)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:43:09\tINFO\ttorchdistill.misc.log\tEpoch: [66]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1111.9161285245032  loss: 0.4310 (0.4212)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:43:20\tINFO\ttorchdistill.misc.log\tEpoch: [66] Total time: 0:00:46\n",
            "2021/01/10 23:43:21\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:07  acc1: 90.6250 (90.6250)  acc5: 100.0000 (100.0000)  time: 0.8561  data: 0.8037  max mem: 700\n",
            "2021/01/10 23:43:23\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:43:23\tINFO\t__main__\t * Acc@1 85.3000\tAcc@5 98.8100\n",
            "\n",
            "2021/01/10 23:43:24\tINFO\ttorchdistill.misc.log\tEpoch: [67]  [  0/391]  eta: 0:09:42  lr: 0.1  img/s: 251.27594720345  loss: 0.3668 (0.3668)  time: 1.4910  data: 0.9815  max mem: 700\n",
            "2021/01/10 23:43:36\tINFO\ttorchdistill.misc.log\tEpoch: [67]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1120.881621472654  loss: 0.4062 (0.4172)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:43:47\tINFO\ttorchdistill.misc.log\tEpoch: [67]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.3411417290176  loss: 0.4079 (0.4228)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:43:59\tINFO\ttorchdistill.misc.log\tEpoch: [67]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.1610843178642  loss: 0.4361 (0.4255)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:44:10\tINFO\ttorchdistill.misc.log\tEpoch: [67] Total time: 0:00:46\n",
            "2021/01/10 23:44:10\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 87.5000 (87.5000)  acc5: 99.2188 (99.2188)  time: 0.6985  data: 0.6570  max mem: 700\n",
            "2021/01/10 23:44:12\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:44:12\tINFO\t__main__\t * Acc@1 84.6500\tAcc@5 98.8600\n",
            "\n",
            "2021/01/10 23:44:14\tINFO\ttorchdistill.misc.log\tEpoch: [68]  [  0/391]  eta: 0:06:37  lr: 0.1  img/s: 350.023478726886  loss: 0.3596 (0.3596)  time: 1.0154  data: 0.6497  max mem: 700\n",
            "2021/01/10 23:44:26\tINFO\ttorchdistill.misc.log\tEpoch: [68]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1120.5447365564914  loss: 0.3950 (0.4119)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:44:37\tINFO\ttorchdistill.misc.log\tEpoch: [68]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.8909078837623  loss: 0.3882 (0.4127)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:44:49\tINFO\ttorchdistill.misc.log\tEpoch: [68]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1104.8295169478795  loss: 0.4254 (0.4132)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:44:59\tINFO\ttorchdistill.misc.log\tEpoch: [68] Total time: 0:00:46\n",
            "2021/01/10 23:45:00\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 82.0312 (82.0312)  acc5: 100.0000 (100.0000)  time: 0.7113  data: 0.6579  max mem: 700\n",
            "2021/01/10 23:45:02\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:45:02\tINFO\t__main__\t * Acc@1 84.8400\tAcc@5 98.8400\n",
            "\n",
            "2021/01/10 23:45:04\tINFO\ttorchdistill.misc.log\tEpoch: [69]  [  0/391]  eta: 0:09:25  lr: 0.1  img/s: 260.0554298291844  loss: 0.3657 (0.3657)  time: 1.4456  data: 0.9534  max mem: 700\n",
            "2021/01/10 23:45:15\tINFO\ttorchdistill.misc.log\tEpoch: [69]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1115.3835535897185  loss: 0.3967 (0.4056)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:45:27\tINFO\ttorchdistill.misc.log\tEpoch: [69]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.0337539772868  loss: 0.4356 (0.4174)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:45:38\tINFO\ttorchdistill.misc.log\tEpoch: [69]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1107.3087824306012  loss: 0.4082 (0.4212)  time: 0.1160  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:45:49\tINFO\ttorchdistill.misc.log\tEpoch: [69] Total time: 0:00:46\n",
            "2021/01/10 23:45:50\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 88.2812 (88.2812)  acc5: 99.2188 (99.2188)  time: 0.7395  data: 0.6718  max mem: 700\n",
            "2021/01/10 23:45:52\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:45:52\tINFO\t__main__\t * Acc@1 86.2400\tAcc@5 99.0900\n",
            "\n",
            "2021/01/10 23:45:53\tINFO\ttorchdistill.misc.log\tEpoch: [70]  [  0/391]  eta: 0:08:08  lr: 0.1  img/s: 279.99081701355806  loss: 0.3518 (0.3518)  time: 1.2482  data: 0.7910  max mem: 700\n",
            "2021/01/10 23:46:05\tINFO\ttorchdistill.misc.log\tEpoch: [70]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1119.9229674873066  loss: 0.4147 (0.4067)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:46:17\tINFO\ttorchdistill.misc.log\tEpoch: [70]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.34184410129  loss: 0.4177 (0.4178)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:46:28\tINFO\ttorchdistill.misc.log\tEpoch: [70]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1118.2248068151048  loss: 0.4107 (0.4181)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:46:39\tINFO\ttorchdistill.misc.log\tEpoch: [70] Total time: 0:00:46\n",
            "2021/01/10 23:46:40\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:12  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 0.9206  data: 0.8756  max mem: 700\n",
            "2021/01/10 23:46:42\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:46:42\tINFO\t__main__\t * Acc@1 86.8000\tAcc@5 99.3100\n",
            "\n",
            "2021/01/10 23:46:43\tINFO\ttorchdistill.misc.log\tEpoch: [71]  [  0/391]  eta: 0:07:45  lr: 0.1  img/s: 252.94795840290683  loss: 0.3583 (0.3583)  time: 1.1907  data: 0.6847  max mem: 700\n",
            "2021/01/10 23:46:55\tINFO\ttorchdistill.misc.log\tEpoch: [71]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1111.4419344153694  loss: 0.4329 (0.4120)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:47:06\tINFO\ttorchdistill.misc.log\tEpoch: [71]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1098.5222898136155  loss: 0.4379 (0.4193)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:47:18\tINFO\ttorchdistill.misc.log\tEpoch: [71]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1111.2440895335792  loss: 0.4366 (0.4213)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:47:28\tINFO\ttorchdistill.misc.log\tEpoch: [71] Total time: 0:00:46\n",
            "2021/01/10 23:47:29\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 89.0625 (89.0625)  acc5: 98.4375 (98.4375)  time: 0.6808  data: 0.6522  max mem: 700\n",
            "2021/01/10 23:47:31\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:47:31\tINFO\t__main__\t * Acc@1 86.0900\tAcc@5 99.2000\n",
            "\n",
            "2021/01/10 23:47:33\tINFO\ttorchdistill.misc.log\tEpoch: [72]  [  0/391]  eta: 0:09:17  lr: 0.1  img/s: 265.8682323484434  loss: 0.4377 (0.4377)  time: 1.4262  data: 0.9448  max mem: 700\n",
            "2021/01/10 23:47:45\tINFO\ttorchdistill.misc.log\tEpoch: [72]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1108.3260294220868  loss: 0.4002 (0.4186)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:47:56\tINFO\ttorchdistill.misc.log\tEpoch: [72]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1096.1224522296245  loss: 0.4183 (0.4224)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:48:08\tINFO\ttorchdistill.misc.log\tEpoch: [72]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1119.9439935081866  loss: 0.4171 (0.4209)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:48:18\tINFO\ttorchdistill.misc.log\tEpoch: [72] Total time: 0:00:46\n",
            "2021/01/10 23:48:19\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 85.1562 (85.1562)  acc5: 97.6562 (97.6562)  time: 0.6956  data: 0.6547  max mem: 700\n",
            "2021/01/10 23:48:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:48:21\tINFO\t__main__\t * Acc@1 84.8000\tAcc@5 98.9200\n",
            "\n",
            "2021/01/10 23:48:23\tINFO\ttorchdistill.misc.log\tEpoch: [73]  [  0/391]  eta: 0:09:15  lr: 0.1  img/s: 211.62987166312092  loss: 0.4467 (0.4467)  time: 1.4208  data: 0.8160  max mem: 700\n",
            "2021/01/10 23:48:35\tINFO\ttorchdistill.misc.log\tEpoch: [73]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1101.951789819376  loss: 0.4044 (0.4073)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:48:46\tINFO\ttorchdistill.misc.log\tEpoch: [73]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1102.7236058078417  loss: 0.4183 (0.4106)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:48:58\tINFO\ttorchdistill.misc.log\tEpoch: [73]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1095.386664490329  loss: 0.4151 (0.4150)  time: 0.1170  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:49:08\tINFO\ttorchdistill.misc.log\tEpoch: [73] Total time: 0:00:47\n",
            "2021/01/10 23:49:09\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:16  acc1: 92.1875 (92.1875)  acc5: 100.0000 (100.0000)  time: 0.9634  data: 0.9242  max mem: 700\n",
            "2021/01/10 23:49:11\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:49:11\tINFO\t__main__\t * Acc@1 87.6200\tAcc@5 99.2500\n",
            "\n",
            "2021/01/10 23:49:11\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 87.1500 -> 87.6200)\n",
            "2021/01/10 23:49:13\tINFO\ttorchdistill.misc.log\tEpoch: [74]  [  0/391]  eta: 0:08:07  lr: 0.1  img/s: 276.8053580129155  loss: 0.3530 (0.3530)  time: 1.2469  data: 0.7845  max mem: 700\n",
            "2021/01/10 23:49:25\tINFO\ttorchdistill.misc.log\tEpoch: [74]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1115.8703948886252  loss: 0.4133 (0.4125)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:49:36\tINFO\ttorchdistill.misc.log\tEpoch: [74]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1100.2309851996672  loss: 0.4108 (0.4132)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:49:48\tINFO\ttorchdistill.misc.log\tEpoch: [74]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1106.238691810629  loss: 0.4180 (0.4184)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:49:58\tINFO\ttorchdistill.misc.log\tEpoch: [74] Total time: 0:00:46\n",
            "2021/01/10 23:49:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 88.2812 (88.2812)  acc5: 100.0000 (100.0000)  time: 0.7003  data: 0.6643  max mem: 700\n",
            "2021/01/10 23:50:01\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:50:01\tINFO\t__main__\t * Acc@1 86.3300\tAcc@5 98.7800\n",
            "\n",
            "2021/01/10 23:50:03\tINFO\ttorchdistill.misc.log\tEpoch: [75]  [  0/391]  eta: 0:08:56  lr: 0.1  img/s: 243.5661357130219  loss: 0.4537 (0.4537)  time: 1.3733  data: 0.8478  max mem: 700\n",
            "2021/01/10 23:50:15\tINFO\ttorchdistill.misc.log\tEpoch: [75]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1114.7258340133342  loss: 0.3758 (0.4127)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:50:26\tINFO\ttorchdistill.misc.log\tEpoch: [75]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.9301976715958  loss: 0.4127 (0.4104)  time: 0.1159  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:50:38\tINFO\ttorchdistill.misc.log\tEpoch: [75]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.015695843535  loss: 0.4190 (0.4130)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:50:48\tINFO\ttorchdistill.misc.log\tEpoch: [75] Total time: 0:00:46\n",
            "2021/01/10 23:50:49\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.6982  data: 0.6509  max mem: 700\n",
            "2021/01/10 23:50:51\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:50:51\tINFO\t__main__\t * Acc@1 87.9000\tAcc@5 99.2900\n",
            "\n",
            "2021/01/10 23:50:51\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 87.6200 -> 87.9000)\n",
            "2021/01/10 23:50:52\tINFO\ttorchdistill.misc.log\tEpoch: [76]  [  0/391]  eta: 0:07:23  lr: 0.1  img/s: 270.48478396571625  loss: 0.3307 (0.3307)  time: 1.1343  data: 0.6611  max mem: 700\n",
            "2021/01/10 23:51:05\tINFO\ttorchdistill.misc.log\tEpoch: [76]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1112.1211239888553  loss: 0.4243 (0.4116)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:51:16\tINFO\ttorchdistill.misc.log\tEpoch: [76]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1117.7475448403652  loss: 0.4294 (0.4161)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:51:28\tINFO\ttorchdistill.misc.log\tEpoch: [76]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1117.8289997501458  loss: 0.4130 (0.4165)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:51:38\tINFO\ttorchdistill.misc.log\tEpoch: [76] Total time: 0:00:46\n",
            "2021/01/10 23:51:39\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 89.8438 (89.8438)  acc5: 98.4375 (98.4375)  time: 0.7002  data: 0.6551  max mem: 700\n",
            "2021/01/10 23:51:41\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:51:41\tINFO\t__main__\t * Acc@1 85.1800\tAcc@5 98.9000\n",
            "\n",
            "2021/01/10 23:51:43\tINFO\ttorchdistill.misc.log\tEpoch: [77]  [  0/391]  eta: 0:08:55  lr: 0.1  img/s: 249.5990865359358  loss: 0.3985 (0.3985)  time: 1.3686  data: 0.8558  max mem: 700\n",
            "2021/01/10 23:51:54\tINFO\ttorchdistill.misc.log\tEpoch: [77]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.8311302822958  loss: 0.3940 (0.4110)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:52:06\tINFO\ttorchdistill.misc.log\tEpoch: [77]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1111.9000084914082  loss: 0.4084 (0.4134)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:52:18\tINFO\ttorchdistill.misc.log\tEpoch: [77]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1107.5235059793831  loss: 0.4238 (0.4152)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:52:28\tINFO\ttorchdistill.misc.log\tEpoch: [77] Total time: 0:00:46\n",
            "2021/01/10 23:52:29\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:00  acc1: 82.8125 (82.8125)  acc5: 98.4375 (98.4375)  time: 0.7714  data: 0.7425  max mem: 700\n",
            "2021/01/10 23:52:31\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:52:31\tINFO\t__main__\t * Acc@1 83.9300\tAcc@5 98.7600\n",
            "\n",
            "2021/01/10 23:52:32\tINFO\ttorchdistill.misc.log\tEpoch: [78]  [  0/391]  eta: 0:08:49  lr: 0.1  img/s: 254.92881739668863  loss: 0.4688 (0.4688)  time: 1.3549  data: 0.8527  max mem: 700\n",
            "2021/01/10 23:52:44\tINFO\ttorchdistill.misc.log\tEpoch: [78]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1112.748095748363  loss: 0.3956 (0.3982)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:52:56\tINFO\ttorchdistill.misc.log\tEpoch: [78]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1115.8425639373565  loss: 0.3989 (0.4043)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:53:07\tINFO\ttorchdistill.misc.log\tEpoch: [78]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1106.9457692957967  loss: 0.4266 (0.4113)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:53:18\tINFO\ttorchdistill.misc.log\tEpoch: [78] Total time: 0:00:46\n",
            "2021/01/10 23:53:19\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 89.0625 (89.0625)  acc5: 100.0000 (100.0000)  time: 0.6935  data: 0.6503  max mem: 700\n",
            "2021/01/10 23:53:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:53:21\tINFO\t__main__\t * Acc@1 87.3300\tAcc@5 99.3400\n",
            "\n",
            "2021/01/10 23:53:23\tINFO\ttorchdistill.misc.log\tEpoch: [79]  [  0/391]  eta: 0:09:25  lr: 0.1  img/s: 242.90240531201914  loss: 0.4298 (0.4298)  time: 1.4468  data: 0.9198  max mem: 700\n",
            "2021/01/10 23:53:34\tINFO\ttorchdistill.misc.log\tEpoch: [79]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1116.4203407876296  loss: 0.3928 (0.4098)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:53:46\tINFO\ttorchdistill.misc.log\tEpoch: [79]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1104.0116144448489  loss: 0.4106 (0.4169)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:53:57\tINFO\ttorchdistill.misc.log\tEpoch: [79]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1112.4160814890483  loss: 0.4049 (0.4164)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:54:08\tINFO\ttorchdistill.misc.log\tEpoch: [79] Total time: 0:00:46\n",
            "2021/01/10 23:54:09\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 85.1562 (85.1562)  acc5: 98.4375 (98.4375)  time: 0.6845  data: 0.6479  max mem: 700\n",
            "2021/01/10 23:54:11\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:54:11\tINFO\t__main__\t * Acc@1 85.8000\tAcc@5 99.1000\n",
            "\n",
            "2021/01/10 23:54:12\tINFO\ttorchdistill.misc.log\tEpoch: [80]  [  0/391]  eta: 0:09:20  lr: 0.1  img/s: 254.0896797274292  loss: 0.4474 (0.4474)  time: 1.4327  data: 0.9289  max mem: 700\n",
            "2021/01/10 23:54:24\tINFO\ttorchdistill.misc.log\tEpoch: [80]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1123.861553855751  loss: 0.3869 (0.4053)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:54:36\tINFO\ttorchdistill.misc.log\tEpoch: [80]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1111.5362806134174  loss: 0.4141 (0.4078)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:54:47\tINFO\ttorchdistill.misc.log\tEpoch: [80]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1132.6271073089947  loss: 0.4369 (0.4135)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:54:58\tINFO\ttorchdistill.misc.log\tEpoch: [80] Total time: 0:00:46\n",
            "2021/01/10 23:54:58\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:02  acc1: 85.9375 (85.9375)  acc5: 99.2188 (99.2188)  time: 0.7974  data: 0.7636  max mem: 700\n",
            "2021/01/10 23:55:01\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:55:01\tINFO\t__main__\t * Acc@1 87.0600\tAcc@5 99.0400\n",
            "\n",
            "2021/01/10 23:55:02\tINFO\ttorchdistill.misc.log\tEpoch: [81]  [  0/391]  eta: 0:08:52  lr: 0.1  img/s: 254.22708553033772  loss: 0.3938 (0.3938)  time: 1.3626  data: 0.8591  max mem: 700\n",
            "2021/01/10 23:55:14\tINFO\ttorchdistill.misc.log\tEpoch: [81]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1113.5489726751928  loss: 0.4043 (0.4084)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:55:25\tINFO\ttorchdistill.misc.log\tEpoch: [81]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1112.630484701279  loss: 0.4107 (0.4063)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:55:37\tINFO\ttorchdistill.misc.log\tEpoch: [81]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1109.5377302534364  loss: 0.4224 (0.4112)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:55:48\tINFO\ttorchdistill.misc.log\tEpoch: [81] Total time: 0:00:46\n",
            "2021/01/10 23:55:48\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:00  acc1: 89.8438 (89.8438)  acc5: 99.2188 (99.2188)  time: 0.7628  data: 0.7363  max mem: 700\n",
            "2021/01/10 23:55:51\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:55:51\tINFO\t__main__\t * Acc@1 85.6100\tAcc@5 98.9500\n",
            "\n",
            "2021/01/10 23:55:52\tINFO\ttorchdistill.misc.log\tEpoch: [82]  [  0/391]  eta: 0:08:55  lr: 0.1  img/s: 238.80405219367796  loss: 0.3882 (0.3882)  time: 1.3688  data: 0.8328  max mem: 700\n",
            "2021/01/10 23:56:04\tINFO\ttorchdistill.misc.log\tEpoch: [82]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1102.4518757482356  loss: 0.4162 (0.4018)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:56:15\tINFO\ttorchdistill.misc.log\tEpoch: [82]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1118.4531053390333  loss: 0.4245 (0.4142)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:56:27\tINFO\ttorchdistill.misc.log\tEpoch: [82]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1115.7567605762597  loss: 0.4168 (0.4163)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:56:37\tINFO\ttorchdistill.misc.log\tEpoch: [82] Total time: 0:00:46\n",
            "2021/01/10 23:56:38\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 89.8438 (89.8438)  acc5: 99.2188 (99.2188)  time: 0.7163  data: 0.6645  max mem: 700\n",
            "2021/01/10 23:56:40\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:56:40\tINFO\t__main__\t * Acc@1 87.4900\tAcc@5 98.9300\n",
            "\n",
            "2021/01/10 23:56:41\tINFO\ttorchdistill.misc.log\tEpoch: [83]  [  0/391]  eta: 0:07:18  lr: 0.1  img/s: 280.39383235937896  loss: 0.3615 (0.3615)  time: 1.1222  data: 0.6656  max mem: 700\n",
            "2021/01/10 23:56:53\tINFO\ttorchdistill.misc.log\tEpoch: [83]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1114.5268183922458  loss: 0.4170 (0.4070)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:57:05\tINFO\ttorchdistill.misc.log\tEpoch: [83]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1119.624016183187  loss: 0.4012 (0.4091)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:57:16\tINFO\ttorchdistill.misc.log\tEpoch: [83]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1116.5178561030189  loss: 0.4197 (0.4108)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:57:27\tINFO\ttorchdistill.misc.log\tEpoch: [83] Total time: 0:00:46\n",
            "2021/01/10 23:57:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 0.6743  data: 0.6195  max mem: 700\n",
            "2021/01/10 23:57:30\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:57:30\tINFO\t__main__\t * Acc@1 86.3300\tAcc@5 99.0400\n",
            "\n",
            "2021/01/10 23:57:31\tINFO\ttorchdistill.misc.log\tEpoch: [84]  [  0/391]  eta: 0:08:08  lr: 0.1  img/s: 212.1952317713274  loss: 0.4191 (0.4191)  time: 1.2489  data: 0.6456  max mem: 700\n",
            "2021/01/10 23:57:43\tINFO\ttorchdistill.misc.log\tEpoch: [84]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1106.582994098866  loss: 0.4138 (0.4056)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:57:55\tINFO\ttorchdistill.misc.log\tEpoch: [84]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1119.5096161264828  loss: 0.4087 (0.4050)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:58:06\tINFO\ttorchdistill.misc.log\tEpoch: [84]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1116.9708290249225  loss: 0.4275 (0.4108)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:58:17\tINFO\ttorchdistill.misc.log\tEpoch: [84] Total time: 0:00:46\n",
            "2021/01/10 23:58:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:00  acc1: 89.0625 (89.0625)  acc5: 99.2188 (99.2188)  time: 0.7675  data: 0.7245  max mem: 700\n",
            "2021/01/10 23:58:20\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/10 23:58:20\tINFO\t__main__\t * Acc@1 86.2700\tAcc@5 98.9400\n",
            "\n",
            "2021/01/10 23:58:21\tINFO\ttorchdistill.misc.log\tEpoch: [85]  [  0/391]  eta: 0:09:12  lr: 0.1  img/s: 241.14030284083967  loss: 0.4153 (0.4153)  time: 1.4130  data: 0.8822  max mem: 700\n",
            "2021/01/10 23:58:33\tINFO\ttorchdistill.misc.log\tEpoch: [85]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1118.4065062329178  loss: 0.4045 (0.4094)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:58:44\tINFO\ttorchdistill.misc.log\tEpoch: [85]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1116.325163694282  loss: 0.3792 (0.4045)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:58:56\tINFO\ttorchdistill.misc.log\tEpoch: [85]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1113.6598475765334  loss: 0.4244 (0.4106)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:59:07\tINFO\ttorchdistill.misc.log\tEpoch: [85] Total time: 0:00:46\n",
            "2021/01/10 23:59:07\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 89.0625 (89.0625)  acc5: 99.2188 (99.2188)  time: 0.6832  data: 0.6280  max mem: 700\n",
            "2021/01/10 23:59:10\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/10 23:59:10\tINFO\t__main__\t * Acc@1 86.6400\tAcc@5 99.2400\n",
            "\n",
            "2021/01/10 23:59:11\tINFO\ttorchdistill.misc.log\tEpoch: [86]  [  0/391]  eta: 0:07:56  lr: 0.1  img/s: 260.47570904514396  loss: 0.4144 (0.4144)  time: 1.2176  data: 0.7262  max mem: 700\n",
            "2021/01/10 23:59:23\tINFO\ttorchdistill.misc.log\tEpoch: [86]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1121.9591400006686  loss: 0.4018 (0.4140)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:59:34\tINFO\ttorchdistill.misc.log\tEpoch: [86]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1108.788408000066  loss: 0.3983 (0.4162)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:59:46\tINFO\ttorchdistill.misc.log\tEpoch: [86]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1114.2931814596807  loss: 0.4387 (0.4155)  time: 0.1157  data: 0.0001  max mem: 700\n",
            "2021/01/10 23:59:56\tINFO\ttorchdistill.misc.log\tEpoch: [86] Total time: 0:00:46\n",
            "2021/01/10 23:59:57\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:12  acc1: 85.9375 (85.9375)  acc5: 99.2188 (99.2188)  time: 0.9116  data: 0.8584  max mem: 700\n",
            "2021/01/11 00:00:00\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:00:00\tINFO\t__main__\t * Acc@1 83.7000\tAcc@5 98.4700\n",
            "\n",
            "2021/01/11 00:00:01\tINFO\ttorchdistill.misc.log\tEpoch: [87]  [  0/391]  eta: 0:10:04  lr: 0.1  img/s: 217.99978803863868  loss: 0.4276 (0.4276)  time: 1.5459  data: 0.9588  max mem: 700\n",
            "2021/01/11 00:00:13\tINFO\ttorchdistill.misc.log\tEpoch: [87]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1102.4179189065985  loss: 0.4057 (0.4065)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:00:24\tINFO\ttorchdistill.misc.log\tEpoch: [87]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1117.1521211225813  loss: 0.4026 (0.4027)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:00:36\tINFO\ttorchdistill.misc.log\tEpoch: [87]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1115.3557469174916  loss: 0.4265 (0.4082)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:00:46\tINFO\ttorchdistill.misc.log\tEpoch: [87] Total time: 0:00:46\n",
            "2021/01/11 00:00:47\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 89.0625 (89.0625)  acc5: 98.4375 (98.4375)  time: 0.7157  data: 0.6800  max mem: 700\n",
            "2021/01/11 00:00:49\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:00:49\tINFO\t__main__\t * Acc@1 88.1600\tAcc@5 99.2100\n",
            "\n",
            "2021/01/11 00:00:49\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 87.9000 -> 88.1600)\n",
            "2021/01/11 00:00:51\tINFO\ttorchdistill.misc.log\tEpoch: [88]  [  0/391]  eta: 0:09:36  lr: 0.1  img/s: 257.00564399462695  loss: 0.3706 (0.3706)  time: 1.4737  data: 0.9756  max mem: 700\n",
            "2021/01/11 00:01:03\tINFO\ttorchdistill.misc.log\tEpoch: [88]  [100/391]  eta: 0:00:38  lr: 0.1  img/s: 1122.3297223395225  loss: 0.3950 (0.4026)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:01:14\tINFO\ttorchdistill.misc.log\tEpoch: [88]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1113.3342153668768  loss: 0.3980 (0.4052)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:01:26\tINFO\ttorchdistill.misc.log\tEpoch: [88]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1123.802740895951  loss: 0.4012 (0.4071)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:01:36\tINFO\ttorchdistill.misc.log\tEpoch: [88] Total time: 0:00:46\n",
            "2021/01/11 00:01:37\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:00  acc1: 87.5000 (87.5000)  acc5: 99.2188 (99.2188)  time: 0.7649  data: 0.7217  max mem: 700\n",
            "2021/01/11 00:01:39\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:01:39\tINFO\t__main__\t * Acc@1 86.3300\tAcc@5 98.8700\n",
            "\n",
            "2021/01/11 00:01:41\tINFO\ttorchdistill.misc.log\tEpoch: [89]  [  0/391]  eta: 0:09:43  lr: 0.1  img/s: 258.4223646373949  loss: 0.4379 (0.4379)  time: 1.4911  data: 0.9957  max mem: 700\n",
            "2021/01/11 00:01:53\tINFO\ttorchdistill.misc.log\tEpoch: [89]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1117.4334727859298  loss: 0.4082 (0.4009)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:02:04\tINFO\ttorchdistill.misc.log\tEpoch: [89]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1106.3093589075195  loss: 0.4058 (0.4034)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:02:16\tINFO\ttorchdistill.misc.log\tEpoch: [89]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1102.725870787786  loss: 0.4336 (0.4094)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:02:26\tINFO\ttorchdistill.misc.log\tEpoch: [89] Total time: 0:00:46\n",
            "2021/01/11 00:02:27\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 85.9375 (85.9375)  acc5: 97.6562 (97.6562)  time: 0.6963  data: 0.6450  max mem: 700\n",
            "2021/01/11 00:02:29\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:02:29\tINFO\t__main__\t * Acc@1 85.8400\tAcc@5 99.0600\n",
            "\n",
            "2021/01/11 00:02:31\tINFO\ttorchdistill.misc.log\tEpoch: [90]  [  0/391]  eta: 0:09:35  lr: 0.1  img/s: 262.49518985361277  loss: 0.4504 (0.4504)  time: 1.4722  data: 0.9846  max mem: 700\n",
            "2021/01/11 00:02:42\tINFO\ttorchdistill.misc.log\tEpoch: [90]  [100/391]  eta: 0:00:37  lr: 0.1  img/s: 1124.195728285451  loss: 0.3936 (0.4021)  time: 0.1145  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:02:54\tINFO\ttorchdistill.misc.log\tEpoch: [90]  [200/391]  eta: 0:00:23  lr: 0.1  img/s: 1117.8452921567525  loss: 0.4017 (0.4048)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:03:05\tINFO\ttorchdistill.misc.log\tEpoch: [90]  [300/391]  eta: 0:00:10  lr: 0.1  img/s: 1116.5666201492024  loss: 0.4200 (0.4107)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:03:16\tINFO\ttorchdistill.misc.log\tEpoch: [90] Total time: 0:00:46\n",
            "2021/01/11 00:03:17\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 89.8438 (89.8438)  acc5: 99.2188 (99.2188)  time: 0.6761  data: 0.6289  max mem: 700\n",
            "2021/01/11 00:03:19\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:03:19\tINFO\t__main__\t * Acc@1 87.4100\tAcc@5 99.2500\n",
            "\n",
            "2021/01/11 00:03:20\tINFO\ttorchdistill.misc.log\tEpoch: [91]  [  0/391]  eta: 0:09:40  lr: 0.010000000000000002  img/s: 277.84380285218054  loss: 0.3905 (0.3905)  time: 1.4854  data: 1.0247  max mem: 700\n",
            "2021/01/11 00:03:32\tINFO\ttorchdistill.misc.log\tEpoch: [91]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1112.6374023099513  loss: 0.3367 (0.3641)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:03:43\tINFO\ttorchdistill.misc.log\tEpoch: [91]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1114.8230535222967  loss: 0.3479 (0.3504)  time: 0.1145  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:03:55\tINFO\ttorchdistill.misc.log\tEpoch: [91]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1104.804507533821  loss: 0.3226 (0.3446)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:04:06\tINFO\ttorchdistill.misc.log\tEpoch: [91] Total time: 0:00:46\n",
            "2021/01/11 00:04:06\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.7150  data: 0.6455  max mem: 700\n",
            "2021/01/11 00:04:09\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:04:09\tINFO\t__main__\t * Acc@1 91.3300\tAcc@5 99.5100\n",
            "\n",
            "2021/01/11 00:04:09\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 88.1600 -> 91.3300)\n",
            "2021/01/11 00:04:10\tINFO\ttorchdistill.misc.log\tEpoch: [92]  [  0/391]  eta: 0:08:10  lr: 0.010000000000000002  img/s: 259.25860865861534  loss: 0.2612 (0.2612)  time: 1.2539  data: 0.7601  max mem: 700\n",
            "2021/01/11 00:04:22\tINFO\ttorchdistill.misc.log\tEpoch: [92]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1112.46679306665  loss: 0.3223 (0.3175)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:04:33\tINFO\ttorchdistill.misc.log\tEpoch: [92]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1106.4780846113101  loss: 0.3097 (0.3188)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:04:45\tINFO\ttorchdistill.misc.log\tEpoch: [92]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1114.3440643278495  loss: 0.3041 (0.3175)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:04:55\tINFO\ttorchdistill.misc.log\tEpoch: [92] Total time: 0:00:46\n",
            "2021/01/11 00:04:56\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:02  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.7936  data: 0.7603  max mem: 700\n",
            "2021/01/11 00:04:58\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:04:58\tINFO\t__main__\t * Acc@1 91.6800\tAcc@5 99.4300\n",
            "\n",
            "2021/01/11 00:04:58\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 91.3300 -> 91.6800)\n",
            "2021/01/11 00:05:00\tINFO\ttorchdistill.misc.log\tEpoch: [93]  [  0/391]  eta: 0:09:46  lr: 0.010000000000000002  img/s: 272.49743907558013  loss: 0.2707 (0.2707)  time: 1.5009  data: 1.0312  max mem: 700\n",
            "2021/01/11 00:05:12\tINFO\ttorchdistill.misc.log\tEpoch: [93]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1121.989621712898  loss: 0.3098 (0.3075)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:05:23\tINFO\ttorchdistill.misc.log\tEpoch: [93]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1122.944772135907  loss: 0.3165 (0.3093)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:05:35\tINFO\ttorchdistill.misc.log\tEpoch: [93]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1113.870108529898  loss: 0.3121 (0.3100)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:05:45\tINFO\ttorchdistill.misc.log\tEpoch: [93] Total time: 0:00:46\n",
            "2021/01/11 00:05:46\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.7256  data: 0.6740  max mem: 700\n",
            "2021/01/11 00:05:48\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:05:48\tINFO\t__main__\t * Acc@1 91.4100\tAcc@5 99.4500\n",
            "\n",
            "2021/01/11 00:05:49\tINFO\ttorchdistill.misc.log\tEpoch: [94]  [  0/391]  eta: 0:09:06  lr: 0.010000000000000002  img/s: 262.7243539929023  loss: 0.2666 (0.2666)  time: 1.3972  data: 0.9100  max mem: 700\n",
            "2021/01/11 00:06:01\tINFO\ttorchdistill.misc.log\tEpoch: [94]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1092.4355816735986  loss: 0.3024 (0.3026)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:06:13\tINFO\ttorchdistill.misc.log\tEpoch: [94]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1113.9278864308803  loss: 0.2895 (0.3035)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:06:24\tINFO\ttorchdistill.misc.log\tEpoch: [94]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1103.4080529105531  loss: 0.2929 (0.3040)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:06:35\tINFO\ttorchdistill.misc.log\tEpoch: [94] Total time: 0:00:46\n",
            "2021/01/11 00:06:36\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.7462  data: 0.6773  max mem: 700\n",
            "2021/01/11 00:06:38\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:06:38\tINFO\t__main__\t * Acc@1 91.6700\tAcc@5 99.4000\n",
            "\n",
            "2021/01/11 00:06:39\tINFO\ttorchdistill.misc.log\tEpoch: [95]  [  0/391]  eta: 0:10:36  lr: 0.010000000000000002  img/s: 243.30199496692427  loss: 0.3273 (0.3273)  time: 1.6275  data: 1.1014  max mem: 700\n",
            "2021/01/11 00:06:51\tINFO\ttorchdistill.misc.log\tEpoch: [95]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1114.6078045458698  loss: 0.2940 (0.2992)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:07:03\tINFO\ttorchdistill.misc.log\tEpoch: [95]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1112.4575724359147  loss: 0.2880 (0.3000)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:07:14\tINFO\ttorchdistill.misc.log\tEpoch: [95]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1115.4438061362082  loss: 0.3052 (0.3033)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:07:25\tINFO\ttorchdistill.misc.log\tEpoch: [95] Total time: 0:00:46\n",
            "2021/01/11 00:07:25\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 92.9688 (92.9688)  acc5: 100.0000 (100.0000)  time: 0.7522  data: 0.7171  max mem: 700\n",
            "2021/01/11 00:07:28\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:07:28\tINFO\t__main__\t * Acc@1 91.7400\tAcc@5 99.4400\n",
            "\n",
            "2021/01/11 00:07:28\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 91.6800 -> 91.7400)\n",
            "2021/01/11 00:07:29\tINFO\ttorchdistill.misc.log\tEpoch: [96]  [  0/391]  eta: 0:09:25  lr: 0.010000000000000002  img/s: 240.77682066783422  loss: 0.2645 (0.2645)  time: 1.4475  data: 0.9159  max mem: 700\n",
            "2021/01/11 00:07:41\tINFO\ttorchdistill.misc.log\tEpoch: [96]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1106.6628298627572  loss: 0.2849 (0.2931)  time: 0.1145  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:07:52\tINFO\ttorchdistill.misc.log\tEpoch: [96]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1120.5119946569826  loss: 0.3033 (0.2972)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:08:04\tINFO\ttorchdistill.misc.log\tEpoch: [96]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1113.7360868798555  loss: 0.2867 (0.2954)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:08:14\tINFO\ttorchdistill.misc.log\tEpoch: [96] Total time: 0:00:46\n",
            "2021/01/11 00:08:15\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.6998  data: 0.6510  max mem: 700\n",
            "2021/01/11 00:08:17\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:08:17\tINFO\t__main__\t * Acc@1 91.7100\tAcc@5 99.4500\n",
            "\n",
            "2021/01/11 00:08:19\tINFO\ttorchdistill.misc.log\tEpoch: [97]  [  0/391]  eta: 0:10:00  lr: 0.010000000000000002  img/s: 251.5720765637769  loss: 0.2717 (0.2717)  time: 1.5347  data: 1.0259  max mem: 700\n",
            "2021/01/11 00:08:31\tINFO\ttorchdistill.misc.log\tEpoch: [97]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1118.9263060926328  loss: 0.2881 (0.2904)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:08:42\tINFO\ttorchdistill.misc.log\tEpoch: [97]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1121.0946184960355  loss: 0.2858 (0.2911)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:08:53\tINFO\ttorchdistill.misc.log\tEpoch: [97]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1117.4869688839303  loss: 0.2907 (0.2920)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:09:04\tINFO\ttorchdistill.misc.log\tEpoch: [97] Total time: 0:00:46\n",
            "2021/01/11 00:09:05\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:09  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.8771  data: 0.8216  max mem: 700\n",
            "2021/01/11 00:09:07\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:09:07\tINFO\t__main__\t * Acc@1 91.9000\tAcc@5 99.4200\n",
            "\n",
            "2021/01/11 00:09:07\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 91.7400 -> 91.9000)\n",
            "2021/01/11 00:09:09\tINFO\ttorchdistill.misc.log\tEpoch: [98]  [  0/391]  eta: 0:10:17  lr: 0.010000000000000002  img/s: 236.45721825976733  loss: 0.2679 (0.2679)  time: 1.5798  data: 1.0384  max mem: 700\n",
            "2021/01/11 00:09:20\tINFO\ttorchdistill.misc.log\tEpoch: [98]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1115.9492567903237  loss: 0.2820 (0.2914)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:09:32\tINFO\ttorchdistill.misc.log\tEpoch: [98]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1114.2631164944366  loss: 0.2933 (0.2917)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:09:43\tINFO\ttorchdistill.misc.log\tEpoch: [98]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1110.3707337654548  loss: 0.2854 (0.2923)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:09:54\tINFO\ttorchdistill.misc.log\tEpoch: [98] Total time: 0:00:46\n",
            "2021/01/11 00:09:55\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:52  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.6591  data: 0.6158  max mem: 700\n",
            "2021/01/11 00:09:57\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:09:57\tINFO\t__main__\t * Acc@1 92.0200\tAcc@5 99.4700\n",
            "\n",
            "2021/01/11 00:09:57\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 91.9000 -> 92.0200)\n",
            "2021/01/11 00:09:59\tINFO\ttorchdistill.misc.log\tEpoch: [99]  [  0/391]  eta: 0:11:47  lr: 0.010000000000000002  img/s: 215.85674601946073  loss: 0.2946 (0.2946)  time: 1.8082  data: 1.2152  max mem: 700\n",
            "2021/01/11 00:10:10\tINFO\ttorchdistill.misc.log\tEpoch: [99]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1108.673921932241  loss: 0.2841 (0.2901)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:10:22\tINFO\ttorchdistill.misc.log\tEpoch: [99]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1115.3858708749885  loss: 0.2848 (0.2902)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:10:33\tINFO\ttorchdistill.misc.log\tEpoch: [99]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1111.3476042320026  loss: 0.2978 (0.2904)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:10:44\tINFO\ttorchdistill.misc.log\tEpoch: [99] Total time: 0:00:46\n",
            "2021/01/11 00:10:45\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.7556  data: 0.7224  max mem: 700\n",
            "2021/01/11 00:10:47\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:10:47\tINFO\t__main__\t * Acc@1 91.9900\tAcc@5 99.4300\n",
            "\n",
            "2021/01/11 00:10:49\tINFO\ttorchdistill.misc.log\tEpoch: [100]  [  0/391]  eta: 0:10:00  lr: 0.010000000000000002  img/s: 254.13466316693845  loss: 0.3151 (0.3151)  time: 1.5347  data: 1.0311  max mem: 700\n",
            "2021/01/11 00:11:00\tINFO\ttorchdistill.misc.log\tEpoch: [100]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1117.6963506871218  loss: 0.2860 (0.2858)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:11:12\tINFO\ttorchdistill.misc.log\tEpoch: [100]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1119.3975734299124  loss: 0.2929 (0.2871)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:11:23\tINFO\ttorchdistill.misc.log\tEpoch: [100]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1115.6640150287192  loss: 0.2859 (0.2874)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:11:34\tINFO\ttorchdistill.misc.log\tEpoch: [100] Total time: 0:00:46\n",
            "2021/01/11 00:11:35\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:04  acc1: 92.9688 (92.9688)  acc5: 99.2188 (99.2188)  time: 0.8172  data: 0.7638  max mem: 700\n",
            "2021/01/11 00:11:37\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:11:37\tINFO\t__main__\t * Acc@1 91.9500\tAcc@5 99.4000\n",
            "\n",
            "2021/01/11 00:11:38\tINFO\ttorchdistill.misc.log\tEpoch: [101]  [  0/391]  eta: 0:09:32  lr: 0.010000000000000002  img/s: 263.5474416006331  loss: 0.2418 (0.2418)  time: 1.4652  data: 0.9795  max mem: 700\n",
            "2021/01/11 00:11:50\tINFO\ttorchdistill.misc.log\tEpoch: [101]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1108.3191653196423  loss: 0.2687 (0.2801)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:12:01\tINFO\ttorchdistill.misc.log\tEpoch: [101]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1112.7665467961406  loss: 0.2750 (0.2818)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:12:13\tINFO\ttorchdistill.misc.log\tEpoch: [101]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1105.5256875160876  loss: 0.2862 (0.2843)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:12:24\tINFO\ttorchdistill.misc.log\tEpoch: [101] Total time: 0:00:46\n",
            "2021/01/11 00:12:24\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.6977  data: 0.6681  max mem: 700\n",
            "2021/01/11 00:12:27\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:12:27\tINFO\t__main__\t * Acc@1 91.8400\tAcc@5 99.4200\n",
            "\n",
            "2021/01/11 00:12:28\tINFO\ttorchdistill.misc.log\tEpoch: [102]  [  0/391]  eta: 0:09:23  lr: 0.010000000000000002  img/s: 235.60165583969618  loss: 0.2730 (0.2730)  time: 1.4416  data: 0.8982  max mem: 700\n",
            "2021/01/11 00:12:40\tINFO\ttorchdistill.misc.log\tEpoch: [102]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1114.640202302898  loss: 0.2712 (0.2834)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:12:51\tINFO\ttorchdistill.misc.log\tEpoch: [102]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1122.029484912703  loss: 0.2741 (0.2816)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:13:03\tINFO\ttorchdistill.misc.log\tEpoch: [102]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1100.914598110565  loss: 0.2914 (0.2825)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:13:13\tINFO\ttorchdistill.misc.log\tEpoch: [102] Total time: 0:00:46\n",
            "2021/01/11 00:13:14\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:50  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6431  data: 0.5977  max mem: 700\n",
            "2021/01/11 00:13:16\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:13:16\tINFO\t__main__\t * Acc@1 91.8100\tAcc@5 99.4500\n",
            "\n",
            "2021/01/11 00:13:18\tINFO\ttorchdistill.misc.log\tEpoch: [103]  [  0/391]  eta: 0:10:20  lr: 0.010000000000000002  img/s: 262.7801640886482  loss: 0.3191 (0.3191)  time: 1.5871  data: 1.1000  max mem: 700\n",
            "2021/01/11 00:13:29\tINFO\ttorchdistill.misc.log\tEpoch: [103]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1112.6881340686716  loss: 0.2787 (0.2850)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:13:41\tINFO\ttorchdistill.misc.log\tEpoch: [103]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1123.5064172454709  loss: 0.2746 (0.2839)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:13:52\tINFO\ttorchdistill.misc.log\tEpoch: [103]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1115.2931869738995  loss: 0.2861 (0.2839)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:14:03\tINFO\ttorchdistill.misc.log\tEpoch: [103] Total time: 0:00:46\n",
            "2021/01/11 00:14:04\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.7034  data: 0.6596  max mem: 700\n",
            "2021/01/11 00:14:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:14:06\tINFO\t__main__\t * Acc@1 91.7700\tAcc@5 99.4400\n",
            "\n",
            "2021/01/11 00:14:07\tINFO\ttorchdistill.misc.log\tEpoch: [104]  [  0/391]  eta: 0:08:19  lr: 0.010000000000000002  img/s: 267.68727008012604  loss: 0.2980 (0.2980)  time: 1.2769  data: 0.7987  max mem: 700\n",
            "2021/01/11 00:14:19\tINFO\ttorchdistill.misc.log\tEpoch: [104]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1110.2719931175538  loss: 0.2898 (0.2799)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:14:31\tINFO\ttorchdistill.misc.log\tEpoch: [104]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1124.146295602212  loss: 0.2668 (0.2802)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:14:42\tINFO\ttorchdistill.misc.log\tEpoch: [104]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1110.4717888893026  loss: 0.2803 (0.2798)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:14:53\tINFO\ttorchdistill.misc.log\tEpoch: [104] Total time: 0:00:46\n",
            "2021/01/11 00:14:54\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.6815  data: 0.6348  max mem: 700\n",
            "2021/01/11 00:14:56\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:14:56\tINFO\t__main__\t * Acc@1 91.8500\tAcc@5 99.4400\n",
            "\n",
            "2021/01/11 00:14:57\tINFO\ttorchdistill.misc.log\tEpoch: [105]  [  0/391]  eta: 0:09:20  lr: 0.010000000000000002  img/s: 249.75026504548921  loss: 0.2737 (0.2737)  time: 1.4327  data: 0.9201  max mem: 700\n",
            "2021/01/11 00:15:09\tINFO\ttorchdistill.misc.log\tEpoch: [105]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1123.2384495163892  loss: 0.2815 (0.2767)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:15:20\tINFO\ttorchdistill.misc.log\tEpoch: [105]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1120.2875303092903  loss: 0.2741 (0.2779)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:15:32\tINFO\ttorchdistill.misc.log\tEpoch: [105]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1118.0687788044825  loss: 0.2681 (0.2786)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:15:43\tINFO\ttorchdistill.misc.log\tEpoch: [105] Total time: 0:00:46\n",
            "2021/01/11 00:15:43\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.7102  data: 0.6761  max mem: 700\n",
            "2021/01/11 00:15:46\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:15:46\tINFO\t__main__\t * Acc@1 91.7800\tAcc@5 99.4000\n",
            "\n",
            "2021/01/11 00:15:47\tINFO\ttorchdistill.misc.log\tEpoch: [106]  [  0/391]  eta: 0:09:12  lr: 0.010000000000000002  img/s: 251.8793034449141  loss: 0.2920 (0.2920)  time: 1.4133  data: 0.9051  max mem: 700\n",
            "2021/01/11 00:15:59\tINFO\ttorchdistill.misc.log\tEpoch: [106]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1120.9682148934614  loss: 0.2761 (0.2768)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:16:10\tINFO\ttorchdistill.misc.log\tEpoch: [106]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1119.7127506924282  loss: 0.2643 (0.2765)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:16:22\tINFO\ttorchdistill.misc.log\tEpoch: [106]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1113.2811161201223  loss: 0.2770 (0.2761)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:16:33\tINFO\ttorchdistill.misc.log\tEpoch: [106] Total time: 0:00:46\n",
            "2021/01/11 00:16:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.7513  data: 0.7134  max mem: 700\n",
            "2021/01/11 00:16:36\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:16:36\tINFO\t__main__\t * Acc@1 91.9100\tAcc@5 99.4100\n",
            "\n",
            "2021/01/11 00:16:37\tINFO\ttorchdistill.misc.log\tEpoch: [107]  [  0/391]  eta: 0:09:24  lr: 0.010000000000000002  img/s: 267.476952341285  loss: 0.2594 (0.2594)  time: 1.4428  data: 0.9642  max mem: 700\n",
            "2021/01/11 00:16:49\tINFO\ttorchdistill.misc.log\tEpoch: [107]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1113.4773777006244  loss: 0.2819 (0.2792)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:17:00\tINFO\ttorchdistill.misc.log\tEpoch: [107]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1119.684727748997  loss: 0.2682 (0.2747)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:17:12\tINFO\ttorchdistill.misc.log\tEpoch: [107]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1118.3692297436924  loss: 0.2707 (0.2760)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:17:22\tINFO\ttorchdistill.misc.log\tEpoch: [107] Total time: 0:00:46\n",
            "2021/01/11 00:17:23\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.7093  data: 0.6503  max mem: 700\n",
            "2021/01/11 00:17:25\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:17:25\tINFO\t__main__\t * Acc@1 91.6700\tAcc@5 99.3400\n",
            "\n",
            "2021/01/11 00:17:26\tINFO\ttorchdistill.misc.log\tEpoch: [108]  [  0/391]  eta: 0:08:09  lr: 0.010000000000000002  img/s: 246.1924596550826  loss: 0.2797 (0.2797)  time: 1.2516  data: 0.7317  max mem: 700\n",
            "2021/01/11 00:17:38\tINFO\ttorchdistill.misc.log\tEpoch: [108]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1084.7476738993832  loss: 0.2742 (0.2727)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:17:50\tINFO\ttorchdistill.misc.log\tEpoch: [108]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1116.7384893156304  loss: 0.2784 (0.2760)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:18:02\tINFO\ttorchdistill.misc.log\tEpoch: [108]  [300/391]  eta: 0:00:11  lr: 0.010000000000000002  img/s: 1121.5958317577774  loss: 0.2747 (0.2747)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:18:13\tINFO\ttorchdistill.misc.log\tEpoch: [108] Total time: 0:00:47\n",
            "2021/01/11 00:18:13\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 92.1875 (92.1875)  acc5: 100.0000 (100.0000)  time: 0.7080  data: 0.6830  max mem: 700\n",
            "2021/01/11 00:18:16\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:18:16\tINFO\t__main__\t * Acc@1 91.9700\tAcc@5 99.4400\n",
            "\n",
            "2021/01/11 00:18:17\tINFO\ttorchdistill.misc.log\tEpoch: [109]  [  0/391]  eta: 0:08:29  lr: 0.010000000000000002  img/s: 246.29015368622615  loss: 0.2682 (0.2682)  time: 1.3037  data: 0.7839  max mem: 700\n",
            "2021/01/11 00:18:29\tINFO\ttorchdistill.misc.log\tEpoch: [109]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1121.3287745336595  loss: 0.2786 (0.2786)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:18:41\tINFO\ttorchdistill.misc.log\tEpoch: [109]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1116.6084212934559  loss: 0.2746 (0.2760)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:18:52\tINFO\ttorchdistill.misc.log\tEpoch: [109]  [300/391]  eta: 0:00:11  lr: 0.010000000000000002  img/s: 1114.7258340133342  loss: 0.2695 (0.2754)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:19:03\tINFO\ttorchdistill.misc.log\tEpoch: [109] Total time: 0:00:47\n",
            "2021/01/11 00:19:03\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:52  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.6657  data: 0.6249  max mem: 700\n",
            "2021/01/11 00:19:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:19:06\tINFO\t__main__\t * Acc@1 91.8800\tAcc@5 99.3700\n",
            "\n",
            "2021/01/11 00:19:07\tINFO\ttorchdistill.misc.log\tEpoch: [110]  [  0/391]  eta: 0:09:33  lr: 0.010000000000000002  img/s: 283.450689367885  loss: 0.2458 (0.2458)  time: 1.4676  data: 1.0160  max mem: 700\n",
            "2021/01/11 00:19:19\tINFO\ttorchdistill.misc.log\tEpoch: [110]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1127.1128727504808  loss: 0.2829 (0.2741)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:19:30\tINFO\ttorchdistill.misc.log\tEpoch: [110]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1115.8657563003378  loss: 0.2658 (0.2724)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:19:42\tINFO\ttorchdistill.misc.log\tEpoch: [110]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1116.1905506408723  loss: 0.2706 (0.2728)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:19:53\tINFO\ttorchdistill.misc.log\tEpoch: [110] Total time: 0:00:46\n",
            "2021/01/11 00:19:53\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.6746  data: 0.6277  max mem: 700\n",
            "2021/01/11 00:19:55\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:19:55\tINFO\t__main__\t * Acc@1 91.8100\tAcc@5 99.4700\n",
            "\n",
            "2021/01/11 00:19:57\tINFO\ttorchdistill.misc.log\tEpoch: [111]  [  0/391]  eta: 0:10:17  lr: 0.010000000000000002  img/s: 260.15687403296016  loss: 0.2571 (0.2571)  time: 1.5803  data: 1.0883  max mem: 700\n",
            "2021/01/11 00:20:09\tINFO\ttorchdistill.misc.log\tEpoch: [111]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1116.8848520655895  loss: 0.2699 (0.2699)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:20:20\tINFO\ttorchdistill.misc.log\tEpoch: [111]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1106.9457692957967  loss: 0.2611 (0.2715)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:20:32\tINFO\ttorchdistill.misc.log\tEpoch: [111]  [300/391]  eta: 0:00:11  lr: 0.010000000000000002  img/s: 1114.276992430642  loss: 0.2615 (0.2713)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:20:43\tINFO\ttorchdistill.misc.log\tEpoch: [111] Total time: 0:00:47\n",
            "2021/01/11 00:20:43\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:52  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.6700  data: 0.6178  max mem: 700\n",
            "2021/01/11 00:20:46\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:20:46\tINFO\t__main__\t * Acc@1 91.8200\tAcc@5 99.3100\n",
            "\n",
            "2021/01/11 00:20:47\tINFO\ttorchdistill.misc.log\tEpoch: [112]  [  0/391]  eta: 0:10:34  lr: 0.010000000000000002  img/s: 252.03029972997638  loss: 0.2895 (0.2895)  time: 1.6226  data: 1.1147  max mem: 700\n",
            "2021/01/11 00:20:59\tINFO\ttorchdistill.misc.log\tEpoch: [112]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1111.9852196750649  loss: 0.2560 (0.2657)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:21:10\tINFO\ttorchdistill.misc.log\tEpoch: [112]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1114.9665990326325  loss: 0.2625 (0.2692)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:21:22\tINFO\ttorchdistill.misc.log\tEpoch: [112]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1115.4368535870854  loss: 0.2631 (0.2693)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:21:33\tINFO\ttorchdistill.misc.log\tEpoch: [112] Total time: 0:00:46\n",
            "2021/01/11 00:21:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:03  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.7988  data: 0.7704  max mem: 700\n",
            "2021/01/11 00:21:36\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:21:36\tINFO\t__main__\t * Acc@1 91.8900\tAcc@5 99.3200\n",
            "\n",
            "2021/01/11 00:21:37\tINFO\ttorchdistill.misc.log\tEpoch: [113]  [  0/391]  eta: 0:10:27  lr: 0.010000000000000002  img/s: 256.92655924203274  loss: 0.2741 (0.2741)  time: 1.6056  data: 1.1074  max mem: 700\n",
            "2021/01/11 00:21:49\tINFO\ttorchdistill.misc.log\tEpoch: [113]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1113.618266901198  loss: 0.2597 (0.2665)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:22:00\tINFO\ttorchdistill.misc.log\tEpoch: [113]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1122.130328004197  loss: 0.2592 (0.2681)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:22:12\tINFO\ttorchdistill.misc.log\tEpoch: [113]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1109.6569818753785  loss: 0.2725 (0.2689)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:22:22\tINFO\ttorchdistill.misc.log\tEpoch: [113] Total time: 0:00:46\n",
            "2021/01/11 00:22:23\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.6821  data: 0.6292  max mem: 700\n",
            "2021/01/11 00:22:25\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:22:25\tINFO\t__main__\t * Acc@1 91.7900\tAcc@5 99.3800\n",
            "\n",
            "2021/01/11 00:22:27\tINFO\ttorchdistill.misc.log\tEpoch: [114]  [  0/391]  eta: 0:09:53  lr: 0.010000000000000002  img/s: 235.31808321743577  loss: 0.2522 (0.2522)  time: 1.5179  data: 0.9739  max mem: 700\n",
            "2021/01/11 00:22:39\tINFO\ttorchdistill.misc.log\tEpoch: [114]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1121.2023181262857  loss: 0.2670 (0.2697)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:22:50\tINFO\ttorchdistill.misc.log\tEpoch: [114]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1117.1079548055516  loss: 0.2750 (0.2700)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:23:02\tINFO\ttorchdistill.misc.log\tEpoch: [114]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1119.5539725570338  loss: 0.2861 (0.2708)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:23:12\tINFO\ttorchdistill.misc.log\tEpoch: [114] Total time: 0:00:46\n",
            "2021/01/11 00:23:13\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:04  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.8185  data: 0.7896  max mem: 700\n",
            "2021/01/11 00:23:15\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:23:15\tINFO\t__main__\t * Acc@1 91.7600\tAcc@5 99.4400\n",
            "\n",
            "2021/01/11 00:23:17\tINFO\ttorchdistill.misc.log\tEpoch: [115]  [  0/391]  eta: 0:09:10  lr: 0.010000000000000002  img/s: 259.23932964001494  loss: 0.2488 (0.2488)  time: 1.4076  data: 0.9139  max mem: 700\n",
            "2021/01/11 00:23:28\tINFO\ttorchdistill.misc.log\tEpoch: [115]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1117.526512770342  loss: 0.2574 (0.2622)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:23:40\tINFO\ttorchdistill.misc.log\tEpoch: [115]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1106.3412760397885  loss: 0.2765 (0.2671)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:23:51\tINFO\ttorchdistill.misc.log\tEpoch: [115]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1110.6969323325693  loss: 0.2689 (0.2689)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:24:02\tINFO\ttorchdistill.misc.log\tEpoch: [115] Total time: 0:00:46\n",
            "2021/01/11 00:24:03\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:12  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.9181  data: 0.8550  max mem: 700\n",
            "2021/01/11 00:24:05\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:24:05\tINFO\t__main__\t * Acc@1 91.7600\tAcc@5 99.4100\n",
            "\n",
            "2021/01/11 00:24:06\tINFO\ttorchdistill.misc.log\tEpoch: [116]  [  0/391]  eta: 0:07:52  lr: 0.010000000000000002  img/s: 259.67731906006134  loss: 0.2491 (0.2491)  time: 1.2083  data: 0.7153  max mem: 700\n",
            "2021/01/11 00:24:18\tINFO\ttorchdistill.misc.log\tEpoch: [116]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1119.521288530593  loss: 0.2624 (0.2689)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:24:30\tINFO\ttorchdistill.misc.log\tEpoch: [116]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1117.2846410302302  loss: 0.2550 (0.2680)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:24:41\tINFO\ttorchdistill.misc.log\tEpoch: [116]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1109.2053370357055  loss: 0.2659 (0.2678)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:24:52\tINFO\ttorchdistill.misc.log\tEpoch: [116] Total time: 0:00:46\n",
            "2021/01/11 00:24:52\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6791  data: 0.6382  max mem: 700\n",
            "2021/01/11 00:24:55\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:24:55\tINFO\t__main__\t * Acc@1 91.7200\tAcc@5 99.3400\n",
            "\n",
            "2021/01/11 00:24:56\tINFO\ttorchdistill.misc.log\tEpoch: [117]  [  0/391]  eta: 0:08:21  lr: 0.010000000000000002  img/s: 246.3883775852906  loss: 0.2528 (0.2528)  time: 1.2818  data: 0.7622  max mem: 700\n",
            "2021/01/11 00:25:08\tINFO\ttorchdistill.misc.log\tEpoch: [117]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1117.6312012740311  loss: 0.2576 (0.2658)  time: 0.1145  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:25:19\tINFO\ttorchdistill.misc.log\tEpoch: [117]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1117.9081387455597  loss: 0.2688 (0.2669)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:25:31\tINFO\ttorchdistill.misc.log\tEpoch: [117]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1103.1405188267324  loss: 0.2589 (0.2672)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:25:41\tINFO\ttorchdistill.misc.log\tEpoch: [117] Total time: 0:00:46\n",
            "2021/01/11 00:25:42\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7534  data: 0.7236  max mem: 700\n",
            "2021/01/11 00:25:45\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:25:45\tINFO\t__main__\t * Acc@1 91.9300\tAcc@5 99.4200\n",
            "\n",
            "2021/01/11 00:25:46\tINFO\ttorchdistill.misc.log\tEpoch: [118]  [  0/391]  eta: 0:09:30  lr: 0.010000000000000002  img/s: 240.30531573953056  loss: 0.2630 (0.2630)  time: 1.4601  data: 0.9274  max mem: 700\n",
            "2021/01/11 00:25:58\tINFO\ttorchdistill.misc.log\tEpoch: [118]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1114.63094560871  loss: 0.2602 (0.2629)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:26:09\tINFO\ttorchdistill.misc.log\tEpoch: [118]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1102.9161623258433  loss: 0.2633 (0.2652)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:26:21\tINFO\ttorchdistill.misc.log\tEpoch: [118]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1104.0797267311177  loss: 0.2602 (0.2647)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:26:31\tINFO\ttorchdistill.misc.log\tEpoch: [118] Total time: 0:00:46\n",
            "2021/01/11 00:26:32\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.6825  data: 0.6397  max mem: 700\n",
            "2021/01/11 00:26:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:26:34\tINFO\t__main__\t * Acc@1 91.7600\tAcc@5 99.4300\n",
            "\n",
            "2021/01/11 00:26:36\tINFO\ttorchdistill.misc.log\tEpoch: [119]  [  0/391]  eta: 0:10:01  lr: 0.010000000000000002  img/s: 260.83257761149144  loss: 0.2632 (0.2632)  time: 1.5392  data: 1.0485  max mem: 700\n",
            "2021/01/11 00:26:47\tINFO\ttorchdistill.misc.log\tEpoch: [119]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1117.0707648260739  loss: 0.2708 (0.2651)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:26:59\tINFO\ttorchdistill.misc.log\tEpoch: [119]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1120.2057167180305  loss: 0.2685 (0.2656)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:27:10\tINFO\ttorchdistill.misc.log\tEpoch: [119]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1115.3464783348466  loss: 0.2608 (0.2654)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:27:21\tINFO\ttorchdistill.misc.log\tEpoch: [119] Total time: 0:00:46\n",
            "2021/01/11 00:27:22\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:06  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.8421  data: 0.8044  max mem: 700\n",
            "2021/01/11 00:27:24\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:27:24\tINFO\t__main__\t * Acc@1 91.6900\tAcc@5 99.2000\n",
            "\n",
            "2021/01/11 00:27:26\tINFO\ttorchdistill.misc.log\tEpoch: [120]  [  0/391]  eta: 0:09:24  lr: 0.010000000000000002  img/s: 243.74350746343194  loss: 0.2399 (0.2399)  time: 1.4430  data: 0.9178  max mem: 700\n",
            "2021/01/11 00:27:37\tINFO\ttorchdistill.misc.log\tEpoch: [120]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1104.7749524132894  loss: 0.2557 (0.2627)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:27:49\tINFO\ttorchdistill.misc.log\tEpoch: [120]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1116.2601740287553  loss: 0.2567 (0.2647)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:28:00\tINFO\ttorchdistill.misc.log\tEpoch: [120]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1114.5453284754876  loss: 0.2546 (0.2645)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:28:11\tINFO\ttorchdistill.misc.log\tEpoch: [120] Total time: 0:00:46\n",
            "2021/01/11 00:28:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7109  data: 0.6673  max mem: 700\n",
            "2021/01/11 00:28:14\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:28:14\tINFO\t__main__\t * Acc@1 91.6800\tAcc@5 99.3000\n",
            "\n",
            "2021/01/11 00:28:15\tINFO\ttorchdistill.misc.log\tEpoch: [121]  [  0/391]  eta: 0:10:14  lr: 0.010000000000000002  img/s: 274.35662058547575  loss: 0.2602 (0.2602)  time: 1.5720  data: 1.1054  max mem: 700\n",
            "2021/01/11 00:28:27\tINFO\ttorchdistill.misc.log\tEpoch: [121]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1113.3827017117449  loss: 0.2726 (0.2651)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:28:38\tINFO\ttorchdistill.misc.log\tEpoch: [121]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1112.750402095873  loss: 0.2508 (0.2643)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:28:50\tINFO\ttorchdistill.misc.log\tEpoch: [121]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1114.746665337785  loss: 0.2532 (0.2637)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:29:00\tINFO\ttorchdistill.misc.log\tEpoch: [121] Total time: 0:00:46\n",
            "2021/01/11 00:29:01\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.6941  data: 0.6333  max mem: 700\n",
            "2021/01/11 00:29:03\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:29:03\tINFO\t__main__\t * Acc@1 91.6400\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 00:29:05\tINFO\ttorchdistill.misc.log\tEpoch: [122]  [  0/391]  eta: 0:10:11  lr: 0.010000000000000002  img/s: 215.752043305457  loss: 0.2645 (0.2645)  time: 1.5644  data: 0.9711  max mem: 700\n",
            "2021/01/11 00:29:17\tINFO\ttorchdistill.misc.log\tEpoch: [122]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1116.0652504266807  loss: 0.2522 (0.2602)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:29:28\tINFO\ttorchdistill.misc.log\tEpoch: [122]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1114.9619679553077  loss: 0.2631 (0.2625)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:29:40\tINFO\ttorchdistill.misc.log\tEpoch: [122]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1116.0745309592858  loss: 0.2687 (0.2629)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:29:50\tINFO\ttorchdistill.misc.log\tEpoch: [122] Total time: 0:00:46\n",
            "2021/01/11 00:29:51\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:08  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.8672  data: 0.8323  max mem: 700\n",
            "2021/01/11 00:29:53\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:29:53\tINFO\t__main__\t * Acc@1 91.8700\tAcc@5 99.2500\n",
            "\n",
            "2021/01/11 00:29:55\tINFO\ttorchdistill.misc.log\tEpoch: [123]  [  0/391]  eta: 0:09:04  lr: 0.010000000000000002  img/s: 262.887092469877  loss: 0.2704 (0.2704)  time: 1.3938  data: 0.9069  max mem: 700\n",
            "2021/01/11 00:30:06\tINFO\ttorchdistill.misc.log\tEpoch: [123]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1109.1663798393079  loss: 0.2666 (0.2625)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:30:18\tINFO\ttorchdistill.misc.log\tEpoch: [123]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1124.007436563102  loss: 0.2576 (0.2622)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:30:29\tINFO\ttorchdistill.misc.log\tEpoch: [123]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1111.2578903792019  loss: 0.2631 (0.2618)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:30:40\tINFO\ttorchdistill.misc.log\tEpoch: [123] Total time: 0:00:46\n",
            "2021/01/11 00:30:41\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:03  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.8039  data: 0.7525  max mem: 700\n",
            "2021/01/11 00:30:43\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:30:43\tINFO\t__main__\t * Acc@1 91.8800\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 00:30:44\tINFO\ttorchdistill.misc.log\tEpoch: [124]  [  0/391]  eta: 0:09:00  lr: 0.010000000000000002  img/s: 244.39293448102723  loss: 0.2540 (0.2540)  time: 1.3828  data: 0.8590  max mem: 700\n",
            "2021/01/11 00:30:56\tINFO\ttorchdistill.misc.log\tEpoch: [124]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1115.7938631130028  loss: 0.2522 (0.2618)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:31:08\tINFO\ttorchdistill.misc.log\tEpoch: [124]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1102.2685336508848  loss: 0.2570 (0.2589)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:31:19\tINFO\ttorchdistill.misc.log\tEpoch: [124]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1114.2954942165159  loss: 0.2539 (0.2606)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:31:30\tINFO\ttorchdistill.misc.log\tEpoch: [124] Total time: 0:00:46\n",
            "2021/01/11 00:31:30\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:52  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.6666  data: 0.6172  max mem: 700\n",
            "2021/01/11 00:31:33\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:31:33\tINFO\t__main__\t * Acc@1 91.8100\tAcc@5 99.2800\n",
            "\n",
            "2021/01/11 00:31:34\tINFO\ttorchdistill.misc.log\tEpoch: [125]  [  0/391]  eta: 0:09:51  lr: 0.010000000000000002  img/s: 209.1659759023377  loss: 0.2424 (0.2424)  time: 1.5125  data: 0.9005  max mem: 700\n",
            "2021/01/11 00:31:46\tINFO\ttorchdistill.misc.log\tEpoch: [125]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1115.1078653739105  loss: 0.2569 (0.2585)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:31:58\tINFO\ttorchdistill.misc.log\tEpoch: [125]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1121.1554896576208  loss: 0.2565 (0.2602)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:32:09\tINFO\ttorchdistill.misc.log\tEpoch: [125]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1111.2256889393004  loss: 0.2543 (0.2591)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:32:20\tINFO\ttorchdistill.misc.log\tEpoch: [125] Total time: 0:00:46\n",
            "2021/01/11 00:32:20\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7383  data: 0.7015  max mem: 700\n",
            "2021/01/11 00:32:23\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:32:23\tINFO\t__main__\t * Acc@1 91.7200\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 00:32:24\tINFO\ttorchdistill.misc.log\tEpoch: [126]  [  0/391]  eta: 0:07:32  lr: 0.010000000000000002  img/s: 279.174169608147  loss: 0.2891 (0.2891)  time: 1.1575  data: 0.6990  max mem: 700\n",
            "2021/01/11 00:32:36\tINFO\ttorchdistill.misc.log\tEpoch: [126]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1113.9486879426001  loss: 0.2484 (0.2598)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:32:47\tINFO\ttorchdistill.misc.log\tEpoch: [126]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1115.1958854540999  loss: 0.2529 (0.2602)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:32:59\tINFO\ttorchdistill.misc.log\tEpoch: [126]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1105.4573967116576  loss: 0.2545 (0.2586)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:33:09\tINFO\ttorchdistill.misc.log\tEpoch: [126] Total time: 0:00:46\n",
            "2021/01/11 00:33:10\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.6834  data: 0.6646  max mem: 700\n",
            "2021/01/11 00:33:12\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:33:12\tINFO\t__main__\t * Acc@1 91.5100\tAcc@5 99.1700\n",
            "\n",
            "2021/01/11 00:33:14\tINFO\ttorchdistill.misc.log\tEpoch: [127]  [  0/391]  eta: 0:09:58  lr: 0.010000000000000002  img/s: 225.5130971863312  loss: 0.2520 (0.2520)  time: 1.5315  data: 0.9639  max mem: 700\n",
            "2021/01/11 00:33:25\tINFO\ttorchdistill.misc.log\tEpoch: [127]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1123.3113052793678  loss: 0.2586 (0.2596)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:33:37\tINFO\ttorchdistill.misc.log\tEpoch: [127]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1134.3453591583966  loss: 0.2543 (0.2580)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:33:48\tINFO\ttorchdistill.misc.log\tEpoch: [127]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1107.0690300815756  loss: 0.2498 (0.2585)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:33:59\tINFO\ttorchdistill.misc.log\tEpoch: [127] Total time: 0:00:46\n",
            "2021/01/11 00:34:00\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.7308  data: 0.7038  max mem: 700\n",
            "2021/01/11 00:34:02\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:34:02\tINFO\t__main__\t * Acc@1 91.6300\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 00:34:03\tINFO\ttorchdistill.misc.log\tEpoch: [128]  [  0/391]  eta: 0:07:56  lr: 0.010000000000000002  img/s: 263.4479903703046  loss: 0.2552 (0.2552)  time: 1.2177  data: 0.7318  max mem: 700\n",
            "2021/01/11 00:34:15\tINFO\ttorchdistill.misc.log\tEpoch: [128]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1115.5434688653213  loss: 0.2542 (0.2586)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:34:27\tINFO\ttorchdistill.misc.log\tEpoch: [128]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1109.682211464926  loss: 0.2506 (0.2598)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:34:38\tINFO\ttorchdistill.misc.log\tEpoch: [128]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1114.1174400265627  loss: 0.2519 (0.2603)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:34:49\tINFO\ttorchdistill.misc.log\tEpoch: [128] Total time: 0:00:46\n",
            "2021/01/11 00:34:50\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.7049  data: 0.6481  max mem: 700\n",
            "2021/01/11 00:34:52\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:34:52\tINFO\t__main__\t * Acc@1 91.6700\tAcc@5 99.2000\n",
            "\n",
            "2021/01/11 00:34:53\tINFO\ttorchdistill.misc.log\tEpoch: [129]  [  0/391]  eta: 0:08:57  lr: 0.010000000000000002  img/s: 248.52453971400308  loss: 0.2463 (0.2463)  time: 1.3759  data: 0.8608  max mem: 700\n",
            "2021/01/11 00:35:05\tINFO\ttorchdistill.misc.log\tEpoch: [129]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1108.250528971102  loss: 0.2478 (0.2600)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:35:17\tINFO\ttorchdistill.misc.log\tEpoch: [129]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1110.2559207206612  loss: 0.2472 (0.2567)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:35:28\tINFO\ttorchdistill.misc.log\tEpoch: [129]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1116.4110545031087  loss: 0.2617 (0.2586)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:35:39\tINFO\ttorchdistill.misc.log\tEpoch: [129] Total time: 0:00:46\n",
            "2021/01/11 00:35:39\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7108  data: 0.6545  max mem: 700\n",
            "2021/01/11 00:35:42\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:35:42\tINFO\t__main__\t * Acc@1 91.8500\tAcc@5 99.3100\n",
            "\n",
            "2021/01/11 00:35:43\tINFO\ttorchdistill.misc.log\tEpoch: [130]  [  0/391]  eta: 0:10:03  lr: 0.010000000000000002  img/s: 209.76829760033007  loss: 0.2413 (0.2413)  time: 1.5424  data: 0.9322  max mem: 700\n",
            "2021/01/11 00:35:55\tINFO\ttorchdistill.misc.log\tEpoch: [130]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1120.0795134723512  loss: 0.2482 (0.2562)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:36:06\tINFO\ttorchdistill.misc.log\tEpoch: [130]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1108.3511985251462  loss: 0.2586 (0.2563)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:36:18\tINFO\ttorchdistill.misc.log\tEpoch: [130]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1103.7664797830587  loss: 0.2596 (0.2570)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:36:29\tINFO\ttorchdistill.misc.log\tEpoch: [130] Total time: 0:00:46\n",
            "2021/01/11 00:36:29\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.7092  data: 0.6527  max mem: 700\n",
            "2021/01/11 00:36:32\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:36:32\tINFO\t__main__\t * Acc@1 91.7200\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 00:36:33\tINFO\ttorchdistill.misc.log\tEpoch: [131]  [  0/391]  eta: 0:09:48  lr: 0.010000000000000002  img/s: 266.9692608195789  loss: 0.2766 (0.2766)  time: 1.5055  data: 1.0261  max mem: 700\n",
            "2021/01/11 00:36:45\tINFO\ttorchdistill.misc.log\tEpoch: [131]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1106.4484398829397  loss: 0.2447 (0.2584)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:36:56\tINFO\ttorchdistill.misc.log\tEpoch: [131]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1121.4576020521133  loss: 0.2541 (0.2570)  time: 0.1145  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:37:08\tINFO\ttorchdistill.misc.log\tEpoch: [131]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1115.7173418344976  loss: 0.2504 (0.2573)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:37:18\tINFO\ttorchdistill.misc.log\tEpoch: [131] Total time: 0:00:46\n",
            "2021/01/11 00:37:19\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.6806  data: 0.6393  max mem: 700\n",
            "2021/01/11 00:37:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:37:21\tINFO\t__main__\t * Acc@1 91.8200\tAcc@5 99.2300\n",
            "\n",
            "2021/01/11 00:37:23\tINFO\ttorchdistill.misc.log\tEpoch: [132]  [  0/391]  eta: 0:08:29  lr: 0.010000000000000002  img/s: 258.3727420035584  loss: 0.2641 (0.2641)  time: 1.3039  data: 0.8085  max mem: 700\n",
            "2021/01/11 00:37:34\tINFO\ttorchdistill.misc.log\tEpoch: [132]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1110.52002622864  loss: 0.2553 (0.2568)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:37:46\tINFO\ttorchdistill.misc.log\tEpoch: [132]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1108.891465679096  loss: 0.2451 (0.2574)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:37:57\tINFO\ttorchdistill.misc.log\tEpoch: [132]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1117.9616803026927  loss: 0.2553 (0.2566)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:38:08\tINFO\ttorchdistill.misc.log\tEpoch: [132] Total time: 0:00:46\n",
            "2021/01/11 00:38:09\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 93.7500 (93.7500)  acc5: 99.2188 (99.2188)  time: 0.7145  data: 0.6895  max mem: 700\n",
            "2021/01/11 00:38:11\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:38:11\tINFO\t__main__\t * Acc@1 91.6800\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 00:38:13\tINFO\ttorchdistill.misc.log\tEpoch: [133]  [  0/391]  eta: 0:08:32  lr: 0.010000000000000002  img/s: 202.89415222005212  loss: 0.2386 (0.2386)  time: 1.3116  data: 0.6807  max mem: 700\n",
            "2021/01/11 00:38:24\tINFO\ttorchdistill.misc.log\tEpoch: [133]  [100/391]  eta: 0:00:38  lr: 0.010000000000000002  img/s: 1120.0911977634516  loss: 0.2488 (0.2578)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:38:36\tINFO\ttorchdistill.misc.log\tEpoch: [133]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1108.957890779597  loss: 0.2583 (0.2578)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:38:47\tINFO\ttorchdistill.misc.log\tEpoch: [133]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1117.091683884835  loss: 0.2500 (0.2566)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:38:58\tINFO\ttorchdistill.misc.log\tEpoch: [133] Total time: 0:00:46\n",
            "2021/01/11 00:38:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7183  data: 0.6800  max mem: 700\n",
            "2021/01/11 00:39:01\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:39:01\tINFO\t__main__\t * Acc@1 91.8000\tAcc@5 99.2300\n",
            "\n",
            "2021/01/11 00:39:02\tINFO\ttorchdistill.misc.log\tEpoch: [134]  [  0/391]  eta: 0:08:46  lr: 0.010000000000000002  img/s: 260.42744236111685  loss: 0.2508 (0.2508)  time: 1.3469  data: 0.8554  max mem: 700\n",
            "2021/01/11 00:39:14\tINFO\ttorchdistill.misc.log\tEpoch: [134]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1110.2283691228536  loss: 0.2563 (0.2563)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:39:26\tINFO\ttorchdistill.misc.log\tEpoch: [134]  [200/391]  eta: 0:00:24  lr: 0.010000000000000002  img/s: 1101.5877593816492  loss: 0.2482 (0.2555)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:39:38\tINFO\ttorchdistill.misc.log\tEpoch: [134]  [300/391]  eta: 0:00:11  lr: 0.010000000000000002  img/s: 1115.6848814325763  loss: 0.2513 (0.2563)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:39:48\tINFO\ttorchdistill.misc.log\tEpoch: [134] Total time: 0:00:47\n",
            "2021/01/11 00:39:49\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.7121  data: 0.6559  max mem: 700\n",
            "2021/01/11 00:39:51\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:39:51\tINFO\t__main__\t * Acc@1 91.7200\tAcc@5 99.1500\n",
            "\n",
            "2021/01/11 00:39:53\tINFO\ttorchdistill.misc.log\tEpoch: [135]  [  0/391]  eta: 0:08:03  lr: 0.010000000000000002  img/s: 252.67795346595605  loss: 0.2686 (0.2686)  time: 1.2353  data: 0.7287  max mem: 700\n",
            "2021/01/11 00:40:04\tINFO\ttorchdistill.misc.log\tEpoch: [135]  [100/391]  eta: 0:00:37  lr: 0.010000000000000002  img/s: 1119.1268961463177  loss: 0.2550 (0.2538)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:40:16\tINFO\ttorchdistill.misc.log\tEpoch: [135]  [200/391]  eta: 0:00:23  lr: 0.010000000000000002  img/s: 1116.5921649210086  loss: 0.2588 (0.2545)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:40:27\tINFO\ttorchdistill.misc.log\tEpoch: [135]  [300/391]  eta: 0:00:10  lr: 0.010000000000000002  img/s: 1115.721979188964  loss: 0.2570 (0.2562)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:40:38\tINFO\ttorchdistill.misc.log\tEpoch: [135] Total time: 0:00:46\n",
            "2021/01/11 00:40:39\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.7079  data: 0.6754  max mem: 700\n",
            "2021/01/11 00:40:41\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:40:41\tINFO\t__main__\t * Acc@1 91.9600\tAcc@5 99.2700\n",
            "\n",
            "2021/01/11 00:40:42\tINFO\ttorchdistill.misc.log\tEpoch: [136]  [  0/391]  eta: 0:09:00  lr: 0.0010000000000000002  img/s: 248.02681736032318  loss: 0.2557 (0.2557)  time: 1.3829  data: 0.8668  max mem: 700\n",
            "2021/01/11 00:40:54\tINFO\ttorchdistill.misc.log\tEpoch: [136]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1121.41309465373  loss: 0.2537 (0.2520)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:41:06\tINFO\ttorchdistill.misc.log\tEpoch: [136]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1120.881621472654  loss: 0.2447 (0.2511)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:41:17\tINFO\ttorchdistill.misc.log\tEpoch: [136]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1113.5027813152033  loss: 0.2379 (0.2506)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:41:28\tINFO\ttorchdistill.misc.log\tEpoch: [136] Total time: 0:00:46\n",
            "2021/01/11 00:41:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.6767  data: 0.6323  max mem: 700\n",
            "2021/01/11 00:41:31\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:41:31\tINFO\t__main__\t * Acc@1 92.2200\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 00:41:31\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 92.0200 -> 92.2200)\n",
            "2021/01/11 00:41:32\tINFO\ttorchdistill.misc.log\tEpoch: [137]  [  0/391]  eta: 0:07:09  lr: 0.0010000000000000002  img/s: 293.90979343629766  loss: 0.2408 (0.2408)  time: 1.0988  data: 0.6632  max mem: 700\n",
            "2021/01/11 00:41:44\tINFO\ttorchdistill.misc.log\tEpoch: [137]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1116.1719858708962  loss: 0.2545 (0.2495)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:41:55\tINFO\ttorchdistill.misc.log\tEpoch: [137]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1115.4646643036124  loss: 0.2422 (0.2487)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:42:07\tINFO\ttorchdistill.misc.log\tEpoch: [137]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1112.9718559795679  loss: 0.2394 (0.2475)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:42:17\tINFO\ttorchdistill.misc.log\tEpoch: [137] Total time: 0:00:46\n",
            "2021/01/11 00:42:18\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:06  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.8408  data: 0.7939  max mem: 700\n",
            "2021/01/11 00:42:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:42:21\tINFO\t__main__\t * Acc@1 92.2900\tAcc@5 99.3200\n",
            "\n",
            "2021/01/11 00:42:21\tINFO\t__main__\tUpdating ckpt (Best top1 accuracy: 92.2200 -> 92.2900)\n",
            "2021/01/11 00:42:22\tINFO\ttorchdistill.misc.log\tEpoch: [138]  [  0/391]  eta: 0:08:23  lr: 0.0010000000000000002  img/s: 266.68811546745724  loss: 0.2506 (0.2506)  time: 1.2871  data: 0.8071  max mem: 700\n",
            "2021/01/11 00:42:34\tINFO\ttorchdistill.misc.log\tEpoch: [138]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1111.3176980049432  loss: 0.2468 (0.2496)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:42:45\tINFO\ttorchdistill.misc.log\tEpoch: [138]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1112.100390675168  loss: 0.2445 (0.2494)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:42:57\tINFO\ttorchdistill.misc.log\tEpoch: [138]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1116.510890158408  loss: 0.2465 (0.2481)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:43:07\tINFO\ttorchdistill.misc.log\tEpoch: [138] Total time: 0:00:46\n",
            "2021/01/11 00:43:08\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7002  data: 0.6728  max mem: 700\n",
            "2021/01/11 00:43:10\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:43:10\tINFO\t__main__\t * Acc@1 92.1300\tAcc@5 99.3000\n",
            "\n",
            "2021/01/11 00:43:12\tINFO\ttorchdistill.misc.log\tEpoch: [139]  [  0/391]  eta: 0:09:53  lr: 0.0010000000000000002  img/s: 238.1460208297015  loss: 0.2370 (0.2370)  time: 1.5190  data: 0.9815  max mem: 700\n",
            "2021/01/11 00:43:24\tINFO\ttorchdistill.misc.log\tEpoch: [139]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1123.1609037656904  loss: 0.2388 (0.2474)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:43:35\tINFO\ttorchdistill.misc.log\tEpoch: [139]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1119.313556124034  loss: 0.2416 (0.2473)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:43:47\tINFO\ttorchdistill.misc.log\tEpoch: [139]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1110.6762520868976  loss: 0.2510 (0.2476)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:43:57\tINFO\ttorchdistill.misc.log\tEpoch: [139] Total time: 0:00:46\n",
            "2021/01/11 00:43:58\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7453  data: 0.6895  max mem: 700\n",
            "2021/01/11 00:44:00\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:44:00\tINFO\t__main__\t * Acc@1 92.2000\tAcc@5 99.3100\n",
            "\n",
            "2021/01/11 00:44:02\tINFO\ttorchdistill.misc.log\tEpoch: [140]  [  0/391]  eta: 0:09:03  lr: 0.0010000000000000002  img/s: 249.92384660575811  loss: 0.2788 (0.2788)  time: 1.3892  data: 0.8770  max mem: 700\n",
            "2021/01/11 00:44:14\tINFO\ttorchdistill.misc.log\tEpoch: [140]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1110.8509094821611  loss: 0.2390 (0.2449)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:44:25\tINFO\ttorchdistill.misc.log\tEpoch: [140]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1113.0895392111129  loss: 0.2391 (0.2453)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:44:37\tINFO\ttorchdistill.misc.log\tEpoch: [140]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1112.9187912910268  loss: 0.2396 (0.2460)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:44:47\tINFO\ttorchdistill.misc.log\tEpoch: [140] Total time: 0:00:46\n",
            "2021/01/11 00:44:48\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.6816  data: 0.6432  max mem: 700\n",
            "2021/01/11 00:44:50\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:44:50\tINFO\t__main__\t * Acc@1 92.1700\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 00:44:51\tINFO\ttorchdistill.misc.log\tEpoch: [141]  [  0/391]  eta: 0:09:02  lr: 0.0010000000000000002  img/s: 258.6586753876959  loss: 0.2490 (0.2490)  time: 1.3882  data: 0.8933  max mem: 700\n",
            "2021/01/11 00:45:03\tINFO\ttorchdistill.misc.log\tEpoch: [141]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1110.9911347664495  loss: 0.2464 (0.2475)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:45:15\tINFO\ttorchdistill.misc.log\tEpoch: [141]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1113.5166383208198  loss: 0.2453 (0.2466)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:45:26\tINFO\ttorchdistill.misc.log\tEpoch: [141]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1114.7350922836386  loss: 0.2401 (0.2458)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:45:37\tINFO\ttorchdistill.misc.log\tEpoch: [141] Total time: 0:00:46\n",
            "2021/01/11 00:45:38\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7321  data: 0.6868  max mem: 700\n",
            "2021/01/11 00:45:40\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:45:40\tINFO\t__main__\t * Acc@1 92.1100\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 00:45:41\tINFO\ttorchdistill.misc.log\tEpoch: [142]  [  0/391]  eta: 0:07:50  lr: 0.0010000000000000002  img/s: 261.19347511229887  loss: 0.2407 (0.2407)  time: 1.2039  data: 0.7138  max mem: 700\n",
            "2021/01/11 00:45:53\tINFO\ttorchdistill.misc.log\tEpoch: [142]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1120.7997210896708  loss: 0.2408 (0.2449)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:46:05\tINFO\ttorchdistill.misc.log\tEpoch: [142]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1111.3476042320026  loss: 0.2555 (0.2461)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:46:16\tINFO\ttorchdistill.misc.log\tEpoch: [142]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1111.319998426804  loss: 0.2362 (0.2461)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:46:27\tINFO\ttorchdistill.misc.log\tEpoch: [142] Total time: 0:00:46\n",
            "2021/01/11 00:46:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:02  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7902  data: 0.7490  max mem: 700\n",
            "2021/01/11 00:46:30\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:46:30\tINFO\t__main__\t * Acc@1 92.1200\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 00:46:31\tINFO\ttorchdistill.misc.log\tEpoch: [143]  [  0/391]  eta: 0:10:02  lr: 0.0010000000000000002  img/s: 254.76925121115673  loss: 0.2330 (0.2330)  time: 1.5421  data: 1.0396  max mem: 700\n",
            "2021/01/11 00:46:43\tINFO\ttorchdistill.misc.log\tEpoch: [143]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1123.6592631041383  loss: 0.2435 (0.2459)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:46:55\tINFO\ttorchdistill.misc.log\tEpoch: [143]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1110.8325219064566  loss: 0.2389 (0.2460)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:47:06\tINFO\ttorchdistill.misc.log\tEpoch: [143]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1120.6570090258585  loss: 0.2470 (0.2466)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:47:17\tINFO\ttorchdistill.misc.log\tEpoch: [143] Total time: 0:00:46\n",
            "2021/01/11 00:47:18\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:01  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7739  data: 0.7457  max mem: 700\n",
            "2021/01/11 00:47:20\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:47:20\tINFO\t__main__\t * Acc@1 92.1200\tAcc@5 99.2700\n",
            "\n",
            "2021/01/11 00:47:21\tINFO\ttorchdistill.misc.log\tEpoch: [144]  [  0/391]  eta: 0:07:59  lr: 0.0010000000000000002  img/s: 252.60638226794384  loss: 0.2457 (0.2457)  time: 1.2254  data: 0.7187  max mem: 700\n",
            "2021/01/11 00:47:33\tINFO\ttorchdistill.misc.log\tEpoch: [144]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1117.4544054316764  loss: 0.2360 (0.2457)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:47:44\tINFO\ttorchdistill.misc.log\tEpoch: [144]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1108.5068147233537  loss: 0.2432 (0.2452)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:47:56\tINFO\ttorchdistill.misc.log\tEpoch: [144]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1121.0501399039465  loss: 0.2420 (0.2456)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:48:07\tINFO\ttorchdistill.misc.log\tEpoch: [144] Total time: 0:00:46\n",
            "2021/01/11 00:48:07\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:01  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.7827  data: 0.7656  max mem: 700\n",
            "2021/01/11 00:48:10\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:48:10\tINFO\t__main__\t * Acc@1 92.0800\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 00:48:11\tINFO\ttorchdistill.misc.log\tEpoch: [145]  [  0/391]  eta: 0:10:27  lr: 0.0010000000000000002  img/s: 252.05183469311297  loss: 0.2456 (0.2456)  time: 1.6048  data: 1.0969  max mem: 700\n",
            "2021/01/11 00:48:23\tINFO\ttorchdistill.misc.log\tEpoch: [145]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1118.7840706858108  loss: 0.2375 (0.2450)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:48:34\tINFO\ttorchdistill.misc.log\tEpoch: [145]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1119.7968279394956  loss: 0.2396 (0.2452)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:48:46\tINFO\ttorchdistill.misc.log\tEpoch: [145]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1120.7178326743792  loss: 0.2374 (0.2451)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:48:56\tINFO\ttorchdistill.misc.log\tEpoch: [145] Total time: 0:00:46\n",
            "2021/01/11 00:48:57\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6964  data: 0.6427  max mem: 700\n",
            "2021/01/11 00:48:59\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:48:59\tINFO\t__main__\t * Acc@1 92.2000\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 00:49:01\tINFO\ttorchdistill.misc.log\tEpoch: [146]  [  0/391]  eta: 0:09:39  lr: 0.0010000000000000002  img/s: 229.55630762468397  loss: 0.2524 (0.2524)  time: 1.4829  data: 0.9253  max mem: 700\n",
            "2021/01/11 00:49:13\tINFO\ttorchdistill.misc.log\tEpoch: [146]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1114.3001197589876  loss: 0.2397 (0.2433)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:49:24\tINFO\ttorchdistill.misc.log\tEpoch: [146]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1113.756881228788  loss: 0.2355 (0.2444)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:49:36\tINFO\ttorchdistill.misc.log\tEpoch: [146]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1116.8639407524522  loss: 0.2446 (0.2451)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:49:46\tINFO\ttorchdistill.misc.log\tEpoch: [146] Total time: 0:00:46\n",
            "2021/01/11 00:49:47\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:59  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.7588  data: 0.7320  max mem: 700\n",
            "2021/01/11 00:49:49\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:49:49\tINFO\t__main__\t * Acc@1 92.1700\tAcc@5 99.2500\n",
            "\n",
            "2021/01/11 00:49:50\tINFO\ttorchdistill.misc.log\tEpoch: [147]  [  0/391]  eta: 0:07:30  lr: 0.0010000000000000002  img/s: 269.9906018667525  loss: 0.2503 (0.2503)  time: 1.1515  data: 0.6774  max mem: 700\n",
            "2021/01/11 00:50:02\tINFO\ttorchdistill.misc.log\tEpoch: [147]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1124.8599600232988  loss: 0.2373 (0.2429)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:50:14\tINFO\ttorchdistill.misc.log\tEpoch: [147]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1121.1531483368694  loss: 0.2360 (0.2424)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:50:25\tINFO\ttorchdistill.misc.log\tEpoch: [147]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1115.6964742164348  loss: 0.2361 (0.2436)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:50:36\tINFO\ttorchdistill.misc.log\tEpoch: [147] Total time: 0:00:46\n",
            "2021/01/11 00:50:37\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:12  acc1: 96.0938 (96.0938)  acc5: 100.0000 (100.0000)  time: 0.9239  data: 0.8833  max mem: 700\n",
            "2021/01/11 00:50:39\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:50:39\tINFO\t__main__\t * Acc@1 92.1400\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 00:50:40\tINFO\ttorchdistill.misc.log\tEpoch: [148]  [  0/391]  eta: 0:08:16  lr: 0.0010000000000000002  img/s: 264.0906368426645  loss: 0.2302 (0.2302)  time: 1.2694  data: 0.7847  max mem: 700\n",
            "2021/01/11 00:50:52\tINFO\ttorchdistill.misc.log\tEpoch: [148]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1114.2793051202757  loss: 0.2492 (0.2468)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:51:03\tINFO\ttorchdistill.misc.log\tEpoch: [148]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1040.5321983572305  loss: 0.2439 (0.2459)  time: 0.1158  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:51:15\tINFO\ttorchdistill.misc.log\tEpoch: [148]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1117.1451472613999  loss: 0.2413 (0.2454)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:51:25\tINFO\ttorchdistill.misc.log\tEpoch: [148] Total time: 0:00:46\n",
            "2021/01/11 00:51:26\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 96.0938 (96.0938)  acc5: 99.2188 (99.2188)  time: 0.7070  data: 0.6815  max mem: 700\n",
            "2021/01/11 00:51:28\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:51:28\tINFO\t__main__\t * Acc@1 92.1700\tAcc@5 99.2700\n",
            "\n",
            "2021/01/11 00:51:29\tINFO\ttorchdistill.misc.log\tEpoch: [149]  [  0/391]  eta: 0:07:18  lr: 0.0010000000000000002  img/s: 286.39255563059385  loss: 0.2464 (0.2464)  time: 1.1227  data: 0.6758  max mem: 700\n",
            "2021/01/11 00:51:41\tINFO\ttorchdistill.misc.log\tEpoch: [149]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1123.8921390276937  loss: 0.2429 (0.2436)  time: 0.1145  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:51:53\tINFO\ttorchdistill.misc.log\tEpoch: [149]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1118.553306567716  loss: 0.2465 (0.2445)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:52:04\tINFO\ttorchdistill.misc.log\tEpoch: [149]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1115.8541599983373  loss: 0.2467 (0.2449)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:52:15\tINFO\ttorchdistill.misc.log\tEpoch: [149] Total time: 0:00:46\n",
            "2021/01/11 00:52:16\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7210  data: 0.6493  max mem: 700\n",
            "2021/01/11 00:52:18\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:52:18\tINFO\t__main__\t * Acc@1 92.1600\tAcc@5 99.3400\n",
            "\n",
            "2021/01/11 00:52:19\tINFO\ttorchdistill.misc.log\tEpoch: [150]  [  0/391]  eta: 0:10:03  lr: 0.0010000000000000002  img/s: 272.3875266237845  loss: 0.2597 (0.2597)  time: 1.5427  data: 1.0728  max mem: 700\n",
            "2021/01/11 00:52:31\tINFO\ttorchdistill.misc.log\tEpoch: [150]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1117.9453845032588  loss: 0.2372 (0.2456)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:52:43\tINFO\ttorchdistill.misc.log\tEpoch: [150]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1117.69402379158  loss: 0.2381 (0.2441)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:52:54\tINFO\ttorchdistill.misc.log\tEpoch: [150]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1120.797381254593  loss: 0.2426 (0.2439)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:53:05\tINFO\ttorchdistill.misc.log\tEpoch: [150] Total time: 0:00:46\n",
            "2021/01/11 00:53:05\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:52  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.6613  data: 0.6334  max mem: 700\n",
            "2021/01/11 00:53:08\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:53:08\tINFO\t__main__\t * Acc@1 92.0900\tAcc@5 99.2700\n",
            "\n",
            "2021/01/11 00:53:09\tINFO\ttorchdistill.misc.log\tEpoch: [151]  [  0/391]  eta: 0:09:47  lr: 0.0010000000000000002  img/s: 232.9945400202498  loss: 0.2367 (0.2367)  time: 1.5034  data: 0.9540  max mem: 700\n",
            "2021/01/11 00:53:21\tINFO\ttorchdistill.misc.log\tEpoch: [151]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1111.0187242355512  loss: 0.2364 (0.2441)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:53:32\tINFO\ttorchdistill.misc.log\tEpoch: [151]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1120.0024032644342  loss: 0.2359 (0.2439)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:53:44\tINFO\ttorchdistill.misc.log\tEpoch: [151]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1114.5476422791232  loss: 0.2392 (0.2435)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:53:54\tINFO\ttorchdistill.misc.log\tEpoch: [151] Total time: 0:00:46\n",
            "2021/01/11 00:53:55\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6999  data: 0.6520  max mem: 700\n",
            "2021/01/11 00:53:57\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:53:57\tINFO\t__main__\t * Acc@1 92.1400\tAcc@5 99.2500\n",
            "\n",
            "2021/01/11 00:53:58\tINFO\ttorchdistill.misc.log\tEpoch: [152]  [  0/391]  eta: 0:07:38  lr: 0.0010000000000000002  img/s: 260.8363793424274  loss: 0.2332 (0.2332)  time: 1.1727  data: 0.6819  max mem: 700\n",
            "2021/01/11 00:54:10\tINFO\ttorchdistill.misc.log\tEpoch: [152]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1124.1486494409314  loss: 0.2409 (0.2451)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:54:22\tINFO\ttorchdistill.misc.log\tEpoch: [152]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1110.8026433942043  loss: 0.2381 (0.2449)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:54:33\tINFO\ttorchdistill.misc.log\tEpoch: [152]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1111.6628677445003  loss: 0.2443 (0.2445)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:54:44\tINFO\ttorchdistill.misc.log\tEpoch: [152] Total time: 0:00:46\n",
            "2021/01/11 00:54:45\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6710  data: 0.6146  max mem: 700\n",
            "2021/01/11 00:54:47\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:54:47\tINFO\t__main__\t * Acc@1 92.2500\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 00:54:49\tINFO\ttorchdistill.misc.log\tEpoch: [153]  [  0/391]  eta: 0:10:51  lr: 0.0010000000000000002  img/s: 258.8386256944401  loss: 0.2442 (0.2442)  time: 1.6665  data: 1.1720  max mem: 700\n",
            "2021/01/11 00:55:00\tINFO\ttorchdistill.misc.log\tEpoch: [153]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1123.4311853270137  loss: 0.2368 (0.2453)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:55:12\tINFO\ttorchdistill.misc.log\tEpoch: [153]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1107.73831282046  loss: 0.2384 (0.2448)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:55:23\tINFO\ttorchdistill.misc.log\tEpoch: [153]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1119.9229674873066  loss: 0.2437 (0.2443)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:55:34\tINFO\ttorchdistill.misc.log\tEpoch: [153] Total time: 0:00:46\n",
            "2021/01/11 00:55:34\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6932  data: 0.6500  max mem: 700\n",
            "2021/01/11 00:55:37\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:55:37\tINFO\t__main__\t * Acc@1 92.1900\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 00:55:38\tINFO\ttorchdistill.misc.log\tEpoch: [154]  [  0/391]  eta: 0:09:06  lr: 0.0010000000000000002  img/s: 246.38023637997387  loss: 0.2533 (0.2533)  time: 1.3965  data: 0.8769  max mem: 700\n",
            "2021/01/11 00:55:50\tINFO\ttorchdistill.misc.log\tEpoch: [154]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1122.7428112543864  loss: 0.2459 (0.2437)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:56:01\tINFO\ttorchdistill.misc.log\tEpoch: [154]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1117.1637444180403  loss: 0.2492 (0.2443)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:56:13\tINFO\ttorchdistill.misc.log\tEpoch: [154]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1096.6463802989233  loss: 0.2391 (0.2436)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:56:23\tINFO\ttorchdistill.misc.log\tEpoch: [154] Total time: 0:00:46\n",
            "2021/01/11 00:56:24\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.6948  data: 0.6597  max mem: 700\n",
            "2021/01/11 00:56:26\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:56:26\tINFO\t__main__\t * Acc@1 92.0900\tAcc@5 99.2200\n",
            "\n",
            "2021/01/11 00:56:28\tINFO\ttorchdistill.misc.log\tEpoch: [155]  [  0/391]  eta: 0:10:13  lr: 0.0010000000000000002  img/s: 256.2282306360379  loss: 0.2331 (0.2331)  time: 1.5683  data: 1.0687  max mem: 700\n",
            "2021/01/11 00:56:39\tINFO\ttorchdistill.misc.log\tEpoch: [155]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1116.2044746236322  loss: 0.2383 (0.2431)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:56:51\tINFO\ttorchdistill.misc.log\tEpoch: [155]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1105.548452992597  loss: 0.2397 (0.2421)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:57:02\tINFO\ttorchdistill.misc.log\tEpoch: [155]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1113.1495441624386  loss: 0.2408 (0.2424)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:57:13\tINFO\ttorchdistill.misc.log\tEpoch: [155] Total time: 0:00:46\n",
            "2021/01/11 00:57:14\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:01  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7815  data: 0.7418  max mem: 700\n",
            "2021/01/11 00:57:16\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:57:16\tINFO\t__main__\t * Acc@1 92.0300\tAcc@5 99.1900\n",
            "\n",
            "2021/01/11 00:57:17\tINFO\ttorchdistill.misc.log\tEpoch: [156]  [  0/391]  eta: 0:08:05  lr: 0.0010000000000000002  img/s: 279.64823148981566  loss: 0.2332 (0.2332)  time: 1.2423  data: 0.7846  max mem: 700\n",
            "2021/01/11 00:57:29\tINFO\ttorchdistill.misc.log\tEpoch: [156]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1117.0196326472865  loss: 0.2415 (0.2421)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:57:41\tINFO\ttorchdistill.misc.log\tEpoch: [156]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1116.3367697880321  loss: 0.2390 (0.2426)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:57:52\tINFO\ttorchdistill.misc.log\tEpoch: [156]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1110.9589487842732  loss: 0.2406 (0.2430)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:58:03\tINFO\ttorchdistill.misc.log\tEpoch: [156] Total time: 0:00:46\n",
            "2021/01/11 00:58:04\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:01  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7773  data: 0.7397  max mem: 700\n",
            "2021/01/11 00:58:06\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:58:06\tINFO\t__main__\t * Acc@1 92.1100\tAcc@5 99.2500\n",
            "\n",
            "2021/01/11 00:58:07\tINFO\ttorchdistill.misc.log\tEpoch: [157]  [  0/391]  eta: 0:09:32  lr: 0.0010000000000000002  img/s: 236.42899853748696  loss: 0.2241 (0.2241)  time: 1.4648  data: 0.9233  max mem: 700\n",
            "2021/01/11 00:58:19\tINFO\ttorchdistill.misc.log\tEpoch: [157]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1113.4196465235118  loss: 0.2374 (0.2428)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:58:31\tINFO\ttorchdistill.misc.log\tEpoch: [157]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1124.5960577305766  loss: 0.2465 (0.2440)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:58:42\tINFO\ttorchdistill.misc.log\tEpoch: [157]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1111.4787505382756  loss: 0.2374 (0.2435)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:58:53\tINFO\ttorchdistill.misc.log\tEpoch: [157] Total time: 0:00:46\n",
            "2021/01/11 00:58:53\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6887  data: 0.6505  max mem: 700\n",
            "2021/01/11 00:58:56\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 00:58:56\tINFO\t__main__\t * Acc@1 92.1100\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 00:58:57\tINFO\ttorchdistill.misc.log\tEpoch: [158]  [  0/391]  eta: 0:08:25  lr: 0.0010000000000000002  img/s: 265.7266386456463  loss: 0.2514 (0.2514)  time: 1.2932  data: 0.8114  max mem: 700\n",
            "2021/01/11 00:59:09\tINFO\ttorchdistill.misc.log\tEpoch: [158]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1108.6716324520337  loss: 0.2457 (0.2472)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:59:20\tINFO\ttorchdistill.misc.log\tEpoch: [158]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1113.7037416581788  loss: 0.2359 (0.2444)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:59:32\tINFO\ttorchdistill.misc.log\tEpoch: [158]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1116.2694578033936  loss: 0.2357 (0.2446)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 00:59:42\tINFO\ttorchdistill.misc.log\tEpoch: [158] Total time: 0:00:46\n",
            "2021/01/11 00:59:43\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:13  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.9255  data: 0.8938  max mem: 700\n",
            "2021/01/11 00:59:45\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 00:59:45\tINFO\t__main__\t * Acc@1 92.0900\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 00:59:47\tINFO\ttorchdistill.misc.log\tEpoch: [159]  [  0/391]  eta: 0:08:58  lr: 0.0010000000000000002  img/s: 208.31671132778155  loss: 0.2353 (0.2353)  time: 1.3777  data: 0.7633  max mem: 700\n",
            "2021/01/11 00:59:59\tINFO\ttorchdistill.misc.log\tEpoch: [159]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1111.3890155114343  loss: 0.2397 (0.2427)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:00:10\tINFO\ttorchdistill.misc.log\tEpoch: [159]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1121.4458892363352  loss: 0.2408 (0.2435)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:00:21\tINFO\ttorchdistill.misc.log\tEpoch: [159]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1110.4419297792026  loss: 0.2398 (0.2436)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:00:32\tINFO\ttorchdistill.misc.log\tEpoch: [159] Total time: 0:00:46\n",
            "2021/01/11 01:00:33\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:58  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7451  data: 0.6818  max mem: 700\n",
            "2021/01/11 01:00:35\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:00:35\tINFO\t__main__\t * Acc@1 91.9800\tAcc@5 99.1900\n",
            "\n",
            "2021/01/11 01:00:37\tINFO\ttorchdistill.misc.log\tEpoch: [160]  [  0/391]  eta: 0:10:31  lr: 0.0010000000000000002  img/s: 227.98779865832805  loss: 0.2373 (0.2373)  time: 1.6148  data: 1.0533  max mem: 700\n",
            "2021/01/11 01:00:48\tINFO\ttorchdistill.misc.log\tEpoch: [160]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1121.640353662817  loss: 0.2393 (0.2425)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:01:00\tINFO\ttorchdistill.misc.log\tEpoch: [160]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1117.156770411741  loss: 0.2348 (0.2417)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:01:11\tINFO\ttorchdistill.misc.log\tEpoch: [160]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1118.9029863344304  loss: 0.2396 (0.2420)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:01:22\tINFO\ttorchdistill.misc.log\tEpoch: [160] Total time: 0:00:46\n",
            "2021/01/11 01:01:23\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6773  data: 0.6279  max mem: 700\n",
            "2021/01/11 01:01:25\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:01:25\tINFO\t__main__\t * Acc@1 92.1100\tAcc@5 99.2500\n",
            "\n",
            "2021/01/11 01:01:26\tINFO\ttorchdistill.misc.log\tEpoch: [161]  [  0/391]  eta: 0:09:24  lr: 0.0010000000000000002  img/s: 245.54276718686685  loss: 0.2351 (0.2351)  time: 1.4440  data: 0.9227  max mem: 700\n",
            "2021/01/11 01:01:38\tINFO\ttorchdistill.misc.log\tEpoch: [161]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1115.5457868151095  loss: 0.2395 (0.2419)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:01:50\tINFO\ttorchdistill.misc.log\tEpoch: [161]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1105.7260558927537  loss: 0.2385 (0.2417)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:02:01\tINFO\ttorchdistill.misc.log\tEpoch: [161]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1113.7152933073887  loss: 0.2361 (0.2425)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:02:12\tINFO\ttorchdistill.misc.log\tEpoch: [161] Total time: 0:00:46\n",
            "2021/01/11 01:02:12\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7285  data: 0.6913  max mem: 700\n",
            "2021/01/11 01:02:15\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:02:15\tINFO\t__main__\t * Acc@1 92.1000\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 01:02:16\tINFO\ttorchdistill.misc.log\tEpoch: [162]  [  0/391]  eta: 0:08:01  lr: 0.0010000000000000002  img/s: 246.46427497519844  loss: 0.2295 (0.2295)  time: 1.2315  data: 0.7121  max mem: 700\n",
            "2021/01/11 01:02:28\tINFO\ttorchdistill.misc.log\tEpoch: [162]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1111.5615957332273  loss: 0.2447 (0.2445)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:02:39\tINFO\ttorchdistill.misc.log\tEpoch: [162]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1115.8611177506148  loss: 0.2495 (0.2448)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:02:51\tINFO\ttorchdistill.misc.log\tEpoch: [162]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1111.8470459591106  loss: 0.2400 (0.2448)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:03:01\tINFO\ttorchdistill.misc.log\tEpoch: [162] Total time: 0:00:46\n",
            "2021/01/11 01:03:02\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:05  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.8266  data: 0.7765  max mem: 700\n",
            "2021/01/11 01:03:04\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:03:04\tINFO\t__main__\t * Acc@1 92.1000\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 01:03:06\tINFO\ttorchdistill.misc.log\tEpoch: [163]  [  0/391]  eta: 0:09:15  lr: 0.0010000000000000002  img/s: 260.2509538769992  loss: 0.2613 (0.2613)  time: 1.4213  data: 0.9295  max mem: 700\n",
            "2021/01/11 01:03:18\tINFO\ttorchdistill.misc.log\tEpoch: [163]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1115.4832055517463  loss: 0.2395 (0.2408)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:03:29\tINFO\ttorchdistill.misc.log\tEpoch: [163]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1124.379373463293  loss: 0.2410 (0.2423)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:03:40\tINFO\ttorchdistill.misc.log\tEpoch: [163]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1112.5428691028303  loss: 0.2367 (0.2424)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:03:51\tINFO\ttorchdistill.misc.log\tEpoch: [163] Total time: 0:00:46\n",
            "2021/01/11 01:03:52\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7068  data: 0.6657  max mem: 700\n",
            "2021/01/11 01:03:54\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:03:54\tINFO\t__main__\t * Acc@1 92.1300\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 01:03:56\tINFO\ttorchdistill.misc.log\tEpoch: [164]  [  0/391]  eta: 0:08:45  lr: 0.0010000000000000002  img/s: 247.7634374759157  loss: 0.2337 (0.2337)  time: 1.3450  data: 0.8283  max mem: 700\n",
            "2021/01/11 01:04:07\tINFO\ttorchdistill.misc.log\tEpoch: [164]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1115.4020921414844  loss: 0.2380 (0.2428)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:04:19\tINFO\ttorchdistill.misc.log\tEpoch: [164]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1120.8254599203333  loss: 0.2371 (0.2427)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:04:30\tINFO\ttorchdistill.misc.log\tEpoch: [164]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1110.1135855158411  loss: 0.2410 (0.2438)  time: 0.1154  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:04:41\tINFO\ttorchdistill.misc.log\tEpoch: [164] Total time: 0:00:46\n",
            "2021/01/11 01:04:41\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:52  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6649  data: 0.6157  max mem: 700\n",
            "2021/01/11 01:04:44\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:04:44\tINFO\t__main__\t * Acc@1 92.0700\tAcc@5 99.2900\n",
            "\n",
            "2021/01/11 01:04:45\tINFO\ttorchdistill.misc.log\tEpoch: [165]  [  0/391]  eta: 0:07:47  lr: 0.0010000000000000002  img/s: 253.71191905730683  loss: 0.2521 (0.2521)  time: 1.1958  data: 0.6913  max mem: 700\n",
            "2021/01/11 01:04:57\tINFO\ttorchdistill.misc.log\tEpoch: [165]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1119.9416572446567  loss: 0.2363 (0.2413)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:05:09\tINFO\ttorchdistill.misc.log\tEpoch: [165]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1118.4857270238626  loss: 0.2441 (0.2408)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:05:20\tINFO\ttorchdistill.misc.log\tEpoch: [165]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1121.1227120569508  loss: 0.2394 (0.2416)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:05:31\tINFO\ttorchdistill.misc.log\tEpoch: [165] Total time: 0:00:46\n",
            "2021/01/11 01:05:31\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:57  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7314  data: 0.6642  max mem: 700\n",
            "2021/01/11 01:05:34\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:05:34\tINFO\t__main__\t * Acc@1 92.0800\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 01:05:35\tINFO\ttorchdistill.misc.log\tEpoch: [166]  [  0/391]  eta: 0:09:02  lr: 0.0010000000000000002  img/s: 259.71450271338716  loss: 0.2394 (0.2394)  time: 1.3870  data: 0.8942  max mem: 700\n",
            "2021/01/11 01:05:47\tINFO\ttorchdistill.misc.log\tEpoch: [166]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1120.8769411283286  loss: 0.2420 (0.2422)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:05:58\tINFO\ttorchdistill.misc.log\tEpoch: [166]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1116.7245520067395  loss: 0.2404 (0.2423)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:06:10\tINFO\ttorchdistill.misc.log\tEpoch: [166]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1124.5324569506322  loss: 0.2388 (0.2428)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:06:20\tINFO\ttorchdistill.misc.log\tEpoch: [166] Total time: 0:00:46\n",
            "2021/01/11 01:06:21\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7075  data: 0.6676  max mem: 700\n",
            "2021/01/11 01:06:23\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:06:23\tINFO\t__main__\t * Acc@1 92.0900\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 01:06:25\tINFO\ttorchdistill.misc.log\tEpoch: [167]  [  0/391]  eta: 0:09:00  lr: 0.0010000000000000002  img/s: 243.27906286492137  loss: 0.2412 (0.2412)  time: 1.3826  data: 0.8565  max mem: 700\n",
            "2021/01/11 01:06:36\tINFO\ttorchdistill.misc.log\tEpoch: [167]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1109.294719768583  loss: 0.2347 (0.2416)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:06:48\tINFO\ttorchdistill.misc.log\tEpoch: [167]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1115.3209905268407  loss: 0.2412 (0.2424)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:06:59\tINFO\ttorchdistill.misc.log\tEpoch: [167]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1115.9446175463686  loss: 0.2334 (0.2423)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:07:10\tINFO\ttorchdistill.misc.log\tEpoch: [167] Total time: 0:00:46\n",
            "2021/01/11 01:07:11\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:04  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.8177  data: 0.7596  max mem: 700\n",
            "2021/01/11 01:07:13\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:07:13\tINFO\t__main__\t * Acc@1 92.1600\tAcc@5 99.2200\n",
            "\n",
            "2021/01/11 01:07:14\tINFO\ttorchdistill.misc.log\tEpoch: [168]  [  0/391]  eta: 0:07:53  lr: 0.0010000000000000002  img/s: 281.6122331974241  loss: 0.2375 (0.2375)  time: 1.2121  data: 0.7575  max mem: 700\n",
            "2021/01/11 01:07:26\tINFO\ttorchdistill.misc.log\tEpoch: [168]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1119.1968863418895  loss: 0.2420 (0.2422)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:07:38\tINFO\ttorchdistill.misc.log\tEpoch: [168]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1115.1750373372274  loss: 0.2371 (0.2420)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:07:49\tINFO\ttorchdistill.misc.log\tEpoch: [168]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1114.7721269027838  loss: 0.2354 (0.2419)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:08:00\tINFO\ttorchdistill.misc.log\tEpoch: [168] Total time: 0:00:46\n",
            "2021/01/11 01:08:00\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:55  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7022  data: 0.6632  max mem: 700\n",
            "2021/01/11 01:08:03\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:08:03\tINFO\t__main__\t * Acc@1 91.9900\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 01:08:04\tINFO\ttorchdistill.misc.log\tEpoch: [169]  [  0/391]  eta: 0:10:26  lr: 0.0010000000000000002  img/s: 247.2667060300605  loss: 0.2225 (0.2225)  time: 1.6030  data: 1.0853  max mem: 700\n",
            "2021/01/11 01:08:16\tINFO\ttorchdistill.misc.log\tEpoch: [169]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1102.3228508775533  loss: 0.2339 (0.2402)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:08:27\tINFO\ttorchdistill.misc.log\tEpoch: [169]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1111.4833527251346  loss: 0.2383 (0.2416)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:08:39\tINFO\ttorchdistill.misc.log\tEpoch: [169]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1115.2978208031245  loss: 0.2364 (0.2413)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:08:49\tINFO\ttorchdistill.misc.log\tEpoch: [169] Total time: 0:00:46\n",
            "2021/01/11 01:08:50\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:11  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.8993  data: 0.8561  max mem: 700\n",
            "2021/01/11 01:08:52\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:08:52\tINFO\t__main__\t * Acc@1 92.1300\tAcc@5 99.2000\n",
            "\n",
            "2021/01/11 01:08:54\tINFO\ttorchdistill.misc.log\tEpoch: [170]  [  0/391]  eta: 0:09:09  lr: 0.0010000000000000002  img/s: 253.9214338044543  loss: 0.2388 (0.2388)  time: 1.4064  data: 0.9023  max mem: 700\n",
            "2021/01/11 01:09:06\tINFO\ttorchdistill.misc.log\tEpoch: [170]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1121.064185393845  loss: 0.2354 (0.2429)  time: 0.1145  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:09:17\tINFO\ttorchdistill.misc.log\tEpoch: [170]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1119.3999074240105  loss: 0.2340 (0.2434)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:09:29\tINFO\ttorchdistill.misc.log\tEpoch: [170]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1120.5166719540498  loss: 0.2443 (0.2432)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:09:39\tINFO\ttorchdistill.misc.log\tEpoch: [170] Total time: 0:00:46\n",
            "2021/01/11 01:09:40\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6920  data: 0.6383  max mem: 700\n",
            "2021/01/11 01:09:42\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:09:42\tINFO\t__main__\t * Acc@1 92.0200\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 01:09:44\tINFO\ttorchdistill.misc.log\tEpoch: [171]  [  0/391]  eta: 0:10:13  lr: 0.0010000000000000002  img/s: 250.85679174674286  loss: 0.2247 (0.2247)  time: 1.5685  data: 1.0582  max mem: 700\n",
            "2021/01/11 01:09:55\tINFO\ttorchdistill.misc.log\tEpoch: [171]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1107.0302227995835  loss: 0.2370 (0.2419)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:10:07\tINFO\ttorchdistill.misc.log\tEpoch: [171]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1118.3552517008504  loss: 0.2363 (0.2426)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:10:18\tINFO\ttorchdistill.misc.log\tEpoch: [171]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1114.0781370292823  loss: 0.2356 (0.2425)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:10:29\tINFO\ttorchdistill.misc.log\tEpoch: [171] Total time: 0:00:46\n",
            "2021/01/11 01:10:30\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:53  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6792  data: 0.6295  max mem: 700\n",
            "2021/01/11 01:10:32\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:10:32\tINFO\t__main__\t * Acc@1 92.0300\tAcc@5 99.2100\n",
            "\n",
            "2021/01/11 01:10:33\tINFO\ttorchdistill.misc.log\tEpoch: [172]  [  0/391]  eta: 0:07:50  lr: 0.0010000000000000002  img/s: 282.0368227978371  loss: 0.2523 (0.2523)  time: 1.2026  data: 0.7487  max mem: 700\n",
            "2021/01/11 01:10:45\tINFO\ttorchdistill.misc.log\tEpoch: [172]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1115.8124153067247  loss: 0.2406 (0.2404)  time: 0.1145  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:10:56\tINFO\ttorchdistill.misc.log\tEpoch: [172]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1118.9846097410502  loss: 0.2346 (0.2410)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:11:08\tINFO\ttorchdistill.misc.log\tEpoch: [172]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1116.5573314310552  loss: 0.2375 (0.2414)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:11:19\tINFO\ttorchdistill.misc.log\tEpoch: [172] Total time: 0:00:46\n",
            "2021/01/11 01:11:19\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6907  data: 0.6314  max mem: 700\n",
            "2021/01/11 01:11:21\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:11:21\tINFO\t__main__\t * Acc@1 92.0400\tAcc@5 99.2100\n",
            "\n",
            "2021/01/11 01:11:23\tINFO\ttorchdistill.misc.log\tEpoch: [173]  [  0/391]  eta: 0:08:31  lr: 0.0010000000000000002  img/s: 265.07522984882144  loss: 0.2317 (0.2317)  time: 1.3089  data: 0.8260  max mem: 700\n",
            "2021/01/11 01:11:35\tINFO\ttorchdistill.misc.log\tEpoch: [173]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1118.187542436777  loss: 0.2453 (0.2406)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:11:46\tINFO\ttorchdistill.misc.log\tEpoch: [173]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1109.916213221309  loss: 0.2342 (0.2403)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:11:58\tINFO\ttorchdistill.misc.log\tEpoch: [173]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1118.432135260749  loss: 0.2373 (0.2410)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:12:08\tINFO\ttorchdistill.misc.log\tEpoch: [173] Total time: 0:00:46\n",
            "2021/01/11 01:12:09\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:52  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.6678  data: 0.6256  max mem: 700\n",
            "2021/01/11 01:12:11\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:12:11\tINFO\t__main__\t * Acc@1 92.0700\tAcc@5 99.2500\n",
            "\n",
            "2021/01/11 01:12:13\tINFO\ttorchdistill.misc.log\tEpoch: [174]  [  0/391]  eta: 0:09:42  lr: 0.0010000000000000002  img/s: 230.67261833407449  loss: 0.2458 (0.2458)  time: 1.4890  data: 0.9341  max mem: 700\n",
            "2021/01/11 01:12:25\tINFO\ttorchdistill.misc.log\tEpoch: [174]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1110.4327426837567  loss: 0.2347 (0.2424)  time: 0.1156  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:12:36\tINFO\ttorchdistill.misc.log\tEpoch: [174]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1123.9109614994106  loss: 0.2386 (0.2419)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:12:47\tINFO\ttorchdistill.misc.log\tEpoch: [174]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1116.8918226773153  loss: 0.2401 (0.2424)  time: 0.1151  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:12:58\tINFO\ttorchdistill.misc.log\tEpoch: [174] Total time: 0:00:46\n",
            "2021/01/11 01:12:59\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:01  acc1: 94.5312 (94.5312)  acc5: 99.2188 (99.2188)  time: 0.7779  data: 0.7617  max mem: 700\n",
            "2021/01/11 01:13:01\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:13:01\tINFO\t__main__\t * Acc@1 92.1000\tAcc@5 99.2800\n",
            "\n",
            "2021/01/11 01:13:02\tINFO\ttorchdistill.misc.log\tEpoch: [175]  [  0/391]  eta: 0:07:48  lr: 0.0010000000000000002  img/s: 237.07703897741794  loss: 0.2697 (0.2697)  time: 1.1982  data: 0.6582  max mem: 700\n",
            "2021/01/11 01:13:14\tINFO\ttorchdistill.misc.log\tEpoch: [175]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1110.9635466675495  loss: 0.2442 (0.2444)  time: 0.1155  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:13:26\tINFO\ttorchdistill.misc.log\tEpoch: [175]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1105.9287750696265  loss: 0.2317 (0.2428)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:13:37\tINFO\ttorchdistill.misc.log\tEpoch: [175]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1122.1913116909448  loss: 0.2350 (0.2426)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:13:48\tINFO\ttorchdistill.misc.log\tEpoch: [175] Total time: 0:00:46\n",
            "2021/01/11 01:13:49\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:02  acc1: 95.3125 (95.3125)  acc5: 99.2188 (99.2188)  time: 0.7919  data: 0.7530  max mem: 700\n",
            "2021/01/11 01:13:51\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:13:51\tINFO\t__main__\t * Acc@1 92.2000\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 01:13:52\tINFO\ttorchdistill.misc.log\tEpoch: [176]  [  0/391]  eta: 0:10:05  lr: 0.0010000000000000002  img/s: 217.72086421495393  loss: 0.2304 (0.2304)  time: 1.5497  data: 0.9617  max mem: 700\n",
            "2021/01/11 01:14:04\tINFO\ttorchdistill.misc.log\tEpoch: [176]  [100/391]  eta: 0:00:38  lr: 0.0010000000000000002  img/s: 1122.832040824863  loss: 0.2406 (0.2421)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:14:16\tINFO\ttorchdistill.misc.log\tEpoch: [176]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1110.8945824142627  loss: 0.2405 (0.2413)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:14:27\tINFO\ttorchdistill.misc.log\tEpoch: [176]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1117.1614197395993  loss: 0.2318 (0.2409)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:14:38\tINFO\ttorchdistill.misc.log\tEpoch: [176] Total time: 0:00:46\n",
            "2021/01/11 01:14:38\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:01  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.7738  data: 0.7297  max mem: 700\n",
            "2021/01/11 01:14:41\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:14:41\tINFO\t__main__\t * Acc@1 92.0500\tAcc@5 99.2500\n",
            "\n",
            "2021/01/11 01:14:42\tINFO\ttorchdistill.misc.log\tEpoch: [177]  [  0/391]  eta: 0:09:13  lr: 0.0010000000000000002  img/s: 256.10062547463946  loss: 0.2482 (0.2482)  time: 1.4144  data: 0.9145  max mem: 700\n",
            "2021/01/11 01:14:54\tINFO\ttorchdistill.misc.log\tEpoch: [177]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1116.7199063144167  loss: 0.2385 (0.2399)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:15:05\tINFO\ttorchdistill.misc.log\tEpoch: [177]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1116.4690963160137  loss: 0.2402 (0.2416)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:15:17\tINFO\ttorchdistill.misc.log\tEpoch: [177]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1114.1405607321476  loss: 0.2383 (0.2412)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:15:27\tINFO\ttorchdistill.misc.log\tEpoch: [177] Total time: 0:00:46\n",
            "2021/01/11 01:15:28\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:05  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.8302  data: 0.7910  max mem: 700\n",
            "2021/01/11 01:15:30\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:15:30\tINFO\t__main__\t * Acc@1 92.1400\tAcc@5 99.2200\n",
            "\n",
            "2021/01/11 01:15:32\tINFO\ttorchdistill.misc.log\tEpoch: [178]  [  0/391]  eta: 0:08:47  lr: 0.0010000000000000002  img/s: 266.10543679541934  loss: 0.2530 (0.2530)  time: 1.3492  data: 0.8682  max mem: 700\n",
            "2021/01/11 01:15:43\tINFO\ttorchdistill.misc.log\tEpoch: [178]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1123.7086529626365  loss: 0.2395 (0.2414)  time: 0.1144  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:15:55\tINFO\ttorchdistill.misc.log\tEpoch: [178]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1117.4799908415378  loss: 0.2338 (0.2406)  time: 0.1146  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:16:06\tINFO\ttorchdistill.misc.log\tEpoch: [178]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1107.9234791796505  loss: 0.2390 (0.2409)  time: 0.1153  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:16:17\tINFO\ttorchdistill.misc.log\tEpoch: [178] Total time: 0:00:46\n",
            "2021/01/11 01:16:18\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:56  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.7214  data: 0.6687  max mem: 700\n",
            "2021/01/11 01:16:20\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:16:20\tINFO\t__main__\t * Acc@1 92.1500\tAcc@5 99.2400\n",
            "\n",
            "2021/01/11 01:16:21\tINFO\ttorchdistill.misc.log\tEpoch: [179]  [  0/391]  eta: 0:08:22  lr: 0.0010000000000000002  img/s: 273.9444794823909  loss: 0.2475 (0.2475)  time: 1.2841  data: 0.8169  max mem: 700\n",
            "2021/01/11 01:16:33\tINFO\ttorchdistill.misc.log\tEpoch: [179]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1115.977093064104  loss: 0.2439 (0.2442)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:16:45\tINFO\ttorchdistill.misc.log\tEpoch: [179]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1118.74676902431  loss: 0.2375 (0.2429)  time: 0.1150  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:16:56\tINFO\ttorchdistill.misc.log\tEpoch: [179]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1116.4853491051413  loss: 0.2373 (0.2424)  time: 0.1147  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:17:07\tINFO\ttorchdistill.misc.log\tEpoch: [179] Total time: 0:00:46\n",
            "2021/01/11 01:17:07\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:54  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  time: 0.6886  data: 0.6447  max mem: 700\n",
            "2021/01/11 01:17:10\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:03\n",
            "2021/01/11 01:17:10\tINFO\t__main__\t * Acc@1 92.2300\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 01:17:11\tINFO\ttorchdistill.misc.log\tEpoch: [180]  [  0/391]  eta: 0:09:03  lr: 0.0010000000000000002  img/s: 257.3561452681342  loss: 0.2381 (0.2381)  time: 1.3899  data: 0.8925  max mem: 700\n",
            "2021/01/11 01:17:23\tINFO\ttorchdistill.misc.log\tEpoch: [180]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1122.097493379705  loss: 0.2397 (0.2430)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:17:34\tINFO\ttorchdistill.misc.log\tEpoch: [180]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1113.5304956713278  loss: 0.2389 (0.2419)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:17:46\tINFO\ttorchdistill.misc.log\tEpoch: [180]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1112.6327905612789  loss: 0.2376 (0.2417)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:17:56\tINFO\ttorchdistill.misc.log\tEpoch: [180] Total time: 0:00:46\n",
            "2021/01/11 01:17:57\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:00:52  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.6611  data: 0.6132  max mem: 700\n",
            "2021/01/11 01:17:59\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:17:59\tINFO\t__main__\t * Acc@1 92.0600\tAcc@5 99.2200\n",
            "\n",
            "2021/01/11 01:18:01\tINFO\ttorchdistill.misc.log\tEpoch: [181]  [  0/391]  eta: 0:07:27  lr: 0.0010000000000000002  img/s: 289.2687349235624  loss: 0.2351 (0.2351)  time: 1.1442  data: 0.7017  max mem: 700\n",
            "2021/01/11 01:18:13\tINFO\ttorchdistill.misc.log\tEpoch: [181]  [100/391]  eta: 0:00:37  lr: 0.0010000000000000002  img/s: 1119.5072816748686  loss: 0.2422 (0.2405)  time: 0.1149  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:18:24\tINFO\ttorchdistill.misc.log\tEpoch: [181]  [200/391]  eta: 0:00:23  lr: 0.0010000000000000002  img/s: 1116.371589517308  loss: 0.2407 (0.2417)  time: 0.1148  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:18:36\tINFO\ttorchdistill.misc.log\tEpoch: [181]  [300/391]  eta: 0:00:10  lr: 0.0010000000000000002  img/s: 1103.1518523845727  loss: 0.2354 (0.2417)  time: 0.1152  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:18:46\tINFO\ttorchdistill.misc.log\tEpoch: [181] Total time: 0:00:46\n",
            "2021/01/11 01:18:47\tINFO\ttorchdistill.misc.log\tValidation:  [ 0/79]  eta: 0:01:01  acc1: 94.5312 (94.5312)  acc5: 100.0000 (100.0000)  time: 0.7812  data: 0.7376  max mem: 700\n",
            "2021/01/11 01:18:49\tINFO\ttorchdistill.misc.log\tValidation: Total time: 0:00:02\n",
            "2021/01/11 01:18:49\tINFO\t__main__\t * Acc@1 92.0900\tAcc@5 99.2600\n",
            "\n",
            "2021/01/11 01:18:49\tINFO\t__main__\tTraining time 2:31:07\n",
            "2021/01/11 01:18:49\tINFO\ttorchdistill.common.main_util\tLoading model parameters\n",
            "2021/01/11 01:18:49\tINFO\t__main__\t[Teacher: densenet_bc_k12_depth100]\n",
            "2021/01/11 01:18:50\tINFO\ttorchdistill.misc.log\tTest:  [    0/10000]  eta: 1:57:05  acc1: 0.0000 (0.0000)  acc5: 100.0000 (100.0000)  time: 0.7026  data: 0.5228  max mem: 700\n",
            "2021/01/11 01:19:08\tINFO\ttorchdistill.misc.log\tTest:  [ 1000/10000]  eta: 0:02:48  acc1: 0.0000 (8.8911)  acc5: 100.0000 (50.2498)  time: 0.0175  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:19:26\tINFO\ttorchdistill.misc.log\tTest:  [ 2000/10000]  eta: 0:02:26  acc1: 0.0000 (9.9450)  acc5: 100.0000 (51.7241)  time: 0.0180  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:19:44\tINFO\ttorchdistill.misc.log\tTest:  [ 3000/10000]  eta: 0:02:07  acc1: 0.0000 (9.5635)  acc5: 100.0000 (50.7831)  time: 0.0175  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:20:02\tINFO\ttorchdistill.misc.log\tTest:  [ 4000/10000]  eta: 0:01:49  acc1: 0.0000 (9.7976)  acc5: 0.0000 (50.4624)  time: 0.0173  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:20:20\tINFO\ttorchdistill.misc.log\tTest:  [ 5000/10000]  eta: 0:01:31  acc1: 0.0000 (10.0980)  acc5: 0.0000 (51.1298)  time: 0.0179  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:20:39\tINFO\ttorchdistill.misc.log\tTest:  [ 6000/10000]  eta: 0:01:13  acc1: 0.0000 (9.8817)  acc5: 100.0000 (50.8082)  time: 0.0192  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:20:57\tINFO\ttorchdistill.misc.log\tTest:  [ 7000/10000]  eta: 0:00:54  acc1: 0.0000 (9.8415)  acc5: 100.0000 (51.2070)  time: 0.0178  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:21:15\tINFO\ttorchdistill.misc.log\tTest:  [ 8000/10000]  eta: 0:00:36  acc1: 0.0000 (9.9613)  acc5: 0.0000 (51.1061)  time: 0.0175  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:21:34\tINFO\ttorchdistill.misc.log\tTest:  [ 9000/10000]  eta: 0:00:18  acc1: 0.0000 (10.0433)  acc5: 0.0000 (51.2276)  time: 0.0174  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:21:52\tINFO\ttorchdistill.misc.log\tTest: Total time: 0:03:03\n",
            "2021/01/11 01:21:52\tINFO\t__main__\t * Acc@1 10.0000\tAcc@5 50.9400\n",
            "\n",
            "2021/01/11 01:21:52\tINFO\t__main__\t[Student: resnet20]\n",
            "2021/01/11 01:21:53\tINFO\ttorchdistill.misc.log\tTest:  [    0/10000]  eta: 1:33:58  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.5638  data: 0.5255  max mem: 700\n",
            "2021/01/11 01:21:58\tINFO\ttorchdistill.misc.log\tTest:  [ 1000/10000]  eta: 0:00:53  acc1: 100.0000 (93.1069)  acc5: 100.0000 (99.4006)  time: 0.0054  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:04\tINFO\ttorchdistill.misc.log\tTest:  [ 2000/10000]  eta: 0:00:45  acc1: 100.0000 (92.7036)  acc5: 100.0000 (99.4003)  time: 0.0054  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:09\tINFO\ttorchdistill.misc.log\tTest:  [ 3000/10000]  eta: 0:00:39  acc1: 100.0000 (92.5025)  acc5: 100.0000 (99.1669)  time: 0.0053  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:15\tINFO\ttorchdistill.misc.log\tTest:  [ 4000/10000]  eta: 0:00:33  acc1: 100.0000 (92.3019)  acc5: 100.0000 (99.1502)  time: 0.0070  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:20\tINFO\ttorchdistill.misc.log\tTest:  [ 5000/10000]  eta: 0:00:27  acc1: 100.0000 (92.2216)  acc5: 100.0000 (99.1202)  time: 0.0053  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:26\tINFO\ttorchdistill.misc.log\tTest:  [ 6000/10000]  eta: 0:00:22  acc1: 100.0000 (92.2346)  acc5: 100.0000 (99.1835)  time: 0.0056  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:31\tINFO\ttorchdistill.misc.log\tTest:  [ 7000/10000]  eta: 0:00:16  acc1: 100.0000 (92.2440)  acc5: 100.0000 (99.2572)  time: 0.0054  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:37\tINFO\ttorchdistill.misc.log\tTest:  [ 8000/10000]  eta: 0:00:11  acc1: 100.0000 (92.2135)  acc5: 100.0000 (99.2751)  time: 0.0053  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:42\tINFO\ttorchdistill.misc.log\tTest:  [ 9000/10000]  eta: 0:00:05  acc1: 100.0000 (92.2564)  acc5: 100.0000 (99.3112)  time: 0.0054  data: 0.0001  max mem: 700\n",
            "2021/01/11 01:22:48\tINFO\ttorchdistill.misc.log\tTest: Total time: 0:00:55\n",
            "2021/01/11 01:22:48\tINFO\t__main__\t * Acc@1 92.2900\tAcc@5 99.3200\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H04cv_LK833s"
      },
      "source": [
        "## 5. More sample configurations, models, datasets...\n",
        "For CIFAR-10/100 datasets, you can find more [sample configurations](https://github.com/yoshitomo-matsubara/torchdistill/tree/master/configs/sample/) and [models](https://github.com/yoshitomo-matsubara/torchdistill/tree/master/torchdistill/models/classification) in the [***torchdistill***](https://github.com/yoshitomo-matsubara/torchdistill) repository.  \n",
        "If you would like to use larger datasets e.g., **ImageNet** and **COCO** datasets and models in `torchvision` (or your own modules), refer to the [official configurations](https://github.com/yoshitomo-matsubara/torchdistill/tree/master/configs/official) used in some published papers.  \n",
        "Experiments with such large datasets and models will require you to use your own machine due to limited disk space and session time (12 hours for free version and 24 hours for Colab Pro) on Google Colab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuzcVbp99EDb"
      },
      "source": [
        "# Colab examples for training student models without teacher models\n",
        "You can find Colab examples for training models without teachers in the [***torchdistill***](https://github.com/yoshitomo-matsubara/torchdistill) repository."
      ]
    }
  ]
}